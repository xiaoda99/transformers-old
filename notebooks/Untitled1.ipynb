{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/raid/xd/.cache/torch'\n",
    "from types import MethodType\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.sampler import RandomSampler, Sampler, SequentialSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from transformers.data.data_collator import DataCollator, default_data_collator\n",
    "from transformers import AutoConfig, pipeline\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import HfArgumentParser, Trainer, TrainingArguments, set_seed\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cached_path: url_or_filename = https://huggingface.co/roberta-large/resolve/main/config.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/roberta-large-config.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/roberta-large-pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-large and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForMaskedLM.from_pretrained('roberta-large', cache_dir=cache_dir)\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', cache_dir=cache_dir)\n",
    "\n",
    "models['roberta-large'] = (model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cached_path: url_or_filename = https://huggingface.co/t5-11b/resolve/main/spiece.model\n",
      "In cached_path: output_path = /raid/xd/.cache/torch/transformers/0172c8f05db06fdc1d9f5be691fa907b7da289cf4b777506b956dc76d9bf1ceb.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-11b')\n",
    "tokenizer.decode_strip_special_tokens = MethodType(decode_strip_special_tokens, tokenizer)\n",
    "tokenizer.decode_old = MethodType(decode_old, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cached_path: url_or_filename = https://huggingface.co/t5-11b/resolve/main/config.json\n",
      "In cached_path: output_path = /raid/xd/.cache/torch/transformers/81569faf106ccedd12b4204414bfaf719ce664c51e4192954c3e2a45c2b6183d.f3d4f63c19654eaafefa7926880e38ff43a93df01b4df7b7b60c00bb1b10e9a6\n",
      "In cached_path: url_or_filename = https://huggingface.co/t5-11b/resolve/main/pytorch_model.bin\n",
      "In cached_path: output_path = /raid/xd/.cache/torch/transformers/3ec200f21984c6b177d08534a7166201616fe542ddd5c6e61927f7908bf9f75f.200226855d13a9f5ec82e28b352f6f771748fba71f240e65cd3dfe99889b4ccc\n"
     ]
    }
   ],
   "source": [
    "model_name = 't5-11b'\n",
    "proxies = {'http': '192.168.50.1:1081'}\n",
    "model = model11b = T5ForConditionalGeneration.from_pretrained(model_name, proxies=proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['t5-11b'] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_map = {0: list(range(0, 6)), 1: list(range(6, 15)), 2: list(range(15, 24))}\n",
    "model.parallelize(device_map)\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['roberta-large'] = models['roberta-large'] + (torch.device('cpu'),)\n",
    "models['t5-11b'] = models['t5-11b'] + (torch.device('cuda:0'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, tokenizer, device = models['t5-11b']\n",
    "model, tokenizer, device = models['roberta-large']\n",
    "\n",
    "masked_lm = tokenizer.mask_token is not None and len(tokenizer.additional_special_tokens) == 0\n",
    "mask_token = tokenizer.mask_token if masked_lm else tokenizer.additional_special_tokens[0] # '<mask>' for roberta and '<sxtra_id_0>' for t5\n",
    "if masked_lm: nlp = pipeline('fill-mask', model=model, tokenizer=tokenizer, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'Big is to small as fast is to _',\n",
    "    'Bread is to eat as gun is to _',\n",
    "    'big: small, fast: _',\n",
    "    'bread: eat, gun: _ .',\n",
    "    'flower: fragrant, fire: hot, bread: delicious, gun: _ ',\n",
    "    'Big and small are _ .',\n",
    "]\n",
    "text = texts[-1]\n",
    "_text = text.replace('_', mask_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bread: eat, gun: <extra_id_0>. <pad> <extra_id_0> shoot<extra_id_1>.<extra_id_2> shoot<extra_id_3>.<extra_id_4> kill<extra_id_5> kill<extra_id_6>..\n",
      "['▁bread', ':', '▁', 'eat', ',', '▁gun', ':', '<extra_id_0>', '▁', '.', '</s>']\n",
      "['<pad>', '<extra_id_0>', '▁shoot', '<extra_id_1>', '▁', '.', '<extra_id_2>', '▁shoot', '<extra_id_3>', '▁', '.', '<extra_id_4>', '▁kill', '<extra_id_5>', '▁kill', '<extra_id_6>', '▁', '.', '▁', '.']\n"
     ]
    }
   ],
   "source": [
    "if masked_lm:\n",
    "    print(_text, ['%s %.3f' % (i['token_str'], i['score']) for i in nlp(_text)])\n",
    "else:\n",
    "    inputs = tokenizer.encode_plus(_text, return_tensors='pt')\n",
    "    inputs = prepare_inputs(inputs, model.device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    print(_text, tokenizer.decode(outputs[0]))\n",
    "    print(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]))\n",
    "    print(tokenizer.convert_ids_to_tokens(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Big', '▁and', '▁small', '▁are', '<extra_id_0>', '▁', '.', '</s>']\n",
      "Big and small are <extra_id_0> . <pad> <extra_id_0> welcome<extra_id_1>.</s>\n",
      "['▁Big', '▁and', '▁small', '▁are', '<extra_id_0>', '.', '</s>']\n",
      "Big and small are <extra_id_0> . <pad> <extra_id_0> welcome<extra_id_1> welcome.</s>\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode_plus(_text)['input_ids']\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids))\n",
    "outputs = model.generate(torch.LongTensor([input_ids]).to(model.device))\n",
    "print(_text, tokenizer.decode(outputs[0]))\n",
    "\n",
    "input_ids = input_ids[: -3] + input_ids[-2:]\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids))\n",
    "outputs = model.generate(torch.LongTensor([input_ids]).to(model.device))\n",
    "print(_text, tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.embeddings.word_embeddings.weight torch.Size([50265, 1024])\n",
      "roberta.embeddings.position_embeddings.weight torch.Size([514, 1024])\n",
      "roberta.embeddings.token_type_embeddings.weight torch.Size([1, 1024])\n",
      "roberta.embeddings.LayerNorm.weight torch.Size([1024])\n",
      "roberta.embeddings.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.0.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.0.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.0.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.0.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.0.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.0.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.0.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.1.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.1.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.1.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.1.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.1.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.1.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.1.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.2.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.2.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.2.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.2.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.2.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.2.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.2.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.3.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.3.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.3.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.3.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.3.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.3.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.3.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.4.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.4.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.4.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.4.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.4.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.4.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.4.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.5.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.5.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.5.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.5.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.5.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.5.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.5.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.6.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.6.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.6.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.6.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.6.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.6.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.6.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.6.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.6.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.7.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.7.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.7.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.7.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.7.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.7.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.7.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.7.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.7.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.8.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.8.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.8.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.8.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.8.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.8.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.8.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.8.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.8.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.9.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.9.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.9.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.9.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.9.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.9.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.9.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.9.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.9.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.10.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.10.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.10.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.10.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.10.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.10.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.10.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.10.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.10.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.11.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.11.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.11.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.11.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.11.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.11.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.11.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.11.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.11.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.12.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.12.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.12.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.12.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.12.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.12.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.12.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.12.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.12.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.12.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.13.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.13.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.13.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.13.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.13.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.13.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.13.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.13.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.13.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.13.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.14.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.14.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.14.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.14.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.14.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.14.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.14.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.14.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.14.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.14.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.15.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.15.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.15.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.15.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.15.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.15.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.15.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.15.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.15.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.15.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.16.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.16.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.16.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.16.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.16.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.16.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.16.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.16.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.16.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.16.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.17.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.17.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.17.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.17.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.17.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.17.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.17.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.17.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.17.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.17.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.18.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.18.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.18.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.18.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.18.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.18.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.18.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.18.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.18.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.18.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.19.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.19.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.19.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.19.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.19.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.19.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.19.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.19.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.19.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.19.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.20.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.20.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.20.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.20.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.20.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.20.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.20.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.20.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.20.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.20.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.21.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.21.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.21.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.21.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.21.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.21.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.21.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.21.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.21.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.21.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.22.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.22.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.22.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.22.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.22.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.22.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.22.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.22.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.22.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.22.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.self.query.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.23.attention.self.query.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.self.key.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.23.attention.self.key.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.self.value.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.23.attention.self.value.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "roberta.encoder.layer.23.attention.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.23.attention.output.LayerNorm.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.intermediate.dense.weight torch.Size([4096, 1024])\n",
      "roberta.encoder.layer.23.intermediate.dense.bias torch.Size([4096])\n",
      "roberta.encoder.layer.23.output.dense.weight torch.Size([1024, 4096])\n",
      "roberta.encoder.layer.23.output.dense.bias torch.Size([1024])\n",
      "roberta.encoder.layer.23.output.LayerNorm.weight torch.Size([1024])\n",
      "roberta.encoder.layer.23.output.LayerNorm.bias torch.Size([1024])\n",
      "lm_head.bias torch.Size([50265])\n",
      "lm_head.dense.weight torch.Size([1024, 1024])\n",
      "lm_head.dense.bias torch.Size([1024])\n",
      "lm_head.layer_norm.weight torch.Size([1024])\n",
      "lm_head.layer_norm.bias torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(name, p.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
