{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "import random\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from itertools import product, chain\n",
    "import numpy as np\n",
    "from pattern.en import comparative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from enum import Enum\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "from child_frames import frames\n",
    "from utils import *\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/nas/xd/projects/transformers/src/transformers')\n",
    "\n",
    "import dataclasses\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, EvalPrediction, GlueDataset\n",
    "from transformers import GlueDataTrainingArguments as DataTrainingArguments\n",
    "from transformers import HfArgumentParser, Trainer, TrainingArguments, set_seed\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizer\n",
    "from transformers.modeling_roberta import RobertaDoubleHeadsModel  # XD\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġshortest']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(' shortest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' _X is bigger than _Z , so _Z ( latter ) is smaller ( opposite ) ? [ Right ] .',\n",
       " ' _X is bigger than _Z , so _X ( former ) is bigger ( same ) ? [ Right ] .',\n",
       " ' _X is bigger than _Z , so _X ( former ) is not smaller ( opposite ) ? [ Right ] .',\n",
       " ' _X is bigger than _Z , so _Z ( latter ) is not bigger ( same ) ? [ Right ] .',\n",
       " ' _Z is smaller than _X , so _Z ( former ) is smaller ( same ) ? [ Right ] .',\n",
       " ' _Z is smaller than _X , so _X ( latter ) is bigger ( opposite ) ? [ Right ] .',\n",
       " ' _Z is smaller than _X , so _X ( latter ) is not smaller ( same ) ? [ Right ] .',\n",
       " ' _Z is smaller than _X , so _Z ( former ) is not bigger ( opposite ) ? [ Right ] .',\n",
       " ' _X is not bigger than _Z , so _Z ( latter ) is not smaller ( opposite ) ? [ Right ] .',\n",
       " ' _X is not bigger than _Z , so _X ( former ) is not bigger ( same ) ? [ Right ] .',\n",
       " ' _X is not bigger than _Z , so _X ( former ) is smaller ( opposite ) ? [ Right ] .',\n",
       " ' _X is not bigger than _Z , so _Z ( latter ) is bigger ( same ) ? [ Right ] .',\n",
       " ' _Z is not smaller than _X , so _Z ( former ) is not smaller ( same ) ? [ Right ] .',\n",
       " ' _Z is not smaller than _X , so _X ( latter ) is not bigger ( opposite ) ? [ Right ] .',\n",
       " ' _Z is not smaller than _X , so _X ( latter ) is smaller ( same ) ? [ Right ] .',\n",
       " ' _Z is not smaller than _X , so _Z ( former ) is bigger ( opposite ) ? [ Right ] .',\n",
       " ' _X is bigger than _Z , so _Z ( latter ) is not smaller ( opposite ) ? [ Wrong ] .',\n",
       " ' _X is bigger than _Z , so _X ( former ) is not bigger ( same ) ? [ Wrong ] .',\n",
       " ' _X is bigger than _Z , so _X ( former ) is smaller ( opposite ) ? [ Wrong ] .',\n",
       " ' _X is bigger than _Z , so _Z ( latter ) is bigger ( same ) ? [ Wrong ] .',\n",
       " ' _Z is smaller than _X , so _Z ( former ) is not smaller ( same ) ? [ Wrong ] .',\n",
       " ' _Z is smaller than _X , so _X ( latter ) is not bigger ( opposite ) ? [ Wrong ] .',\n",
       " ' _Z is smaller than _X , so _X ( latter ) is smaller ( same ) ? [ Wrong ] .',\n",
       " ' _Z is smaller than _X , so _Z ( former ) is bigger ( opposite ) ? [ Wrong ] .',\n",
       " ' _X is not bigger than _Z , so _Z ( latter ) is smaller ( opposite ) ? [ Wrong ] .',\n",
       " ' _X is not bigger than _Z , so _X ( former ) is bigger ( same ) ? [ Wrong ] .',\n",
       " ' _X is not bigger than _Z , so _X ( former ) is not smaller ( opposite ) ? [ Wrong ] .',\n",
       " ' _X is not bigger than _Z , so _Z ( latter ) is not bigger ( same ) ? [ Wrong ] .',\n",
       " ' _Z is not smaller than _X , so _Z ( former ) is smaller ( same ) ? [ Wrong ] .',\n",
       " ' _Z is not smaller than _X , so _X ( latter ) is bigger ( opposite ) ? [ Wrong ] .',\n",
       " ' _Z is not smaller than _X , so _X ( latter ) is not smaller ( same ) ? [ Wrong ] .',\n",
       " ' _Z is not smaller than _X , so _Z ( former ) is not bigger ( opposite ) ? [ Wrong ] .',\n",
       " ' _X is not bigger than _Z , so _Z ( latter ) is taller ( unrelated ) ? [ Maybe ] .',\n",
       " ' _Z is not smaller than _X , so _Z ( former ) is shorter ( unrelated ) ? [ Maybe ] .',\n",
       " ' _Z is smaller than _X , so _Z ( former ) is not taller ( unrelated ) ? [ Maybe ] .',\n",
       " ' _Z is not smaller than _X , so _X ( latter ) is not taller ( unrelated ) ? [ Maybe ] .',\n",
       " ' _X is bigger than _Z , so _Z ( latter ) is shorter ( unrelated ) ? [ Maybe ] .',\n",
       " ' _Z is smaller than _X , so _X ( latter ) is not shorter ( unrelated ) ? [ Maybe ] .',\n",
       " ' _Z is not smaller than _X , so _Z ( former ) is not shorter ( unrelated ) ? [ Maybe ] .',\n",
       " ' _X is bigger than _Z , so _Z ( latter ) is taller ( unrelated ) ? [ Maybe ] .',\n",
       " ' _Z is smaller than _X , so _Z ( former ) is shorter ( unrelated ) ? [ Maybe ] .',\n",
       " ' _Z is not smaller than _X , so _X ( latter ) is not higher ( unrelated ) ? [ Maybe ] .',\n",
       " ' _X is not bigger than _Z , so _Z ( latter ) is not taller ( unrelated ) ? [ Maybe ] .',\n",
       " ' _X is not bigger than _Z , so _X ( former ) is higher ( unrelated ) ? [ Maybe ] .',\n",
       " ' _X is not bigger than _Z , so _Z ( latter ) is not shorter ( unrelated ) ? [ Maybe ] .',\n",
       " ' _X is not bigger than _Z , so _Z ( latter ) is higher ( unrelated ) ? [ Maybe ] .',\n",
       " ' _Z is not smaller than _X , so _X ( latter ) is higher ( unrelated ) ? [ Maybe ] .',\n",
       " ' _Z is smaller than _X , so _X ( latter ) is higher ( unrelated ) ? [ Maybe ] .']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_template = \"{rel_prefix} {dt} {ent0} {rel} {dt} {ent1} {rel_suffix}\"\n",
    "B_templates = [\"{pred_prefix} {dt} {ent} {pred}\", \"{pred_prefix} {pred} {dt} {ent}\"]\n",
    "B_template = B_templates[0]\n",
    "entailment_templates = [\n",
    "    \"{A} ? {conj} , {B} .\",  # yes/no/maybe\n",
    "    \"{A} , so {B} ? {conj} .\",\n",
    "]\n",
    "marker = '*'\n",
    "def get_comparative(word, add_marker=False):\n",
    "    compar = comparative(word)\n",
    "    if add_marker:\n",
    "        compar = compar.replace('more ', 'more %s ' % marker) if compar.startswith('more ') else marker + ' ' + compar\n",
    "    return compar\n",
    "    \n",
    "def negate_sent(sent):\n",
    "    assert ' is ' in sent\n",
    "    neg_sents = []\n",
    "    neg_sents.append(sent.replace(' is ', ' is not '))\n",
    "    neg_sents.append('it is unlikely that ' + sent)\n",
    "    return neg_sents\n",
    "\n",
    "def strip_rel_id(s, lexical_rel=''):\n",
    "    rel_id_span = s[s.index(':'): s.index(':') + 2]\n",
    "    if lexical_rel != '': lexical_rel = ' ( ' + lexical_rel + ' )'\n",
    "    return s.replace(rel_id_span, lexical_rel)\n",
    "        \n",
    "tag2id = {'Ġsame': 0, 'Ġopposite': 1, 'Ġunrelated': 2, 'Ġformer': 3, 'Ġlatter': 4, 'Ġanother': 5}\n",
    "id2tag = {v: k for k, v in tag2id.items()}\n",
    "\n",
    "def make_sentences(index=-1, entities=[\"_X\", \"_Z\"], entity_set=string.ascii_uppercase, determiner=\"\",\n",
    "                   relation_group=[[\"big\",], [\"small\"]], rand_relation_group=[[\"short\"], [\"tall\", \"high\"]],\n",
    "                   relation_prefix=\"\", relation_suffix=\"\", predicate_prefix=\"\",\n",
    "                   n_entity_trials=3, has_negA=True, has_negB=True, has_neutral=False, mask_types=['sent_rel'], \n",
    "                   lexical_relations=['same', 'opposite', 'unrelated'], tag_lexical_rel=False, tag_entity_rel=False):\n",
    "    def form_As(relations):\n",
    "        return [A_template.format(dt=determiner, ent0=ent0, ent1=ent1, rel=rel, rel_prefix=relation_prefix, rel_suffix=relation_suffix)\n",
    "              for ent0, ent1, rel in [entities + relations[:1], reverse(entities) + reverse(relations)[:1]]]\n",
    "\n",
    "    As = []\n",
    "    for rel0 in relation_group[0]:\n",
    "        for rel1 in relation_group[1]:\n",
    "            relations = [\"is %s:%d than\" % (get_comparative(rel), i) for i, rel in enumerate([rel0, rel1])]\n",
    "            As += form_As(relations)\n",
    "    As = list(set(As))\n",
    "    negAs = join_lists([negate_sent(A)[:1] for A in As]) if has_negA else []\n",
    "\n",
    "    def form_Bs(predicates): \n",
    "        f = mask if 'entity' in mask_types else (lambda x: x)\n",
    "        return [B_template.format(dt=determiner, ent=f(ent), pred=pred, pred_prefix=predicate_prefix)\n",
    "              for ent, pred in zip(entities, predicates)]\n",
    "\n",
    "    Bs, negBs = {'orig': [], 'rand': []}, {}\n",
    "    for k, group in zip(['orig', 'rand'], [relation_group, rand_relation_group]):\n",
    "        for rel0 in group[0]:\n",
    "            for rel1 in group[1]:\n",
    "                predicates = [\"is %s:%d\" % (get_comparative(rel), i) for i, rel in enumerate([rel0, rel1])]\n",
    "                Bs[k] += form_Bs(predicates)\n",
    "    for k in Bs:\n",
    "        Bs[k] = list(set(Bs[k]))\n",
    "        if has_negB:\n",
    "            negBs[k] = join_lists([negate_sent(B)[:1] for B in Bs[k]])\n",
    "            Bs[k], negBs[k] = Bs[k] + [swap_entities(negB) for negB in negBs[k]], negBs[k] + [swap_entities(B) for B in Bs[k]]\n",
    "        else:\n",
    "            negBs[k] = [swap_entities(B) for B in Bs[k]]\n",
    "\n",
    "    def form_sentences(sentence_template, As, Bs, conj):\n",
    "        def extract_rel_id(s): return int(s[s.index(':') + 1])\n",
    "        def get_lexical_rel(rel_id_A, rel_id_B): return 'same' if rel_id_A == rel_id_B else 'opposite'\n",
    "        def compare_and_tag_entity(B, A):\n",
    "            entity = [e for e in entities if e in B][0]\n",
    "            entity_rel = 'former' if A.strip().startswith(entity) else 'latter'\n",
    "            if 'entity_rel' in mask_types: entity_rel = mask(entity_rel)\n",
    "            return B.replace(entity, entity + ' ( ' + entity_rel + ' )')                    \n",
    "        \n",
    "        if 'sent_rel' in mask_types: conj = mask(conj)\n",
    "        As_with_rel_ids = [(A, extract_rel_id(A)) for A in As]\n",
    "        Bs_with_rel_ids = [(B, extract_rel_id(B)) for B in Bs]\n",
    "            \n",
    "        sentences = []\n",
    "        for (A, rel_id_A), (B, rel_id_B) in product(As_with_rel_ids, Bs_with_rel_ids):\n",
    "            lexical_rel = 'unrelated' if 'Maybe' in conj else get_lexical_rel(rel_id_A, rel_id_B)\n",
    "            if lexical_rel in lexical_relations:\n",
    "                if tag_entity_rel: B = compare_and_tag_entity(B, A)\n",
    "                if not tag_lexical_rel: lexical_rel = ''\n",
    "                elif 'lexical_rel' in mask_types: lexical_rel = mask(lexical_rel)\n",
    "                sent = sentence_template.format(A=strip_rel_id(A), B=strip_rel_id(B, lexical_rel), conj=conj)\n",
    "                sent = \" \" + \" \".join(sent.split())\n",
    "                sentences.append(sent)\n",
    "        return sentences\n",
    "\n",
    "    sentences = defaultdict(list)\n",
    "    for entailment_template in entailment_templates[-1:]:\n",
    "        for A, B, conj in [(As, Bs['orig'], 'Right'), \n",
    "                           (negAs, negBs['orig'], 'Right'), \n",
    "                           (As, negBs['orig'], 'Wrong'), \n",
    "                           (negAs, Bs['orig'], 'Wrong'),\n",
    "                           (As, Bs['rand'], 'Maybe'), \n",
    "                           (negAs, negBs['rand'], 'Maybe'), \n",
    "                           (As, negBs['rand'], 'Maybe'), \n",
    "                           (negAs, Bs['rand'], 'Maybe'),\n",
    "                          ]:\n",
    "            sentences[conj] += form_sentences(entailment_template, A, B, conj)\n",
    "    assert len(sentences['Right']) == len(sentences['Wrong']), '%d %d' % (len(sentences['Right']), len(sentences['Wrong']))\n",
    "    if has_neutral: sentences['Maybe'] = random.sample(sentences['Maybe'], len(sentences['Right']))\n",
    "    sentences = join_lists(sentences[k] for k in (sentences.keys() if has_neutral else ['Right', 'Wrong']))\n",
    "    \n",
    "    substituted_sent_groups = []\n",
    "    for sent in sentences:\n",
    "        sent_group = []\n",
    "        for _ in range(n_entity_trials):\n",
    "            e0, e1 = random.sample(entity_set, 2)\n",
    "            sent_group.append(sent.replace(entities[0], e0).replace(entities[1], e1))\n",
    "        substituted_sent_groups.append(sent_group)\n",
    "    return sentences, substituted_sent_groups\n",
    "\n",
    "make_sentences(has_negA=True, has_negB=True, has_neutral=True, tag_lexical_rel=True, tag_entity_rel=True, \n",
    "               mask_types=['sent_rel'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([' _X is bigger than _Y and _Y is bigger than _Z , so _X is bigger than _Z ? [ Right ] .',\n",
       "  ' _X is bigger than _Y and _Y is bigger than _Z , so _Z is smaller than _X ? [ Right ] .',\n",
       "  ' _X is bigger than _Y and _Z is smaller than _Y , so _X is bigger than _Z ? [ Right ] .',\n",
       "  ' _X is bigger than _Y and _Z is smaller than _Y , so _Z is smaller than _X ? [ Right ] .',\n",
       "  ' _Y is smaller than _X and _Y is bigger than _Z , so _X is bigger than _Z ? [ Right ] .',\n",
       "  ' _Y is smaller than _X and _Y is bigger than _Z , so _Z is smaller than _X ? [ Right ] .',\n",
       "  ' _Y is smaller than _X and _Z is smaller than _Y , so _X is bigger than _Z ? [ Right ] .',\n",
       "  ' _Y is smaller than _X and _Z is smaller than _Y , so _Z is smaller than _X ? [ Right ] .',\n",
       "  ' _Y is bigger than _Z and _X is bigger than _Y , so _X is bigger than _Z ? [ Right ] .',\n",
       "  ' _Y is bigger than _Z and _X is bigger than _Y , so _Z is smaller than _X ? [ Right ] .',\n",
       "  ' _Y is bigger than _Z and _Y is smaller than _X , so _X is bigger than _Z ? [ Right ] .',\n",
       "  ' _Y is bigger than _Z and _Y is smaller than _X , so _Z is smaller than _X ? [ Right ] .',\n",
       "  ' _Z is smaller than _Y and _X is bigger than _Y , so _X is bigger than _Z ? [ Right ] .',\n",
       "  ' _Z is smaller than _Y and _X is bigger than _Y , so _Z is smaller than _X ? [ Right ] .',\n",
       "  ' _Z is smaller than _Y and _Y is smaller than _X , so _X is bigger than _Z ? [ Right ] .',\n",
       "  ' _Z is smaller than _Y and _Y is smaller than _X , so _Z is smaller than _X ? [ Right ] .',\n",
       "  ' _X is bigger than _Y and _Y is bigger than _Z , so _Z is bigger than _X ? [ Wrong ] .',\n",
       "  ' _X is bigger than _Y and _Y is bigger than _Z , so _X is smaller than _Z ? [ Wrong ] .',\n",
       "  ' _X is bigger than _Y and _Z is smaller than _Y , so _Z is bigger than _X ? [ Wrong ] .',\n",
       "  ' _X is bigger than _Y and _Z is smaller than _Y , so _X is smaller than _Z ? [ Wrong ] .',\n",
       "  ' _Y is smaller than _X and _Y is bigger than _Z , so _Z is bigger than _X ? [ Wrong ] .',\n",
       "  ' _Y is smaller than _X and _Y is bigger than _Z , so _X is smaller than _Z ? [ Wrong ] .',\n",
       "  ' _Y is smaller than _X and _Z is smaller than _Y , so _Z is bigger than _X ? [ Wrong ] .',\n",
       "  ' _Y is smaller than _X and _Z is smaller than _Y , so _X is smaller than _Z ? [ Wrong ] .',\n",
       "  ' _Y is bigger than _Z and _X is bigger than _Y , so _Z is bigger than _X ? [ Wrong ] .',\n",
       "  ' _Y is bigger than _Z and _X is bigger than _Y , so _X is smaller than _Z ? [ Wrong ] .',\n",
       "  ' _Y is bigger than _Z and _Y is smaller than _X , so _Z is bigger than _X ? [ Wrong ] .',\n",
       "  ' _Y is bigger than _Z and _Y is smaller than _X , so _X is smaller than _Z ? [ Wrong ] .',\n",
       "  ' _Z is smaller than _Y and _X is bigger than _Y , so _Z is bigger than _X ? [ Wrong ] .',\n",
       "  ' _Z is smaller than _Y and _X is bigger than _Y , so _X is smaller than _Z ? [ Wrong ] .',\n",
       "  ' _Z is smaller than _Y and _Y is smaller than _X , so _Z is bigger than _X ? [ Wrong ] .',\n",
       "  ' _Z is smaller than _Y and _Y is smaller than _X , so _X is smaller than _Z ? [ Wrong ] .'],\n",
       " [[' U is bigger than D and D is bigger than A , so U is bigger than A ? [ Right ] .',\n",
       "   ' X is bigger than I and I is bigger than H , so X is bigger than H ? [ Right ] .',\n",
       "   ' H is bigger than E and E is bigger than X , so H is bigger than X ? [ Right ] .'],\n",
       "  [' D is bigger than V and V is bigger than X , so X is smaller than D ? [ Right ] .',\n",
       "   ' R is bigger than C and C is bigger than S , so S is smaller than R ? [ Right ] .',\n",
       "   ' N is bigger than B and B is bigger than A , so A is smaller than N ? [ Right ] .'],\n",
       "  [' C is bigger than G and H is smaller than G , so C is bigger than H ? [ Right ] .',\n",
       "   ' Q is bigger than T and A is smaller than T , so Q is bigger than A ? [ Right ] .',\n",
       "   ' R is bigger than G and W is smaller than G , so R is bigger than W ? [ Right ] .'],\n",
       "  [' U is bigger than W and R is smaller than W , so R is smaller than U ? [ Right ] .',\n",
       "   ' N is bigger than H and O is smaller than H , so O is smaller than N ? [ Right ] .',\n",
       "   ' S is bigger than I and Z is smaller than I , so Z is smaller than S ? [ Right ] .'],\n",
       "  [' Y is smaller than A and Y is bigger than Z , so A is bigger than Z ? [ Right ] .',\n",
       "   ' W is smaller than F and W is bigger than N , so F is bigger than N ? [ Right ] .',\n",
       "   ' I is smaller than K and I is bigger than E , so K is bigger than E ? [ Right ] .'],\n",
       "  [' Y is smaller than G and Y is bigger than K , so K is smaller than G ? [ Right ] .',\n",
       "   ' C is smaller than D and C is bigger than M , so M is smaller than D ? [ Right ] .',\n",
       "   ' L is smaller than D and L is bigger than T , so T is smaller than D ? [ Right ] .'],\n",
       "  [' Z is smaller than I and B is smaller than Z , so I is bigger than B ? [ Right ] .',\n",
       "   ' O is smaller than X and R is smaller than O , so X is bigger than R ? [ Right ] .',\n",
       "   ' M is smaller than D and C is smaller than M , so D is bigger than C ? [ Right ] .'],\n",
       "  [' J is smaller than R and U is smaller than J , so U is smaller than R ? [ Right ] .',\n",
       "   ' L is smaller than T and S is smaller than L , so S is smaller than T ? [ Right ] .',\n",
       "   ' W is smaller than G and C is smaller than W , so C is smaller than G ? [ Right ] .'],\n",
       "  [' V is bigger than H and B is bigger than V , so B is bigger than H ? [ Right ] .',\n",
       "   ' J is bigger than C and Y is bigger than J , so Y is bigger than C ? [ Right ] .',\n",
       "   ' D is bigger than M and H is bigger than D , so H is bigger than M ? [ Right ] .'],\n",
       "  [' O is bigger than U and I is bigger than O , so U is smaller than I ? [ Right ] .',\n",
       "   ' F is bigger than G and L is bigger than F , so G is smaller than L ? [ Right ] .',\n",
       "   ' I is bigger than W and V is bigger than I , so W is smaller than V ? [ Right ] .'],\n",
       "  [' U is bigger than C and U is smaller than V , so V is bigger than C ? [ Right ] .',\n",
       "   ' U is bigger than F and U is smaller than T , so T is bigger than F ? [ Right ] .',\n",
       "   ' X is bigger than H and X is smaller than R , so R is bigger than H ? [ Right ] .'],\n",
       "  [' O is bigger than M and O is smaller than F , so M is smaller than F ? [ Right ] .',\n",
       "   ' U is bigger than W and U is smaller than I , so W is smaller than I ? [ Right ] .',\n",
       "   ' H is bigger than V and H is smaller than R , so V is smaller than R ? [ Right ] .'],\n",
       "  [' B is smaller than Y and K is bigger than Y , so K is bigger than B ? [ Right ] .',\n",
       "   ' Z is smaller than B and H is bigger than B , so H is bigger than Z ? [ Right ] .',\n",
       "   ' I is smaller than M and K is bigger than M , so K is bigger than I ? [ Right ] .'],\n",
       "  [' S is smaller than G and C is bigger than G , so S is smaller than C ? [ Right ] .',\n",
       "   ' G is smaller than K and W is bigger than K , so G is smaller than W ? [ Right ] .',\n",
       "   ' M is smaller than P and U is bigger than P , so M is smaller than U ? [ Right ] .'],\n",
       "  [' E is smaller than O and O is smaller than U , so U is bigger than E ? [ Right ] .',\n",
       "   ' H is smaller than E and E is smaller than I , so I is bigger than H ? [ Right ] .',\n",
       "   ' I is smaller than R and R is smaller than X , so X is bigger than I ? [ Right ] .'],\n",
       "  [' N is smaller than S and S is smaller than X , so N is smaller than X ? [ Right ] .',\n",
       "   ' L is smaller than M and M is smaller than S , so L is smaller than S ? [ Right ] .',\n",
       "   ' Q is smaller than E and E is smaller than H , so Q is smaller than H ? [ Right ] .'],\n",
       "  [' P is bigger than C and C is bigger than Y , so Y is bigger than P ? [ Wrong ] .',\n",
       "   ' B is bigger than D and D is bigger than E , so E is bigger than B ? [ Wrong ] .',\n",
       "   ' U is bigger than F and F is bigger than Z , so Z is bigger than U ? [ Wrong ] .'],\n",
       "  [' V is bigger than N and N is bigger than T , so V is smaller than T ? [ Wrong ] .',\n",
       "   ' C is bigger than M and M is bigger than T , so C is smaller than T ? [ Wrong ] .',\n",
       "   ' O is bigger than Q and Q is bigger than I , so O is smaller than I ? [ Wrong ] .'],\n",
       "  [' R is bigger than A and V is smaller than A , so V is bigger than R ? [ Wrong ] .',\n",
       "   ' X is bigger than D and V is smaller than D , so V is bigger than X ? [ Wrong ] .',\n",
       "   ' R is bigger than Y and I is smaller than Y , so I is bigger than R ? [ Wrong ] .'],\n",
       "  [' Y is bigger than U and K is smaller than U , so Y is smaller than K ? [ Wrong ] .',\n",
       "   ' D is bigger than J and N is smaller than J , so D is smaller than N ? [ Wrong ] .',\n",
       "   ' F is bigger than O and A is smaller than O , so F is smaller than A ? [ Wrong ] .'],\n",
       "  [' I is smaller than X and I is bigger than Q , so Q is bigger than X ? [ Wrong ] .',\n",
       "   ' F is smaller than Y and F is bigger than Q , so Q is bigger than Y ? [ Wrong ] .',\n",
       "   ' U is smaller than D and U is bigger than J , so J is bigger than D ? [ Wrong ] .'],\n",
       "  [' Q is smaller than U and Q is bigger than T , so U is smaller than T ? [ Wrong ] .',\n",
       "   ' E is smaller than G and E is bigger than L , so G is smaller than L ? [ Wrong ] .',\n",
       "   ' F is smaller than Y and F is bigger than R , so Y is smaller than R ? [ Wrong ] .'],\n",
       "  [' Q is smaller than Y and A is smaller than Q , so A is bigger than Y ? [ Wrong ] .',\n",
       "   ' K is smaller than T and P is smaller than K , so P is bigger than T ? [ Wrong ] .',\n",
       "   ' D is smaller than A and L is smaller than D , so L is bigger than A ? [ Wrong ] .'],\n",
       "  [' J is smaller than Z and H is smaller than J , so Z is smaller than H ? [ Wrong ] .',\n",
       "   ' H is smaller than B and S is smaller than H , so B is smaller than S ? [ Wrong ] .',\n",
       "   ' X is smaller than C and P is smaller than X , so C is smaller than P ? [ Wrong ] .'],\n",
       "  [' Y is bigger than R and C is bigger than Y , so R is bigger than C ? [ Wrong ] .',\n",
       "   ' E is bigger than V and Y is bigger than E , so V is bigger than Y ? [ Wrong ] .',\n",
       "   ' R is bigger than F and P is bigger than R , so F is bigger than P ? [ Wrong ] .'],\n",
       "  [' Q is bigger than T and I is bigger than Q , so I is smaller than T ? [ Wrong ] .',\n",
       "   ' G is bigger than R and N is bigger than G , so N is smaller than R ? [ Wrong ] .',\n",
       "   ' X is bigger than W and Y is bigger than X , so Y is smaller than W ? [ Wrong ] .'],\n",
       "  [' W is bigger than J and W is smaller than G , so J is bigger than G ? [ Wrong ] .',\n",
       "   ' V is bigger than U and V is smaller than M , so U is bigger than M ? [ Wrong ] .',\n",
       "   ' O is bigger than Q and O is smaller than L , so Q is bigger than L ? [ Wrong ] .'],\n",
       "  [' D is bigger than H and D is smaller than O , so O is smaller than H ? [ Wrong ] .',\n",
       "   ' C is bigger than K and C is smaller than H , so H is smaller than K ? [ Wrong ] .',\n",
       "   ' S is bigger than R and S is smaller than A , so A is smaller than R ? [ Wrong ] .'],\n",
       "  [' A is smaller than S and H is bigger than S , so A is bigger than H ? [ Wrong ] .',\n",
       "   ' U is smaller than W and C is bigger than W , so U is bigger than C ? [ Wrong ] .',\n",
       "   ' C is smaller than H and B is bigger than H , so C is bigger than B ? [ Wrong ] .'],\n",
       "  [' C is smaller than K and B is bigger than K , so B is smaller than C ? [ Wrong ] .',\n",
       "   ' I is smaller than H and Q is bigger than H , so Q is smaller than I ? [ Wrong ] .',\n",
       "   ' G is smaller than P and V is bigger than P , so V is smaller than G ? [ Wrong ] .'],\n",
       "  [' X is smaller than E and E is smaller than R , so X is bigger than R ? [ Wrong ] .',\n",
       "   ' H is smaller than P and P is smaller than S , so H is bigger than S ? [ Wrong ] .',\n",
       "   ' N is smaller than P and P is smaller than Z , so N is bigger than Z ? [ Wrong ] .'],\n",
       "  [' V is smaller than D and D is smaller than G , so G is smaller than V ? [ Wrong ] .',\n",
       "   ' O is smaller than L and L is smaller than N , so N is smaller than O ? [ Wrong ] .',\n",
       "   ' V is smaller than B and B is smaller than X , so X is smaller than V ? [ Wrong ] .']])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_template = '{ent0} {rel} {ent1}'\n",
    "transitive_template = '{p0} and {p1} , so {Q} ? {conj} .'\n",
    "transitive_wh_QA_template = '{which} is {pred} ? {ent} .'\n",
    "    \n",
    "def make_transitive(entities=[\"_X\", \"_Y\", \"_Z\"], entity_set=string.ascii_uppercase, relation_group=[[\"big\", ], [\"small\", ]], \n",
    "                    n_entity_trials=3, has_negP=True, has_negQ=True, has_neutral=False, mask_types=['sent_rel']):\n",
    "    def form_atoms(relations, entities, has_neg=True):\n",
    "        atoms = [P_template.format(ent0=ent0, ent1=ent1, rel=rel) \n",
    "                 for ent0, ent1, rel in [entities + relations[:1], reverse(entities) + reverse(relations)[:1]]]\n",
    "        if has_neg:\n",
    "            neg_relations = [r.replace('is ', 'is not ') for r in relations]\n",
    "            atoms += [P_template.format(ent0=ent0, ent1=ent1, rel=rel) \n",
    "                      for ent0, ent1, rel in [entities + reverse(neg_relations)[:1], reverse(entities) + neg_relations[:1]]]\n",
    "        return atoms\n",
    " \n",
    "    def form_sentences(transitive_template, Ps, Qs, conj):\n",
    "        sentences = []\n",
    "        if 'sent_rel' in mask_types: conj = mask(conj)\n",
    "        for (p0, p1), Q in product(Ps, Qs):\n",
    "            sent = transitive_template.format(p0=strip_rel_id(p0), p1=strip_rel_id(p1), Q=strip_rel_id(Q), conj=conj)\n",
    "            sent = \" \" + \" \".join(sent.split())\n",
    "            sentences.append(sent)\n",
    "        return sentences\n",
    "    \n",
    "    def form_all(P0_entities, P1_entities, Q_entities, neutral=False):\n",
    "        P0, P1 = [], []\n",
    "        for rel0 in relation_group[0]:\n",
    "            for rel1 in relation_group[1]:\n",
    "                relations = [\"is %s:%d than\" % (get_comparative(rel), i) for i, rel in enumerate([rel0, rel1])]\n",
    "                P0 += form_atoms(relations, P0_entities, has_neg=has_negP)\n",
    "                P1 += form_atoms(relations, P1_entities, has_neg=has_negP)\n",
    "        Ps = [(p0, p1) for p0, p1 in list(product(P0, P1)) + list(product(P1, P0))]\n",
    "\n",
    "        Qs = form_atoms(relations, Q_entities, has_neg=has_negQ)\n",
    "        negQs = [swap_entities(Q, *Q_entities) for Q in Qs]\n",
    "        \n",
    "        for P, Q, conj in [(Ps, Qs, 'Right'), (Ps, negQs, 'Wrong')]:\n",
    "            if neutral: conj = 'Maybe'\n",
    "            sentences[conj] += form_sentences(transitive_template, P, Q, conj)\n",
    "        return sentences\n",
    "    \n",
    "    e0, e1, e2 = entities\n",
    "    sentences = defaultdict(list)\n",
    "    form_all(P0_entities=[e0, e1], P1_entities=[e1, e2], Q_entities=[e0, e2])\n",
    "    assert len(sentences['Right']) == len(sentences['Wrong']), '%d %d' % (len(sentences['Right']), len(sentences['Wrong']))\n",
    "    sample_ratio = len(relation_group[0]) * len(relation_group[1])\n",
    "    if sample_ratio > 1:\n",
    "        for key in sentences: sentences[key] = random.sample(sentences[key], len(sentences[key]) // sample_ratio)\n",
    "#     print('nRight =', len(sentences['Right']))\n",
    "    if has_neutral:\n",
    "        form_all(P0_entities=[e0, e1], P1_entities=[e0, e2], Q_entities=[e1, e2], neutral=True)\n",
    "        sentences['Maybe'] = random.sample(sentences['Maybe'], len(sentences['Right']))\n",
    "    sentences = join_lists(sentences[k] for k in (sentences.keys() if has_neutral else ['Right', 'Wrong']))\n",
    "    \n",
    "    substituted_sent_groups = []\n",
    "    for sent in sentences:\n",
    "        sent_group = []\n",
    "        for _ in range(n_entity_trials):\n",
    "            e0, e1, e2 = random.sample(entity_set, 3)\n",
    "            sent_group.append(sent.replace(entities[0], e0).replace(entities[1], e1).replace(entities[2], e2))\n",
    "        substituted_sent_groups.append(sent_group)\n",
    "    return sentences, substituted_sent_groups\n",
    "\n",
    "make_transitive(has_negP=False, has_negQ=False, has_neutral=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, shortcut = RobertaForMaskedLM, RobertaTokenizer, 'roberta-large'\n",
    "# model_class = RobertaDoubleHeadsModel\n",
    "model, tokenizer = None, tokenizer_class.from_pretrained(shortcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in convert_example_to_features: features.labels = [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 5143, -100, -100, -100, -100]\n",
      "in convert_example_to_features: features.labels = [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 5143, -100, -100]\n",
      "nTrain = 32320, nValid = 15040\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(frames)\n",
    "# all_lines = [make_sentences(relation_group=rg, rand_relation_group=frames[(i + 1) % len(frames)], n_entity_trials=10, \n",
    "#                             has_negA=True, has_negB=True, tag_lexical_rel=True, tag_entity_rel=True,\n",
    "#                             has_neutral=False, mask_types=['sent_rel'])[1] \n",
    "#              for i, rg in enumerate(frames)]\n",
    "all_lines = [make_transitive(relation_group=rg, n_entity_trials=10, \n",
    "                             has_negP=False, has_negQ=False, has_neutral=False, mask_types=['sent_rel'])[1] \n",
    "             for i, rg in enumerate(frames)]\n",
    "# all_lines = join_lists(all_lines)\n",
    "# all_lines = join_lists(all_lines)\n",
    "tokenizer.tag2id, tokenizer.id2tag = tag2id, id2tag\n",
    "for k in CHILDDataset.all_lines: CHILDDataset.all_lines[k] = None\n",
    "train_dataset = CHILDDataset(all_lines, tokenizer, max_noise_len=0, split_pct=[0.7, 0.3, 0.0], mode='train')\n",
    "eval_dataset = CHILDDataset(all_lines, tokenizer, max_noise_len=0, split_pct=[0.7, 0.3, 0.0], mode='dev')\n",
    "print('nTrain = %d, nValid = %d' % (len(train_dataset), len(eval_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cc09b5450f4a39b24099d8a8be03fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68e9afa243245b79274a9d37cad3569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1010.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.901, 'learning_rate': 1.9339933993399344e-05, 'epoch': 0.099, 'step': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4986401a9c4954b76d64a26499c658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.705, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠRight 0.00 0.50, ĠWrong 1.00 0.56, ', 'epoch': 0.099, 'step': 100}\n",
      "{'loss': 0.73, 'learning_rate': 1.867986798679868e-05, 'epoch': 0.198, 'step': 200}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fd0f690ae24316a3c3d133463496f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.741, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠRight 1.00 0.65, ', 'epoch': 0.198, 'step': 200}\n",
      "{'loss': 0.725, 'learning_rate': 1.8019801980198022e-05, 'epoch': 0.297, 'step': 300}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3279f00dd1a47db9cbf38d0848c27c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.695, 'eval_acc_0': 0.502, 'eval_stat_0': 'ĠRight 0.42 0.51, ĠWrong 0.58 0.51, ', 'epoch': 0.297, 'step': 300}\n",
      "{'loss': 0.737, 'learning_rate': 1.735973597359736e-05, 'epoch': 0.396, 'step': 400}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d161bee356240909e307c5678059f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.697, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠRight 1.00 0.54, ', 'epoch': 0.396, 'step': 400}\n",
      "{'loss': 0.721, 'learning_rate': 1.66996699669967e-05, 'epoch': 0.495, 'step': 500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703f9a63c3e4431dbf0a40ad4fc64e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.705, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠRight 1.00 0.57, ', 'epoch': 0.495, 'step': 500}\n",
      "{'loss': 0.71, 'learning_rate': 1.6039603960396042e-05, 'epoch': 0.594, 'step': 600}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab507f0867da4f8eba1e97c7a4507b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.715, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.60, ', 'epoch': 0.594, 'step': 600}\n",
      "{'loss': 0.713, 'learning_rate': 1.537953795379538e-05, 'epoch': 0.693, 'step': 700}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a55e86955049bebca579253ee3710c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.698, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.54, ', 'epoch': 0.693, 'step': 700}\n",
      "{'loss': 0.705, 'learning_rate': 1.4719471947194721e-05, 'epoch': 0.792, 'step': 800}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576cb39db9114f7bbeb247e858c0e634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.698, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠRight 1.00 0.55, ', 'epoch': 0.792, 'step': 800}\n",
      "{'loss': 0.713, 'learning_rate': 1.405940594059406e-05, 'epoch': 0.891, 'step': 900}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43dfca092bd04a8c91bc84a1cfebba82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.695, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.52, ', 'epoch': 0.891, 'step': 900}\n",
      "{'loss': 0.708, 'learning_rate': 1.33993399339934e-05, 'epoch': 0.99, 'step': 1000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9277ed265c3143449c7a4bad18fba062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.731, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠRight 1.00 0.63, ', 'epoch': 0.99, 'step': 1000}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e855ded7054938b51ccd3b970fccec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1010.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.718, 'learning_rate': 1.2739273927392741e-05, 'epoch': 1.089, 'step': 1100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e693b49e634396a5f2e79c47fba294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.702, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.56, ', 'epoch': 1.089, 'step': 1100}\n",
      "{'loss': 0.703, 'learning_rate': 1.207920792079208e-05, 'epoch': 1.188, 'step': 1200}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235bc824e23446599fcc130a9092187e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.702, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.56, ', 'epoch': 1.188, 'step': 1200}\n",
      "{'loss': 0.698, 'learning_rate': 1.141914191419142e-05, 'epoch': 1.287, 'step': 1300}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e3a5a9e50b471882d7bf60a5a3f3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.698, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.55, ', 'epoch': 1.287, 'step': 1300}\n",
      "{'loss': 0.702, 'learning_rate': 1.075907590759076e-05, 'epoch': 1.386, 'step': 1400}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72575d30b3194bfd80c213787956182c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.693, 'eval_acc_0': 0.505, 'eval_stat_0': 'ĠRight 0.18 0.50, ĠWrong 0.82 0.50, ', 'epoch': 1.386, 'step': 1400}\n",
      "{'loss': 0.706, 'learning_rate': 1.00990099009901e-05, 'epoch': 1.485, 'step': 1500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6c9aecdf7644aa85a6c47ac3586fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.693, 'eval_acc_0': 0.497, 'eval_stat_0': 'ĠRight 0.74 0.51, ĠWrong 0.26 0.50, ', 'epoch': 1.485, 'step': 1500}\n",
      "{'loss': 0.706, 'learning_rate': 9.43894389438944e-06, 'epoch': 1.584, 'step': 1600}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4c9006d50b4d68a41921e78e4a6ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.693, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠRight 1.00 0.51, ĠWrong 0.00 0.50, ', 'epoch': 1.584, 'step': 1600}\n",
      "{'loss': 0.7, 'learning_rate': 8.77887788778878e-06, 'epoch': 1.683, 'step': 1700}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70d55a4774b44af9810b90ff0b38ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.725, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠRight 1.00 0.62, ', 'epoch': 1.683, 'step': 1700}\n",
      "{'loss': 0.704, 'learning_rate': 8.11881188118812e-06, 'epoch': 1.782, 'step': 1800}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaab6b9971204161a89fe41b339d2d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.695, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.53, ', 'epoch': 1.782, 'step': 1800}\n",
      "{'loss': 0.702, 'learning_rate': 7.458745874587459e-06, 'epoch': 1.881, 'step': 1900}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a350ceeb844845a33071d01b114188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.702, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.56, ', 'epoch': 1.881, 'step': 1900}\n",
      "{'loss': 0.702, 'learning_rate': 6.798679867986799e-06, 'epoch': 1.98, 'step': 2000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29cbe8b4270457eb01475e8e9e7605a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.695, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.53, ', 'epoch': 1.98, 'step': 2000}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107a987660b74d80856f965d3cee4d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1010.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.698, 'learning_rate': 6.138613861386139e-06, 'epoch': 2.079, 'step': 2100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193c40b840ee42b1bc807254ec334012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.693, 'eval_acc_0': 0.499, 'eval_stat_0': 'ĠRight 0.02 0.50, ĠWrong 0.98 0.51, ', 'epoch': 2.079, 'step': 2100}\n",
      "{'loss': 0.698, 'learning_rate': 5.4785478547854785e-06, 'epoch': 2.178, 'step': 2200}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d97e52452545d79746c20eb95c008d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.694, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠRight 1.00 0.52, ', 'epoch': 2.178, 'step': 2200}\n",
      "{'loss': 0.697, 'learning_rate': 4.818481848184819e-06, 'epoch': 2.277, 'step': 2300}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75388f71e17494784374b4c12a8b3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.699, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠRight 1.00 0.55, ', 'epoch': 2.277, 'step': 2300}\n",
      "{'loss': 0.698, 'learning_rate': 4.158415841584159e-06, 'epoch': 2.376, 'step': 2400}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9257ad05fda6452b8d6549f61f8eca54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.693, 'eval_acc_0': 0.503, 'eval_stat_0': 'ĠRight 0.54 0.50, ĠWrong 0.46 0.50, ', 'epoch': 2.376, 'step': 2400}\n",
      "{'loss': 0.698, 'learning_rate': 3.4983498349834986e-06, 'epoch': 2.475, 'step': 2500}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b6d210c5824b79ae38d061d7ebcf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.693, 'eval_acc_0': 0.502, 'eval_stat_0': 'ĠRight 0.86 0.50, ĠWrong 0.14 0.50, ', 'epoch': 2.475, 'step': 2500}\n",
      "{'loss': 0.698, 'learning_rate': 2.8382838283828383e-06, 'epoch': 2.574, 'step': 2600}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d182876b9248cbba59ee6e7316180a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.694, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.52, ', 'epoch': 2.574, 'step': 2600}\n",
      "{'loss': 0.697, 'learning_rate': 2.1782178217821785e-06, 'epoch': 2.673, 'step': 2700}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00656a89bfe48e695a28593a725d308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.695, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.53, ', 'epoch': 2.673, 'step': 2700}\n",
      "{'loss': 0.698, 'learning_rate': 1.5181518151815183e-06, 'epoch': 2.772, 'step': 2800}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a912acb8d7485a8e0b8611777bb472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.693, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠRight 0.05 0.50, ĠWrong 0.95 0.51, ', 'epoch': 2.772, 'step': 2800}\n",
      "{'loss': 0.696, 'learning_rate': 8.580858085808581e-07, 'epoch': 2.871, 'step': 2900}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdb2b1f2d52478fb9a379de1ea59e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.693, 'eval_acc_0': 0.499, 'eval_stat_0': 'ĠRight 0.30 0.50, ĠWrong 0.70 0.50, ', 'epoch': 2.871, 'step': 2900}\n",
      "{'loss': 0.695, 'learning_rate': 1.9801980198019803e-07, 'epoch': 2.97, 'step': 3000}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0162ad81a34b1b84e99856557396cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.694, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.51, ', 'epoch': 2.97, 'step': 3000}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b46ef69e462422ebfc2792b5a26e1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=235.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'eval_loss': 0.694, 'eval_acc_0': 0.5, 'eval_stat_0': 'ĠWrong 1.00 0.51, ', 'epoch': 3.0, 'step': 3030}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3030, training_loss=0.7125059162429457)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_class.from_pretrained('roberta-base', model=model)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"./models/model_name\", \n",
    "    overwrite_output_dir=True, do_train=True, do_eval=True,\n",
    "    per_device_train_batch_size=32, per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5, num_train_epochs=3,\n",
    "    logging_steps=100, eval_steps=100, save_steps=0,\n",
    "    no_cuda=False, evaluate_during_training=True,\n",
    ")\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=eval_dataset)\n",
    "trainer.tokenizer = tokenizer\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertSelfAttention(\n",
       "  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0].attention.self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataloader = trainer.get_eval_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs in dataloader: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  0, 387,  16,  ...,   2,   0,   0],\n",
       "         [  0, 534,  16,  ...,   2,   0,   0],\n",
       "         [  0, 975,  16,  ...,   2,   0,   0],\n",
       "         ...,\n",
       "         [  0, 487,  16,  ..., 479,   2,   0],\n",
       "         [  0, 673,  16,  ..., 479,   2,   0],\n",
       "         [  0, 725,  16,  ..., 479,   2,   0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         ...,\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100]]),\n",
       " 'position_ids': tensor([[ 0,  1,  2,  ..., 22,  0,  0],\n",
       "         [ 0,  1,  2,  ..., 22,  0,  0],\n",
       "         [ 0,  1,  2,  ..., 22,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  1,  2,  ..., 22, 23,  0],\n",
       "         [ 0,  1,  2,  ..., 22, 23,  0],\n",
       "         [ 0,  1,  2,  ..., 22, 23,  0]])}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = trainer._prepare_inputs(inputs, model)\n",
    "loss, logits = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax((logits * (inputs['labels'] != -100).unsqueeze(-1)).sum(dim=1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsz, seq_len, vocab_size = (logits).size()\n",
    "masks = (inputs['labels'] != -100)\n",
    "n_mask = masks.sum(dim=-1)[0].item()\n",
    "pred_labels = logits.masked_select(mask.unsqueeze(-1)).view(bsz, n_mask, vocab_size).argmax(dim=-1)\n",
    "labels = inputs['labels'].masked_select(masks).view(bsz, n_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 5442,\n",
       "        -100, -100, -100, -100, -100, 5483, -100, -100, 5143, -100, -100, -100,\n",
       "        -100])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90625"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = (logits * (inputs['labels'] != -100).unsqueeze(-1)).sum(dim=1).argmax(dim=-1)\n",
    "\n",
    "labels = (inputs['labels'] * (inputs['labels'] != -100)).sum(dim=-1)\n",
    "\n",
    "(pred_labels == labels).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.4\n"
     ]
    }
   ],
   "source": [
    "print('%.1f' % 94.433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ĠRight 0.6260414719581604\n",
      "ĠRight 0.6174842119216919\n",
      "ĠRight 0.627226710319519\n",
      "ĠRight 0.6074517965316772\n",
      "ĠRight 0.6034893989562988\n",
      "ĠRight 0.5928120613098145\n",
      "ĠMaybe 0.9999963045120239\n",
      "ĠMaybe 0.9999955892562866\n",
      "ĠMaybe 0.9999963045120239\n",
      "ĠRight 0.6209385395050049\n",
      "ĠRight 0.6153814196586609\n",
      "ĠRight 0.6189284324645996\n",
      "ĠRight 0.6173365712165833\n",
      "ĠRight 0.6170286536216736\n",
      "ĠRight 0.6148619651794434\n",
      "ĠMaybe 0.9999971389770508\n",
      "ĠMaybe 0.9999972581863403\n",
      "ĠMaybe 0.9999969005584717\n",
      "ĠRight 0.6081119179725647\n",
      "ĠRight 0.6188942790031433\n",
      "ĠRight 0.6106655597686768\n",
      "ĠRight 0.6149485111236572\n",
      "ĠRight 0.6151918172836304\n",
      "ĠRight 0.6127419471740723\n",
      "ĠRight 0.6444377303123474\n",
      "ĠRight 0.6497629284858704\n",
      "ĠRight 0.6418505311012268\n",
      "ĠRight 0.6264133453369141\n",
      "ĠRight 0.6273400783538818\n",
      "ĠRight 0.6344654560089111\n",
      "ĠRight 0.6158509254455566\n",
      "ĠRight 0.6200970411300659\n",
      "ĠRight 0.6208559274673462\n",
      "ĠMaybe 0.9999988079071045\n",
      "ĠMaybe 0.9999986886978149\n",
      "ĠMaybe 0.9999988079071045\n",
      "ĠMaybe 0.9999974966049194\n",
      "ĠMaybe 0.9999971389770508\n",
      "ĠMaybe 0.9999974966049194\n",
      "ĠMaybe 0.9999963045120239\n",
      "ĠMaybe 0.999996542930603\n",
      "ĠMaybe 0.9999966621398926\n",
      "ĠRight 0.623246967792511\n",
      "ĠRight 0.6270768046379089\n",
      "ĠRight 0.618299663066864\n",
      "ĠMaybe 0.9999973773956299\n",
      "ĠMaybe 0.9999972581863403\n",
      "ĠMaybe 0.9999977350234985\n",
      "ĠMaybe 0.9999961853027344\n",
      "ĠMaybe 0.9999959468841553\n",
      "ĠMaybe 0.9999960660934448\n",
      "ĠRight 0.6204316020011902\n",
      "ĠRight 0.6157919764518738\n",
      "ĠRight 0.6199951171875\n",
      "ĠMaybe 0.9999948740005493\n",
      "ĠMaybe 0.9999945163726807\n",
      "ĠMaybe 0.9999958276748657\n",
      "ĠRight 0.6182829141616821\n",
      "ĠRight 0.6187686324119568\n",
      "ĠRight 0.6175054907798767\n",
      "ĠRight 0.6209660768508911\n",
      "ĠRight 0.6262878775596619\n",
      "ĠRight 0.6350439786911011\n",
      "ĠRight 0.6232182383537292\n"
     ]
    }
   ],
   "source": [
    "for i, label_id in enumerate(pred_labels):\n",
    "    print(tokenizer._convert_id_to_token(label_id.item()), probs[i, label_id].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([40, 24,  0], device='cuda:0'),\n",
       "indices=tensor([5143, 5359,    0], device='cuda:0'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels.bincount().topk(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([24, 22, 18], device='cuda:0'),\n",
       "indices=tensor([ 5359,  5143, 31273], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.bincount().topk(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ĠMaybe'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer._convert_id_to_token(5359)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = probs.topk(5, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5143, 31273, 13984, 235, 37234]\n",
      "['ĠRight', 'ĠWrong', 'Right', 'Ġright', 'ĠCorrect']\n",
      "[5143, 31273, 235, 13984, 10039]\n",
      "['ĠRight', 'ĠWrong', 'Ġright', 'Right', 'ĠLeft']\n",
      "[5143, 31273, 235, 13984, 38103]\n",
      "['ĠRight', 'ĠWrong', 'Ġright', 'Right', 'ĠRIGHT']\n",
      "[5143, 31273, 235, 13984, 38103]\n",
      "['ĠRight', 'ĠWrong', 'Ġright', 'Right', 'ĠRIGHT']\n",
      "[5143, 31273, 235, 13984, 38103]\n",
      "['ĠRight', 'ĠWrong', 'Ġright', 'Right', 'ĠRIGHT']\n",
      "[31273, 5143, 235, 13984, 38103]\n",
      "['ĠWrong', 'ĠRight', 'Ġright', 'Right', 'ĠRIGHT']\n",
      "[31273, 5143, 235, 13984, 38103]\n",
      "['ĠWrong', 'ĠRight', 'Ġright', 'Right', 'ĠRIGHT']\n",
      "[5143, 31273, 235, 13984, 1593]\n",
      "['ĠRight', 'ĠWrong', 'Ġright', 'Right', 'Ġwrong']\n",
      "[5143, 31273, 13984, 235, 38103]\n",
      "['ĠRight', 'ĠWrong', 'Right', 'Ġright', 'ĠRIGHT']\n",
      "[5143, 31273, 13984, 235, 37234]\n",
      "['ĠRight', 'ĠWrong', 'Right', 'Ġright', 'ĠCorrect']\n",
      "[5143, 31273, 13984, 235, 37234]\n",
      "['ĠRight', 'ĠWrong', 'Right', 'Ġright', 'ĠCorrect']\n",
      "[5143, 31273, 235, 13984, 38103]\n",
      "['ĠRight', 'ĠWrong', 'Ġright', 'Right', 'ĠRIGHT']\n",
      "[5143, 31273, 235, 13984, 38103]\n",
      "['ĠRight', 'ĠWrong', 'Ġright', 'Right', 'ĠRIGHT']\n",
      "[5143, 31273, 235, 13984, 1593]\n",
      "['ĠRight', 'ĠWrong', 'Ġright', 'Right', 'Ġwrong']\n",
      "[5143, 31273, 13984, 235, 38103]\n",
      "['ĠRight', 'ĠWrong', 'Right', 'Ġright', 'ĠRIGHT']\n",
      "[5143, 31273, 13984, 235, 38103]\n",
      "['ĠRight', 'ĠWrong', 'Right', 'Ġright', 'ĠRIGHT']\n"
     ]
    }
   ],
   "source": [
    "for top_idx in indices:\n",
    "    print(top_idx.tolist())\n",
    "    print(tokenizer.convert_ids_to_tokens(top_idx.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
