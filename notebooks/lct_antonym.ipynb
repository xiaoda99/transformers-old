{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from random import sample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import *\n",
    "\n",
    "import collections\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATTRIBUTE$Action:ObjectAttribute</td>\n",
       "      <td>apple</td>\n",
       "      <td>picker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATTRIBUTE$Action:ObjectAttribute</td>\n",
       "      <td>collect</td>\n",
       "      <td>fee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATTRIBUTE$Action:ObjectAttribute</td>\n",
       "      <td>hunter</td>\n",
       "      <td>game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATTRIBUTE$Action:ObjectAttribute</td>\n",
       "      <td>paint</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATTRIBUTE$Action:ObjectAttribute</td>\n",
       "      <td>vitamin</td>\n",
       "      <td>deficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12453</th>\n",
       "      <td>vn-deriv</td>\n",
       "      <td>yawn</td>\n",
       "      <td>yawning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12454</th>\n",
       "      <td>vn-deriv</td>\n",
       "      <td>yearn</td>\n",
       "      <td>yearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12455</th>\n",
       "      <td>vn-deriv</td>\n",
       "      <td>yell</td>\n",
       "      <td>yelling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12456</th>\n",
       "      <td>vn-deriv</td>\n",
       "      <td>yield</td>\n",
       "      <td>yielding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12457</th>\n",
       "      <td>vn-deriv</td>\n",
       "      <td>zip</td>\n",
       "      <td>zipper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12458 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               relation    word1       word2\n",
       "0      ATTRIBUTE$Action:ObjectAttribute    apple      picker\n",
       "1      ATTRIBUTE$Action:ObjectAttribute  collect         fee\n",
       "2      ATTRIBUTE$Action:ObjectAttribute   hunter        game\n",
       "3      ATTRIBUTE$Action:ObjectAttribute    paint       house\n",
       "4      ATTRIBUTE$Action:ObjectAttribute  vitamin  deficiency\n",
       "...                                 ...      ...         ...\n",
       "12453                          vn-deriv     yawn     yawning\n",
       "12454                          vn-deriv    yearn    yearning\n",
       "12455                          vn-deriv     yell     yelling\n",
       "12456                          vn-deriv    yield    yielding\n",
       "12457                          vn-deriv      zip      zipper\n",
       "\n",
       "[12458 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先处理 DiffVec的数据\n",
    "filename = 'diffvec_word_pairs_final.SEMBLESS.csv'\n",
    "file_colname=['relation','word1','word2']\n",
    "df = pd.read_csv(filename,header=None,names=file_colname)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>acetaminophen</td>\n",
       "      <td>headache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>acid</td>\n",
       "      <td>base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>activity</td>\n",
       "      <td>boredom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>antibiotic</td>\n",
       "      <td>infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>antibiotics</td>\n",
       "      <td>bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>cat</td>\n",
       "      <td>mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>cure</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>education</td>\n",
       "      <td>ignorance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>fast</td>\n",
       "      <td>slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>food</td>\n",
       "      <td>hunger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>fungicide</td>\n",
       "      <td>fungus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>fungicide</td>\n",
       "      <td>mold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>good</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>happy</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>immunization</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>insecticide</td>\n",
       "      <td>bugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>insecticide</td>\n",
       "      <td>pests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>ignorance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>locks</td>\n",
       "      <td>theft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>mediation</td>\n",
       "      <td>conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>medicine</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>medicine</td>\n",
       "      <td>illness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>money</td>\n",
       "      <td>poverty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>nice</td>\n",
       "      <td>evil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>preparation</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>rest</td>\n",
       "      <td>exhaustion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>shot</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>sleep</td>\n",
       "      <td>exhaustion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>sleep</td>\n",
       "      <td>tiredness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>sun</td>\n",
       "      <td>darkness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>swimming</td>\n",
       "      <td>drowning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>CAUSE-PURPOSE$Prevention</td>\n",
       "      <td>water</td>\n",
       "      <td>thirst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     relation          word1       word2\n",
       "287  CAUSE-PURPOSE$Prevention  acetaminophen    headache\n",
       "288  CAUSE-PURPOSE$Prevention           acid        base\n",
       "289  CAUSE-PURPOSE$Prevention       activity     boredom\n",
       "290  CAUSE-PURPOSE$Prevention     antibiotic   infection\n",
       "291  CAUSE-PURPOSE$Prevention    antibiotics    bacteria\n",
       "292  CAUSE-PURPOSE$Prevention            cat       mouse\n",
       "293  CAUSE-PURPOSE$Prevention           cure     disease\n",
       "294  CAUSE-PURPOSE$Prevention      education   ignorance\n",
       "295  CAUSE-PURPOSE$Prevention           fast        slow\n",
       "296  CAUSE-PURPOSE$Prevention           food      hunger\n",
       "297  CAUSE-PURPOSE$Prevention      fungicide      fungus\n",
       "298  CAUSE-PURPOSE$Prevention      fungicide        mold\n",
       "299  CAUSE-PURPOSE$Prevention           good         bad\n",
       "300  CAUSE-PURPOSE$Prevention          happy         sad\n",
       "301  CAUSE-PURPOSE$Prevention   immunization     disease\n",
       "302  CAUSE-PURPOSE$Prevention    insecticide        bugs\n",
       "303  CAUSE-PURPOSE$Prevention    insecticide       pests\n",
       "304  CAUSE-PURPOSE$Prevention      knowledge   ignorance\n",
       "305  CAUSE-PURPOSE$Prevention          locks       theft\n",
       "306  CAUSE-PURPOSE$Prevention      mediation    conflict\n",
       "307  CAUSE-PURPOSE$Prevention       medicine     disease\n",
       "308  CAUSE-PURPOSE$Prevention       medicine     illness\n",
       "309  CAUSE-PURPOSE$Prevention          money     poverty\n",
       "310  CAUSE-PURPOSE$Prevention           nice        evil\n",
       "311  CAUSE-PURPOSE$Prevention    preparation    disaster\n",
       "312  CAUSE-PURPOSE$Prevention           rest  exhaustion\n",
       "313  CAUSE-PURPOSE$Prevention           shot     disease\n",
       "314  CAUSE-PURPOSE$Prevention          sleep  exhaustion\n",
       "315  CAUSE-PURPOSE$Prevention          sleep   tiredness\n",
       "316  CAUSE-PURPOSE$Prevention            sun    darkness\n",
       "317  CAUSE-PURPOSE$Prevention       swimming    drowning\n",
       "318  CAUSE-PURPOSE$Prevention        vaccine       virus\n",
       "319  CAUSE-PURPOSE$Prevention          water      thirst"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df[df['relation'].str.contains('Prevention')]\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acetaminophen': ['headache'], 'acid': ['base'], 'activity': ['boredom'], 'antibiotic': ['infection'], 'antibiotics': ['bacteria'], 'cat': ['mouse'], 'cure': ['disease'], 'education': ['ignorance'], 'fast': ['slow'], 'food': ['hunger'], 'fungicide': ['fungus', 'mold'], 'good': ['bad'], 'happy': ['sad'], 'immunization': ['disease'], 'insecticide': ['bugs', 'pests'], 'knowledge': ['ignorance'], 'locks': ['theft'], 'mediation': ['conflict'], 'medicine': ['disease', 'illness'], 'money': ['poverty'], 'nice': ['evil'], 'preparation': ['disaster'], 'rest': ['exhaustion'], 'shot': ['disease'], 'sleep': ['exhaustion', 'tiredness'], 'sun': ['darkness'], 'swimming': ['drowning'], 'vaccine': ['virus'], 'water': ['thirst']}\n",
      "{'antibiotic': ['infection'], 'good': ['bad'], 'happy': ['sad'], 'nice': ['evil']}\n",
      "============================================\n",
      "{'acetaminophen': 'NN', 'acid': 'NN', 'activity': 'NN', 'antibiotics': 'NNS', 'cat': 'NN', 'cure': 'NN', 'education': 'NN', 'fast': 'NN', 'food': 'NN', 'fungicide': 'NN', 'immunization': 'NN', 'insecticide': 'NN', 'knowledge': 'NN', 'locks': 'NNS', 'mediation': 'NN', 'medicine': 'NN', 'money': 'NN', 'preparation': 'NN', 'rest': 'NN', 'shot': 'NN', 'sleep': 'NN', 'sun': 'NN', 'swimming': 'VBG', 'vaccine': 'NN', 'water': 'NN'}\n"
     ]
    }
   ],
   "source": [
    "# 先处理相同 word1 的数据，合并，再转换成列表\n",
    "data = df_clean.groupby(['word1'])['word2'].apply(list).to_dict()\n",
    "print(data)\n",
    "\n",
    "\n",
    "# 提取形容词\n",
    "adj_data_dict = {}\n",
    "not_adj = {}\n",
    "\n",
    "for (key,value) in data.items():\n",
    "    if nltk.pos_tag([key])[0][1] == \"JJ\":\n",
    "        adj_data_dict[key] = value\n",
    "    else:\n",
    "        not_adj[key] = nltk.pos_tag([key])[0][1]\n",
    "        \n",
    "print(adj_data_dict)\n",
    "print('============================================')\n",
    "print(not_adj)\n",
    "\n",
    "# 最终的数据是 adj_data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再处理 BAT3的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beautiful/pretty\tugly/disfigured/evil-looking/fugly/grotesque/monstrous/hideous/repulsive/ill-favored/ill-favoured/scrofulous/unlovely/unpicturesque/unsightly/displeasing/unattractive/awkward\n",
      "big\tsmall/atomic/subatomic/bantam/diminutive/lilliputian/midget/petite/tiny/flyspeck/bitty/bittie/teensy/teentsy/teeny/wee/weeny/weensy/teensy-weensy/teeny-weeny/itty-bitty/itsy-bitsy/dinky/dwarfish/elfin/elflike/gnomish/half-size/infinitesimal/minute/lesser/microscopic/microscopical/micro/miniature/minuscule/miniscule/olive-sized/pocket-size/pocket-sized/pocketable/puny/runty/shrimpy/slender/slim/smaller/littler/smallish/small-scale/undersize/undersized\n",
      "bright\tpale/colorless/colourless/dull/neutral/pale/white/bleached/faded/washed-out/washy/drab/somber/sombre/dulled/greyed/etiolate/etiolated/lurid/waxen/waxlike/waxy/whitened\n",
      "cheap\texpensive/big-ticket/high-ticket/costly/dear/high-priced/pricey/pricy/dearly-won/overpriced/valuable\n",
      "clean\tdirty/soiled/unclean/augean/bedraggled/draggled/befouled/fouled/begrimed/dingy/grimy/grubby/grungy/raunchy/black/smutty/buggy/cobwebby/dirty-faced/feculent/filthy/foul/nasty/flyblown/squalid/sordid/greasy/oily/lousy/maculate/mucky/muddy/ratty/scummy/smudgy/snotty/snot-nosed/sooty/travel-soiled/travel-stained/uncleanly/unswept/unwashed\n",
      "clear\tvague/obscure/unclear/undefined/indefinable/undefinable\n",
      "close\tdistant/remote/removed/far/faraway/\n",
      "dangerous/risky\tsafe/fail-safe/risk-free/riskless/unhazardous/safe-and-sound/unhurt/harmless/invulnerable/secure/uninjured\n",
      "dry\twet/bedewed/dewy/besprent/boggy/marshy/miry/mucky/muddy/quaggy/sloppy/sloughy/soggy/squashy/swampy/waterlogged/clammy/dank/damp/dampish/moist/sodden/soppy/drippy/drizzly/humid/misty/muggy/steamy/sticky/reeking/watery/rheumy/showery/rainy/steaming/tacky/undried/washed\n",
      "fat\tthin/lean/anorexic/anorectic/bony/cadaverous/emaciated/gaunt/haggard/pinched/skeletal/wasted/deep-eyed/hollow-eyed/sunken-eyed/gangling/gangly/lanky/lank/spindly/rawboned/reedy/reedlike/twiggy/twiglike/scarecrowish/scraggy/boney/scrawny/skinny/underweight/weedy/shriveled/shrivelled/shrunken/withered/wizen/wizened/slender/slight/slim/svelte/slender-waisted/slim-waisted/wasp-waisted/spare/trim/spindle-legged/spindle-shanked/stringy/wiry/wisplike/wispy\n",
      "generous\tstingy/beggarly/mean/cheap/chinchy/chintzy/cheeseparing/close/near/penny-pinching/skinny/closefisted/hardfisted/tightfisted/grudging/niggardly/scrimy/mingy/miserly/tight/parsimonious/penurious/selfish/uncharitable/ungenerous/meanspirited\n",
      "happy\tsad/bittersweet/doleful/mournful/heavyhearted/melancholy/melancholic/pensive/wistful/tragic/tragical/tragicomic/tragicomical/deplorable/distressing/lamentable/pitiful/sorry\n",
      "hard\tsoft/mellow/brushed/fleecy/napped/cheeselike/compressible/squeezable/cottony/cushioned/cushiony/padded/demulcent/emollient/salving/softening/downy/downlike/flossy/fluffy/flaccid/flocculent/woolly/wooly/yielding/mushy/overstuffed/softish/semisoft/spongy/squashy/squishy/spongelike/velvet/velvety\n",
      "hot\tcold/chilly/frosty/cool/frigid\n",
      "interesting\tuninteresting/dull/boring/deadening/ho-hum/irksome/slow/tedious/tiresome/wearisome/insipid/jejune/narcotic/soporiferous/soporific/prosaic/prosy/earthbound/ponderous/putdownable/unexciting/unstimulating\n",
      "introvert\textravert/extrovert/outgoing/extroverted/forthcoming/sociable\n",
      "large\tsmall/little/atomic/subatomic/bantam/diminutive/lilliputian/midget/petite/tiny/flyspeck/bitty/bittie/teensy/teentsy/teeny/wee/weeny/weensy/teensy-weensy/teeny-weeny/itty-bitty/itsy-bitsy/dinky/dwarfish/elfin/elflike/gnomish/half-size/infinitesimal/minute/lesser/microscopic/microscopical/micro/miniature/minuscule/miniscule/olive-sized/pocket-size/pocket-sized/pocketable/puny/runty/shrimpy/slender/slim/smaller/littler/smallish/small-scale/undersize/undersized\n",
      "long\tshort/abbreviated/shortened/truncated/brief/clipped/fleeting/fugitive/momentaneous/momentary/short_and_sweet/short-dated/short-range/short-run/short-term/abbreviated/brief/close/curtal/sawed-off/sawn-off/shortened/shortish/short-range/short-snouted/snub/stubby/telescoped/truncate/truncated/chunky/dumpy/low-set/squat/squatty/stumpy/compact/heavyset/stocky/thick/thickset/half-length/pint-size/pint-sized/runty/sawed-off/sawn-off/short-stalked/squab/squabby\n",
      "lumpy\tflat/level/plane/even/\n",
      "noisy\tsilent/uncommunicative/dumb/mute/inarticulate/unarticulate\n",
      "normal\tabnormal/aberrant/deviant/deviate/anomalous/antidromic/atypical/irregular/brachydactylic/brachydactylous/defective/freakish/kinky/perverted/subnormal/supernormal/vicarious/unusual/exceptional/insane/unnatural\n",
      "organized\tunorganized/unstructured/uncoordinated/unformed/unincorporated\n",
      "pale\ttanned/bronzed/suntanned/brunet/brunette\n",
      "rich\tpoor/broke/bust/skint/stone-broke/stony-broke/destitute/impoverished/indigent/necessitous/needy/poverty-stricken/hard_up/impecunious/penniless/penurious/pinched/moneyless/unprovided\n",
      "sane\tcrazy/loony/looney/nutcase/weirdo/mad/insane\n",
      "short\ttall/gangling/gangly/lanky/rangy/height/leggy/long-legged/long-shanked/tall-growing/long/long-stalked/tall-stalked/stately/statuesque/tallish\n",
      "simple\tdifficult/challenging/hard/complicated/demanding/daunting/taxing\n",
      "sincere\tinsincere/bootlicking/fawning/obsequious/sycophantic/toadyish/buttery/fulsome/oily/oleaginous/smarmy/soapy/unctuous/dissimulative/false/feigned/gilded/meretricious/specious/hypocritical/plausible/counterfeit/imitative/dishonest/dishonorable/disingenuous/artful/false/unreal\n",
      "slow\tfast/quick/accelerated/alacritous/blistering/hot/red-hot/double-quick/express/fast-breaking/fast-paced/fleet/swift/high-speed/high-velocity/hurrying/scurrying/immediate/prompt/quick/straightaway/instantaneous/instant/meteoric/speedy/rapid/winged/windy\n",
      "sweet\tsour/acerb/acerbic/astringent/acetose/acetous/vinegary/vinegarish/acidic/acid/acidulent/acidulous/lemony/lemonlike/sourish/tangy/tart/subacid/bitter\n",
      "tasty\ttasteless/bland/flat/flavorless/flavourless/insipid/savorless/savourless/vapid/unflavored/unflavoured/nonflavored/nonflavoured/unsalted/unseasoned/unappetizing/unappetising/unpalatable\n",
      "tight\tloose/lax/baggy/loose-fitting/sloppy/flyaway/free/liberal/informal/unofficial\n",
      "warm\tcool/cold/chilly/frosty/cool/frigid\n",
      "white\tblack/dark/lightless\n",
      "wide\tnarrow/constricting/constrictive/narrowing/narrowed/narrow-mouthed/slender/thin/strait/straplike/tapered/tapering/limited\n",
      "willing\tunwilling/defiantnoncompliant/involuntary/nonvoluntary/unvoluntary/disinclined/averse/backward/hesitant/indisposed/loath/reluctant/uneager/unwishful\n",
      "young\told/aged/elderly/older/senior/age/aging/ageing/senescent/ancient/anile/centenarian/darkened/doddering/doddery/gaga/senile/emeritus/grey/gray/grey-haired/gray-haired/grey-headed/gray-headed/grizzly/hoar/hoary/white-haired/middle-aged/nonagenarian/octogenarian/oldish/overage/overaged/superannuated/over-the-hill/sexagenarian/venerable/experienced/experient/mature/senior\n",
      "\n",
      "able\tunable/incapable/incompetent/unequal\n",
      "abundant\tscarce/rare/tight/meager/meagre/meagerly/stingy/scrimpy/insufficient/deficient\n",
      "aware\tunaware/oblivious/unmindful/unconscious/unsuspecting/asleep/insensible/unconscious/unwitting/ignorant/indifferent/oblivious\n",
      "beautiful\tugly/disfigured/evil-looking/fugly/grotesque/monstrous/hideous/repulsive/ill-favored/ill-favoured/scrofulous/unlovely/unpicturesque/unsightly/displeasing/unattractive/awkward\n",
      "big\tsmall/atomic/subatomic/bantam/diminutive/lilliputian/midget/petite/tiny/flyspeck/bitty/bittie/teensy/teentsy/teeny/wee/weeny/weensy/teensy-weensy/teeny-weeny/itty-bitty/itsy-bitsy/dinky/dwarfish/elfin/elflike/gnomish/half-size/infinitesimal/minute/lesser/microscopic/microscopical/micro/miniature/minuscule/miniscule/olive-sized/pocket-size/pocket-sized/pocketable/puny/runty/shrimpy/slender/slim/smaller/littler/smallish/small-scale/undersize/undersized\n",
      "bright\tpale/colorless/colourless/dull/neutral/pale/white/bleached/faded/washed-out/washy/drab/somber/sombre/dulled/greyed/etiolate/etiolated/lurid/waxen/waxlike/waxy/whitened\n",
      "cheap\texpensive/big-ticket/high-ticket/costly/dear/high-priced/pricey/pricy/dearly-won/overpriced/valuable\n",
      "clean\tdirty/soiled/unclean/augean/bedraggled/draggled/befouled/fouled/begrimed/dingy/grimy/grubby/grungy/raunchy/black/smutty/buggy/cobwebby/dirty-faced/feculent/filthy/foul/nasty/flyblown/squalid/sordid/greasy/oily/lousy/maculate/mucky/muddy/ratty/scummy/smudgy/snotty/snot-nosed/sooty/travel-soiled/travel-stained/uncleanly/unswept/unwashed\n",
      "clear\tvague/obscure/unclear/undefined/indefinable/undefinable\n",
      "close\tdistant/remote/removed/far/faraway/\n",
      "colorful\tcolorless/colourless/dull/neutral/pale/white/bleached/faded/washed-out/washy/drab/somber/sombre/dulled/greyed/etiolate/etiolated/lurid/waxen/waxlike/waxy/whitened\n",
      "common\trare/infrequent/scarce/uncommon/extraordinary\n",
      "competent\tincompetent/unskilled/unqualified/inefficient/unqualified/unskilled\n",
      "concerned\tunconcerned/blase/blithe/casual/insouciant/nonchalant/degage/detached/uninvolved/indifferent/careless/uninvolved/untroubled\n",
      "cooked\traw/half-baked/fresh/natural/underdone/rare/uncooked/untoasted\n",
      "dangerous\tsafe/fail-safe/risk-free/riskless/unhazardous/safe-and-sound/unhurt/harmless/invulnerable/secure/uninjured\n",
      "decisive\thesitating/indecisive/hesitant/inconclusive/irresolute\n",
      "dry\twet/bedewed/dewy/besprent/boggy/marshy/miry/mucky/muddy/quaggy/sloppy/sloughy/soggy/squashy/swampy/waterlogged/clammy/dank/damp/dampish/moist/sodden/soppy/drippy/drizzly/humid/misty/muggy/steamy/sticky/reeking/watery/rheumy/showery/rainy/steaming/tacky/undried/washed\n",
      "energetic\tlethargic/unergetic/dazed/foggy/groggy/logy/stuporous/dreamy/lackadaisical/languid/languorous/listless/inactive\n",
      "familiar\tunfamiliar/strange/unknown/unacquainted/unacquainted/foreign/strange/unknown\n",
      "fat\tthin/lean/anorexic/anorectic/bony/cadaverous/emaciated/gaunt/haggard/pinched/skeletal/wasted/deep-eyed/hollow-eyed/sunken-eyed/gangling/gangly/lanky/lank/spindly/rawboned/reedy/reedlike/twiggy/twiglike/scarecrowish/scraggy/boney/scrawny/skinny/underweight/weedy/shriveled/shrivelled/shrunken/withered/wizen/wizened/slender/slight/slim/svelte/slender-waisted/slim-waisted/wasp-waisted/spare/trim/spindle-legged/spindle-shanked/stringy/wiry/wisplike/wispy\n",
      "full\tempty/bare/stripped/blank/clean/white/empty-handed/glassy/glazed/lifeless/looted/pillaged/plundered/ransacked/vacant/vacuous/void\n",
      "gaseous\tsolid/hard/coagulated/solidified/concrete/congealed/jelled/jellied/dry/semisolid/solid-state\n",
      "generous\tstingy/beggarly/mean/cheap/chinchy/chintzy/cheeseparing/close/near/penny-pinching/skinny/closefisted/hardfisted/tightfisted/grudging/niggardly/scrimy/mingy/miserly/tight/parsimonious/penurious/selfish/uncharitable/ungenerous/meanspirited\n",
      "happy\tsad/bittersweet/doleful/mournful/heavyhearted/melancholy/melancholic/pensive/wistful/tragic/tragical/tragicomic/tragicomical/deplorable/distressing/lamentable/pitiful/sorry\n",
      "hard\tsoft/mellow/brushed/fleecy/napped/cheeselike/compressible/squeezable/cottony/cushioned/cushiony/padded/demulcent/emollient/salving/softening/downy/downlike/flossy/fluffy/flaccid/flocculent/woolly/wooly/yielding/mushy/overstuffed/softish/semisoft/spongy/squashy/squishy/spongelike/velvet/velvety\n",
      "hot\tcold/chilly/frosty/cool/frigid\n",
      "interesting\tuninteresting/dull/boring/deadening/ho-hum/irksome/slow/tedious/tiresome/wearisome/insipid/jejune/narcotic/soporiferous/soporific/prosaic/prosy/earthbound/ponderous/putdownable/unexciting/unstimulating\n",
      "introvert\textravert/extrovert/outgoing/extroverted/forthcoming/sociable\n",
      "large\tsmall/little/atomic/subatomic/bantam/diminutive/lilliputian/midget/petite/tiny/flyspeck/bitty/bittie/teensy/teentsy/teeny/wee/weeny/weensy/teensy-weensy/teeny-weeny/itty-bitty/itsy-bitsy/dinky/dwarfish/elfin/elflike/gnomish/half-size/infinitesimal/minute/lesser/microscopic/microscopical/micro/miniature/minuscule/miniscule/olive-sized/pocket-size/pocket-sized/pocketable/puny/runty/shrimpy/slender/slim/smaller/littler/smallish/small-scale/undersize/undersized\n",
      "long\tshort/abbreviated/shortened/truncated/brief/clipped/fleeting/fugitive/momentaneous/momentary/short_and_sweet/short-dated/short-range/short-run/short-term/abbreviated/brief/close/curtal/sawed-off/sawn-off/shortened/shortish/short-range/short-snouted/snub/stubby/telescoped/truncate/truncated/chunky/dumpy/low-set/squat/squatty/stumpy/compact/heavyset/stocky/thick/thickset/half-length/pint-size/pint-sized/runty/sawed-off/sawn-off/short-stalked/squab/squabby\n",
      "lumpy\tflat/level/plane/even/\n",
      "noisy\tsilent/uncommunicative/dumb/mute/inarticulate/unarticulate\n",
      "normal\tabnormal/aberrant/deviant/deviate/anomalous/antidromic/atypical/irregular/brachydactylic/brachydactylous/defective/freakish/kinky/perverted/subnormal/supernormal/vicarious/unusual/exceptional/insane/unnatural\n",
      "organized\tunorganized/unstructured/uncoordinated/unformed/unincorporated\n",
      "pale\ttanned/bronzed/suntanned/brunet/brunette\n",
      "rich\tpoor/broke/bust/skint/stone-broke/stony-broke/destitute/impoverished/indigent/necessitous/needy/poverty-stricken/hard_up/impecunious/penniless/penurious/pinched/moneyless/unprovided\n",
      "sane\tcrazy/loony/looney/nutcase/weirdo/mad/insane\n",
      "short\ttall/gangling/gangly/lanky/rangy/height/leggy/long-legged/long-shanked/tall-growing/long/long-stalked/tall-stalked/stately/statuesque/tallish\n",
      "simple\tdifficult/challenging/hard/complicated/demanding/daunting/taxing\n",
      "sincere\tinsincere/bootlicking/fawning/obsequious/sycophantic/toadyish/buttery/fulsome/oily/oleaginous/smarmy/soapy/unctuous/dissimulative/false/feigned/gilded/meretricious/specious/hypocritical/plausible/counterfeit/imitative/dishonest/dishonorable/disingenuous/artful/false/unreal\n",
      "slow\tfast/quick/accelerated/alacritous/blistering/hot/red-hot/double-quick/express/fast-breaking/fast-paced/fleet/swift/high-speed/high-velocity/hurrying/scurrying/immediate/prompt/quick/straightaway/instantaneous/instant/meteoric/speedy/rapid/winged/windy\n",
      "sweet\tsour/acerb/acerbic/astringent/acetose/acetous/vinegary/vinegarish/acidic/acid/acidulent/acidulous/lemony/lemonlike/sourish/tangy/tart/subacid/bitter\n",
      "tasty\ttasteless/bland/flat/flavorless/flavourless/insipid/savorless/savourless/vapid/unflavored/unflavoured/nonflavored/nonflavoured/unsalted/unseasoned/unappetizing/unappetising/unpalatable\n",
      "tight\tloose/lax/baggy/loose-fitting/sloppy/flyaway/free/liberal/informal/unofficial\n",
      "warm\tcool/cold/chilly/frosty/cool/frigid\n",
      "white\tblack/dark/lightless\n",
      "wide\tnarrow/constricting/constrictive/narrowing/narrowed/narrow-mouthed/slender/thin/strait/straplike/tapered/tapering/limited\n",
      "willing\tunwilling/defiantnoncompliant/involuntary/nonvoluntary/unvoluntary/disinclined/averse/backward/hesitant/indisposed/loath/reluctant/uneager/unwishful\n",
      "young\told/aged/elderly/older/senior/age/aging/ageing/senescent/ancient/anile/centenarian/darkened/doddering/doddery/gaga/senile/emeritus/grey/gray/grey-haired/gray-haired/grey-headed/gray-headed/grizzly/hoar/hoary/white-haired/middle-aged/nonagenarian/octogenarian/oldish/overage/overaged/superannuated/over-the-hill/sexagenarian/venerable/experienced/experient/mature/senior\n"
     ]
    }
   ],
   "source": [
    "bat3file1 = open('antonyms_adj.txt')\n",
    "bat3file2 = open('antonyms_comparable.txt')\n",
    "\n",
    "\n",
    "antonyms_adj = bat3file1.read()\n",
    "antonyms_comparable = bat3file2.read()\n",
    "\n",
    "print(antonyms_adj)\n",
    "print(antonyms_comparable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('able', ['unable', 'incapable', 'incompetent', 'unequal']),\n",
       "             ('abundant',\n",
       "              ['scarce',\n",
       "               'rare',\n",
       "               'tight',\n",
       "               'meager',\n",
       "               'meagre',\n",
       "               'meagerly',\n",
       "               'stingy',\n",
       "               'scrimpy',\n",
       "               'insufficient',\n",
       "               'deficient']),\n",
       "             ('aware',\n",
       "              ['unaware',\n",
       "               'oblivious',\n",
       "               'unmindful',\n",
       "               'unconscious',\n",
       "               'unsuspecting',\n",
       "               'asleep',\n",
       "               'insensible',\n",
       "               'unconscious',\n",
       "               'unwitting',\n",
       "               'ignorant',\n",
       "               'indifferent',\n",
       "               'oblivious']),\n",
       "             ('beautiful',\n",
       "              ['ugly',\n",
       "               'disfigured',\n",
       "               'evil-looking',\n",
       "               'fugly',\n",
       "               'grotesque',\n",
       "               'monstrous',\n",
       "               'hideous',\n",
       "               'repulsive',\n",
       "               'ill-favored',\n",
       "               'ill-favoured',\n",
       "               'scrofulous',\n",
       "               'unlovely',\n",
       "               'unpicturesque',\n",
       "               'unsightly',\n",
       "               'displeasing',\n",
       "               'unattractive',\n",
       "               'awkward']),\n",
       "             ('big',\n",
       "              ['small',\n",
       "               'atomic',\n",
       "               'subatomic',\n",
       "               'bantam',\n",
       "               'diminutive',\n",
       "               'lilliputian',\n",
       "               'midget',\n",
       "               'petite',\n",
       "               'tiny',\n",
       "               'flyspeck',\n",
       "               'bitty',\n",
       "               'bittie',\n",
       "               'teensy',\n",
       "               'teentsy',\n",
       "               'teeny',\n",
       "               'wee',\n",
       "               'weeny',\n",
       "               'weensy',\n",
       "               'teensy-weensy',\n",
       "               'teeny-weeny',\n",
       "               'itty-bitty',\n",
       "               'itsy-bitsy',\n",
       "               'dinky',\n",
       "               'dwarfish',\n",
       "               'elfin',\n",
       "               'elflike',\n",
       "               'gnomish',\n",
       "               'half-size',\n",
       "               'infinitesimal',\n",
       "               'minute',\n",
       "               'lesser',\n",
       "               'microscopic',\n",
       "               'microscopical',\n",
       "               'micro',\n",
       "               'miniature',\n",
       "               'minuscule',\n",
       "               'miniscule',\n",
       "               'olive-sized',\n",
       "               'pocket-size',\n",
       "               'pocket-sized',\n",
       "               'pocketable',\n",
       "               'puny',\n",
       "               'runty',\n",
       "               'shrimpy',\n",
       "               'slender',\n",
       "               'slim',\n",
       "               'smaller',\n",
       "               'littler',\n",
       "               'smallish',\n",
       "               'small-scale',\n",
       "               'undersize',\n",
       "               'undersized']),\n",
       "             ('bright',\n",
       "              ['pale',\n",
       "               'colorless',\n",
       "               'colourless',\n",
       "               'dull',\n",
       "               'neutral',\n",
       "               'pale',\n",
       "               'white',\n",
       "               'bleached',\n",
       "               'faded',\n",
       "               'washed-out',\n",
       "               'washy',\n",
       "               'drab',\n",
       "               'somber',\n",
       "               'sombre',\n",
       "               'dulled',\n",
       "               'greyed',\n",
       "               'etiolate',\n",
       "               'etiolated',\n",
       "               'lurid',\n",
       "               'waxen',\n",
       "               'waxlike',\n",
       "               'waxy',\n",
       "               'whitened']),\n",
       "             ('cheap',\n",
       "              ['expensive',\n",
       "               'big-ticket',\n",
       "               'high-ticket',\n",
       "               'costly',\n",
       "               'dear',\n",
       "               'high-priced',\n",
       "               'pricey',\n",
       "               'pricy',\n",
       "               'dearly-won',\n",
       "               'overpriced',\n",
       "               'valuable']),\n",
       "             ('clean',\n",
       "              ['dirty',\n",
       "               'soiled',\n",
       "               'unclean',\n",
       "               'augean',\n",
       "               'bedraggled',\n",
       "               'draggled',\n",
       "               'befouled',\n",
       "               'fouled',\n",
       "               'begrimed',\n",
       "               'dingy',\n",
       "               'grimy',\n",
       "               'grubby',\n",
       "               'grungy',\n",
       "               'raunchy',\n",
       "               'black',\n",
       "               'smutty',\n",
       "               'buggy',\n",
       "               'cobwebby',\n",
       "               'dirty-faced',\n",
       "               'feculent',\n",
       "               'filthy',\n",
       "               'foul',\n",
       "               'nasty',\n",
       "               'flyblown',\n",
       "               'squalid',\n",
       "               'sordid',\n",
       "               'greasy',\n",
       "               'oily',\n",
       "               'lousy',\n",
       "               'maculate',\n",
       "               'mucky',\n",
       "               'muddy',\n",
       "               'ratty',\n",
       "               'scummy',\n",
       "               'smudgy',\n",
       "               'snotty',\n",
       "               'snot-nosed',\n",
       "               'sooty',\n",
       "               'travel-soiled',\n",
       "               'travel-stained',\n",
       "               'uncleanly',\n",
       "               'unswept',\n",
       "               'unwashed']),\n",
       "             ('clear',\n",
       "              ['vague',\n",
       "               'obscure',\n",
       "               'unclear',\n",
       "               'undefined',\n",
       "               'indefinable',\n",
       "               'undefinable']),\n",
       "             ('close', ['distant', 'remote', 'removed', 'far', 'faraway', '']),\n",
       "             ('colorful',\n",
       "              ['colorless',\n",
       "               'colourless',\n",
       "               'dull',\n",
       "               'neutral',\n",
       "               'pale',\n",
       "               'white',\n",
       "               'bleached',\n",
       "               'faded',\n",
       "               'washed-out',\n",
       "               'washy',\n",
       "               'drab',\n",
       "               'somber',\n",
       "               'sombre',\n",
       "               'dulled',\n",
       "               'greyed',\n",
       "               'etiolate',\n",
       "               'etiolated',\n",
       "               'lurid',\n",
       "               'waxen',\n",
       "               'waxlike',\n",
       "               'waxy',\n",
       "               'whitened']),\n",
       "             ('common',\n",
       "              ['rare', 'infrequent', 'scarce', 'uncommon', 'extraordinary']),\n",
       "             ('competent',\n",
       "              ['incompetent',\n",
       "               'unskilled',\n",
       "               'unqualified',\n",
       "               'inefficient',\n",
       "               'unqualified',\n",
       "               'unskilled']),\n",
       "             ('concerned',\n",
       "              ['unconcerned',\n",
       "               'blase',\n",
       "               'blithe',\n",
       "               'casual',\n",
       "               'insouciant',\n",
       "               'nonchalant',\n",
       "               'degage',\n",
       "               'detached',\n",
       "               'uninvolved',\n",
       "               'indifferent',\n",
       "               'careless',\n",
       "               'uninvolved',\n",
       "               'untroubled']),\n",
       "             ('cooked',\n",
       "              ['raw',\n",
       "               'half-baked',\n",
       "               'fresh',\n",
       "               'natural',\n",
       "               'underdone',\n",
       "               'rare',\n",
       "               'uncooked',\n",
       "               'untoasted']),\n",
       "             ('dangerous',\n",
       "              ['safe',\n",
       "               'fail-safe',\n",
       "               'risk-free',\n",
       "               'riskless',\n",
       "               'unhazardous',\n",
       "               'safe-and-sound',\n",
       "               'unhurt',\n",
       "               'harmless',\n",
       "               'invulnerable',\n",
       "               'secure',\n",
       "               'uninjured']),\n",
       "             ('decisive',\n",
       "              ['hesitating',\n",
       "               'indecisive',\n",
       "               'hesitant',\n",
       "               'inconclusive',\n",
       "               'irresolute']),\n",
       "             ('dry',\n",
       "              ['wet',\n",
       "               'bedewed',\n",
       "               'dewy',\n",
       "               'besprent',\n",
       "               'boggy',\n",
       "               'marshy',\n",
       "               'miry',\n",
       "               'mucky',\n",
       "               'muddy',\n",
       "               'quaggy',\n",
       "               'sloppy',\n",
       "               'sloughy',\n",
       "               'soggy',\n",
       "               'squashy',\n",
       "               'swampy',\n",
       "               'waterlogged',\n",
       "               'clammy',\n",
       "               'dank',\n",
       "               'damp',\n",
       "               'dampish',\n",
       "               'moist',\n",
       "               'sodden',\n",
       "               'soppy',\n",
       "               'drippy',\n",
       "               'drizzly',\n",
       "               'humid',\n",
       "               'misty',\n",
       "               'muggy',\n",
       "               'steamy',\n",
       "               'sticky',\n",
       "               'reeking',\n",
       "               'watery',\n",
       "               'rheumy',\n",
       "               'showery',\n",
       "               'rainy',\n",
       "               'steaming',\n",
       "               'tacky',\n",
       "               'undried',\n",
       "               'washed']),\n",
       "             ('energetic',\n",
       "              ['lethargic',\n",
       "               'unergetic',\n",
       "               'dazed',\n",
       "               'foggy',\n",
       "               'groggy',\n",
       "               'logy',\n",
       "               'stuporous',\n",
       "               'dreamy',\n",
       "               'lackadaisical',\n",
       "               'languid',\n",
       "               'languorous',\n",
       "               'listless',\n",
       "               'inactive']),\n",
       "             ('familiar',\n",
       "              ['unfamiliar',\n",
       "               'strange',\n",
       "               'unknown',\n",
       "               'unacquainted',\n",
       "               'unacquainted',\n",
       "               'foreign',\n",
       "               'strange',\n",
       "               'unknown']),\n",
       "             ('fat',\n",
       "              ['thin',\n",
       "               'lean',\n",
       "               'anorexic',\n",
       "               'anorectic',\n",
       "               'bony',\n",
       "               'cadaverous',\n",
       "               'emaciated',\n",
       "               'gaunt',\n",
       "               'haggard',\n",
       "               'pinched',\n",
       "               'skeletal',\n",
       "               'wasted',\n",
       "               'deep-eyed',\n",
       "               'hollow-eyed',\n",
       "               'sunken-eyed',\n",
       "               'gangling',\n",
       "               'gangly',\n",
       "               'lanky',\n",
       "               'lank',\n",
       "               'spindly',\n",
       "               'rawboned',\n",
       "               'reedy',\n",
       "               'reedlike',\n",
       "               'twiggy',\n",
       "               'twiglike',\n",
       "               'scarecrowish',\n",
       "               'scraggy',\n",
       "               'boney',\n",
       "               'scrawny',\n",
       "               'skinny',\n",
       "               'underweight',\n",
       "               'weedy',\n",
       "               'shriveled',\n",
       "               'shrivelled',\n",
       "               'shrunken',\n",
       "               'withered',\n",
       "               'wizen',\n",
       "               'wizened',\n",
       "               'slender',\n",
       "               'slight',\n",
       "               'slim',\n",
       "               'svelte',\n",
       "               'slender-waisted',\n",
       "               'slim-waisted',\n",
       "               'wasp-waisted',\n",
       "               'spare',\n",
       "               'trim',\n",
       "               'spindle-legged',\n",
       "               'spindle-shanked',\n",
       "               'stringy',\n",
       "               'wiry',\n",
       "               'wisplike',\n",
       "               'wispy']),\n",
       "             ('full',\n",
       "              ['empty',\n",
       "               'bare',\n",
       "               'stripped',\n",
       "               'blank',\n",
       "               'clean',\n",
       "               'white',\n",
       "               'empty-handed',\n",
       "               'glassy',\n",
       "               'glazed',\n",
       "               'lifeless',\n",
       "               'looted',\n",
       "               'pillaged',\n",
       "               'plundered',\n",
       "               'ransacked',\n",
       "               'vacant',\n",
       "               'vacuous',\n",
       "               'void']),\n",
       "             ('gaseous',\n",
       "              ['solid',\n",
       "               'hard',\n",
       "               'coagulated',\n",
       "               'solidified',\n",
       "               'concrete',\n",
       "               'congealed',\n",
       "               'jelled',\n",
       "               'jellied',\n",
       "               'dry',\n",
       "               'semisolid',\n",
       "               'solid-state']),\n",
       "             ('generous',\n",
       "              ['stingy',\n",
       "               'beggarly',\n",
       "               'mean',\n",
       "               'cheap',\n",
       "               'chinchy',\n",
       "               'chintzy',\n",
       "               'cheeseparing',\n",
       "               'close',\n",
       "               'near',\n",
       "               'penny-pinching',\n",
       "               'skinny',\n",
       "               'closefisted',\n",
       "               'hardfisted',\n",
       "               'tightfisted',\n",
       "               'grudging',\n",
       "               'niggardly',\n",
       "               'scrimy',\n",
       "               'mingy',\n",
       "               'miserly',\n",
       "               'tight',\n",
       "               'parsimonious',\n",
       "               'penurious',\n",
       "               'selfish',\n",
       "               'uncharitable',\n",
       "               'ungenerous',\n",
       "               'meanspirited']),\n",
       "             ('happy',\n",
       "              ['sad',\n",
       "               'bittersweet',\n",
       "               'doleful',\n",
       "               'mournful',\n",
       "               'heavyhearted',\n",
       "               'melancholy',\n",
       "               'melancholic',\n",
       "               'pensive',\n",
       "               'wistful',\n",
       "               'tragic',\n",
       "               'tragical',\n",
       "               'tragicomic',\n",
       "               'tragicomical',\n",
       "               'deplorable',\n",
       "               'distressing',\n",
       "               'lamentable',\n",
       "               'pitiful',\n",
       "               'sorry']),\n",
       "             ('hard',\n",
       "              ['soft',\n",
       "               'mellow',\n",
       "               'brushed',\n",
       "               'fleecy',\n",
       "               'napped',\n",
       "               'cheeselike',\n",
       "               'compressible',\n",
       "               'squeezable',\n",
       "               'cottony',\n",
       "               'cushioned',\n",
       "               'cushiony',\n",
       "               'padded',\n",
       "               'demulcent',\n",
       "               'emollient',\n",
       "               'salving',\n",
       "               'softening',\n",
       "               'downy',\n",
       "               'downlike',\n",
       "               'flossy',\n",
       "               'fluffy',\n",
       "               'flaccid',\n",
       "               'flocculent',\n",
       "               'woolly',\n",
       "               'wooly',\n",
       "               'yielding',\n",
       "               'mushy',\n",
       "               'overstuffed',\n",
       "               'softish',\n",
       "               'semisoft',\n",
       "               'spongy',\n",
       "               'squashy',\n",
       "               'squishy',\n",
       "               'spongelike',\n",
       "               'velvet',\n",
       "               'velvety']),\n",
       "             ('hot', ['cold', 'chilly', 'frosty', 'cool', 'frigid']),\n",
       "             ('interesting',\n",
       "              ['uninteresting',\n",
       "               'dull',\n",
       "               'boring',\n",
       "               'deadening',\n",
       "               'ho-hum',\n",
       "               'irksome',\n",
       "               'slow',\n",
       "               'tedious',\n",
       "               'tiresome',\n",
       "               'wearisome',\n",
       "               'insipid',\n",
       "               'jejune',\n",
       "               'narcotic',\n",
       "               'soporiferous',\n",
       "               'soporific',\n",
       "               'prosaic',\n",
       "               'prosy',\n",
       "               'earthbound',\n",
       "               'ponderous',\n",
       "               'putdownable',\n",
       "               'unexciting',\n",
       "               'unstimulating']),\n",
       "             ('introvert',\n",
       "              ['extravert',\n",
       "               'extrovert',\n",
       "               'outgoing',\n",
       "               'extroverted',\n",
       "               'forthcoming',\n",
       "               'sociable']),\n",
       "             ('large',\n",
       "              ['small',\n",
       "               'little',\n",
       "               'atomic',\n",
       "               'subatomic',\n",
       "               'bantam',\n",
       "               'diminutive',\n",
       "               'lilliputian',\n",
       "               'midget',\n",
       "               'petite',\n",
       "               'tiny',\n",
       "               'flyspeck',\n",
       "               'bitty',\n",
       "               'bittie',\n",
       "               'teensy',\n",
       "               'teentsy',\n",
       "               'teeny',\n",
       "               'wee',\n",
       "               'weeny',\n",
       "               'weensy',\n",
       "               'teensy-weensy',\n",
       "               'teeny-weeny',\n",
       "               'itty-bitty',\n",
       "               'itsy-bitsy',\n",
       "               'dinky',\n",
       "               'dwarfish',\n",
       "               'elfin',\n",
       "               'elflike',\n",
       "               'gnomish',\n",
       "               'half-size',\n",
       "               'infinitesimal',\n",
       "               'minute',\n",
       "               'lesser',\n",
       "               'microscopic',\n",
       "               'microscopical',\n",
       "               'micro',\n",
       "               'miniature',\n",
       "               'minuscule',\n",
       "               'miniscule',\n",
       "               'olive-sized',\n",
       "               'pocket-size',\n",
       "               'pocket-sized',\n",
       "               'pocketable',\n",
       "               'puny',\n",
       "               'runty',\n",
       "               'shrimpy',\n",
       "               'slender',\n",
       "               'slim',\n",
       "               'smaller',\n",
       "               'littler',\n",
       "               'smallish',\n",
       "               'small-scale',\n",
       "               'undersize',\n",
       "               'undersized']),\n",
       "             ('long',\n",
       "              ['short',\n",
       "               'abbreviated',\n",
       "               'shortened',\n",
       "               'truncated',\n",
       "               'brief',\n",
       "               'clipped',\n",
       "               'fleeting',\n",
       "               'fugitive',\n",
       "               'momentaneous',\n",
       "               'momentary',\n",
       "               'short_and_sweet',\n",
       "               'short-dated',\n",
       "               'short-range',\n",
       "               'short-run',\n",
       "               'short-term',\n",
       "               'abbreviated',\n",
       "               'brief',\n",
       "               'close',\n",
       "               'curtal',\n",
       "               'sawed-off',\n",
       "               'sawn-off',\n",
       "               'shortened',\n",
       "               'shortish',\n",
       "               'short-range',\n",
       "               'short-snouted',\n",
       "               'snub',\n",
       "               'stubby',\n",
       "               'telescoped',\n",
       "               'truncate',\n",
       "               'truncated',\n",
       "               'chunky',\n",
       "               'dumpy',\n",
       "               'low-set',\n",
       "               'squat',\n",
       "               'squatty',\n",
       "               'stumpy',\n",
       "               'compact',\n",
       "               'heavyset',\n",
       "               'stocky',\n",
       "               'thick',\n",
       "               'thickset',\n",
       "               'half-length',\n",
       "               'pint-size',\n",
       "               'pint-sized',\n",
       "               'runty',\n",
       "               'sawed-off',\n",
       "               'sawn-off',\n",
       "               'short-stalked',\n",
       "               'squab',\n",
       "               'squabby']),\n",
       "             ('lumpy', ['flat', 'level', 'plane', 'even', '']),\n",
       "             ('noisy',\n",
       "              ['silent',\n",
       "               'uncommunicative',\n",
       "               'dumb',\n",
       "               'mute',\n",
       "               'inarticulate',\n",
       "               'unarticulate']),\n",
       "             ('normal',\n",
       "              ['abnormal',\n",
       "               'aberrant',\n",
       "               'deviant',\n",
       "               'deviate',\n",
       "               'anomalous',\n",
       "               'antidromic',\n",
       "               'atypical',\n",
       "               'irregular',\n",
       "               'brachydactylic',\n",
       "               'brachydactylous',\n",
       "               'defective',\n",
       "               'freakish',\n",
       "               'kinky',\n",
       "               'perverted',\n",
       "               'subnormal',\n",
       "               'supernormal',\n",
       "               'vicarious',\n",
       "               'unusual',\n",
       "               'exceptional',\n",
       "               'insane',\n",
       "               'unnatural']),\n",
       "             ('organized',\n",
       "              ['unorganized',\n",
       "               'unstructured',\n",
       "               'uncoordinated',\n",
       "               'unformed',\n",
       "               'unincorporated']),\n",
       "             ('pale',\n",
       "              ['tanned', 'bronzed', 'suntanned', 'brunet', 'brunette']),\n",
       "             ('pretty',\n",
       "              ['ugly',\n",
       "               'disfigured',\n",
       "               'evil-looking',\n",
       "               'fugly',\n",
       "               'grotesque',\n",
       "               'monstrous',\n",
       "               'hideous',\n",
       "               'repulsive',\n",
       "               'ill-favored',\n",
       "               'ill-favoured',\n",
       "               'scrofulous',\n",
       "               'unlovely',\n",
       "               'unpicturesque',\n",
       "               'unsightly',\n",
       "               'displeasing',\n",
       "               'unattractive',\n",
       "               'awkward']),\n",
       "             ('rich',\n",
       "              ['poor',\n",
       "               'broke',\n",
       "               'bust',\n",
       "               'skint',\n",
       "               'stone-broke',\n",
       "               'stony-broke',\n",
       "               'destitute',\n",
       "               'impoverished',\n",
       "               'indigent',\n",
       "               'necessitous',\n",
       "               'needy',\n",
       "               'poverty-stricken',\n",
       "               'hard_up',\n",
       "               'impecunious',\n",
       "               'penniless',\n",
       "               'penurious',\n",
       "               'pinched',\n",
       "               'moneyless',\n",
       "               'unprovided']),\n",
       "             ('risky',\n",
       "              ['safe',\n",
       "               'fail-safe',\n",
       "               'risk-free',\n",
       "               'riskless',\n",
       "               'unhazardous',\n",
       "               'safe-and-sound',\n",
       "               'unhurt',\n",
       "               'harmless',\n",
       "               'invulnerable',\n",
       "               'secure',\n",
       "               'uninjured']),\n",
       "             ('sane',\n",
       "              ['crazy',\n",
       "               'loony',\n",
       "               'looney',\n",
       "               'nutcase',\n",
       "               'weirdo',\n",
       "               'mad',\n",
       "               'insane']),\n",
       "             ('short',\n",
       "              ['tall',\n",
       "               'gangling',\n",
       "               'gangly',\n",
       "               'lanky',\n",
       "               'rangy',\n",
       "               'height',\n",
       "               'leggy',\n",
       "               'long-legged',\n",
       "               'long-shanked',\n",
       "               'tall-growing',\n",
       "               'long',\n",
       "               'long-stalked',\n",
       "               'tall-stalked',\n",
       "               'stately',\n",
       "               'statuesque',\n",
       "               'tallish']),\n",
       "             ('simple',\n",
       "              ['difficult',\n",
       "               'challenging',\n",
       "               'hard',\n",
       "               'complicated',\n",
       "               'demanding',\n",
       "               'daunting',\n",
       "               'taxing']),\n",
       "             ('sincere',\n",
       "              ['insincere',\n",
       "               'bootlicking',\n",
       "               'fawning',\n",
       "               'obsequious',\n",
       "               'sycophantic',\n",
       "               'toadyish',\n",
       "               'buttery',\n",
       "               'fulsome',\n",
       "               'oily',\n",
       "               'oleaginous',\n",
       "               'smarmy',\n",
       "               'soapy',\n",
       "               'unctuous',\n",
       "               'dissimulative',\n",
       "               'false',\n",
       "               'feigned',\n",
       "               'gilded',\n",
       "               'meretricious',\n",
       "               'specious',\n",
       "               'hypocritical',\n",
       "               'plausible',\n",
       "               'counterfeit',\n",
       "               'imitative',\n",
       "               'dishonest',\n",
       "               'dishonorable',\n",
       "               'disingenuous',\n",
       "               'artful',\n",
       "               'false',\n",
       "               'unreal']),\n",
       "             ('slow',\n",
       "              ['fast',\n",
       "               'quick',\n",
       "               'accelerated',\n",
       "               'alacritous',\n",
       "               'blistering',\n",
       "               'hot',\n",
       "               'red-hot',\n",
       "               'double-quick',\n",
       "               'express',\n",
       "               'fast-breaking',\n",
       "               'fast-paced',\n",
       "               'fleet',\n",
       "               'swift',\n",
       "               'high-speed',\n",
       "               'high-velocity',\n",
       "               'hurrying',\n",
       "               'scurrying',\n",
       "               'immediate',\n",
       "               'prompt',\n",
       "               'quick',\n",
       "               'straightaway',\n",
       "               'instantaneous',\n",
       "               'instant',\n",
       "               'meteoric',\n",
       "               'speedy',\n",
       "               'rapid',\n",
       "               'winged',\n",
       "               'windy']),\n",
       "             ('sweet',\n",
       "              ['sour',\n",
       "               'acerb',\n",
       "               'acerbic',\n",
       "               'astringent',\n",
       "               'acetose',\n",
       "               'acetous',\n",
       "               'vinegary',\n",
       "               'vinegarish',\n",
       "               'acidic',\n",
       "               'acid',\n",
       "               'acidulent',\n",
       "               'acidulous',\n",
       "               'lemony',\n",
       "               'lemonlike',\n",
       "               'sourish',\n",
       "               'tangy',\n",
       "               'tart',\n",
       "               'subacid',\n",
       "               'bitter']),\n",
       "             ('tasty',\n",
       "              ['tasteless',\n",
       "               'bland',\n",
       "               'flat',\n",
       "               'flavorless',\n",
       "               'flavourless',\n",
       "               'insipid',\n",
       "               'savorless',\n",
       "               'savourless',\n",
       "               'vapid',\n",
       "               'unflavored',\n",
       "               'unflavoured',\n",
       "               'nonflavored',\n",
       "               'nonflavoured',\n",
       "               'unsalted',\n",
       "               'unseasoned',\n",
       "               'unappetizing',\n",
       "               'unappetising',\n",
       "               'unpalatable']),\n",
       "             ('tight',\n",
       "              ['loose',\n",
       "               'lax',\n",
       "               'baggy',\n",
       "               'loose-fitting',\n",
       "               'sloppy',\n",
       "               'flyaway',\n",
       "               'free',\n",
       "               'liberal',\n",
       "               'informal',\n",
       "               'unofficial']),\n",
       "             ('warm', ['cool', 'cold', 'chilly', 'frosty', 'cool', 'frigid']),\n",
       "             ('white', ['black', 'dark', 'lightless']),\n",
       "             ('wide',\n",
       "              ['narrow',\n",
       "               'constricting',\n",
       "               'constrictive',\n",
       "               'narrowing',\n",
       "               'narrowed',\n",
       "               'narrow-mouthed',\n",
       "               'slender',\n",
       "               'thin',\n",
       "               'strait',\n",
       "               'straplike',\n",
       "               'tapered',\n",
       "               'tapering',\n",
       "               'limited']),\n",
       "             ('willing',\n",
       "              ['unwilling',\n",
       "               'defiantnoncompliant',\n",
       "               'involuntary',\n",
       "               'nonvoluntary',\n",
       "               'unvoluntary',\n",
       "               'disinclined',\n",
       "               'averse',\n",
       "               'backward',\n",
       "               'hesitant',\n",
       "               'indisposed',\n",
       "               'loath',\n",
       "               'reluctant',\n",
       "               'uneager',\n",
       "               'unwishful']),\n",
       "             ('young',\n",
       "              ['old',\n",
       "               'aged',\n",
       "               'elderly',\n",
       "               'older',\n",
       "               'senior',\n",
       "               'age',\n",
       "               'aging',\n",
       "               'ageing',\n",
       "               'senescent',\n",
       "               'ancient',\n",
       "               'anile',\n",
       "               'centenarian',\n",
       "               'darkened',\n",
       "               'doddering',\n",
       "               'doddery',\n",
       "               'gaga',\n",
       "               'senile',\n",
       "               'emeritus',\n",
       "               'grey',\n",
       "               'gray',\n",
       "               'grey-haired',\n",
       "               'gray-haired',\n",
       "               'grey-headed',\n",
       "               'gray-headed',\n",
       "               'grizzly',\n",
       "               'hoar',\n",
       "               'hoary',\n",
       "               'white-haired',\n",
       "               'middle-aged',\n",
       "               'nonagenarian',\n",
       "               'octogenarian',\n",
       "               'oldish',\n",
       "               'overage',\n",
       "               'overaged',\n",
       "               'superannuated',\n",
       "               'over-the-hill',\n",
       "               'sexagenarian',\n",
       "               'venerable',\n",
       "               'experienced',\n",
       "               'experient',\n",
       "               'mature',\n",
       "               'senior'])])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antonyms_dict = {}\n",
    "files = [bat3file1,bat3file2]\n",
    "\n",
    "for each in files:\n",
    "    \n",
    "    # put the pos to the start of file\n",
    "    each.seek(0, os.SEEK_SET)\n",
    "\n",
    "    for line in each.read().split(\"\\n\"):\n",
    "        # 处理 空行\n",
    "        if not line:\n",
    "            continue\n",
    "        line_split = line.split()\n",
    "        master = line_split[0]\n",
    "        slave = line_split[1].split('/')\n",
    "        \n",
    "        # 处理多个 master\n",
    "        if '/' in master:\n",
    "            master_list = master.split('/')\n",
    "            for each_master in master_list:\n",
    "                if not each_master in antonyms_dict:\n",
    "                    antonyms_dict[each_master] = slave\n",
    "        else:\n",
    "            if not master in antonyms_dict:\n",
    "                antonyms_dict[master] = slave\n",
    "            \n",
    "ordered_antonyms_dict = collections.OrderedDict(sorted(antonyms_dict.items()))\n",
    "ordered_antonyms_dict\n",
    "\n",
    "#print(type(ordered_antonyms_dict))\n",
    "\n",
    "# 最终的数据是 ordered_antonyms_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全是形容词，不需要使用nltk选出形容词\n",
    "# 但是有的 master 是有两个的需要处理一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-large and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "model_class, tokenizer_class, shortcut, mask_token = RobertaForMaskedLM, RobertaTokenizer, 'roberta-base', '<mask>'\n",
    "model, tokenizer = model_class.from_pretrained(shortcut), tokenizer_class.from_pretrained(shortcut)\n",
    "models[shortcut] = (model, tokenizer, mask_token)\n",
    "\n",
    "model_class, tokenizer_class, shortcut, mask_token = RobertaForMaskedLM, RobertaTokenizer, 'roberta-large', '<mask>'\n",
    "model, tokenizer = model_class.from_pretrained(shortcut), tokenizer_class.from_pretrained(shortcut)\n",
    "models[shortcut] = (model, tokenizer, mask_token)\n",
    "\n",
    "model, tokenizer, mask_token = models['roberta-large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\n",
    "    'John is * but Mary is  _ .'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理 am-for-bert 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new': ['old'], 'other': ['same'], 'many': ['few'], 'high': ['low'], 'same': ['other'], 'general': ['specific'], 'international': ['national'], 'local': ['national'], 'small': ['big', 'large'], 'large': ['little', 'small'], 'much': ['little'], 'old': ['young'], 'single': ['common'], 'different': ['same'], 'white': ['black'], 'few': ['many'], 'popular': ['unpopular'], 'black': ['white'], 'young': ['old'], 'northern': ['southern'], 'married': ['unmarried'], 'southern': ['northern'], 'little': ['big', 'large'], 'good': ['bad'], 'available': ['unavailable'], 'full': ['empty'], 'able': ['unable'], 'successful': ['unsuccessful'], 'native': ['foreign'], 'possible': ['impossible'], 'natural': ['unnatural'], 'big': ['little', 'small'], 'strong': ['weak'], 'active': ['inactive'], 'limited': ['unlimited'], 'low': ['high'], 'foreign': ['domestic'], 'related': ['unrelated'], 'legal': ['illegal'], 'true': ['false'], 'dead': ['alive'], 'specific': ['general'], 'hard': ['easy'], 'likely': ['unlikely'], 'clear': ['unclear'], 'difficult': ['easy'], 'rural': ['urban'], 'potential': ['actual'], 'normal': ['abnormal'], 'necessary': ['unnecessary'], 'nuclear': ['conventional'], 'unable': ['able'], 'bad': ['good'], 'positive': ['negative'], 'internal': ['external'], 'effective': ['ineffective'], 'actual': ['potential'], 'rich': ['poor'], 'domestic': ['foreign'], 'formal': ['informal'], 'external': ['internal'], 'capable': ['incapable'], 'easy': ['difficult'], 'affected': ['unaffected'], 'experienced': ['inexperienced'], 'unusual': ['usual'], 'safe': ['dangerous'], 'visible': ['invisible'], 'instrumental': ['vocal'], 'illegal': ['legal'], 'happy': ['unhappy'], 'vocal': ['instrumental'], 'dangerous': ['safe'], 'alive': ['dead'], 'civilian': ['military'], 'conventional': ['unconventional'], 'unsuccessful': ['successful'], 'false': ['true'], 'soft': ['hard'], 'stable': ['unstable'], 'usual': ['unusual'], 'impossible': ['possible'], 'endemic': ['epidemic'], 'ordinary': ['extraordinary'], 'vertical': ['inclined'], 'automatic': ['manual'], 'weak': ['strong'], 'accessible': ['inaccessible'], 'artificial': ['natural'], 'familiar': ['unfamiliar'], 'empty': ['full'], 'emotional': ['cerebral'], 'theoretical': ['empirical'], 'eligible': ['ineligible'], 'willing': ['unwilling'], 'valid': ['invalid'], 'extraordinary': ['ordinary'], 'busy': ['idle'], 'reliable': ['unreliable'], 'sudden': ['gradual'], 'unlikely': ['probable'], 'nice': ['nasty'], 'voluntary': ['involuntary'], 'informal': ['formal'], 'reasonable': ['unreasonable'], 'sophisticated': ['naive'], 'compatible': ['incompatible'], 'acceptable': ['unacceptable'], 'comfortable': ['uncomfortable'], 'uncommon': ['common'], 'rational': ['irrational'], 'supernatural': ['natural'], 'unrelated': ['related'], 'unconscious': ['conscious'], 'homosexual': ['bisexual'], 'invisible': ['visible'], 'induced': ['spontaneous'], 'unlimited': ['limited'], 'incredible': ['credible'], 'unstable': ['stable'], 'unhappy': ['happy'], 'gradual': ['sudden'], 'unpopular': ['popular'], 'epidemic': ['endemic'], 'unnecessary': ['necessary'], 'empirical': ['theoretical'], 'peripheral': ['central'], 'unwilling': ['willing'], 'spontaneous': ['induced'], 'inexpensive': ['expensive'], 'unavailable': ['available'], 'ineffective': ['effective'], 'cerebral': ['emotional'], 'invalid': ['valid'], 'unconstitutional': ['constitutional'], 'abnormal': ['normal'], 'unmarried': ['married'], 'idle': ['busy'], 'bisexual': ['heterosexual'], 'uncomfortable': ['comfortable'], 'unconventional': ['conventional'], 'incapable': ['capable'], 'incompatible': ['compatible'], 'credible': ['incredible'], 'lawful': ['unlawful'], 'undesirable': ['desirable'], 'heterosexual': ['homosexual'], 'unfamiliar': ['familiar'], 'ineligible': ['eligible'], 'inexperienced': ['experienced'], 'unpredictable': ['predictable'], 'predictable': ['unpredictable'], 'nasty': ['nice'], 'inaccessible': ['accessible'], 'naive': ['sophisticated'], 'affirmative': ['negative'], 'impractical': ['practical'], 'adoptive': ['biological'], 'unaffected': ['affected'], 'unequal': ['equal'], 'irrational': ['rational'], 'sensible': ['unreasonable'], 'involuntary': ['voluntary'], 'uneasy': ['easy'], 'immoral': ['moral'], 'fractional': ['whole'], 'heterogeneous': ['homogeneous'], 'unconditional': ['conditional'], 'unfavorable': ['favorable'], 'atypical': ['typical'], 'unnatural': ['natural'], 'unreasonable': ['reasonable'], 'displeased': ['pleased'], 'unrealistic': ['realistic'], 'improbable': ['probable'], 'impartial': ['partial'], 'unhealthy': ['healthy'], 'irresponsible': ['responsible'], 'unprepared': ['prepared'], 'intangible': ['tangible'], 'asymmetrical': ['symmetrical'], 'undue': ['due'], 'insoluble': ['soluble'], 'insensitive': ['sensitive'], 'unbelievable': ['credible'], 'unethical': ['ethical'], 'unimportant': ['important'], 'frivolous': ['serious'], 'unprofitable': ['profitable'], 'pessimistic': ['optimistic'], 'high-pitched': ['low'], 'unfavourable': ['favorable'], 'unproductive': ['productive'], 'discontinuous': ['continuous'], 'dependable': ['unreliable'], 'uninterested': ['interested'], 'unambiguous': ['ambiguous'], 'ineffectual': ['effective'], 'unattractive': ['attractive'], 'believable': ['incredible'], 'asexual': ['sexual'], 'inflexible': ['flexible'], 'impersonal': ['personal'], 'inconspicuous': ['conspicuous'], 'incomparable': ['comparable'], 'implausible': ['plausible'], 'invulnerable': ['vulnerable'], 'unsympathetic': ['sympathetic'], 'extrinsic': ['intrinsic'], 'undemocratic': ['democratic'], 'illogical': ['logical'], 'uninjured': ['injured'], 'inedible': ['edible'], 'inelastic': ['elastic'], 'uncharacteristic': ['characteristic'], 'theoretic': ['empirical'], 'unscientific': ['scientific'], 'unimpressive': ['impressive'], 'unplayable': ['playable'], 'unprofessional': ['professional'], 'unconcerned': ['concerned'], 'nontraditional': ['traditional'], 'unsanitary': ['sanitary'], 'dishonorable': ['honorable'], 'inoperative': ['operative'], 'uncritical': ['critical'], 'unfashionable': ['fashionable'], 'noncommercial': ['commercial'], 'unsteady': ['steady'], 'invariable': ['variable'], 'unneeded': ['necessary'], 'inaudible': ['audible'], 'uncontroversial': ['controversial'], 'unquestionable': ['questionable'], 'avoidable': ['inevitable'], 'unenthusiastic': ['enthusiastic'], 'unwary': ['wary'], 'unready': ['ready'], 'unapologetic': ['apologetic'], 'impious': ['pious'], 'unfree': ['free'], 'unarmored': ['armored'], 'effectual': ['ineffective'], 'unpatriotic': ['patriotic'], 'unidentifiable': ['identifiable'], 'inoffensive': ['offensive'], 'unarmoured': ['armored'], 'low-pitched': ['high'], 'noninvasive': ['invasive'], 'nonfunctional': ['functional'], 'ungrammatical': ['grammatical'], 'ignoble': ['noble'], 'unemotional': ['emotional'], 'nonnative': ['native'], 'unimpaired': ['impaired'], 'dishonourable': ['honorable'], 'inconsiderable': ['considerable'], 'ahistorical': ['historical'], 'unquiet': ['quiet'], 'untraditional': ['traditional'], 'untroubled': ['troubled'], 'unrighteous': ['righteous'], 'noncompetitive': ['competitive'], 'unsystematic': ['systematic'], 'insensible': ['sensible'], 'nonpolitical': ['political'], 'unambitious': ['ambitious'], 'unlikeable': ['sympathetic'], 'self-generated': ['induced'], 'indissoluble': ['soluble'], 'nonmilitary': ['military'], 'nonprofessional': ['professional'], 'resistible': ['irresistible'], 'nonsurgical': ['surgical'], 'nonrenewable': ['renewable'], 'unspecialized': ['specialized'], 'unlikable': ['sympathetic'], 'nontechnical': ['technical'], 'nonclassical': ['classical'], 'insanitary': ['sanitary'], 'incautious': ['cautious'], 'uncharitable': ['charitable'], 'untypical': ['typical'], 'nonmagnetic': ['magnetic'], 'nonalcoholic': ['alcoholic'], 'unsurprised': ['surprised'], 'unaccessible': ['accessible'], 'undependable': ['reliable'], 'unmusical': ['musical'], 'undramatic': ['dramatic'], 'nonfictional': ['fictional'], 'ungenerous': ['generous'], 'undiplomatic': ['diplomatic'], 'nonresidential': ['residential'], 'unkept': ['unbroken'], 'uncreative': ['creative'], 'nonproprietary': ['proprietary'], 'nonsexual': ['sexual'], 'unadventurous': ['adventurous'], 'ill-formed': ['grammatical'], 'noninfectious': ['infectious'], 'unaggressive': ['aggressive'], 'noncontroversial': ['controversial'], 'unsocial': ['social'], 'unhealthful': ['sanitary'], 'unseeable': ['visible'], 'synthetical': ['analytic'], 'unobvious': ['obvious'], 'inconvertible': ['convertible'], 'unaesthetic': ['aesthetic'], 'nonmusical': ['musical'], 'nonfinancial': ['financial'], 'unspecialised': ['specialized'], 'impalpable': ['tangible'], 'uncomparable': ['comparable'], 'nonaggressive': ['aggressive'], 'heterogenous': ['homogeneous'], 'nonindustrial': ['industrial'], 'nonoperational': ['operational'], 'unmilitary': ['military'], 'uncomplete': ['complete'], 'nonspherical': ['spherical'], 'uninfluential': ['influential'], 'antonymous': ['synonymous'], 'onymous': ['anonymous'], 'evitable': ['inevitable'], 'nonlinguistic': ['linguistic'], 'unvoluntary': ['voluntary'], 'nonreciprocal': ['reciprocal'], 'nonracial': ['racial'], 'antimagnetic': ['magnetic'], 'nonexplosive': ['explosive'], 'unrespectable': ['respectable'], 'noninstitutional': ['institutional'], 'uneatable': ['edible'], 'insusceptible': ['susceptible'], 'unportable': ['portable'], 'noncontinuous': ['continuous'], 'undiversified': ['diversified'], 'undynamic': ['dynamic'], 'incurious': ['curious'], 'nonhierarchical': ['hierarchical'], 'unmalicious': ['malicious'], 'concentrical': ['eccentric'], 'noncritical': ['critical'], 'nonspatial': ['spatial'], 'unconvertible': ['convertible'], 'nonvoluntary': ['voluntary'], 'unhearable': ['audible'], 'unsusceptible': ['susceptible'], 'unpresidential': ['presidential'], 'uneffective': ['effective'], 'inaesthetic': ['aesthetic'], 'unrenewable': ['renewable'], 'nonmechanical': ['mechanical'], 'undomestic': ['domestic'], 'untechnical': ['technical'], 'unthematic': ['thematic'], 'unhumorous': ['humorous'], 'nonmodern': ['modern'], 'noncellular': ['cellular'], 'untheatrical': ['theatrical'], 'avertable': ['inevitable'], 'adynamic': ['dynamic'], 'unlogical': ['logical'], 'seeable': ['invisible']}\n",
      "366\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "am_for_bert = 'am_for_bert_antonyms.txt'\n",
    "#am_for_bert_file = open(am_for_bert)\n",
    "\n",
    "with open(am_for_bert, 'r') as f:\n",
    "    file_lines = f.readlines()\n",
    "\n",
    "keymap =  [re.split(' |\\t',string) for string in file_lines]\n",
    "\n",
    "adj_antonym = {}\n",
    "flag = 0\n",
    "for item in keymap:\n",
    "\n",
    "    # 筛选出形态词的反义词\n",
    "    if (('antonym' == item[4]) and ('a' in item[3])):\n",
    "        master3 = item[2]\n",
    "        slave3 = []\n",
    "        length = len(item)\n",
    "        \n",
    "        for i in range(int((length-5)/2)):\n",
    "            slave3.append(item[5+i*2])\n",
    "        \n",
    "        adj_antonym[master3] = slave3\n",
    "        \n",
    "print(adj_antonym)\n",
    "print(len(adj_antonym))\n",
    "\n",
    "# 最终的数据 adj_antonym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'antibiotic': ['infection'], 'good': ['bad'], 'happy': ['sad'], 'nice': ['evil']}\n",
      "===========================\n",
      "OrderedDict([('able', ['unable', 'incapable', 'incompetent', 'unequal']), ('abundant', ['scarce', 'rare', 'tight', 'meager', 'meagre', 'meagerly', 'stingy', 'scrimpy', 'insufficient', 'deficient']), ('aware', ['unaware', 'oblivious', 'unmindful', 'unconscious', 'unsuspecting', 'asleep', 'insensible', 'unconscious', 'unwitting', 'ignorant', 'indifferent', 'oblivious']), ('beautiful', ['ugly', 'disfigured', 'evil-looking', 'fugly', 'grotesque', 'monstrous', 'hideous', 'repulsive', 'ill-favored', 'ill-favoured', 'scrofulous', 'unlovely', 'unpicturesque', 'unsightly', 'displeasing', 'unattractive', 'awkward']), ('big', ['small', 'atomic', 'subatomic', 'bantam', 'diminutive', 'lilliputian', 'midget', 'petite', 'tiny', 'flyspeck', 'bitty', 'bittie', 'teensy', 'teentsy', 'teeny', 'wee', 'weeny', 'weensy', 'teensy-weensy', 'teeny-weeny', 'itty-bitty', 'itsy-bitsy', 'dinky', 'dwarfish', 'elfin', 'elflike', 'gnomish', 'half-size', 'infinitesimal', 'minute', 'lesser', 'microscopic', 'microscopical', 'micro', 'miniature', 'minuscule', 'miniscule', 'olive-sized', 'pocket-size', 'pocket-sized', 'pocketable', 'puny', 'runty', 'shrimpy', 'slender', 'slim', 'smaller', 'littler', 'smallish', 'small-scale', 'undersize', 'undersized']), ('bright', ['pale', 'colorless', 'colourless', 'dull', 'neutral', 'pale', 'white', 'bleached', 'faded', 'washed-out', 'washy', 'drab', 'somber', 'sombre', 'dulled', 'greyed', 'etiolate', 'etiolated', 'lurid', 'waxen', 'waxlike', 'waxy', 'whitened']), ('cheap', ['expensive', 'big-ticket', 'high-ticket', 'costly', 'dear', 'high-priced', 'pricey', 'pricy', 'dearly-won', 'overpriced', 'valuable']), ('clean', ['dirty', 'soiled', 'unclean', 'augean', 'bedraggled', 'draggled', 'befouled', 'fouled', 'begrimed', 'dingy', 'grimy', 'grubby', 'grungy', 'raunchy', 'black', 'smutty', 'buggy', 'cobwebby', 'dirty-faced', 'feculent', 'filthy', 'foul', 'nasty', 'flyblown', 'squalid', 'sordid', 'greasy', 'oily', 'lousy', 'maculate', 'mucky', 'muddy', 'ratty', 'scummy', 'smudgy', 'snotty', 'snot-nosed', 'sooty', 'travel-soiled', 'travel-stained', 'uncleanly', 'unswept', 'unwashed']), ('clear', ['vague', 'obscure', 'unclear', 'undefined', 'indefinable', 'undefinable']), ('close', ['distant', 'remote', 'removed', 'far', 'faraway', '']), ('colorful', ['colorless', 'colourless', 'dull', 'neutral', 'pale', 'white', 'bleached', 'faded', 'washed-out', 'washy', 'drab', 'somber', 'sombre', 'dulled', 'greyed', 'etiolate', 'etiolated', 'lurid', 'waxen', 'waxlike', 'waxy', 'whitened']), ('common', ['rare', 'infrequent', 'scarce', 'uncommon', 'extraordinary']), ('competent', ['incompetent', 'unskilled', 'unqualified', 'inefficient', 'unqualified', 'unskilled']), ('concerned', ['unconcerned', 'blase', 'blithe', 'casual', 'insouciant', 'nonchalant', 'degage', 'detached', 'uninvolved', 'indifferent', 'careless', 'uninvolved', 'untroubled']), ('cooked', ['raw', 'half-baked', 'fresh', 'natural', 'underdone', 'rare', 'uncooked', 'untoasted']), ('dangerous', ['safe', 'fail-safe', 'risk-free', 'riskless', 'unhazardous', 'safe-and-sound', 'unhurt', 'harmless', 'invulnerable', 'secure', 'uninjured']), ('decisive', ['hesitating', 'indecisive', 'hesitant', 'inconclusive', 'irresolute']), ('dry', ['wet', 'bedewed', 'dewy', 'besprent', 'boggy', 'marshy', 'miry', 'mucky', 'muddy', 'quaggy', 'sloppy', 'sloughy', 'soggy', 'squashy', 'swampy', 'waterlogged', 'clammy', 'dank', 'damp', 'dampish', 'moist', 'sodden', 'soppy', 'drippy', 'drizzly', 'humid', 'misty', 'muggy', 'steamy', 'sticky', 'reeking', 'watery', 'rheumy', 'showery', 'rainy', 'steaming', 'tacky', 'undried', 'washed']), ('energetic', ['lethargic', 'unergetic', 'dazed', 'foggy', 'groggy', 'logy', 'stuporous', 'dreamy', 'lackadaisical', 'languid', 'languorous', 'listless', 'inactive']), ('familiar', ['unfamiliar', 'strange', 'unknown', 'unacquainted', 'unacquainted', 'foreign', 'strange', 'unknown']), ('fat', ['thin', 'lean', 'anorexic', 'anorectic', 'bony', 'cadaverous', 'emaciated', 'gaunt', 'haggard', 'pinched', 'skeletal', 'wasted', 'deep-eyed', 'hollow-eyed', 'sunken-eyed', 'gangling', 'gangly', 'lanky', 'lank', 'spindly', 'rawboned', 'reedy', 'reedlike', 'twiggy', 'twiglike', 'scarecrowish', 'scraggy', 'boney', 'scrawny', 'skinny', 'underweight', 'weedy', 'shriveled', 'shrivelled', 'shrunken', 'withered', 'wizen', 'wizened', 'slender', 'slight', 'slim', 'svelte', 'slender-waisted', 'slim-waisted', 'wasp-waisted', 'spare', 'trim', 'spindle-legged', 'spindle-shanked', 'stringy', 'wiry', 'wisplike', 'wispy']), ('full', ['empty', 'bare', 'stripped', 'blank', 'clean', 'white', 'empty-handed', 'glassy', 'glazed', 'lifeless', 'looted', 'pillaged', 'plundered', 'ransacked', 'vacant', 'vacuous', 'void']), ('gaseous', ['solid', 'hard', 'coagulated', 'solidified', 'concrete', 'congealed', 'jelled', 'jellied', 'dry', 'semisolid', 'solid-state']), ('generous', ['stingy', 'beggarly', 'mean', 'cheap', 'chinchy', 'chintzy', 'cheeseparing', 'close', 'near', 'penny-pinching', 'skinny', 'closefisted', 'hardfisted', 'tightfisted', 'grudging', 'niggardly', 'scrimy', 'mingy', 'miserly', 'tight', 'parsimonious', 'penurious', 'selfish', 'uncharitable', 'ungenerous', 'meanspirited']), ('happy', ['sad', 'bittersweet', 'doleful', 'mournful', 'heavyhearted', 'melancholy', 'melancholic', 'pensive', 'wistful', 'tragic', 'tragical', 'tragicomic', 'tragicomical', 'deplorable', 'distressing', 'lamentable', 'pitiful', 'sorry']), ('hard', ['soft', 'mellow', 'brushed', 'fleecy', 'napped', 'cheeselike', 'compressible', 'squeezable', 'cottony', 'cushioned', 'cushiony', 'padded', 'demulcent', 'emollient', 'salving', 'softening', 'downy', 'downlike', 'flossy', 'fluffy', 'flaccid', 'flocculent', 'woolly', 'wooly', 'yielding', 'mushy', 'overstuffed', 'softish', 'semisoft', 'spongy', 'squashy', 'squishy', 'spongelike', 'velvet', 'velvety']), ('hot', ['cold', 'chilly', 'frosty', 'cool', 'frigid']), ('interesting', ['uninteresting', 'dull', 'boring', 'deadening', 'ho-hum', 'irksome', 'slow', 'tedious', 'tiresome', 'wearisome', 'insipid', 'jejune', 'narcotic', 'soporiferous', 'soporific', 'prosaic', 'prosy', 'earthbound', 'ponderous', 'putdownable', 'unexciting', 'unstimulating']), ('introvert', ['extravert', 'extrovert', 'outgoing', 'extroverted', 'forthcoming', 'sociable']), ('large', ['small', 'little', 'atomic', 'subatomic', 'bantam', 'diminutive', 'lilliputian', 'midget', 'petite', 'tiny', 'flyspeck', 'bitty', 'bittie', 'teensy', 'teentsy', 'teeny', 'wee', 'weeny', 'weensy', 'teensy-weensy', 'teeny-weeny', 'itty-bitty', 'itsy-bitsy', 'dinky', 'dwarfish', 'elfin', 'elflike', 'gnomish', 'half-size', 'infinitesimal', 'minute', 'lesser', 'microscopic', 'microscopical', 'micro', 'miniature', 'minuscule', 'miniscule', 'olive-sized', 'pocket-size', 'pocket-sized', 'pocketable', 'puny', 'runty', 'shrimpy', 'slender', 'slim', 'smaller', 'littler', 'smallish', 'small-scale', 'undersize', 'undersized']), ('long', ['short', 'abbreviated', 'shortened', 'truncated', 'brief', 'clipped', 'fleeting', 'fugitive', 'momentaneous', 'momentary', 'short_and_sweet', 'short-dated', 'short-range', 'short-run', 'short-term', 'abbreviated', 'brief', 'close', 'curtal', 'sawed-off', 'sawn-off', 'shortened', 'shortish', 'short-range', 'short-snouted', 'snub', 'stubby', 'telescoped', 'truncate', 'truncated', 'chunky', 'dumpy', 'low-set', 'squat', 'squatty', 'stumpy', 'compact', 'heavyset', 'stocky', 'thick', 'thickset', 'half-length', 'pint-size', 'pint-sized', 'runty', 'sawed-off', 'sawn-off', 'short-stalked', 'squab', 'squabby']), ('lumpy', ['flat', 'level', 'plane', 'even', '']), ('noisy', ['silent', 'uncommunicative', 'dumb', 'mute', 'inarticulate', 'unarticulate']), ('normal', ['abnormal', 'aberrant', 'deviant', 'deviate', 'anomalous', 'antidromic', 'atypical', 'irregular', 'brachydactylic', 'brachydactylous', 'defective', 'freakish', 'kinky', 'perverted', 'subnormal', 'supernormal', 'vicarious', 'unusual', 'exceptional', 'insane', 'unnatural']), ('organized', ['unorganized', 'unstructured', 'uncoordinated', 'unformed', 'unincorporated']), ('pale', ['tanned', 'bronzed', 'suntanned', 'brunet', 'brunette']), ('pretty', ['ugly', 'disfigured', 'evil-looking', 'fugly', 'grotesque', 'monstrous', 'hideous', 'repulsive', 'ill-favored', 'ill-favoured', 'scrofulous', 'unlovely', 'unpicturesque', 'unsightly', 'displeasing', 'unattractive', 'awkward']), ('rich', ['poor', 'broke', 'bust', 'skint', 'stone-broke', 'stony-broke', 'destitute', 'impoverished', 'indigent', 'necessitous', 'needy', 'poverty-stricken', 'hard_up', 'impecunious', 'penniless', 'penurious', 'pinched', 'moneyless', 'unprovided']), ('risky', ['safe', 'fail-safe', 'risk-free', 'riskless', 'unhazardous', 'safe-and-sound', 'unhurt', 'harmless', 'invulnerable', 'secure', 'uninjured']), ('sane', ['crazy', 'loony', 'looney', 'nutcase', 'weirdo', 'mad', 'insane']), ('short', ['tall', 'gangling', 'gangly', 'lanky', 'rangy', 'height', 'leggy', 'long-legged', 'long-shanked', 'tall-growing', 'long', 'long-stalked', 'tall-stalked', 'stately', 'statuesque', 'tallish']), ('simple', ['difficult', 'challenging', 'hard', 'complicated', 'demanding', 'daunting', 'taxing']), ('sincere', ['insincere', 'bootlicking', 'fawning', 'obsequious', 'sycophantic', 'toadyish', 'buttery', 'fulsome', 'oily', 'oleaginous', 'smarmy', 'soapy', 'unctuous', 'dissimulative', 'false', 'feigned', 'gilded', 'meretricious', 'specious', 'hypocritical', 'plausible', 'counterfeit', 'imitative', 'dishonest', 'dishonorable', 'disingenuous', 'artful', 'false', 'unreal']), ('slow', ['fast', 'quick', 'accelerated', 'alacritous', 'blistering', 'hot', 'red-hot', 'double-quick', 'express', 'fast-breaking', 'fast-paced', 'fleet', 'swift', 'high-speed', 'high-velocity', 'hurrying', 'scurrying', 'immediate', 'prompt', 'quick', 'straightaway', 'instantaneous', 'instant', 'meteoric', 'speedy', 'rapid', 'winged', 'windy']), ('sweet', ['sour', 'acerb', 'acerbic', 'astringent', 'acetose', 'acetous', 'vinegary', 'vinegarish', 'acidic', 'acid', 'acidulent', 'acidulous', 'lemony', 'lemonlike', 'sourish', 'tangy', 'tart', 'subacid', 'bitter']), ('tasty', ['tasteless', 'bland', 'flat', 'flavorless', 'flavourless', 'insipid', 'savorless', 'savourless', 'vapid', 'unflavored', 'unflavoured', 'nonflavored', 'nonflavoured', 'unsalted', 'unseasoned', 'unappetizing', 'unappetising', 'unpalatable']), ('tight', ['loose', 'lax', 'baggy', 'loose-fitting', 'sloppy', 'flyaway', 'free', 'liberal', 'informal', 'unofficial']), ('warm', ['cool', 'cold', 'chilly', 'frosty', 'cool', 'frigid']), ('white', ['black', 'dark', 'lightless']), ('wide', ['narrow', 'constricting', 'constrictive', 'narrowing', 'narrowed', 'narrow-mouthed', 'slender', 'thin', 'strait', 'straplike', 'tapered', 'tapering', 'limited']), ('willing', ['unwilling', 'defiantnoncompliant', 'involuntary', 'nonvoluntary', 'unvoluntary', 'disinclined', 'averse', 'backward', 'hesitant', 'indisposed', 'loath', 'reluctant', 'uneager', 'unwishful']), ('young', ['old', 'aged', 'elderly', 'older', 'senior', 'age', 'aging', 'ageing', 'senescent', 'ancient', 'anile', 'centenarian', 'darkened', 'doddering', 'doddery', 'gaga', 'senile', 'emeritus', 'grey', 'gray', 'grey-haired', 'gray-haired', 'grey-headed', 'gray-headed', 'grizzly', 'hoar', 'hoary', 'white-haired', 'middle-aged', 'nonagenarian', 'octogenarian', 'oldish', 'overage', 'overaged', 'superannuated', 'over-the-hill', 'sexagenarian', 'venerable', 'experienced', 'experient', 'mature', 'senior'])])\n",
      "===========================\n",
      "{'new': ['old'], 'other': ['same'], 'many': ['few'], 'high': ['low'], 'same': ['other'], 'general': ['specific'], 'international': ['national'], 'local': ['national'], 'small': ['big', 'large'], 'large': ['little', 'small'], 'much': ['little'], 'old': ['young'], 'single': ['common'], 'different': ['same'], 'white': ['black'], 'few': ['many'], 'popular': ['unpopular'], 'black': ['white'], 'young': ['old'], 'northern': ['southern'], 'married': ['unmarried'], 'southern': ['northern'], 'little': ['big', 'large'], 'good': ['bad'], 'available': ['unavailable'], 'full': ['empty'], 'able': ['unable'], 'successful': ['unsuccessful'], 'native': ['foreign'], 'possible': ['impossible'], 'natural': ['unnatural'], 'big': ['little', 'small'], 'strong': ['weak'], 'active': ['inactive'], 'limited': ['unlimited'], 'low': ['high'], 'foreign': ['domestic'], 'related': ['unrelated'], 'legal': ['illegal'], 'true': ['false'], 'dead': ['alive'], 'specific': ['general'], 'hard': ['easy'], 'likely': ['unlikely'], 'clear': ['unclear'], 'difficult': ['easy'], 'rural': ['urban'], 'potential': ['actual'], 'normal': ['abnormal'], 'necessary': ['unnecessary'], 'nuclear': ['conventional'], 'unable': ['able'], 'bad': ['good'], 'positive': ['negative'], 'internal': ['external'], 'effective': ['ineffective'], 'actual': ['potential'], 'rich': ['poor'], 'domestic': ['foreign'], 'formal': ['informal'], 'external': ['internal'], 'capable': ['incapable'], 'easy': ['difficult'], 'affected': ['unaffected'], 'experienced': ['inexperienced'], 'unusual': ['usual'], 'safe': ['dangerous'], 'visible': ['invisible'], 'instrumental': ['vocal'], 'illegal': ['legal'], 'happy': ['unhappy'], 'vocal': ['instrumental'], 'dangerous': ['safe'], 'alive': ['dead'], 'civilian': ['military'], 'conventional': ['unconventional'], 'unsuccessful': ['successful'], 'false': ['true'], 'soft': ['hard'], 'stable': ['unstable'], 'usual': ['unusual'], 'impossible': ['possible'], 'endemic': ['epidemic'], 'ordinary': ['extraordinary'], 'vertical': ['inclined'], 'automatic': ['manual'], 'weak': ['strong'], 'accessible': ['inaccessible'], 'artificial': ['natural'], 'familiar': ['unfamiliar'], 'empty': ['full'], 'emotional': ['cerebral'], 'theoretical': ['empirical'], 'eligible': ['ineligible'], 'willing': ['unwilling'], 'valid': ['invalid'], 'extraordinary': ['ordinary'], 'busy': ['idle'], 'reliable': ['unreliable'], 'sudden': ['gradual'], 'unlikely': ['probable'], 'nice': ['nasty'], 'voluntary': ['involuntary'], 'informal': ['formal'], 'reasonable': ['unreasonable'], 'sophisticated': ['naive'], 'compatible': ['incompatible'], 'acceptable': ['unacceptable'], 'comfortable': ['uncomfortable'], 'uncommon': ['common'], 'rational': ['irrational'], 'supernatural': ['natural'], 'unrelated': ['related'], 'unconscious': ['conscious'], 'homosexual': ['bisexual'], 'invisible': ['visible'], 'induced': ['spontaneous'], 'unlimited': ['limited'], 'incredible': ['credible'], 'unstable': ['stable'], 'unhappy': ['happy'], 'gradual': ['sudden'], 'unpopular': ['popular'], 'epidemic': ['endemic'], 'unnecessary': ['necessary'], 'empirical': ['theoretical'], 'peripheral': ['central'], 'unwilling': ['willing'], 'spontaneous': ['induced'], 'inexpensive': ['expensive'], 'unavailable': ['available'], 'ineffective': ['effective'], 'cerebral': ['emotional'], 'invalid': ['valid'], 'unconstitutional': ['constitutional'], 'abnormal': ['normal'], 'unmarried': ['married'], 'idle': ['busy'], 'bisexual': ['heterosexual'], 'uncomfortable': ['comfortable'], 'unconventional': ['conventional'], 'incapable': ['capable'], 'incompatible': ['compatible'], 'credible': ['incredible'], 'lawful': ['unlawful'], 'undesirable': ['desirable'], 'heterosexual': ['homosexual'], 'unfamiliar': ['familiar'], 'ineligible': ['eligible'], 'inexperienced': ['experienced'], 'unpredictable': ['predictable'], 'predictable': ['unpredictable'], 'nasty': ['nice'], 'inaccessible': ['accessible'], 'naive': ['sophisticated'], 'affirmative': ['negative'], 'impractical': ['practical'], 'adoptive': ['biological'], 'unaffected': ['affected'], 'unequal': ['equal'], 'irrational': ['rational'], 'sensible': ['unreasonable'], 'involuntary': ['voluntary'], 'uneasy': ['easy'], 'immoral': ['moral'], 'fractional': ['whole'], 'heterogeneous': ['homogeneous'], 'unconditional': ['conditional'], 'unfavorable': ['favorable'], 'atypical': ['typical'], 'unnatural': ['natural'], 'unreasonable': ['reasonable'], 'displeased': ['pleased'], 'unrealistic': ['realistic'], 'improbable': ['probable'], 'impartial': ['partial'], 'unhealthy': ['healthy'], 'irresponsible': ['responsible'], 'unprepared': ['prepared'], 'intangible': ['tangible'], 'asymmetrical': ['symmetrical'], 'undue': ['due'], 'insoluble': ['soluble'], 'insensitive': ['sensitive'], 'unbelievable': ['credible'], 'unethical': ['ethical'], 'unimportant': ['important'], 'frivolous': ['serious'], 'unprofitable': ['profitable'], 'pessimistic': ['optimistic'], 'high-pitched': ['low'], 'unfavourable': ['favorable'], 'unproductive': ['productive'], 'discontinuous': ['continuous'], 'dependable': ['unreliable'], 'uninterested': ['interested'], 'unambiguous': ['ambiguous'], 'ineffectual': ['effective'], 'unattractive': ['attractive'], 'believable': ['incredible'], 'asexual': ['sexual'], 'inflexible': ['flexible'], 'impersonal': ['personal'], 'inconspicuous': ['conspicuous'], 'incomparable': ['comparable'], 'implausible': ['plausible'], 'invulnerable': ['vulnerable'], 'unsympathetic': ['sympathetic'], 'extrinsic': ['intrinsic'], 'undemocratic': ['democratic'], 'illogical': ['logical'], 'uninjured': ['injured'], 'inedible': ['edible'], 'inelastic': ['elastic'], 'uncharacteristic': ['characteristic'], 'theoretic': ['empirical'], 'unscientific': ['scientific'], 'unimpressive': ['impressive'], 'unplayable': ['playable'], 'unprofessional': ['professional'], 'unconcerned': ['concerned'], 'nontraditional': ['traditional'], 'unsanitary': ['sanitary'], 'dishonorable': ['honorable'], 'inoperative': ['operative'], 'uncritical': ['critical'], 'unfashionable': ['fashionable'], 'noncommercial': ['commercial'], 'unsteady': ['steady'], 'invariable': ['variable'], 'unneeded': ['necessary'], 'inaudible': ['audible'], 'uncontroversial': ['controversial'], 'unquestionable': ['questionable'], 'avoidable': ['inevitable'], 'unenthusiastic': ['enthusiastic'], 'unwary': ['wary'], 'unready': ['ready'], 'unapologetic': ['apologetic'], 'impious': ['pious'], 'unfree': ['free'], 'unarmored': ['armored'], 'effectual': ['ineffective'], 'unpatriotic': ['patriotic'], 'unidentifiable': ['identifiable'], 'inoffensive': ['offensive'], 'unarmoured': ['armored'], 'low-pitched': ['high'], 'noninvasive': ['invasive'], 'nonfunctional': ['functional'], 'ungrammatical': ['grammatical'], 'ignoble': ['noble'], 'unemotional': ['emotional'], 'nonnative': ['native'], 'unimpaired': ['impaired'], 'dishonourable': ['honorable'], 'inconsiderable': ['considerable'], 'ahistorical': ['historical'], 'unquiet': ['quiet'], 'untraditional': ['traditional'], 'untroubled': ['troubled'], 'unrighteous': ['righteous'], 'noncompetitive': ['competitive'], 'unsystematic': ['systematic'], 'insensible': ['sensible'], 'nonpolitical': ['political'], 'unambitious': ['ambitious'], 'unlikeable': ['sympathetic'], 'self-generated': ['induced'], 'indissoluble': ['soluble'], 'nonmilitary': ['military'], 'nonprofessional': ['professional'], 'resistible': ['irresistible'], 'nonsurgical': ['surgical'], 'nonrenewable': ['renewable'], 'unspecialized': ['specialized'], 'unlikable': ['sympathetic'], 'nontechnical': ['technical'], 'nonclassical': ['classical'], 'insanitary': ['sanitary'], 'incautious': ['cautious'], 'uncharitable': ['charitable'], 'untypical': ['typical'], 'nonmagnetic': ['magnetic'], 'nonalcoholic': ['alcoholic'], 'unsurprised': ['surprised'], 'unaccessible': ['accessible'], 'undependable': ['reliable'], 'unmusical': ['musical'], 'undramatic': ['dramatic'], 'nonfictional': ['fictional'], 'ungenerous': ['generous'], 'undiplomatic': ['diplomatic'], 'nonresidential': ['residential'], 'unkept': ['unbroken'], 'uncreative': ['creative'], 'nonproprietary': ['proprietary'], 'nonsexual': ['sexual'], 'unadventurous': ['adventurous'], 'ill-formed': ['grammatical'], 'noninfectious': ['infectious'], 'unaggressive': ['aggressive'], 'noncontroversial': ['controversial'], 'unsocial': ['social'], 'unhealthful': ['sanitary'], 'unseeable': ['visible'], 'synthetical': ['analytic'], 'unobvious': ['obvious'], 'inconvertible': ['convertible'], 'unaesthetic': ['aesthetic'], 'nonmusical': ['musical'], 'nonfinancial': ['financial'], 'unspecialised': ['specialized'], 'impalpable': ['tangible'], 'uncomparable': ['comparable'], 'nonaggressive': ['aggressive'], 'heterogenous': ['homogeneous'], 'nonindustrial': ['industrial'], 'nonoperational': ['operational'], 'unmilitary': ['military'], 'uncomplete': ['complete'], 'nonspherical': ['spherical'], 'uninfluential': ['influential'], 'antonymous': ['synonymous'], 'onymous': ['anonymous'], 'evitable': ['inevitable'], 'nonlinguistic': ['linguistic'], 'unvoluntary': ['voluntary'], 'nonreciprocal': ['reciprocal'], 'nonracial': ['racial'], 'antimagnetic': ['magnetic'], 'nonexplosive': ['explosive'], 'unrespectable': ['respectable'], 'noninstitutional': ['institutional'], 'uneatable': ['edible'], 'insusceptible': ['susceptible'], 'unportable': ['portable'], 'noncontinuous': ['continuous'], 'undiversified': ['diversified'], 'undynamic': ['dynamic'], 'incurious': ['curious'], 'nonhierarchical': ['hierarchical'], 'unmalicious': ['malicious'], 'concentrical': ['eccentric'], 'noncritical': ['critical'], 'nonspatial': ['spatial'], 'unconvertible': ['convertible'], 'nonvoluntary': ['voluntary'], 'unhearable': ['audible'], 'unsusceptible': ['susceptible'], 'unpresidential': ['presidential'], 'uneffective': ['effective'], 'inaesthetic': ['aesthetic'], 'unrenewable': ['renewable'], 'nonmechanical': ['mechanical'], 'undomestic': ['domestic'], 'untechnical': ['technical'], 'unthematic': ['thematic'], 'unhumorous': ['humorous'], 'nonmodern': ['modern'], 'noncellular': ['cellular'], 'untheatrical': ['theatrical'], 'avertable': ['inevitable'], 'adynamic': ['dynamic'], 'unlogical': ['logical'], 'seeable': ['invisible']}\n"
     ]
    }
   ],
   "source": [
    "print(adj_data_dict)\n",
    "print('===========================')\n",
    "print(ordered_antonyms_dict)\n",
    "print('===========================')\n",
    "print(adj_antonym)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_antonym_dict = {}\n",
    "final_antonym_dict.update(adj_data_dict)\n",
    "final_antonym_dict.update(ordered_antonyms_dict)\n",
    "final_antonym_dict.update(adj_antonym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'antibiotic': ['infection'], 'good': ['bad'], 'happy': ['unhappy'], 'nice': ['nasty'], 'able': ['unable'], 'abundant': ['scarce', 'rare', 'tight', 'meager', 'meagre', 'meagerly', 'stingy', 'scrimpy', 'insufficient', 'deficient'], 'aware': ['unaware', 'oblivious', 'unmindful', 'unconscious', 'unsuspecting', 'asleep', 'insensible', 'unconscious', 'unwitting', 'ignorant', 'indifferent', 'oblivious'], 'beautiful': ['ugly', 'disfigured', 'evil-looking', 'fugly', 'grotesque', 'monstrous', 'hideous', 'repulsive', 'ill-favored', 'ill-favoured', 'scrofulous', 'unlovely', 'unpicturesque', 'unsightly', 'displeasing', 'unattractive', 'awkward'], 'big': ['little', 'small'], 'bright': ['pale', 'colorless', 'colourless', 'dull', 'neutral', 'pale', 'white', 'bleached', 'faded', 'washed-out', 'washy', 'drab', 'somber', 'sombre', 'dulled', 'greyed', 'etiolate', 'etiolated', 'lurid', 'waxen', 'waxlike', 'waxy', 'whitened'], 'cheap': ['expensive', 'big-ticket', 'high-ticket', 'costly', 'dear', 'high-priced', 'pricey', 'pricy', 'dearly-won', 'overpriced', 'valuable'], 'clean': ['dirty', 'soiled', 'unclean', 'augean', 'bedraggled', 'draggled', 'befouled', 'fouled', 'begrimed', 'dingy', 'grimy', 'grubby', 'grungy', 'raunchy', 'black', 'smutty', 'buggy', 'cobwebby', 'dirty-faced', 'feculent', 'filthy', 'foul', 'nasty', 'flyblown', 'squalid', 'sordid', 'greasy', 'oily', 'lousy', 'maculate', 'mucky', 'muddy', 'ratty', 'scummy', 'smudgy', 'snotty', 'snot-nosed', 'sooty', 'travel-soiled', 'travel-stained', 'uncleanly', 'unswept', 'unwashed'], 'clear': ['unclear'], 'close': ['distant', 'remote', 'removed', 'far', 'faraway', ''], 'colorful': ['colorless', 'colourless', 'dull', 'neutral', 'pale', 'white', 'bleached', 'faded', 'washed-out', 'washy', 'drab', 'somber', 'sombre', 'dulled', 'greyed', 'etiolate', 'etiolated', 'lurid', 'waxen', 'waxlike', 'waxy', 'whitened'], 'common': ['rare', 'infrequent', 'scarce', 'uncommon', 'extraordinary'], 'competent': ['incompetent', 'unskilled', 'unqualified', 'inefficient', 'unqualified', 'unskilled'], 'concerned': ['unconcerned', 'blase', 'blithe', 'casual', 'insouciant', 'nonchalant', 'degage', 'detached', 'uninvolved', 'indifferent', 'careless', 'uninvolved', 'untroubled'], 'cooked': ['raw', 'half-baked', 'fresh', 'natural', 'underdone', 'rare', 'uncooked', 'untoasted'], 'dangerous': ['safe'], 'decisive': ['hesitating', 'indecisive', 'hesitant', 'inconclusive', 'irresolute'], 'dry': ['wet', 'bedewed', 'dewy', 'besprent', 'boggy', 'marshy', 'miry', 'mucky', 'muddy', 'quaggy', 'sloppy', 'sloughy', 'soggy', 'squashy', 'swampy', 'waterlogged', 'clammy', 'dank', 'damp', 'dampish', 'moist', 'sodden', 'soppy', 'drippy', 'drizzly', 'humid', 'misty', 'muggy', 'steamy', 'sticky', 'reeking', 'watery', 'rheumy', 'showery', 'rainy', 'steaming', 'tacky', 'undried', 'washed'], 'energetic': ['lethargic', 'unergetic', 'dazed', 'foggy', 'groggy', 'logy', 'stuporous', 'dreamy', 'lackadaisical', 'languid', 'languorous', 'listless', 'inactive'], 'familiar': ['unfamiliar'], 'fat': ['thin', 'lean', 'anorexic', 'anorectic', 'bony', 'cadaverous', 'emaciated', 'gaunt', 'haggard', 'pinched', 'skeletal', 'wasted', 'deep-eyed', 'hollow-eyed', 'sunken-eyed', 'gangling', 'gangly', 'lanky', 'lank', 'spindly', 'rawboned', 'reedy', 'reedlike', 'twiggy', 'twiglike', 'scarecrowish', 'scraggy', 'boney', 'scrawny', 'skinny', 'underweight', 'weedy', 'shriveled', 'shrivelled', 'shrunken', 'withered', 'wizen', 'wizened', 'slender', 'slight', 'slim', 'svelte', 'slender-waisted', 'slim-waisted', 'wasp-waisted', 'spare', 'trim', 'spindle-legged', 'spindle-shanked', 'stringy', 'wiry', 'wisplike', 'wispy'], 'full': ['empty'], 'gaseous': ['solid', 'hard', 'coagulated', 'solidified', 'concrete', 'congealed', 'jelled', 'jellied', 'dry', 'semisolid', 'solid-state'], 'generous': ['stingy', 'beggarly', 'mean', 'cheap', 'chinchy', 'chintzy', 'cheeseparing', 'close', 'near', 'penny-pinching', 'skinny', 'closefisted', 'hardfisted', 'tightfisted', 'grudging', 'niggardly', 'scrimy', 'mingy', 'miserly', 'tight', 'parsimonious', 'penurious', 'selfish', 'uncharitable', 'ungenerous', 'meanspirited'], 'hard': ['easy'], 'hot': ['cold', 'chilly', 'frosty', 'cool', 'frigid'], 'interesting': ['uninteresting', 'dull', 'boring', 'deadening', 'ho-hum', 'irksome', 'slow', 'tedious', 'tiresome', 'wearisome', 'insipid', 'jejune', 'narcotic', 'soporiferous', 'soporific', 'prosaic', 'prosy', 'earthbound', 'ponderous', 'putdownable', 'unexciting', 'unstimulating'], 'introvert': ['extravert', 'extrovert', 'outgoing', 'extroverted', 'forthcoming', 'sociable'], 'large': ['little', 'small'], 'long': ['short', 'abbreviated', 'shortened', 'truncated', 'brief', 'clipped', 'fleeting', 'fugitive', 'momentaneous', 'momentary', 'short_and_sweet', 'short-dated', 'short-range', 'short-run', 'short-term', 'abbreviated', 'brief', 'close', 'curtal', 'sawed-off', 'sawn-off', 'shortened', 'shortish', 'short-range', 'short-snouted', 'snub', 'stubby', 'telescoped', 'truncate', 'truncated', 'chunky', 'dumpy', 'low-set', 'squat', 'squatty', 'stumpy', 'compact', 'heavyset', 'stocky', 'thick', 'thickset', 'half-length', 'pint-size', 'pint-sized', 'runty', 'sawed-off', 'sawn-off', 'short-stalked', 'squab', 'squabby'], 'lumpy': ['flat', 'level', 'plane', 'even', ''], 'noisy': ['silent', 'uncommunicative', 'dumb', 'mute', 'inarticulate', 'unarticulate'], 'normal': ['abnormal'], 'organized': ['unorganized', 'unstructured', 'uncoordinated', 'unformed', 'unincorporated'], 'pale': ['tanned', 'bronzed', 'suntanned', 'brunet', 'brunette'], 'pretty': ['ugly', 'disfigured', 'evil-looking', 'fugly', 'grotesque', 'monstrous', 'hideous', 'repulsive', 'ill-favored', 'ill-favoured', 'scrofulous', 'unlovely', 'unpicturesque', 'unsightly', 'displeasing', 'unattractive', 'awkward'], 'rich': ['poor'], 'risky': ['safe', 'fail-safe', 'risk-free', 'riskless', 'unhazardous', 'safe-and-sound', 'unhurt', 'harmless', 'invulnerable', 'secure', 'uninjured'], 'sane': ['crazy', 'loony', 'looney', 'nutcase', 'weirdo', 'mad', 'insane'], 'short': ['tall', 'gangling', 'gangly', 'lanky', 'rangy', 'height', 'leggy', 'long-legged', 'long-shanked', 'tall-growing', 'long', 'long-stalked', 'tall-stalked', 'stately', 'statuesque', 'tallish'], 'simple': ['difficult', 'challenging', 'hard', 'complicated', 'demanding', 'daunting', 'taxing'], 'sincere': ['insincere', 'bootlicking', 'fawning', 'obsequious', 'sycophantic', 'toadyish', 'buttery', 'fulsome', 'oily', 'oleaginous', 'smarmy', 'soapy', 'unctuous', 'dissimulative', 'false', 'feigned', 'gilded', 'meretricious', 'specious', 'hypocritical', 'plausible', 'counterfeit', 'imitative', 'dishonest', 'dishonorable', 'disingenuous', 'artful', 'false', 'unreal'], 'slow': ['fast', 'quick', 'accelerated', 'alacritous', 'blistering', 'hot', 'red-hot', 'double-quick', 'express', 'fast-breaking', 'fast-paced', 'fleet', 'swift', 'high-speed', 'high-velocity', 'hurrying', 'scurrying', 'immediate', 'prompt', 'quick', 'straightaway', 'instantaneous', 'instant', 'meteoric', 'speedy', 'rapid', 'winged', 'windy'], 'sweet': ['sour', 'acerb', 'acerbic', 'astringent', 'acetose', 'acetous', 'vinegary', 'vinegarish', 'acidic', 'acid', 'acidulent', 'acidulous', 'lemony', 'lemonlike', 'sourish', 'tangy', 'tart', 'subacid', 'bitter'], 'tasty': ['tasteless', 'bland', 'flat', 'flavorless', 'flavourless', 'insipid', 'savorless', 'savourless', 'vapid', 'unflavored', 'unflavoured', 'nonflavored', 'nonflavoured', 'unsalted', 'unseasoned', 'unappetizing', 'unappetising', 'unpalatable'], 'tight': ['loose', 'lax', 'baggy', 'loose-fitting', 'sloppy', 'flyaway', 'free', 'liberal', 'informal', 'unofficial'], 'warm': ['cool', 'cold', 'chilly', 'frosty', 'cool', 'frigid'], 'white': ['black'], 'wide': ['narrow', 'constricting', 'constrictive', 'narrowing', 'narrowed', 'narrow-mouthed', 'slender', 'thin', 'strait', 'straplike', 'tapered', 'tapering', 'limited'], 'willing': ['unwilling'], 'young': ['old'], 'new': ['old'], 'other': ['same'], 'many': ['few'], 'high': ['low'], 'same': ['other'], 'general': ['specific'], 'international': ['national'], 'local': ['national'], 'small': ['big', 'large'], 'much': ['little'], 'old': ['young'], 'single': ['common'], 'different': ['same'], 'few': ['many'], 'popular': ['unpopular'], 'black': ['white'], 'northern': ['southern'], 'married': ['unmarried'], 'southern': ['northern'], 'little': ['big', 'large'], 'available': ['unavailable'], 'successful': ['unsuccessful'], 'native': ['foreign'], 'possible': ['impossible'], 'natural': ['unnatural'], 'strong': ['weak'], 'active': ['inactive'], 'limited': ['unlimited'], 'low': ['high'], 'foreign': ['domestic'], 'related': ['unrelated'], 'legal': ['illegal'], 'true': ['false'], 'dead': ['alive'], 'specific': ['general'], 'likely': ['unlikely'], 'difficult': ['easy'], 'rural': ['urban'], 'potential': ['actual'], 'necessary': ['unnecessary'], 'nuclear': ['conventional'], 'unable': ['able'], 'bad': ['good'], 'positive': ['negative'], 'internal': ['external'], 'effective': ['ineffective'], 'actual': ['potential'], 'domestic': ['foreign'], 'formal': ['informal'], 'external': ['internal'], 'capable': ['incapable'], 'easy': ['difficult'], 'affected': ['unaffected'], 'experienced': ['inexperienced'], 'unusual': ['usual'], 'safe': ['dangerous'], 'visible': ['invisible'], 'instrumental': ['vocal'], 'illegal': ['legal'], 'vocal': ['instrumental'], 'alive': ['dead'], 'civilian': ['military'], 'conventional': ['unconventional'], 'unsuccessful': ['successful'], 'false': ['true'], 'soft': ['hard'], 'stable': ['unstable'], 'usual': ['unusual'], 'impossible': ['possible'], 'endemic': ['epidemic'], 'ordinary': ['extraordinary'], 'vertical': ['inclined'], 'automatic': ['manual'], 'weak': ['strong'], 'accessible': ['inaccessible'], 'artificial': ['natural'], 'empty': ['full'], 'emotional': ['cerebral'], 'theoretical': ['empirical'], 'eligible': ['ineligible'], 'valid': ['invalid'], 'extraordinary': ['ordinary'], 'busy': ['idle'], 'reliable': ['unreliable'], 'sudden': ['gradual'], 'unlikely': ['probable'], 'voluntary': ['involuntary'], 'informal': ['formal'], 'reasonable': ['unreasonable'], 'sophisticated': ['naive'], 'compatible': ['incompatible'], 'acceptable': ['unacceptable'], 'comfortable': ['uncomfortable'], 'uncommon': ['common'], 'rational': ['irrational'], 'supernatural': ['natural'], 'unrelated': ['related'], 'unconscious': ['conscious'], 'homosexual': ['bisexual'], 'invisible': ['visible'], 'induced': ['spontaneous'], 'unlimited': ['limited'], 'incredible': ['credible'], 'unstable': ['stable'], 'unhappy': ['happy'], 'gradual': ['sudden'], 'unpopular': ['popular'], 'epidemic': ['endemic'], 'unnecessary': ['necessary'], 'empirical': ['theoretical'], 'peripheral': ['central'], 'unwilling': ['willing'], 'spontaneous': ['induced'], 'inexpensive': ['expensive'], 'unavailable': ['available'], 'ineffective': ['effective'], 'cerebral': ['emotional'], 'invalid': ['valid'], 'unconstitutional': ['constitutional'], 'abnormal': ['normal'], 'unmarried': ['married'], 'idle': ['busy'], 'bisexual': ['heterosexual'], 'uncomfortable': ['comfortable'], 'unconventional': ['conventional'], 'incapable': ['capable'], 'incompatible': ['compatible'], 'credible': ['incredible'], 'lawful': ['unlawful'], 'undesirable': ['desirable'], 'heterosexual': ['homosexual'], 'unfamiliar': ['familiar'], 'ineligible': ['eligible'], 'inexperienced': ['experienced'], 'unpredictable': ['predictable'], 'predictable': ['unpredictable'], 'nasty': ['nice'], 'inaccessible': ['accessible'], 'naive': ['sophisticated'], 'affirmative': ['negative'], 'impractical': ['practical'], 'adoptive': ['biological'], 'unaffected': ['affected'], 'unequal': ['equal'], 'irrational': ['rational'], 'sensible': ['unreasonable'], 'involuntary': ['voluntary'], 'uneasy': ['easy'], 'immoral': ['moral'], 'fractional': ['whole'], 'heterogeneous': ['homogeneous'], 'unconditional': ['conditional'], 'unfavorable': ['favorable'], 'atypical': ['typical'], 'unnatural': ['natural'], 'unreasonable': ['reasonable'], 'displeased': ['pleased'], 'unrealistic': ['realistic'], 'improbable': ['probable'], 'impartial': ['partial'], 'unhealthy': ['healthy'], 'irresponsible': ['responsible'], 'unprepared': ['prepared'], 'intangible': ['tangible'], 'asymmetrical': ['symmetrical'], 'undue': ['due'], 'insoluble': ['soluble'], 'insensitive': ['sensitive'], 'unbelievable': ['credible'], 'unethical': ['ethical'], 'unimportant': ['important'], 'frivolous': ['serious'], 'unprofitable': ['profitable'], 'pessimistic': ['optimistic'], 'high-pitched': ['low'], 'unfavourable': ['favorable'], 'unproductive': ['productive'], 'discontinuous': ['continuous'], 'dependable': ['unreliable'], 'uninterested': ['interested'], 'unambiguous': ['ambiguous'], 'ineffectual': ['effective'], 'unattractive': ['attractive'], 'believable': ['incredible'], 'asexual': ['sexual'], 'inflexible': ['flexible'], 'impersonal': ['personal'], 'inconspicuous': ['conspicuous'], 'incomparable': ['comparable'], 'implausible': ['plausible'], 'invulnerable': ['vulnerable'], 'unsympathetic': ['sympathetic'], 'extrinsic': ['intrinsic'], 'undemocratic': ['democratic'], 'illogical': ['logical'], 'uninjured': ['injured'], 'inedible': ['edible'], 'inelastic': ['elastic'], 'uncharacteristic': ['characteristic'], 'theoretic': ['empirical'], 'unscientific': ['scientific'], 'unimpressive': ['impressive'], 'unplayable': ['playable'], 'unprofessional': ['professional'], 'unconcerned': ['concerned'], 'nontraditional': ['traditional'], 'unsanitary': ['sanitary'], 'dishonorable': ['honorable'], 'inoperative': ['operative'], 'uncritical': ['critical'], 'unfashionable': ['fashionable'], 'noncommercial': ['commercial'], 'unsteady': ['steady'], 'invariable': ['variable'], 'unneeded': ['necessary'], 'inaudible': ['audible'], 'uncontroversial': ['controversial'], 'unquestionable': ['questionable'], 'avoidable': ['inevitable'], 'unenthusiastic': ['enthusiastic'], 'unwary': ['wary'], 'unready': ['ready'], 'unapologetic': ['apologetic'], 'impious': ['pious'], 'unfree': ['free'], 'unarmored': ['armored'], 'effectual': ['ineffective'], 'unpatriotic': ['patriotic'], 'unidentifiable': ['identifiable'], 'inoffensive': ['offensive'], 'unarmoured': ['armored'], 'low-pitched': ['high'], 'noninvasive': ['invasive'], 'nonfunctional': ['functional'], 'ungrammatical': ['grammatical'], 'ignoble': ['noble'], 'unemotional': ['emotional'], 'nonnative': ['native'], 'unimpaired': ['impaired'], 'dishonourable': ['honorable'], 'inconsiderable': ['considerable'], 'ahistorical': ['historical'], 'unquiet': ['quiet'], 'untraditional': ['traditional'], 'untroubled': ['troubled'], 'unrighteous': ['righteous'], 'noncompetitive': ['competitive'], 'unsystematic': ['systematic'], 'insensible': ['sensible'], 'nonpolitical': ['political'], 'unambitious': ['ambitious'], 'unlikeable': ['sympathetic'], 'self-generated': ['induced'], 'indissoluble': ['soluble'], 'nonmilitary': ['military'], 'nonprofessional': ['professional'], 'resistible': ['irresistible'], 'nonsurgical': ['surgical'], 'nonrenewable': ['renewable'], 'unspecialized': ['specialized'], 'unlikable': ['sympathetic'], 'nontechnical': ['technical'], 'nonclassical': ['classical'], 'insanitary': ['sanitary'], 'incautious': ['cautious'], 'uncharitable': ['charitable'], 'untypical': ['typical'], 'nonmagnetic': ['magnetic'], 'nonalcoholic': ['alcoholic'], 'unsurprised': ['surprised'], 'unaccessible': ['accessible'], 'undependable': ['reliable'], 'unmusical': ['musical'], 'undramatic': ['dramatic'], 'nonfictional': ['fictional'], 'ungenerous': ['generous'], 'undiplomatic': ['diplomatic'], 'nonresidential': ['residential'], 'unkept': ['unbroken'], 'uncreative': ['creative'], 'nonproprietary': ['proprietary'], 'nonsexual': ['sexual'], 'unadventurous': ['adventurous'], 'ill-formed': ['grammatical'], 'noninfectious': ['infectious'], 'unaggressive': ['aggressive'], 'noncontroversial': ['controversial'], 'unsocial': ['social'], 'unhealthful': ['sanitary'], 'unseeable': ['visible'], 'synthetical': ['analytic'], 'unobvious': ['obvious'], 'inconvertible': ['convertible'], 'unaesthetic': ['aesthetic'], 'nonmusical': ['musical'], 'nonfinancial': ['financial'], 'unspecialised': ['specialized'], 'impalpable': ['tangible'], 'uncomparable': ['comparable'], 'nonaggressive': ['aggressive'], 'heterogenous': ['homogeneous'], 'nonindustrial': ['industrial'], 'nonoperational': ['operational'], 'unmilitary': ['military'], 'uncomplete': ['complete'], 'nonspherical': ['spherical'], 'uninfluential': ['influential'], 'antonymous': ['synonymous'], 'onymous': ['anonymous'], 'evitable': ['inevitable'], 'nonlinguistic': ['linguistic'], 'unvoluntary': ['voluntary'], 'nonreciprocal': ['reciprocal'], 'nonracial': ['racial'], 'antimagnetic': ['magnetic'], 'nonexplosive': ['explosive'], 'unrespectable': ['respectable'], 'noninstitutional': ['institutional'], 'uneatable': ['edible'], 'insusceptible': ['susceptible'], 'unportable': ['portable'], 'noncontinuous': ['continuous'], 'undiversified': ['diversified'], 'undynamic': ['dynamic'], 'incurious': ['curious'], 'nonhierarchical': ['hierarchical'], 'unmalicious': ['malicious'], 'concentrical': ['eccentric'], 'noncritical': ['critical'], 'nonspatial': ['spatial'], 'unconvertible': ['convertible'], 'nonvoluntary': ['voluntary'], 'unhearable': ['audible'], 'unsusceptible': ['susceptible'], 'unpresidential': ['presidential'], 'uneffective': ['effective'], 'inaesthetic': ['aesthetic'], 'unrenewable': ['renewable'], 'nonmechanical': ['mechanical'], 'undomestic': ['domestic'], 'untechnical': ['technical'], 'unthematic': ['thematic'], 'unhumorous': ['humorous'], 'nonmodern': ['modern'], 'noncellular': ['cellular'], 'untheatrical': ['theatrical'], 'avertable': ['inevitable'], 'adynamic': ['dynamic'], 'unlogical': ['logical'], 'seeable': ['invisible']}\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "# 合并后的数据\n",
    "print(final_antonym_dict)\n",
    "print('===========')\n",
    "\n",
    "# 复制一份作为 最后结果的json 文件的生成文件\n",
    "import copy\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "templates = [\n",
    "    'John is * but Mary is _ .',\n",
    "    'The antonym of * is _ .'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "John is antibiotic but Mary is _ .\n",
      "['not', 'Catholic', 'Jewish', 'pregnant', 'alive', 'gay', 'Christian', 'dead', 'Baptist', 'Muslim']\n",
      "tensor([0.2017, 0.0369, 0.0303, 0.0162, 0.0140, 0.0109, 0.0100, 0.0094, 0.0087,\n",
      "        0.0072])\n",
      "{'infection': tensor(8.2644e-07)}\n",
      "max_probe is: tensor(8.2644e-07)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "10240\n",
      "20480\n",
      "the position of max probe is: 12846\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is good but Mary is _ .\n",
      "['better', 'bad', 'good', 'great', 'beautiful', 'evil', 'worse', 'perfect', 'wonderful', 'amazing']\n",
      "tensor([0.4136, 0.0610, 0.0500, 0.0352, 0.0322, 0.0296, 0.0150, 0.0137, 0.0118,\n",
      "        0.0099])\n",
      "{'bad': tensor(0.0610)}\n",
      "max_probe is: tensor(0.0610)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is happy but Mary is _ .\n",
      "['sad', 'not', 'worried', 'unhappy', 'afraid', 'angry', 'scared', 'crying', 'lonely', 'upset']\n",
      "tensor([0.2500, 0.1998, 0.0794, 0.0543, 0.0351, 0.0297, 0.0287, 0.0223, 0.0205,\n",
      "        0.0183])\n",
      "{'unhappy': tensor(0.0543)}\n",
      "max_probe is: tensor(0.0543)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nice but Mary is _ .\n",
      "['nice', 'nicer', 'beautiful', 'pretty', 'better', 'not', 'ugly', 'good', 'evil', 'sweet']\n",
      "tensor([0.0750, 0.0501, 0.0500, 0.0362, 0.0315, 0.0258, 0.0181, 0.0177, 0.0165,\n",
      "        0.0157])\n",
      "{'nasty': tensor(0.0040)}\n",
      "max_probe is: tensor(0.0040)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 39\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is able but Mary is _ .\n",
      "['not', 'unwilling', 'willing', 'weak', 'helpless', 'unable', 'afraid', 'pregnant', 'strong', 'ready']\n",
      "tensor([0.2629, 0.1289, 0.0825, 0.0334, 0.0251, 0.0238, 0.0236, 0.0108, 0.0101,\n",
      "        0.0094])\n",
      "{'unable': tensor(0.0238)}\n",
      "max_probe is: tensor(0.0238)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is abundant but Mary is _ .\n",
      "['scarce', 'poor', 'not', 'hungry', 'precious', 'lacking', 'needed', 'barren', 'needy', 'starving']\n",
      "tensor([0.1027, 0.1010, 0.0692, 0.0292, 0.0265, 0.0226, 0.0166, 0.0160, 0.0135,\n",
      "        0.0135])\n",
      "meagreis not in list\n",
      "meagerlyis not in list\n",
      "stingyis not in list\n",
      "scrimpyis not in list\n",
      "{'scarce': tensor(0.1027), 'rare': tensor(0.0133), 'tight': tensor(4.6578e-05), 'meager': tensor(0.0046), 'insufficient': tensor(0.0128), 'deficient': tensor(0.0020)}\n",
      "max_probe is: tensor(0.1027)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is aware but Mary is _ .\n",
      "['not', 'asleep', 'unaware', 'oblivious', 'sleeping', 'silent', 'confused', 'unconscious', 'afraid', 'too']\n",
      "tensor([0.4543, 0.0758, 0.0397, 0.0333, 0.0311, 0.0133, 0.0107, 0.0082, 0.0077,\n",
      "        0.0075])\n",
      "unmindfulis not in list\n",
      "insensibleis not in list\n",
      "{'unaware': tensor(0.0397), 'oblivious': tensor(0.0333), 'unconscious': tensor(0.0082), 'unsuspecting': tensor(6.9984e-05), 'asleep': tensor(0.0758), 'unwitting': tensor(2.5068e-05), 'ignorant': tensor(0.0008), 'indifferent': tensor(0.0007)}\n",
      "max_probe is: tensor(0.0758)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is beautiful but Mary is _ .\n",
      "['beautiful', 'perfect', 'better', 'pretty', 'divine', 'amazing', 'lovely', 'precious', 'Beautiful', 'special']\n",
      "tensor([0.4710, 0.0223, 0.0169, 0.0158, 0.0150, 0.0142, 0.0122, 0.0094, 0.0093,\n",
      "        0.0093])\n",
      "disfiguredis not in list\n",
      "evil-lookingis not in list\n",
      "fuglyis not in list\n",
      "repulsiveis not in list\n",
      "ill-favoredis not in list\n",
      "ill-favouredis not in list\n",
      "scrofulousis not in list\n",
      "unlovelyis not in list\n",
      "unpicturesqueis not in list\n",
      "unsightlyis not in list\n",
      "displeasingis not in list\n",
      "unattractiveis not in list\n",
      "{'ugly': tensor(0.0039), 'grotesque': tensor(3.3397e-05), 'monstrous': tensor(8.6014e-05), 'hideous': tensor(0.0004), 'awkward': tensor(3.1914e-05)}\n",
      "max_probe is: tensor(0.0039)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 26\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is big but Mary is _ .\n",
      "['small', 'tiny', 'beautiful', 'strong', 'little', 'smaller', 'pretty', 'big', 'bigger', 'tall']\n",
      "tensor([0.2324, 0.0911, 0.0633, 0.0534, 0.0487, 0.0332, 0.0284, 0.0275, 0.0178,\n",
      "        0.0108])\n",
      "{'little': tensor(0.0487), 'small': tensor(0.2324)}\n",
      "max_probe is: tensor(0.2324)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is bright but Mary is _ .\n",
      "['beautiful', 'dark', 'quiet', 'kind', 'wise', 'bright', 'silent', 'gentle', 'soft', 'strong']\n",
      "tensor([0.0977, 0.0869, 0.0490, 0.0308, 0.0266, 0.0254, 0.0185, 0.0178, 0.0171,\n",
      "        0.0148])\n",
      "colorlessis not in list\n",
      "colourlessis not in list\n",
      "bleachedis not in list\n",
      "washed-outis not in list\n",
      "washyis not in list\n",
      "drabis not in list\n",
      "somberis not in list\n",
      "sombreis not in list\n",
      "dulledis not in list\n",
      "greyedis not in list\n",
      "etiolateis not in list\n",
      "etiolatedis not in list\n",
      "luridis not in list\n",
      "waxenis not in list\n",
      "waxlikeis not in list\n",
      "waxyis not in list\n",
      "whitenedis not in list\n",
      "{'pale': tensor(0.0015), 'dull': tensor(0.0022), 'neutral': tensor(2.7891e-05), 'white': tensor(0.0025), 'faded': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0025)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 68\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is cheap but Mary is _ .\n",
      "['rich', 'expensive', 'free', 'priceless', 'beautiful', 'cheap', 'good', 'pretty', 'special', 'not']\n",
      "tensor([0.0846, 0.0834, 0.0667, 0.0595, 0.0567, 0.0344, 0.0246, 0.0201, 0.0194,\n",
      "        0.0178])\n",
      "big-ticketis not in list\n",
      "high-ticketis not in list\n",
      "high-pricedis not in list\n",
      "pricyis not in list\n",
      "dearly-wonis not in list\n",
      "overpricedis not in list\n",
      "{'expensive': tensor(0.0834), 'costly': tensor(0.0042), 'dear': tensor(0.0017), 'pricey': tensor(0.0056), 'valuable': tensor(0.0022)}\n",
      "max_probe is: tensor(0.0834)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is clean but Mary is _ .\n",
      "['dirty', 'filthy', 'stained', 'not', 'messy', 'clean', 'tainted', 'contaminated', 'wet', 'polluted']\n",
      "tensor([0.6952, 0.0588, 0.0262, 0.0215, 0.0147, 0.0112, 0.0094, 0.0090, 0.0078,\n",
      "        0.0055])\n",
      "soiledis not in list\n",
      "uncleanis not in list\n",
      "augeanis not in list\n",
      "bedraggledis not in list\n",
      "draggledis not in list\n",
      "befouledis not in list\n",
      "fouledis not in list\n",
      "begrimedis not in list\n",
      "dingyis not in list\n",
      "grimyis not in list\n",
      "grubbyis not in list\n",
      "grungyis not in list\n",
      "raunchyis not in list\n",
      "smuttyis not in list\n",
      "cobwebbyis not in list\n",
      "dirty-facedis not in list\n",
      "feculentis not in list\n",
      "flyblownis not in list\n",
      "squalidis not in list\n",
      "sordidis not in list\n",
      "greasyis not in list\n",
      "maculateis not in list\n",
      "muckyis not in list\n",
      "rattyis not in list\n",
      "scummyis not in list\n",
      "smudgyis not in list\n",
      "snottyis not in list\n",
      "snot-nosedis not in list\n",
      "sootyis not in list\n",
      "travel-soiledis not in list\n",
      "travel-stainedis not in list\n",
      "uncleanlyis not in list\n",
      "unsweptis not in list\n",
      "unwashedis not in list\n",
      "{'dirty': tensor(0.6952), 'black': tensor(0.0009), 'buggy': tensor(8.8581e-07), 'filthy': tensor(0.0588), 'foul': tensor(0.0004), 'nasty': tensor(0.0005), 'oily': tensor(9.6729e-05), 'lousy': tensor(0.0001), 'muddy': tensor(0.0010)}\n",
      "max_probe is: tensor(0.6952)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is clear but Mary is _ .\n",
      "['not', 'confused', 'unclear', 'ambiguous', 'silent', 'elusive', 'conflicted', 'vague', 'murky', 'misunderstood']\n",
      "tensor([0.3666, 0.1024, 0.0601, 0.0578, 0.0368, 0.0151, 0.0139, 0.0120, 0.0096,\n",
      "        0.0081])\n",
      "{'unclear': tensor(0.0601)}\n",
      "max_probe is: tensor(0.0601)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is close but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'stronger', 'closer', 'ahead', 'better', 'far', 'free', 'gone', 'alone', 'different']\n",
      "tensor([0.0623, 0.0469, 0.0453, 0.0271, 0.0267, 0.0206, 0.0146, 0.0133, 0.0130,\n",
      "        0.0120])\n",
      "farawayis not in list\n",
      "{'distant': tensor(0.0074), 'remote': tensor(0.0004), 'removed': tensor(0.0002), 'far': tensor(0.0206), '': tensor(8.0063e-05)}\n",
      "max_probe is: tensor(0.0206)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is colorful but Mary is _ .\n",
      "['beautiful', 'not', 'white', 'plain', 'black', 'simple', 'real', 'pure', 'quiet', 'elegant']\n",
      "tensor([0.1292, 0.0326, 0.0304, 0.0263, 0.0257, 0.0248, 0.0193, 0.0190, 0.0178,\n",
      "        0.0170])\n",
      "colorlessis not in list\n",
      "colourlessis not in list\n",
      "bleachedis not in list\n",
      "washed-outis not in list\n",
      "washyis not in list\n",
      "drabis not in list\n",
      "somberis not in list\n",
      "sombreis not in list\n",
      "dulledis not in list\n",
      "greyedis not in list\n",
      "etiolateis not in list\n",
      "etiolatedis not in list\n",
      "luridis not in list\n",
      "waxenis not in list\n",
      "waxlikeis not in list\n",
      "waxyis not in list\n",
      "whitenedis not in list\n",
      "{'dull': tensor(0.0014), 'neutral': tensor(0.0003), 'pale': tensor(0.0017), 'white': tensor(0.0304), 'faded': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0304)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is common but Mary is _ .\n",
      "['rare', 'uncommon', 'not', 'unusual', 'special', 'unique', 'different', 'common', 'scarce', 'popular']\n",
      "tensor([0.5977, 0.1375, 0.0821, 0.0324, 0.0232, 0.0146, 0.0091, 0.0063, 0.0059,\n",
      "        0.0029])\n",
      "infrequentis not in list\n",
      "{'rare': tensor(0.5977), 'scarce': tensor(0.0059), 'uncommon': tensor(0.1375), 'extraordinary': tensor(0.0003)}\n",
      "max_probe is: tensor(0.5977)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is competent but Mary is _ .\n",
      "['not', 'beautiful', 'incompetent', 'better', 'desperate', 'naive', 'weak', 'naÃ¯ve', 'pretty', 'stupid']\n",
      "tensor([0.1666, 0.0218, 0.0120, 0.0100, 0.0095, 0.0095, 0.0094, 0.0082, 0.0073,\n",
      "        0.0072])\n",
      "unskilledis not in list\n",
      "unqualifiedis not in list\n",
      "unqualifiedis not in list\n",
      "unskilledis not in list\n",
      "{'incompetent': tensor(0.0120), 'inefficient': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0120)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is concerned but Mary is _ .\n",
      "['not', 'happy', 'worried', 'calm', 'excited', 'adamant', 'relieved', 'relaxed', 'concerned', 'delighted']\n",
      "tensor([0.2837, 0.0610, 0.0512, 0.0247, 0.0211, 0.0171, 0.0159, 0.0136, 0.0124,\n",
      "        0.0109])\n",
      "unconcernedis not in list\n",
      "blaseis not in list\n",
      "blitheis not in list\n",
      "insouciantis not in list\n",
      "nonchalantis not in list\n",
      "degageis not in list\n",
      "uninvolvedis not in list\n",
      "uninvolvedis not in list\n",
      "untroubledis not in list\n",
      "{'casual': tensor(1.9099e-05), 'detached': tensor(9.4330e-05), 'indifferent': tensor(0.0031), 'careless': tensor(6.0006e-05)}\n",
      "max_probe is: tensor(0.0031)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 43\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is cooked but Mary is _ .\n",
      "['not', 'saved', 'alive', 'cooked', 'eaten', 'untouched', 'killed', 'born', 'asleep', 'cold']\n",
      "tensor([0.2783, 0.0761, 0.0290, 0.0194, 0.0149, 0.0146, 0.0134, 0.0131, 0.0109,\n",
      "        0.0106])\n",
      "half-bakedis not in list\n",
      "underdoneis not in list\n",
      "uncookedis not in list\n",
      "untoastedis not in list\n",
      "{'raw': tensor(0.0015), 'fresh': tensor(0.0006), 'natural': tensor(2.3249e-05), 'rare': tensor(3.5633e-05)}\n",
      "max_probe is: tensor(0.0015)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 80\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is dangerous but Mary is _ .\n",
      "['not', 'beautiful', 'stronger', 'innocent', 'strong', 'free', 'better', 'safe', 'powerful', 'trustworthy']\n",
      "tensor([0.0995, 0.0699, 0.0313, 0.0307, 0.0230, 0.0199, 0.0192, 0.0155, 0.0132,\n",
      "        0.0130])\n",
      "{'safe': tensor(0.0155)}\n",
      "max_probe is: tensor(0.0155)\n",
      "the position of max probe is: 7\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is decisive but Mary is _ .\n",
      "['not', 'decisive', 'vulnerable', 'silent', 'weak', 'powerless', 'conflicted', 'determined', 'involved', 'fragile']\n",
      "tensor([0.0536, 0.0373, 0.0369, 0.0212, 0.0211, 0.0145, 0.0128, 0.0112, 0.0100,\n",
      "        0.0092])\n",
      "hesitatingis not in list\n",
      "indecisiveis not in list\n",
      "inconclusiveis not in list\n",
      "irresoluteis not in list\n",
      "{'hesitant': tensor(0.0033)}\n",
      "max_probe is: tensor(0.0033)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 49\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is dry but Mary is _ .\n",
      "['wet', 'not', 'soaked', 'thirsty', 'damp', 'moist', 'drowning', 'hot', 'pregnant', 'sick']\n",
      "tensor([0.6842, 0.0344, 0.0311, 0.0258, 0.0106, 0.0091, 0.0091, 0.0086, 0.0084,\n",
      "        0.0054])\n",
      "bedewedis not in list\n",
      "dewyis not in list\n",
      "besprentis not in list\n",
      "boggyis not in list\n",
      "marshyis not in list\n",
      "miryis not in list\n",
      "muckyis not in list\n",
      "quaggyis not in list\n",
      "sloughyis not in list\n",
      "soggyis not in list\n",
      "squashyis not in list\n",
      "swampyis not in list\n",
      "waterloggedis not in list\n",
      "clammyis not in list\n",
      "dankis not in list\n",
      "dampishis not in list\n",
      "soddenis not in list\n",
      "soppyis not in list\n",
      "drippyis not in list\n",
      "drizzlyis not in list\n",
      "mistyis not in list\n",
      "muggyis not in list\n",
      "steamyis not in list\n",
      "reekingis not in list\n",
      "wateryis not in list\n",
      "rheumyis not in list\n",
      "showeryis not in list\n",
      "steamingis not in list\n",
      "tackyis not in list\n",
      "undriedis not in list\n",
      "{'wet': tensor(0.6842), 'muddy': tensor(0.0009), 'sloppy': tensor(6.5683e-05), 'damp': tensor(0.0106), 'moist': tensor(0.0091), 'humid': tensor(0.0004), 'sticky': tensor(0.0002), 'rainy': tensor(0.0011), 'washed': tensor(0.0007)}\n",
      "max_probe is: tensor(0.6842)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is energetic but Mary is _ .\n",
      "['not', 'quiet', 'passive', 'weak', 'lonely', 'timid', 'tired', 'shy', 'patient', 'depressed']\n",
      "tensor([0.0514, 0.0378, 0.0231, 0.0222, 0.0206, 0.0194, 0.0192, 0.0179, 0.0162,\n",
      "        0.0155])\n",
      "lethargicis not in list\n",
      "unergeticis not in list\n",
      "dazedis not in list\n",
      "foggyis not in list\n",
      "groggyis not in list\n",
      "logyis not in list\n",
      "stuporousis not in list\n",
      "dreamyis not in list\n",
      "lackadaisicalis not in list\n",
      "languidis not in list\n",
      "languorousis not in list\n",
      "listlessis not in list\n",
      "{'inactive': tensor(0.0020)}\n",
      "max_probe is: tensor(0.0020)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 103\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is familiar but Mary is _ .\n",
      "['not', 'new', 'different', 'unknown', 'mysterious', 'unfamiliar', 'stranger', 'alien', 'foreign', 'exotic']\n",
      "tensor([0.3450, 0.2321, 0.0595, 0.0438, 0.0250, 0.0240, 0.0177, 0.0112, 0.0102,\n",
      "        0.0094])\n",
      "{'unfamiliar': tensor(0.0240)}\n",
      "max_probe is: tensor(0.0240)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is fat but Mary is _ .\n",
      "['thin', 'skinny', 'beautiful', 'fat', 'slim', 'pretty', 'not', 'pregnant', 'strong', 'perfect']\n",
      "tensor([0.1945, 0.1335, 0.0971, 0.0598, 0.0357, 0.0306, 0.0234, 0.0181, 0.0145,\n",
      "        0.0139])\n",
      "anorexicis not in list\n",
      "anorecticis not in list\n",
      "bonyis not in list\n",
      "cadaverousis not in list\n",
      "emaciatedis not in list\n",
      "gauntis not in list\n",
      "haggardis not in list\n",
      "pinchedis not in list\n",
      "deep-eyedis not in list\n",
      "hollow-eyedis not in list\n",
      "sunken-eyedis not in list\n",
      "ganglingis not in list\n",
      "ganglyis not in list\n",
      "lankyis not in list\n",
      "lankis not in list\n",
      "spindlyis not in list\n",
      "rawbonedis not in list\n",
      "reedyis not in list\n",
      "reedlikeis not in list\n",
      "twiggyis not in list\n",
      "twiglikeis not in list\n",
      "scarecrowishis not in list\n",
      "scraggyis not in list\n",
      "boneyis not in list\n",
      "scrawnyis not in list\n",
      "underweightis not in list\n",
      "weedyis not in list\n",
      "shriveledis not in list\n",
      "shrivelledis not in list\n",
      "shrunkenis not in list\n",
      "witheredis not in list\n",
      "wizenis not in list\n",
      "wizenedis not in list\n",
      "svelteis not in list\n",
      "slender-waistedis not in list\n",
      "slim-waistedis not in list\n",
      "wasp-waistedis not in list\n",
      "spindle-leggedis not in list\n",
      "spindle-shankedis not in list\n",
      "stringyis not in list\n",
      "wiryis not in list\n",
      "wisplikeis not in list\n",
      "wispyis not in list\n",
      "{'thin': tensor(0.1945), 'lean': tensor(0.0021), 'skeletal': tensor(9.6009e-05), 'wasted': tensor(0.0002), 'skinny': tensor(0.1335), 'slender': tensor(0.0100), 'slight': tensor(5.6642e-05), 'slim': tensor(0.0357), 'spare': tensor(1.0924e-05), 'trim': tensor(0.0002)}\n",
      "max_probe is: tensor(0.1945)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is full but Mary is _ .\n",
      "['empty', 'hungry', 'full', 'starving', 'not', 'lonely', 'thirsty', 'alone', 'ready', 'bursting']\n",
      "tensor([0.2547, 0.2053, 0.0843, 0.0446, 0.0285, 0.0217, 0.0214, 0.0111, 0.0107,\n",
      "        0.0089])\n",
      "{'empty': tensor(0.2547)}\n",
      "max_probe is: tensor(0.2547)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is gaseous but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['solid', 'liquid', 'not', 'fluid', 'water', 'inert', 'transparent', 'pure', 'immortal', 'dry']\n",
      "tensor([0.5519, 0.1244, 0.0578, 0.0150, 0.0124, 0.0091, 0.0090, 0.0064, 0.0062,\n",
      "        0.0050])\n",
      "coagulatedis not in list\n",
      "solidifiedis not in list\n",
      "congealedis not in list\n",
      "jelledis not in list\n",
      "jelliedis not in list\n",
      "semisolidis not in list\n",
      "solid-stateis not in list\n",
      "{'solid': tensor(0.5519), 'hard': tensor(0.0005), 'concrete': tensor(0.0007), 'dry': tensor(0.0050)}\n",
      "max_probe is: tensor(0.5519)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is generous but Mary is _ .\n",
      "['not', 'selfish', 'kind', 'generous', 'greedy', 'modest', 'wise', 'afraid', 'poor', 'practical']\n",
      "tensor([0.0930, 0.0457, 0.0277, 0.0224, 0.0222, 0.0167, 0.0136, 0.0135, 0.0128,\n",
      "        0.0120])\n",
      "stingyis not in list\n",
      "beggarlyis not in list\n",
      "chinchyis not in list\n",
      "chintzyis not in list\n",
      "cheeseparingis not in list\n",
      "penny-pinchingis not in list\n",
      "closefistedis not in list\n",
      "hardfistedis not in list\n",
      "tightfistedis not in list\n",
      "grudgingis not in list\n",
      "niggardlyis not in list\n",
      "scrimyis not in list\n",
      "mingyis not in list\n",
      "miserlyis not in list\n",
      "parsimoniousis not in list\n",
      "penuriousis not in list\n",
      "uncharitableis not in list\n",
      "ungenerousis not in list\n",
      "meanspiritedis not in list\n",
      "{'mean': tensor(0.0033), 'cheap': tensor(0.0013), 'close': tensor(0.0003), 'near': tensor(3.5711e-05), 'skinny': tensor(4.9493e-05), 'tight': tensor(0.0002), 'selfish': tensor(0.0457)}\n",
      "max_probe is: tensor(0.0457)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is hard but Mary is _ .\n",
      "['soft', 'gentle', 'strong', 'beautiful', 'kind', 'stronger', 'easy', 'good', 'sweet', 'softer']\n",
      "tensor([0.0732, 0.0609, 0.0520, 0.0498, 0.0426, 0.0332, 0.0295, 0.0258, 0.0219,\n",
      "        0.0216])\n",
      "{'easy': tensor(0.0295)}\n",
      "max_probe is: tensor(0.0295)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is hot but Mary is _ .\n",
      "['cold', 'cool', 'hot', 'warm', 'not', 'hotter', 'colder', 'chilly', 'beautiful', 'sexy']\n",
      "tensor([0.6272, 0.0497, 0.0348, 0.0331, 0.0267, 0.0123, 0.0115, 0.0078, 0.0069,\n",
      "        0.0046])\n",
      "frostyis not in list\n",
      "frigidis not in list\n",
      "{'cold': tensor(0.6272), 'chilly': tensor(0.0078), 'cool': tensor(0.0497)}\n",
      "max_probe is: tensor(0.6272)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is interesting but Mary is _ .\n",
      "['not', 'more', 'better', 'important', 'fascinating', 'interesting', '..', 'amazing', 'beautiful', '...']\n",
      "tensor([0.0958, 0.0536, 0.0478, 0.0452, 0.0425, 0.0360, 0.0199, 0.0168, 0.0125,\n",
      "        0.0118])\n",
      "uninterestingis not in list\n",
      "deadeningis not in list\n",
      "ho-humis not in list\n",
      "irksomeis not in list\n",
      "tiresomeis not in list\n",
      "wearisomeis not in list\n",
      "insipidis not in list\n",
      "jejuneis not in list\n",
      "narcoticis not in list\n",
      "soporiferousis not in list\n",
      "soporificis not in list\n",
      "prosaicis not in list\n",
      "prosyis not in list\n",
      "earthboundis not in list\n",
      "ponderousis not in list\n",
      "putdownableis not in list\n",
      "unexcitingis not in list\n",
      "unstimulatingis not in list\n",
      "{'dull': tensor(0.0003), 'boring': tensor(0.0111), 'slow': tensor(4.1897e-05), 'tedious': tensor(0.0004)}\n",
      "max_probe is: tensor(0.0111)\n",
      "20\n",
      "the position of max probe is: 10\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is introvert but Mary is _ .\n",
      "['outgoing', 'not', 'shy', 'social', 'outspoken', 'intuitive', 'charismatic', 'passionate', 'optimistic', 'ambitious']\n",
      "tensor([0.3922, 0.1017, 0.0502, 0.0322, 0.0238, 0.0132, 0.0120, 0.0112, 0.0091,\n",
      "        0.0081])\n",
      "extravertis not in list\n",
      "extrovertis not in list\n",
      "extrovertedis not in list\n",
      "sociableis not in list\n",
      "{'outgoing': tensor(0.3922), 'forthcoming': tensor(0.0013)}\n",
      "max_probe is: tensor(0.3922)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is large but Mary is _ .\n",
      "['small', 'smaller', 'tiny', 'beautiful', 'not', 'large', 'tall', 'strong', 'thin', 'pretty']\n",
      "tensor([0.3492, 0.0903, 0.0674, 0.0504, 0.0215, 0.0139, 0.0136, 0.0111, 0.0093,\n",
      "        0.0091])\n",
      "{'little': tensor(0.0079), 'small': tensor(0.3492)}\n",
      "max_probe is: tensor(0.3492)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is long but Mary is _ .\n",
      "['short', 'tall', 'long', 'small', 'slender', 'thin', 'beautiful', 'slim', 'shorter', 'tiny']\n",
      "tensor([0.7204, 0.0469, 0.0272, 0.0230, 0.0123, 0.0119, 0.0089, 0.0088, 0.0083,\n",
      "        0.0061])\n",
      "abbreviatedis not in list\n",
      "truncatedis not in list\n",
      "momentaneousis not in list\n",
      "momentaryis not in list\n",
      "short_and_sweetis not in list\n",
      "short-datedis not in list\n",
      "short-rangeis not in list\n",
      "short-runis not in list\n",
      "short-termis not in list\n",
      "abbreviatedis not in list\n",
      "curtalis not in list\n",
      "sawed-offis not in list\n",
      "sawn-offis not in list\n",
      "shortishis not in list\n",
      "short-rangeis not in list\n",
      "short-snoutedis not in list\n",
      "snubis not in list\n",
      "stubbyis not in list\n",
      "telescopedis not in list\n",
      "truncateis not in list\n",
      "truncatedis not in list\n",
      "chunkyis not in list\n",
      "dumpyis not in list\n",
      "low-setis not in list\n",
      "squattyis not in list\n",
      "stumpyis not in list\n",
      "heavysetis not in list\n",
      "stockyis not in list\n",
      "thicksetis not in list\n",
      "half-lengthis not in list\n",
      "pint-sizeis not in list\n",
      "pint-sizedis not in list\n",
      "runtyis not in list\n",
      "sawed-offis not in list\n",
      "sawn-offis not in list\n",
      "short-stalkedis not in list\n",
      "squabis not in list\n",
      "squabbyis not in list\n",
      "{'short': tensor(0.7204), 'shortened': tensor(0.0001), 'brief': tensor(0.0005), 'clipped': tensor(6.5077e-07), 'fleeting': tensor(8.6406e-05), 'fugitive': tensor(1.1093e-06), 'close': tensor(0.0005), 'squat': tensor(0.0002), 'compact': tensor(0.0002), 'thick': tensor(0.0004)}\n",
      "max_probe is: tensor(0.7204)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is lumpy but Mary is _ .\n",
      "['not', 'thin', 'soft', 'beautiful', 'slim', 'skinny', 'pretty', 'perfect', 'fat', 'slender']\n",
      "tensor([0.1025, 0.0438, 0.0403, 0.0308, 0.0227, 0.0226, 0.0199, 0.0197, 0.0196,\n",
      "        0.0192])\n",
      "{'flat': tensor(0.0125), 'level': tensor(2.7093e-05), 'plane': tensor(6.6463e-06), 'even': tensor(0.0002), '': tensor(6.5157e-06)}\n",
      "max_probe is: tensor(0.0125)\n",
      "20\n",
      "the position of max probe is: 15\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is noisy but Mary is _ .\n",
      "['quiet', 'silent', 'quieter', 'beautiful', 'peaceful', 'pretty', 'not', 'sweet', 'kind', 'gentle']\n",
      "tensor([0.5079, 0.1413, 0.0380, 0.0283, 0.0133, 0.0122, 0.0111, 0.0109, 0.0076,\n",
      "        0.0065])\n",
      "uncommunicativeis not in list\n",
      "inarticulateis not in list\n",
      "unarticulateis not in list\n",
      "{'silent': tensor(0.1413), 'dumb': tensor(8.6820e-05), 'mute': tensor(0.0043)}\n",
      "max_probe is: tensor(0.1413)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is normal but Mary is _ .\n",
      "['not', 'pregnant', 'autistic', 'sick', 'different', 'abnormal', 'special', 'depressed', 'ill', 'normal']\n",
      "tensor([0.2092, 0.0483, 0.0411, 0.0338, 0.0328, 0.0172, 0.0168, 0.0163, 0.0113,\n",
      "        0.0097])\n",
      "{'abnormal': tensor(0.0172)}\n",
      "max_probe is: tensor(0.0172)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is organized but Mary is _ .\n",
      "['not', 'free', 'organized', 'spontaneous', 'spiritual', 'lost', 'chaotic', 'messy', 'passionate', 'born']\n",
      "tensor([0.2482, 0.0421, 0.0331, 0.0200, 0.0103, 0.0094, 0.0094, 0.0085, 0.0078,\n",
      "        0.0073])\n",
      "unorganizedis not in list\n",
      "unstructuredis not in list\n",
      "uncoordinatedis not in list\n",
      "unformedis not in list\n",
      "unincorporatedis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is pale but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dark', 'not', 'white', 'beautiful', 'black', 'pale', 'darker', 'red', 'fair', 'blonde']\n",
      "tensor([0.1195, 0.1150, 0.0908, 0.0759, 0.0593, 0.0540, 0.0440, 0.0253, 0.0243,\n",
      "        0.0181])\n",
      "tannedis not in list\n",
      "bronzedis not in list\n",
      "suntannedis not in list\n",
      "brunetis not in list\n",
      "brunetteis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is pretty but Mary is _ .\n",
      "['beautiful', 'pretty', 'better', 'smarter', 'special', 'sexy', 'real', 'more', 'lovely', 'amazing']\n",
      "tensor([0.2285, 0.1289, 0.0347, 0.0189, 0.0165, 0.0161, 0.0161, 0.0159, 0.0126,\n",
      "        0.0122])\n",
      "disfiguredis not in list\n",
      "evil-lookingis not in list\n",
      "fuglyis not in list\n",
      "repulsiveis not in list\n",
      "ill-favoredis not in list\n",
      "ill-favouredis not in list\n",
      "scrofulousis not in list\n",
      "unlovelyis not in list\n",
      "unpicturesqueis not in list\n",
      "unsightlyis not in list\n",
      "displeasingis not in list\n",
      "unattractiveis not in list\n",
      "{'ugly': tensor(0.0072), 'grotesque': tensor(1.7344e-05), 'monstrous': tensor(2.5896e-05), 'hideous': tensor(0.0002), 'awkward': tensor(4.9993e-05)}\n",
      "max_probe is: tensor(0.0072)\n",
      "20\n",
      "the position of max probe is: 17\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is rich but Mary is _ .\n",
      "['poor', 'rich', 'hungry', 'not', 'beautiful', 'starving', 'lonely', 'poorer', 'humble', 'free']\n",
      "tensor([0.7580, 0.0185, 0.0178, 0.0116, 0.0097, 0.0071, 0.0068, 0.0063, 0.0061,\n",
      "        0.0043])\n",
      "{'poor': tensor(0.7580)}\n",
      "max_probe is: tensor(0.7580)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is risky but Mary is _ .\n",
      "['not', 'safe', 'safer', 'lucky', 'risky', 'trustworthy', 'beautiful', 'secure', 'smart', 'predictable']\n",
      "tensor([0.1176, 0.1015, 0.0161, 0.0153, 0.0150, 0.0140, 0.0136, 0.0107, 0.0106,\n",
      "        0.0101])\n",
      "fail-safeis not in list\n",
      "risk-freeis not in list\n",
      "risklessis not in list\n",
      "unhazardousis not in list\n",
      "safe-and-soundis not in list\n",
      "unhurtis not in list\n",
      "invulnerableis not in list\n",
      "uninjuredis not in list\n",
      "{'safe': tensor(0.1015), 'harmless': tensor(0.0017), 'secure': tensor(0.0107)}\n",
      "max_probe is: tensor(0.1015)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is sane but Mary is _ .\n",
      "['insane', 'not', 'crazy', 'mad', 'delusional', 'sane', 'psychotic', 'dead', 'evil', 'possessed']\n",
      "tensor([0.2459, 0.1962, 0.0988, 0.0398, 0.0218, 0.0195, 0.0176, 0.0142, 0.0130,\n",
      "        0.0115])\n",
      "loonyis not in list\n",
      "looneyis not in list\n",
      "nutcaseis not in list\n",
      "weirdois not in list\n",
      "{'crazy': tensor(0.0988), 'mad': tensor(0.0398), 'insane': tensor(0.2459)}\n",
      "max_probe is: tensor(0.2459)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is short but Mary is _ .\n",
      "['tall', 'taller', 'long', 'fat', 'not', 'beautiful', 'short', 'strong', 'pretty', 'big']\n",
      "tensor([0.6882, 0.0583, 0.0341, 0.0322, 0.0196, 0.0188, 0.0153, 0.0102, 0.0065,\n",
      "        0.0057])\n",
      "ganglingis not in list\n",
      "ganglyis not in list\n",
      "lankyis not in list\n",
      "rangyis not in list\n",
      "leggyis not in list\n",
      "long-leggedis not in list\n",
      "long-shankedis not in list\n",
      "tall-growingis not in list\n",
      "long-stalkedis not in list\n",
      "tall-stalkedis not in list\n",
      "statelyis not in list\n",
      "statuesqueis not in list\n",
      "tallishis not in list\n",
      "{'tall': tensor(0.6882), 'height': tensor(3.8220e-05), 'long': tensor(0.0341)}\n",
      "max_probe is: tensor(0.6882)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is simple but Mary is _ .\n",
      "['complex', 'beautiful', 'complicated', 'special', 'not', 'perfect', 'extraordinary', 'divine', 'elegant', 'amazing']\n",
      "tensor([0.1882, 0.1363, 0.1311, 0.0232, 0.0187, 0.0163, 0.0159, 0.0134, 0.0126,\n",
      "        0.0106])\n",
      "{'difficult': tensor(0.0046), 'challenging': tensor(0.0003), 'hard': tensor(0.0018), 'complicated': tensor(0.1311), 'demanding': tensor(0.0003), 'daunting': tensor(8.3604e-05), 'taxing': tensor(1.1579e-06)}\n",
      "max_probe is: tensor(0.1311)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is sincere but Mary is _ .\n",
      "['not', 'better', 'deceptive', 'deceived', 'cunning', 'manipulative', 'desperate', 'evil', 'more', 'selfish']\n",
      "tensor([0.1343, 0.0277, 0.0244, 0.0226, 0.0177, 0.0164, 0.0143, 0.0127, 0.0125,\n",
      "        0.0115])\n",
      "insincereis not in list\n",
      "bootlickingis not in list\n",
      "fawningis not in list\n",
      "obsequiousis not in list\n",
      "sycophanticis not in list\n",
      "toadyishis not in list\n",
      "butteryis not in list\n",
      "fulsomeis not in list\n",
      "oleaginousis not in list\n",
      "smarmyis not in list\n",
      "soapyis not in list\n",
      "unctuousis not in list\n",
      "dissimulativeis not in list\n",
      "feignedis not in list\n",
      "gildedis not in list\n",
      "meretriciousis not in list\n",
      "speciousis not in list\n",
      "imitativeis not in list\n",
      "dishonorableis not in list\n",
      "disingenuousis not in list\n",
      "artfulis not in list\n",
      "{'oily': tensor(2.7864e-06), 'false': tensor(0.0027), 'hypocritical': tensor(0.0014), 'plausible': tensor(3.2485e-05), 'counterfeit': tensor(4.3676e-05), 'dishonest': tensor(0.0097), 'unreal': tensor(8.4008e-05)}\n",
      "max_probe is: tensor(0.0097)\n",
      "20\n",
      "the position of max probe is: 14\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is slow but Mary is _ .\n",
      "['fast', 'strong', 'quick', 'swift', 'patient', 'faster', 'beautiful', 'ready', 'perfect', 'good']\n",
      "tensor([0.2157, 0.0780, 0.0306, 0.0267, 0.0231, 0.0212, 0.0182, 0.0170, 0.0159,\n",
      "        0.0148])\n",
      "alacritousis not in list\n",
      "blisteringis not in list\n",
      "red-hotis not in list\n",
      "double-quickis not in list\n",
      "fast-breakingis not in list\n",
      "fast-pacedis not in list\n",
      "high-speedis not in list\n",
      "high-velocityis not in list\n",
      "hurryingis not in list\n",
      "scurryingis not in list\n",
      "straightawayis not in list\n",
      "meteoricis not in list\n",
      "wingedis not in list\n",
      "windyis not in list\n",
      "{'fast': tensor(0.2157), 'quick': tensor(0.0306), 'accelerated': tensor(1.2306e-05), 'hot': tensor(0.0012), 'express': tensor(3.3388e-06), 'fleet': tensor(1.8487e-05), 'swift': tensor(0.0267), 'immediate': tensor(2.2580e-05), 'prompt': tensor(0.0002), 'instantaneous': tensor(5.0389e-05), 'instant': tensor(1.8754e-05), 'speedy': tensor(0.0041), 'rapid': tensor(0.0003)}\n",
      "max_probe is: tensor(0.2157)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is sweet but Mary is _ .\n",
      "['beautiful', 'strong', 'kind', 'tough', 'fierce', 'stubborn', 'sweet', 'not', 'pretty', 'cold']\n",
      "tensor([0.0491, 0.0442, 0.0343, 0.0275, 0.0186, 0.0164, 0.0159, 0.0149, 0.0145,\n",
      "        0.0143])\n",
      "acerbis not in list\n",
      "acerbicis not in list\n",
      "astringentis not in list\n",
      "acetoseis not in list\n",
      "acetousis not in list\n",
      "vinegaryis not in list\n",
      "vinegarishis not in list\n",
      "acidulentis not in list\n",
      "acidulousis not in list\n",
      "lemonyis not in list\n",
      "lemonlikeis not in list\n",
      "sourishis not in list\n",
      "tangyis not in list\n",
      "subacidis not in list\n",
      "{'sour': tensor(0.0015), 'acidic': tensor(1.4115e-05), 'acid': tensor(7.3582e-06), 'tart': tensor(0.0011), 'bitter': tensor(0.0102)}\n",
      "max_probe is: tensor(0.0102)\n",
      "20\n",
      "the position of max probe is: 13\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is tasty but Mary is _ .\n",
      "['delicious', 'irresistible', 'better', 'sweet', 'tasty', 'beautiful', 'not', 'good', 'special', 'sexy']\n",
      "tensor([0.0703, 0.0472, 0.0453, 0.0417, 0.0413, 0.0184, 0.0173, 0.0151, 0.0147,\n",
      "        0.0136])\n",
      "tastelessis not in list\n",
      "flavorlessis not in list\n",
      "flavourlessis not in list\n",
      "insipidis not in list\n",
      "savorlessis not in list\n",
      "savourlessis not in list\n",
      "vapidis not in list\n",
      "unflavoredis not in list\n",
      "unflavouredis not in list\n",
      "nonflavoredis not in list\n",
      "nonflavouredis not in list\n",
      "unsaltedis not in list\n",
      "unseasonedis not in list\n",
      "unappetizingis not in list\n",
      "unappetisingis not in list\n",
      "unpalatableis not in list\n",
      "{'bland': tensor(0.0005), 'flat': tensor(4.1079e-05)}\n",
      "max_probe is: tensor(0.0005)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 248\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is tight but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loose', 'free', 'not', 'open', 'soft', 'flexible', 'tight', 'strong', 'thin', 'relaxed']\n",
      "tensor([0.2238, 0.0875, 0.0487, 0.0319, 0.0269, 0.0219, 0.0200, 0.0179, 0.0137,\n",
      "        0.0106])\n",
      "baggyis not in list\n",
      "loose-fittingis not in list\n",
      "flyawayis not in list\n",
      "{'loose': tensor(0.2238), 'lax': tensor(0.0054), 'sloppy': tensor(0.0005), 'free': tensor(0.0875), 'liberal': tensor(0.0004), 'informal': tensor(1.3132e-05), 'unofficial': tensor(3.1635e-06)}\n",
      "max_probe is: tensor(0.2238)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is warm but Mary is _ .\n",
      "['cold', 'not', 'freezing', 'frozen', 'warm', 'chilly', 'colder', 'hot', 'hungry', 'afraid']\n",
      "tensor([0.7989, 0.0324, 0.0157, 0.0117, 0.0103, 0.0103, 0.0072, 0.0066, 0.0065,\n",
      "        0.0045])\n",
      "frostyis not in list\n",
      "frigidis not in list\n",
      "{'cool': tensor(0.0040), 'cold': tensor(0.7989), 'chilly': tensor(0.0103)}\n",
      "max_probe is: tensor(0.7989)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is white but Mary is _ .\n",
      "['black', 'brown', 'white', 'Jewish', 'Black', 'not', 'Catholic', 'African', 'Hispanic', 'colored']\n",
      "tensor([0.8135, 0.0319, 0.0266, 0.0192, 0.0178, 0.0100, 0.0054, 0.0052, 0.0051,\n",
      "        0.0041])\n",
      "{'black': tensor(0.8135)}\n",
      "max_probe is: tensor(0.8135)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is wide but Mary is _ .\n",
      "['close', 'not', 'closer', 'near', 'narrow', 'inside', 'tight', 'in', 'right', 'safe']\n",
      "tensor([0.3088, 0.0695, 0.0553, 0.0300, 0.0281, 0.0256, 0.0235, 0.0191, 0.0146,\n",
      "        0.0131])\n",
      "constrictingis not in list\n",
      "constrictiveis not in list\n",
      "narrow-mouthedis not in list\n",
      "straitis not in list\n",
      "straplikeis not in list\n",
      "taperedis not in list\n",
      "taperingis not in list\n",
      "{'narrow': tensor(0.0281), 'narrowing': tensor(0.0002), 'narrowed': tensor(0.0003), 'slender': tensor(0.0002), 'thin': tensor(0.0008), 'limited': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0281)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is willing but Mary is _ .\n",
      "['afraid', 'not', 'scared', 'unwilling', 'reluctant', 'terrified', 'angry', 'frightened', 'ready', 'stubborn']\n",
      "tensor([0.2107, 0.1839, 0.0616, 0.0483, 0.0345, 0.0215, 0.0199, 0.0180, 0.0140,\n",
      "        0.0104])\n",
      "{'unwilling': tensor(0.0483)}\n",
      "max_probe is: tensor(0.0483)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is young but Mary is _ .\n",
      "['old', 'older', 'not', 'young', 'pregnant', 'beautiful', 'mature', 'wise', 'elderly', 'strong']\n",
      "tensor([0.4389, 0.1102, 0.0582, 0.0297, 0.0244, 0.0209, 0.0154, 0.0096, 0.0091,\n",
      "        0.0087])\n",
      "{'old': tensor(0.4389)}\n",
      "max_probe is: tensor(0.4389)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is new but Mary is _ .\n",
      "['old', 'not', 'Old', 'older', 'new', 'ancient', 'dead', 'born', 'dying', 'different']\n",
      "tensor([0.7072, 0.0620, 0.0208, 0.0192, 0.0117, 0.0092, 0.0085, 0.0058, 0.0045,\n",
      "        0.0044])\n",
      "{'old': tensor(0.7072)}\n",
      "max_probe is: tensor(0.7072)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is other but Mary is _ .\n",
      "['not', 'other', 'one', 'Jewish', 'Catholic', 'her', 'mother', 'Mary', 'sister', 'his']\n",
      "tensor([0.1219, 0.0479, 0.0335, 0.0229, 0.0153, 0.0139, 0.0133, 0.0127, 0.0125,\n",
      "        0.0124])\n",
      "{'same': tensor(0.0020)}\n",
      "max_probe is: tensor(0.0020)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 65\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is many but Mary is _ .\n",
      "['one', 'few', 'special', 'none', 'all', 'unique', 'many', 'One', 'alone', 'singular']\n",
      "tensor([0.5227, 0.0304, 0.0292, 0.0241, 0.0191, 0.0160, 0.0143, 0.0120, 0.0100,\n",
      "        0.0087])\n",
      "{'few': tensor(0.0304)}\n",
      "max_probe is: tensor(0.0304)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is high but Mary is _ .\n",
      "['low', 'high', 'lower', 'humble', 'holy', 'below', 'mighty', 'down', 'beautiful', 'deep']\n",
      "tensor([0.5047, 0.0599, 0.0529, 0.0140, 0.0122, 0.0121, 0.0101, 0.0094, 0.0092,\n",
      "        0.0090])\n",
      "{'low': tensor(0.5047)}\n",
      "max_probe is: tensor(0.5047)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is same but Mary is _ .\n",
      "['different', 'not', 'Mary', 'other', 'new', 'special', 'better', 'female', 'more', 'same']\n",
      "tensor([0.7322, 0.0193, 0.0109, 0.0082, 0.0079, 0.0070, 0.0061, 0.0043, 0.0039,\n",
      "        0.0038])\n",
      "{'other': tensor(0.0082)}\n",
      "max_probe is: tensor(0.0082)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is general but Mary is _ .\n",
      "['not', 'special', 'specific', 'personal', 'political', 'particular', 'queen', 'religious', 'diplomatic', 'divine']\n",
      "tensor([0.0760, 0.0663, 0.0471, 0.0279, 0.0177, 0.0173, 0.0171, 0.0157, 0.0120,\n",
      "        0.0110])\n",
      "{'specific': tensor(0.0471)}\n",
      "max_probe is: tensor(0.0471)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is international but Mary is _ .\n",
      "['not', 'local', 'national', 'American', 'British', 'Catholic', 'domestic', 'private', 'international', 'English']\n",
      "tensor([0.5629, 0.0331, 0.0325, 0.0187, 0.0162, 0.0127, 0.0108, 0.0086, 0.0084,\n",
      "        0.0075])\n",
      "{'national': tensor(0.0325)}\n",
      "max_probe is: tensor(0.0325)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is local but Mary is _ .\n",
      "['not', 'international', 'American', 'British', 'English', 'Australian', 'Canadian', 'global', 'local', 'Scottish']\n",
      "tensor([0.2468, 0.0599, 0.0521, 0.0318, 0.0244, 0.0241, 0.0226, 0.0218, 0.0216,\n",
      "        0.0198])\n",
      "{'national': tensor(0.0179)}\n",
      "max_probe is: tensor(0.0179)\n",
      "20\n",
      "the position of max probe is: 10\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is small but Mary is _ .\n",
      "['beautiful', 'tall', 'small', 'big', 'strong', 'not', 'tiny', 'large', 'bigger', 'fat']\n",
      "tensor([0.0935, 0.0694, 0.0678, 0.0611, 0.0569, 0.0345, 0.0342, 0.0315, 0.0273,\n",
      "        0.0272])\n",
      "{'big': tensor(0.0611), 'large': tensor(0.0315)}\n",
      "max_probe is: tensor(0.0611)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is much but Mary is _ .\n",
      "['more', 'much', 'little', 'less', 'everything', 'all', 'great', 'greater', 'good', 'not']\n",
      "tensor([0.2775, 0.0758, 0.0686, 0.0646, 0.0401, 0.0280, 0.0204, 0.0155, 0.0148,\n",
      "        0.0141])\n",
      "{'little': tensor(0.0686)}\n",
      "max_probe is: tensor(0.0686)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is old but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['young', 'new', 'younger', 'beautiful', 'old', 'not', 'wise', 'pretty', 'pregnant', 'born']\n",
      "tensor([0.7566, 0.0291, 0.0228, 0.0164, 0.0133, 0.0076, 0.0047, 0.0047, 0.0038,\n",
      "        0.0038])\n",
      "{'young': tensor(0.7566)}\n",
      "max_probe is: tensor(0.7566)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is single but Mary is _ .\n",
      "['married', 'engaged', 'pregnant', 'not', 'divorced', 'dating', 'single', 'unmarried', 'attached', 'involved']\n",
      "tensor([0.5571, 0.1394, 0.1222, 0.0722, 0.0275, 0.0059, 0.0052, 0.0038, 0.0030,\n",
      "        0.0025])\n",
      "{'common': tensor(3.6739e-06)}\n",
      "max_probe is: tensor(3.6739e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 1195\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is different but Mary is _ .\n",
      "['not', 'different', 'better', 'special', 'Jesus', 'unique', 'Mary', 'same', 'beautiful', 'more']\n",
      "tensor([0.1717, 0.1237, 0.0490, 0.0433, 0.0367, 0.0277, 0.0264, 0.0189, 0.0181,\n",
      "        0.0164])\n",
      "{'same': tensor(0.0189)}\n",
      "max_probe is: tensor(0.0189)\n",
      "the position of max probe is: 7\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is few but Mary is _ .\n",
      "['many', 'everywhere', 'numerous', 'few', 'all', 'one', 'none', 'not', 'more', 'legion']\n",
      "tensor([0.5157, 0.0449, 0.0439, 0.0274, 0.0251, 0.0238, 0.0177, 0.0157, 0.0153,\n",
      "        0.0081])\n",
      "{'many': tensor(0.5157)}\n",
      "max_probe is: tensor(0.5157)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is popular but Mary is _ .\n",
      "['not', 'unpopular', 'popular', 'controversial', 'misunderstood', 'disliked', 'ignored', 'hated', 'despised', 'underrated']\n",
      "tensor([0.2791, 0.0901, 0.0497, 0.0407, 0.0287, 0.0256, 0.0161, 0.0140, 0.0089,\n",
      "        0.0086])\n",
      "{'unpopular': tensor(0.0901)}\n",
      "max_probe is: tensor(0.0901)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is black but Mary is _ .\n",
      "['white', 'Jewish', 'not', 'black', 'Catholic', 'brown', 'Irish', 'Hispanic', 'blonde', 'White']\n",
      "tensor([0.8802, 0.0280, 0.0177, 0.0119, 0.0102, 0.0039, 0.0038, 0.0034, 0.0031,\n",
      "        0.0016])\n",
      "{'white': tensor(0.8802)}\n",
      "max_probe is: tensor(0.8802)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is northern but Mary is _ .\n",
      "['southern', 'south', 'eastern', 'Southern', 'western', 'northern', 'central', 'east', 'southwest', 'southwestern']\n",
      "tensor([0.7288, 0.1038, 0.0298, 0.0226, 0.0188, 0.0073, 0.0069, 0.0066, 0.0056,\n",
      "        0.0056])\n",
      "{'southern': tensor(0.7288)}\n",
      "max_probe is: tensor(0.7288)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is married but Mary is _ .\n",
      "['pregnant', 'not', 'single', 'engaged', 'divorced', 'unmarried', 'married', 'alone', 'lonely', 'separated']\n",
      "tensor([0.3738, 0.2150, 0.0832, 0.0546, 0.0504, 0.0328, 0.0088, 0.0081, 0.0073,\n",
      "        0.0062])\n",
      "{'unmarried': tensor(0.0328)}\n",
      "max_probe is: tensor(0.0328)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is southern but Mary is _ .\n",
      "['northern', 'southern', 'eastern', 'western', 'Irish', 'north', 'Northern', 'northeastern', 'Scottish', 'English']\n",
      "tensor([0.6071, 0.0568, 0.0468, 0.0257, 0.0249, 0.0224, 0.0177, 0.0167, 0.0107,\n",
      "        0.0102])\n",
      "{'northern': tensor(0.6071)}\n",
      "max_probe is: tensor(0.6071)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is little but Mary is _ .\n",
      "['big', 'not', 'beautiful', 'tall', 'bigger', 'strong', 'older', 'large', 'fat', 'tiny']\n",
      "tensor([0.1249, 0.0548, 0.0511, 0.0458, 0.0362, 0.0354, 0.0291, 0.0290, 0.0282,\n",
      "        0.0254])\n",
      "{'big': tensor(0.1249), 'large': tensor(0.0290)}\n",
      "max_probe is: tensor(0.1249)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is available but Mary is _ .\n",
      "['not', 'unavailable', 'missing', 'available', 'no', 'dead', '', 'offline', 'scarce', 'inaccessible']\n",
      "tensor([0.7552, 0.1109, 0.0162, 0.0048, 0.0033, 0.0028, 0.0026, 0.0026, 0.0025,\n",
      "        0.0022])\n",
      "{'unavailable': tensor(0.1109)}\n",
      "max_probe is: tensor(0.1109)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is successful but Mary is _ .\n",
      "['not', 'devastated', 'disappointed', 'unhappy', 'pregnant', 'unsuccessful', 'crushed', 'distraught', 'killed', 'betrayed']\n",
      "tensor([0.3975, 0.0498, 0.0416, 0.0293, 0.0244, 0.0206, 0.0173, 0.0120, 0.0119,\n",
      "        0.0117])\n",
      "{'unsuccessful': tensor(0.0206)}\n",
      "max_probe is: tensor(0.0206)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is native but Mary is _ .\n",
      "['not', 'American', 'English', 'white', 'adopted', 'Irish', 'British', 'Scottish', 'Catholic', 'German']\n",
      "tensor([0.2169, 0.1116, 0.0762, 0.0512, 0.0505, 0.0359, 0.0314, 0.0267, 0.0227,\n",
      "        0.0226])\n",
      "{'foreign': tensor(0.0022)}\n",
      "max_probe is: tensor(0.0022)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 38\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is possible but Mary is _ .\n",
      "['not', 'unlikely', 'impossible', 'doubtful', 'likely', 'probable', 'possible', 'no', 'certain', 'difficult']\n",
      "tensor([0.5282, 0.1211, 0.0624, 0.0139, 0.0119, 0.0111, 0.0109, 0.0073, 0.0065,\n",
      "        0.0063])\n",
      "{'impossible': tensor(0.0624)}\n",
      "max_probe is: tensor(0.0624)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is natural but Mary is _ .\n",
      "['divine', 'not', 'unnatural', 'special', 'supernatural', 'God', 'chosen', 'human', 'born', 'miraculous']\n",
      "tensor([0.1469, 0.1418, 0.0479, 0.0427, 0.0329, 0.0274, 0.0211, 0.0190, 0.0159,\n",
      "        0.0111])\n",
      "{'unnatural': tensor(0.0479)}\n",
      "max_probe is: tensor(0.0479)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is strong but Mary is _ .\n",
      "['weak', 'strong', 'weaker', 'vulnerable', 'stronger', 'fragile', 'beautiful', 'powerful', 'frail', 'afraid']\n",
      "tensor([0.3377, 0.1311, 0.0538, 0.0289, 0.0238, 0.0208, 0.0178, 0.0172, 0.0133,\n",
      "        0.0103])\n",
      "{'weak': tensor(0.3377)}\n",
      "max_probe is: tensor(0.3377)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is active but Mary is _ .\n",
      "['inactive', 'not', 'passive', 'asleep', 'silent', 'sleeping', 'absent', 'dead', 'quiet', 'active']\n",
      "tensor([0.1421, 0.0995, 0.0919, 0.0774, 0.0759, 0.0750, 0.0376, 0.0259, 0.0255,\n",
      "        0.0165])\n",
      "{'inactive': tensor(0.1421)}\n",
      "max_probe is: tensor(0.1421)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is limited but Mary is _ .\n",
      "['not', 'free', 'unlimited', '', 'limitless', 'powerful', 'more', 'limited', 'full', 'open']\n",
      "tensor([0.5416, 0.0376, 0.0121, 0.0120, 0.0052, 0.0044, 0.0044, 0.0040, 0.0036,\n",
      "        0.0034])\n",
      "{'unlimited': tensor(0.0121)}\n",
      "max_probe is: tensor(0.0121)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is low but Mary is _ .\n",
      "['high', 'higher', 'low', 'tall', 'highest', 'upper', 'above', 'not', 'top', 'medium']\n",
      "tensor([0.7706, 0.0504, 0.0172, 0.0098, 0.0065, 0.0050, 0.0041, 0.0038, 0.0035,\n",
      "        0.0034])\n",
      "{'high': tensor(0.7706)}\n",
      "max_probe is: tensor(0.7706)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is foreign but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['home', 'not', 'local', 'native', 'domestic', 'divine', 'American', 'English', 'here', 'Greek']\n",
      "tensor([0.1633, 0.1237, 0.0653, 0.0393, 0.0288, 0.0246, 0.0236, 0.0170, 0.0168,\n",
      "        0.0124])\n",
      "{'domestic': tensor(0.0288)}\n",
      "max_probe is: tensor(0.0288)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is related but Mary is _ .\n",
      "['not', 'unrelated', 'different', 'older', 'married', 'related', 'sister', 'younger', 'distant', 't']\n",
      "tensor([0.6874, 0.0721, 0.0181, 0.0099, 0.0096, 0.0094, 0.0086, 0.0084, 0.0063,\n",
      "        0.0049])\n",
      "{'unrelated': tensor(0.0721)}\n",
      "max_probe is: tensor(0.0721)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is legal but Mary is _ .\n",
      "['not', 'illegal', 'legal', 'illegitimate', 'dead', 'immoral', 't', 'alive', 'Catholic', 'Jewish']\n",
      "tensor([0.6468, 0.0965, 0.0184, 0.0166, 0.0152, 0.0103, 0.0082, 0.0040, 0.0034,\n",
      "        0.0032])\n",
      "{'illegal': tensor(0.0965)}\n",
      "max_probe is: tensor(0.0965)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is true but Mary is _ .\n",
      "['false', 'not', 'true', 'better', 'wrong', 'real', 'right', 'more', 'beautiful', 'untrue']\n",
      "tensor([0.2000, 0.0884, 0.0750, 0.0482, 0.0218, 0.0209, 0.0130, 0.0122, 0.0117,\n",
      "        0.0115])\n",
      "{'false': tensor(0.2000)}\n",
      "max_probe is: tensor(0.2000)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is dead but Mary is _ .\n",
      "['alive', 'not', 'pregnant', 'living', 'free', 'safe', 'dying', 'dead', 'happy', 'saved']\n",
      "tensor([0.6116, 0.0774, 0.0393, 0.0239, 0.0139, 0.0125, 0.0104, 0.0096, 0.0080,\n",
      "        0.0066])\n",
      "{'alive': tensor(0.6116)}\n",
      "max_probe is: tensor(0.6116)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is specific but Mary is _ .\n",
      "['general', 'vague', 'not', 'universal', 'generic', 'specific', 'generalized', 'broader', 'ambiguous', 'plural']\n",
      "tensor([0.1487, 0.1463, 0.1325, 0.0970, 0.0757, 0.0268, 0.0236, 0.0188, 0.0130,\n",
      "        0.0117])\n",
      "{'general': tensor(0.1487)}\n",
      "max_probe is: tensor(0.1487)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is likely but Mary is _ .\n",
      "['not', 'unlikely', 'possible', 'likely', 'doubtful', 'uncertain', 'questionable', 'unknown', 'impossible', 'excluded']\n",
      "tensor([0.2314, 0.1514, 0.0552, 0.0381, 0.0304, 0.0203, 0.0185, 0.0184, 0.0173,\n",
      "        0.0157])\n",
      "{'unlikely': tensor(0.1514)}\n",
      "max_probe is: tensor(0.1514)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is difficult but Mary is _ .\n",
      "['beautiful', 'not', 'wonderful', 'perfect', 'patient', 'strong', 'special', 'kind', 'easy', 'lovely']\n",
      "tensor([0.0826, 0.0431, 0.0281, 0.0259, 0.0194, 0.0189, 0.0156, 0.0154, 0.0128,\n",
      "        0.0127])\n",
      "{'easy': tensor(0.0128)}\n",
      "max_probe is: tensor(0.0128)\n",
      "the position of max probe is: 8\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is rural but Mary is _ .\n",
      "['urban', 'educated', 'city', 'suburban', 'not', 'metropolitan', 'cultured', 'religious', 'downtown', 'modern']\n",
      "tensor([0.8300, 0.0321, 0.0214, 0.0172, 0.0103, 0.0054, 0.0029, 0.0027, 0.0023,\n",
      "        0.0022])\n",
      "{'urban': tensor(0.8300)}\n",
      "max_probe is: tensor(0.8300)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is potential but Mary is _ .\n",
      "['not', 'destiny', 'real', 'potential', 'hope', 'vulnerable', 'future', 'important', 'dangerous', 'promise']\n",
      "tensor([0.0339, 0.0300, 0.0253, 0.0219, 0.0121, 0.0097, 0.0094, 0.0093, 0.0074,\n",
      "        0.0065])\n",
      "{'actual': tensor(0.0011)}\n",
      "max_probe is: tensor(0.0011)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 163\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is necessary but Mary is _ .\n",
      "['indispensable', 'sufficient', 'more', 'better', 'important', 'enough', 'beautiful', 'necessary', 'special', 'needed']\n",
      "tensor([0.0946, 0.0605, 0.0550, 0.0544, 0.0457, 0.0399, 0.0339, 0.0332, 0.0315,\n",
      "        0.0271])\n",
      "{'unnecessary': tensor(0.0048)}\n",
      "max_probe is: tensor(0.0048)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 26\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nuclear but Mary is _ .\n",
      "['radioactive', 'nuclear', 'not', 'human', 'organic', 'warm', 'atomic', 'magical', 'cold', 'green']\n",
      "tensor([0.0880, 0.0681, 0.0414, 0.0334, 0.0165, 0.0159, 0.0135, 0.0102, 0.0099,\n",
      "        0.0098])\n",
      "{'conventional': tensor(0.0054)}\n",
      "max_probe is: tensor(0.0054)\n",
      "20\n",
      "the position of max probe is: 17\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unable but Mary is _ .\n",
      "['willing', 'able', 'ready', '', 'strong', 'not', 'capable', 'pregnant', '.', 'determined']\n",
      "tensor([0.1461, 0.0928, 0.0673, 0.0531, 0.0458, 0.0404, 0.0232, 0.0194, 0.0174,\n",
      "        0.0171])\n",
      "{'able': tensor(0.0928)}\n",
      "max_probe is: tensor(0.0928)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is bad but Mary is _ .\n",
      "['good', 'better', 'beautiful', 'great', 'worse', 'evil', 'bad', 'wonderful', 'perfect', 'Good']\n",
      "tensor([0.5666, 0.1488, 0.0186, 0.0179, 0.0154, 0.0127, 0.0123, 0.0097, 0.0087,\n",
      "        0.0077])\n",
      "{'good': tensor(0.5666)}\n",
      "max_probe is: tensor(0.5666)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is positive but Mary is _ .\n",
      "['negative', 'not', 'pessimistic', 'positive', 'skeptical', 'depressed', 'optimistic', 'passive', 'worried', 'scared']\n",
      "tensor([0.5333, 0.0837, 0.0420, 0.0244, 0.0091, 0.0074, 0.0069, 0.0067, 0.0062,\n",
      "        0.0062])\n",
      "{'negative': tensor(0.5333)}\n",
      "max_probe is: tensor(0.5333)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is internal but Mary is _ .\n",
      "['external', 'External', 'outside', 'exterior', 'not', 'externally', 'outward', 'outer', 'spiritual', 'universal']\n",
      "tensor([0.9237, 0.0092, 0.0070, 0.0068, 0.0042, 0.0038, 0.0037, 0.0031, 0.0023,\n",
      "        0.0019])\n",
      "{'external': tensor(0.9237)}\n",
      "max_probe is: tensor(0.9237)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is effective but Mary is _ .\n",
      "['not', 'effective', 'indispensable', 'unreliable', 'better', 'powerful', 'vulnerable', 'ineffective', 'weak', 'dangerous']\n",
      "tensor([0.1716, 0.0162, 0.0146, 0.0125, 0.0116, 0.0103, 0.0103, 0.0097, 0.0096,\n",
      "        0.0095])\n",
      "{'ineffective': tensor(0.0097)}\n",
      "max_probe is: tensor(0.0097)\n",
      "the position of max probe is: 7\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is actual but Mary is _ .\n",
      "['fictional', 'not', 'imaginary', 'fiction', 'fictitious', 'mythical', 'myth', 'fantasy', 'invented', 'fake']\n",
      "tensor([0.2729, 0.1567, 0.0935, 0.0842, 0.0613, 0.0307, 0.0262, 0.0213, 0.0161,\n",
      "        0.0141])\n",
      "{'potential': tensor(0.0001)}\n",
      "max_probe is: tensor(0.0001)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 250\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is domestic but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'divine', 'spiritual', 'religious', 'missionary', 'Catholic', 'heavenly', 'independent', 'foreign', 'holy']\n",
      "tensor([0.2800, 0.1086, 0.0416, 0.0263, 0.0243, 0.0151, 0.0146, 0.0140, 0.0134,\n",
      "        0.0108])\n",
      "{'foreign': tensor(0.0134)}\n",
      "max_probe is: tensor(0.0134)\n",
      "the position of max probe is: 8\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is formal but Mary is _ .\n",
      "['not', 'informal', 'personal', 'spiritual', 'passionate', 'real', 'intuitive', 'spontaneous', 'emotional', 'humble']\n",
      "tensor([0.1038, 0.0633, 0.0297, 0.0270, 0.0252, 0.0203, 0.0165, 0.0160, 0.0157,\n",
      "        0.0147])\n",
      "{'informal': tensor(0.0633)}\n",
      "max_probe is: tensor(0.0633)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is external but Mary is _ .\n",
      "['internal', 'interior', 'inner', 'external', 'spiritual', 'inside', 'inward', 'within', 'Internal', 'not']\n",
      "tensor([0.8665, 0.0158, 0.0102, 0.0086, 0.0072, 0.0055, 0.0046, 0.0038, 0.0038,\n",
      "        0.0034])\n",
      "{'internal': tensor(0.8665)}\n",
      "max_probe is: tensor(0.8665)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is capable but Mary is _ .\n",
      "['not', 'weak', 'stronger', 'unwilling', 'better', 'willing', 'capable', 'strong', 'more', 'weaker']\n",
      "tensor([0.2206, 0.0270, 0.0252, 0.0174, 0.0170, 0.0158, 0.0145, 0.0123, 0.0111,\n",
      "        0.0108])\n",
      "{'incapable': tensor(0.0081)}\n",
      "max_probe is: tensor(0.0081)\n",
      "20\n",
      "the position of max probe is: 14\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is easy but Mary is _ .\n",
      "['hard', 'difficult', 'harder', 'tough', 'not', 'complicated', 'impossible', 'tricky', 'special', 'complex']\n",
      "tensor([0.3022, 0.1528, 0.0833, 0.0569, 0.0546, 0.0407, 0.0283, 0.0255, 0.0113,\n",
      "        0.0090])\n",
      "{'difficult': tensor(0.1528)}\n",
      "max_probe is: tensor(0.1528)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is affected but Mary is _ .\n",
      "['not', 'unaffected', 'immune', 'healed', 'spared', 'saved', 'cured', 'fine', 'protected', 'affected']\n",
      "tensor([0.5947, 0.1979, 0.0169, 0.0118, 0.0087, 0.0075, 0.0071, 0.0058, 0.0056,\n",
      "        0.0052])\n",
      "{'unaffected': tensor(0.1979)}\n",
      "max_probe is: tensor(0.1979)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is experienced but Mary is _ .\n",
      "['inexperienced', 'young', 'naive', 'not', 'naÃ¯ve', 'younger', 'new', 'vulnerable', 'innocent', 'passionate']\n",
      "tensor([0.1758, 0.1557, 0.0597, 0.0492, 0.0451, 0.0384, 0.0353, 0.0184, 0.0108,\n",
      "        0.0080])\n",
      "{'inexperienced': tensor(0.1758)}\n",
      "max_probe is: tensor(0.1758)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unusual but Mary is _ .\n",
      "['not', 'unique', 'rare', 'unusual', 'extraordinary', 'special', 'normal', 'ordinary', 'exceptional', 'different']\n",
      "tensor([0.2526, 0.0962, 0.0542, 0.0462, 0.0411, 0.0401, 0.0175, 0.0172, 0.0170,\n",
      "        0.0166])\n",
      "{'usual': tensor(0.0013)}\n",
      "max_probe is: tensor(0.0013)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 66\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is safe but Mary is _ .\n",
      "['not', 'afraid', 'scared', 'terrified', 'alone', 'worried', 'missing', 'lost', 'dead', 'vulnerable']\n",
      "tensor([0.5956, 0.0362, 0.0256, 0.0180, 0.0120, 0.0104, 0.0101, 0.0091, 0.0083,\n",
      "        0.0075])\n",
      "{'dangerous': tensor(0.0017)}\n",
      "max_probe is: tensor(0.0017)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 43\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is visible but Mary is _ .\n",
      "['not', 'invisible', 'hidden', 'obscured', 'unseen', 'missing', 'concealed', 'absent', 'behind', 'hiding']\n",
      "tensor([0.4064, 0.2339, 0.1216, 0.0509, 0.0191, 0.0121, 0.0068, 0.0053, 0.0053,\n",
      "        0.0049])\n",
      "{'invisible': tensor(0.2339)}\n",
      "max_probe is: tensor(0.2339)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is instrumental but Mary is _ .\n",
      "['not', 'silent', 'instrumental', 'vocal', 'passive', 'spiritual', 'emotional', 'invisible', 'quiet', 'passionate']\n",
      "tensor([0.0693, 0.0487, 0.0456, 0.0300, 0.0231, 0.0185, 0.0145, 0.0139, 0.0131,\n",
      "        0.0098])\n",
      "{'vocal': tensor(0.0300)}\n",
      "max_probe is: tensor(0.0300)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is illegal but Mary is _ .\n",
      "['not', 'legal', 'free', 'illegal', 'innocent', 'exempt', 'holy', 'Catholic', '', 'safe']\n",
      "tensor([0.5467, 0.1129, 0.0318, 0.0120, 0.0118, 0.0091, 0.0065, 0.0054, 0.0050,\n",
      "        0.0049])\n",
      "{'legal': tensor(0.1129)}\n",
      "max_probe is: tensor(0.1129)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is vocal but Mary is _ .\n",
      "['quiet', 'silent', 'not', 'quieter', 'shy', 'beautiful', 'vocal', 'visual', 'emotional', 'expressive']\n",
      "tensor([0.1587, 0.0771, 0.0760, 0.0551, 0.0430, 0.0145, 0.0132, 0.0123, 0.0114,\n",
      "        0.0088])\n",
      "{'instrumental': tensor(0.0024)}\n",
      "max_probe is: tensor(0.0024)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 40\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is alive but Mary is _ .\n",
      "['dead', 'not', 'dying', 'gone', 'pregnant', 'killed', 'murdered', 'missing', 'afraid', 'sick']\n",
      "tensor([0.5884, 0.1954, 0.0355, 0.0205, 0.0088, 0.0072, 0.0068, 0.0064, 0.0045,\n",
      "        0.0044])\n",
      "{'dead': tensor(0.5884)}\n",
      "max_probe is: tensor(0.5884)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is civilian but Mary is _ .\n",
      "['not', 'Catholic', 'religious', 'divine', 'military', 'Christian', 'a', 'royal', 'priest', 'queen']\n",
      "tensor([0.2199, 0.0838, 0.0479, 0.0456, 0.0293, 0.0281, 0.0271, 0.0175, 0.0168,\n",
      "        0.0135])\n",
      "{'military': tensor(0.0293)}\n",
      "max_probe is: tensor(0.0293)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is conventional but Mary is _ .\n",
      "['not', 'unconventional', 'revolutionary', 'divine', 'radical', 'unorthodox', 'different', 'unique', 'unusual', 'spiritual']\n",
      "tensor([0.2042, 0.1700, 0.0314, 0.0199, 0.0196, 0.0182, 0.0154, 0.0104, 0.0104,\n",
      "        0.0104])\n",
      "{'unconventional': tensor(0.1700)}\n",
      "max_probe is: tensor(0.1700)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unsuccessful but Mary is _ .\n",
      "['saved', 'not', 'pregnant', 'successful', '', 'safe', 'rescued', 'killed', 'raped', 'protected']\n",
      "tensor([0.1932, 0.0611, 0.0581, 0.0399, 0.0371, 0.0270, 0.0174, 0.0168, 0.0152,\n",
      "        0.0135])\n",
      "{'successful': tensor(0.0399)}\n",
      "max_probe is: tensor(0.0399)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is false but Mary is _ .\n",
      "['true', 'real', 'not', 'false', 'truth', 'right', 'truthful', 'faithful', 'innocent', 'True']\n",
      "tensor([0.5018, 0.1211, 0.0627, 0.0237, 0.0189, 0.0156, 0.0131, 0.0088, 0.0079,\n",
      "        0.0076])\n",
      "{'true': tensor(0.5018)}\n",
      "max_probe is: tensor(0.5018)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is soft but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['strong', 'tough', 'firm', 'hard', 'fierce', 'stern', 'cold', 'stubborn', 'stronger', 'powerful']\n",
      "tensor([0.4540, 0.1001, 0.0820, 0.0678, 0.0484, 0.0152, 0.0097, 0.0091, 0.0085,\n",
      "        0.0069])\n",
      "{'hard': tensor(0.0678)}\n",
      "max_probe is: tensor(0.0678)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is stable but Mary is _ .\n",
      "['not', 'unstable', 'pregnant', 'troubled', 'volatile', 'unpredictable', 'restless', 'unhappy', 'struggling', 'dangerous']\n",
      "tensor([0.3624, 0.1557, 0.0262, 0.0191, 0.0118, 0.0106, 0.0093, 0.0089, 0.0064,\n",
      "        0.0058])\n",
      "{'unstable': tensor(0.1557)}\n",
      "max_probe is: tensor(0.1557)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is usual but Mary is _ .\n",
      "['not', 'unusual', 'rare', 'special', 'different', 'unique', 'uncommon', 'new', 'a', '']\n",
      "tensor([0.1347, 0.1197, 0.0698, 0.0650, 0.0553, 0.0358, 0.0280, 0.0197, 0.0092,\n",
      "        0.0087])\n",
      "{'unusual': tensor(0.1197)}\n",
      "max_probe is: tensor(0.1197)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is impossible but Mary is _ .\n",
      "['not', 'impossible', 'possible', 'perfect', 'beautiful', 'divine', 'real', 'miraculous', 'true', 'achievable']\n",
      "tensor([0.1978, 0.1622, 0.1107, 0.0258, 0.0199, 0.0193, 0.0189, 0.0129, 0.0117,\n",
      "        0.0106])\n",
      "{'possible': tensor(0.1107)}\n",
      "max_probe is: tensor(0.1107)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is endemic but Mary is _ .\n",
      "['not', 'rare', 'endangered', '', 'extinct', 'endemic', 'common', 'uncommon', 'universal', '.']\n",
      "tensor([0.8589, 0.0190, 0.0115, 0.0079, 0.0040, 0.0035, 0.0035, 0.0034, 0.0030,\n",
      "        0.0030])\n",
      "{'epidemic': tensor(1.1748e-05)}\n",
      "max_probe is: tensor(1.1748e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 747\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is ordinary but Mary is _ .\n",
      "['extraordinary', 'special', 'divine', 'exceptional', 'beautiful', 'unique', 'unusual', 'perfect', 'ordinary', 'miraculous']\n",
      "tensor([0.3836, 0.1204, 0.0644, 0.0603, 0.0299, 0.0178, 0.0171, 0.0140, 0.0132,\n",
      "        0.0123])\n",
      "{'extraordinary': tensor(0.3836)}\n",
      "max_probe is: tensor(0.3836)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is vertical but Mary is _ .\n",
      "['horizontal', 'vertical', 'not', 'sideways', 'horizontally', 'diagonal', 'curved', 'inverted', 'flat', 'parallel']\n",
      "tensor([0.9129, 0.0144, 0.0097, 0.0056, 0.0055, 0.0038, 0.0032, 0.0024, 0.0021,\n",
      "        0.0015])\n",
      "{'inclined': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0003)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 27\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is automatic but Mary is _ .\n",
      "['not', 'human', 'special', 'mortal', 'immortal', 'alive', 'different', 'unpredictable', 'slow', 'automatic']\n",
      "tensor([0.3061, 0.0533, 0.0269, 0.0113, 0.0109, 0.0101, 0.0082, 0.0077, 0.0077,\n",
      "        0.0071])\n",
      "{'manual': tensor(0.0046)}\n",
      "max_probe is: tensor(0.0046)\n",
      "20\n",
      "the position of max probe is: 14\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is weak but Mary is _ .\n",
      "['strong', 'stronger', 'powerful', 'not', 'mighty', 'brave', 'courageous', 'weak', 'invincible', 'strongest']\n",
      "tensor([0.6987, 0.0987, 0.0433, 0.0107, 0.0098, 0.0051, 0.0041, 0.0041, 0.0032,\n",
      "        0.0025])\n",
      "{'strong': tensor(0.6987)}\n",
      "max_probe is: tensor(0.6987)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is accessible but Mary is _ .\n",
      "['not', 'inaccessible', 'invisible', 'elusive', 'hidden', 'private', 'unavailable', 'closed', 'accessible', 'special']\n",
      "tensor([0.4036, 0.1248, 0.0400, 0.0209, 0.0168, 0.0129, 0.0104, 0.0064, 0.0063,\n",
      "        0.0051])\n",
      "{'inaccessible': tensor(0.1248)}\n",
      "max_probe is: tensor(0.1248)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is artificial but Mary is _ .\n",
      "['real', 'not', 'human', 'divine', 'natural', 'organic', 'alive', 'genuine', 'true', 'immortal']\n",
      "tensor([0.6838, 0.1134, 0.0408, 0.0146, 0.0094, 0.0063, 0.0055, 0.0048, 0.0046,\n",
      "        0.0042])\n",
      "{'natural': tensor(0.0094)}\n",
      "max_probe is: tensor(0.0094)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is empty but Mary is _ .\n",
      "['full', 'not', 'filled', 'alive', 'whole', 'filling', 'pregnant', 'empty', 'overflowing', 'beautiful']\n",
      "tensor([0.4559, 0.0691, 0.0678, 0.0312, 0.0216, 0.0196, 0.0166, 0.0159, 0.0138,\n",
      "        0.0130])\n",
      "{'full': tensor(0.4559)}\n",
      "max_probe is: tensor(0.4559)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is emotional but Mary is _ .\n",
      "['not', 'calm', 'strong', 'angry', 'cold', 'pragmatic', 'rational', 'scared', 'silent', 'quiet']\n",
      "tensor([0.1762, 0.0262, 0.0261, 0.0216, 0.0171, 0.0129, 0.0117, 0.0117, 0.0116,\n",
      "        0.0114])\n",
      "{'cerebral': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0002)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 592\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is theoretical but Mary is _ .\n",
      "['practical', 'real', 'pragmatic', 'empirical', 'spiritual', 'personal', 'literal', 'actual', 'human', 'factual']\n",
      "tensor([0.5434, 0.1288, 0.0237, 0.0141, 0.0133, 0.0129, 0.0109, 0.0066, 0.0065,\n",
      "        0.0064])\n",
      "{'empirical': tensor(0.0141)}\n",
      "max_probe is: tensor(0.0141)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is eligible but Mary is _ .\n",
      "['not', 'married', 'pregnant', 'ineligible', '', 'unmarried', 'dead', 'alive', 'excluded', 'older']\n",
      "tensor([0.7961, 0.0217, 0.0196, 0.0172, 0.0070, 0.0033, 0.0031, 0.0028, 0.0027,\n",
      "        0.0024])\n",
      "{'ineligible': tensor(0.0172)}\n",
      "max_probe is: tensor(0.0172)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is valid but Mary is _ .\n",
      "['not', 'invalid', 'valid', 'wrong', 'false', 'dead', 'divine', 'better', 'illegitimate', 'true']\n",
      "tensor([0.3909, 0.0444, 0.0380, 0.0248, 0.0237, 0.0233, 0.0117, 0.0098, 0.0094,\n",
      "        0.0068])\n",
      "{'invalid': tensor(0.0444)}\n",
      "max_probe is: tensor(0.0444)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is extraordinary but Mary is _ .\n",
      "['extraordinary', 'special', 'divine', 'not', 'exceptional', 'beautiful', 'ordinary', 'amazing', 'unique', 'better']\n",
      "tensor([0.1259, 0.0519, 0.0424, 0.0378, 0.0287, 0.0276, 0.0276, 0.0252, 0.0246,\n",
      "        0.0216])\n",
      "{'ordinary': tensor(0.0276)}\n",
      "max_probe is: tensor(0.0276)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is busy but Mary is _ .\n",
      "['not', 'lonely', 'worried', 'waiting', 'alone', 'missing', 'happy', 'bored', 'home', 'restless']\n",
      "tensor([0.1291, 0.1123, 0.0519, 0.0420, 0.0310, 0.0307, 0.0209, 0.0164, 0.0157,\n",
      "        0.0132])\n",
      "{'idle': tensor(0.0005)}\n",
      "max_probe is: tensor(0.0005)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 187\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is reliable but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unreliable', 'not', 'unpredictable', 'trustworthy', 'unstable', 'reliable', 'inconsistent', 'dangerous', 'deceptive', 'different']\n",
      "tensor([0.3129, 0.1677, 0.0292, 0.0221, 0.0114, 0.0110, 0.0104, 0.0092, 0.0069,\n",
      "        0.0054])\n",
      "{'unreliable': tensor(0.3129)}\n",
      "max_probe is: tensor(0.3129)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is sudden but Mary is _ .\n",
      "['not', 'ready', 'patient', 'late', 'waiting', 'silent', 'prepared', 'strong', 'quiet', 'pregnant']\n",
      "tensor([0.2132, 0.0356, 0.0256, 0.0214, 0.0197, 0.0120, 0.0119, 0.0105, 0.0101,\n",
      "        0.0083])\n",
      "{'gradual': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0003)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 446\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unlikely but Mary is _ .\n",
      "['possible', 'not', 'likely', 'certain', 'probable', 'unlikely', 'impossible', 'definitely', 'probably', '']\n",
      "tensor([0.1314, 0.1309, 0.1113, 0.0517, 0.0391, 0.0378, 0.0247, 0.0220, 0.0163,\n",
      "        0.0162])\n",
      "{'probable': tensor(0.0391)}\n",
      "max_probe is: tensor(0.0391)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is voluntary but Mary is _ .\n",
      "['not', 'involuntary', 'forced', 'coerced', 'compelled', 'obedient', 'voluntary', 'free', 'unwilling', 'enslaved']\n",
      "tensor([0.5172, 0.0584, 0.0369, 0.0357, 0.0235, 0.0220, 0.0150, 0.0088, 0.0084,\n",
      "        0.0074])\n",
      "{'involuntary': tensor(0.0584)}\n",
      "max_probe is: tensor(0.0584)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is informal but Mary is _ .\n",
      "['formal', 'not', 'strict', 'serious', 'polite', 'reserved', 'proper', 'traditional', 'rigid', 'elegant']\n",
      "tensor([0.2697, 0.1122, 0.0344, 0.0161, 0.0149, 0.0147, 0.0100, 0.0096, 0.0095,\n",
      "        0.0084])\n",
      "{'formal': tensor(0.2697)}\n",
      "max_probe is: tensor(0.2697)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is reasonable but Mary is _ .\n",
      "['not', 'unreasonable', 'crazy', 'insane', 'irrational', 'naive', 'stubborn', 'evil', 'passionate', 'beautiful']\n",
      "tensor([0.1892, 0.0401, 0.0327, 0.0203, 0.0174, 0.0132, 0.0124, 0.0117, 0.0094,\n",
      "        0.0089])\n",
      "{'unreasonable': tensor(0.0401)}\n",
      "max_probe is: tensor(0.0401)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is sophisticated but Mary is _ .\n",
      "['naive', 'not', 'naÃ¯ve', 'beautiful', 'simple', 'passionate', 'young', 'vulnerable', 'innocent', 'humble']\n",
      "tensor([0.0654, 0.0471, 0.0449, 0.0416, 0.0360, 0.0244, 0.0161, 0.0144, 0.0128,\n",
      "        0.0126])\n",
      "{'naive': tensor(0.0654)}\n",
      "max_probe is: tensor(0.0654)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is compatible but Mary is _ .\n",
      "['not', 'married', 'pregnant', 'sterile', 'gay', 'unwilling', 'incompatible', 'different', '', 'unmarried']\n",
      "tensor([0.6582, 0.0247, 0.0146, 0.0076, 0.0064, 0.0053, 0.0046, 0.0044, 0.0042,\n",
      "        0.0039])\n",
      "{'incompatible': tensor(0.0046)}\n",
      "max_probe is: tensor(0.0046)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is acceptable but Mary is _ .\n",
      "['not', 'better', 'unacceptable', 'indispensable', 'perfect', 'preferable', 'superior', '', 'exceptional', 'excellent']\n",
      "tensor([0.2485, 0.0980, 0.0391, 0.0135, 0.0123, 0.0101, 0.0096, 0.0084, 0.0080,\n",
      "        0.0080])\n",
      "{'unacceptable': tensor(0.0391)}\n",
      "max_probe is: tensor(0.0391)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is comfortable but Mary is _ .\n",
      "['not', 'scared', 'afraid', 'worried', 'uncomfortable', 'terrified', 'frightened', 'nervous', 'restless', 'lonely']\n",
      "tensor([0.3201, 0.0475, 0.0470, 0.0378, 0.0312, 0.0270, 0.0178, 0.0143, 0.0125,\n",
      "        0.0117])\n",
      "{'uncomfortable': tensor(0.0312)}\n",
      "max_probe is: tensor(0.0312)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uncommon but Mary is _ .\n",
      "['rare', 'common', 'not', 'uncommon', 'ubiquitous', 'abundant', 'unusual', '', 'unique', 'scarce']\n",
      "tensor([0.3775, 0.2713, 0.1043, 0.0306, 0.0116, 0.0108, 0.0095, 0.0081, 0.0080,\n",
      "        0.0070])\n",
      "{'common': tensor(0.2713)}\n",
      "max_probe is: tensor(0.2713)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is rational but Mary is _ .\n",
      "['not', 'irrational', 'emotional', 'intuitive', 'spiritual', 'passionate', 'religious', 'divine', 'crazy', 'magical']\n",
      "tensor([0.1338, 0.1145, 0.0961, 0.0591, 0.0529, 0.0303, 0.0221, 0.0199, 0.0124,\n",
      "        0.0091])\n",
      "{'irrational': tensor(0.1145)}\n",
      "max_probe is: tensor(0.1145)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is supernatural but Mary is _ .\n",
      "['not', 'human', 'mortal', 'real', 'divine', 'supernatural', 'spiritual', 'natural', 't', 'religious']\n",
      "tensor([0.6928, 0.0739, 0.0326, 0.0280, 0.0205, 0.0077, 0.0070, 0.0054, 0.0037,\n",
      "        0.0028])\n",
      "{'natural': tensor(0.0054)}\n",
      "max_probe is: tensor(0.0054)\n",
      "the position of max probe is: 7\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unrelated but Mary is _ .\n",
      "['related', '', 'not', '.', 'unrelated', '', 'known', ',', '', 'from']\n",
      "tensor([0.2527, 0.1839, 0.1461, 0.0430, 0.0259, 0.0155, 0.0152, 0.0094, 0.0082,\n",
      "        0.0075])\n",
      "{'related': tensor(0.2527)}\n",
      "max_probe is: tensor(0.2527)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unconscious but Mary is _ .\n",
      "['awake', 'alive', 'not', 'alert', 'conscious', 'crying', 'asleep', 'fine', 'lucid', 'sleeping']\n",
      "tensor([0.3495, 0.1113, 0.1025, 0.0346, 0.0220, 0.0219, 0.0211, 0.0118, 0.0106,\n",
      "        0.0092])\n",
      "{'conscious': tensor(0.0220)}\n",
      "max_probe is: tensor(0.0220)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is homosexual but Mary is _ .\n",
      "['not', 'heterosexual', 'married', 'bisexual', 'Catholic', 'straight', 'lesbian', 'Christian', 'Jewish', 'neither']\n",
      "tensor([0.6532, 0.1302, 0.0478, 0.0416, 0.0162, 0.0102, 0.0071, 0.0062, 0.0038,\n",
      "        0.0036])\n",
      "{'bisexual': tensor(0.0416)}\n",
      "max_probe is: tensor(0.0416)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is invisible but Mary is _ .\n",
      "['not', 'visible', 'invisible', 'alive', 'real', 'everywhere', 'seen', 'beautiful', '', 'known']\n",
      "tensor([0.3341, 0.0394, 0.0369, 0.0259, 0.0193, 0.0191, 0.0171, 0.0152, 0.0123,\n",
      "        0.0123])\n",
      "{'visible': tensor(0.0394)}\n",
      "max_probe is: tensor(0.0394)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is induced but Mary is _ .\n",
      "['not', 'asleep', 'unconscious', 'killed', 'awake', 'saved', 'awakened', 'raped', 'released', 'murdered']\n",
      "tensor([0.4646, 0.0309, 0.0273, 0.0181, 0.0180, 0.0115, 0.0090, 0.0079, 0.0066,\n",
      "        0.0064])\n",
      "{'spontaneous': tensor(7.2988e-05)}\n",
      "max_probe is: tensor(7.2988e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 643\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unlimited but Mary is _ .\n",
      "['not', 'finite', 'limited', 'immortal', 'unlimited', 'restricted', 'infinite', 'mortal', 'eternal', 'free']\n",
      "tensor([0.4148, 0.1000, 0.0951, 0.0226, 0.0225, 0.0135, 0.0132, 0.0071, 0.0057,\n",
      "        0.0044])\n",
      "{'limited': tensor(0.0951)}\n",
      "max_probe is: tensor(0.0951)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is incredible but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazing', 'better', 'incredible', 'beautiful', 'more', 'awesome', 'unbelievable', 'wonderful', 'extraordinary', 'too']\n",
      "tensor([0.1876, 0.0958, 0.0666, 0.0323, 0.0301, 0.0190, 0.0185, 0.0163, 0.0136,\n",
      "        0.0131])\n",
      "{'credible': tensor(2.9341e-05)}\n",
      "max_probe is: tensor(2.9341e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 1188\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unstable but Mary is _ .\n",
      "['not', 'stable', 'strong', 'beautiful', 'sane', 'unstable', 'calm', 'resilient', 'perfect', 'loyal']\n",
      "tensor([0.1899, 0.1115, 0.0492, 0.0175, 0.0163, 0.0150, 0.0144, 0.0114, 0.0103,\n",
      "        0.0097])\n",
      "{'stable': tensor(0.1115)}\n",
      "max_probe is: tensor(0.1115)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unhappy but Mary is _ .\n",
      "['happy', 'not', 'hopeful', 'happier', 'pleased', 'content', 'unhappy', 'worried', 'ecstatic', 'sad']\n",
      "tensor([0.3521, 0.1297, 0.0207, 0.0191, 0.0187, 0.0186, 0.0179, 0.0177, 0.0127,\n",
      "        0.0108])\n",
      "{'happy': tensor(0.3521)}\n",
      "max_probe is: tensor(0.3521)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is gradual but Mary is _ .\n",
      "['not', 'fast', 'impatient', 'abrupt', 'instantaneous', 'relentless', 'quick', 'swift', 'forceful', 'brutal']\n",
      "tensor([0.1572, 0.0433, 0.0304, 0.0277, 0.0264, 0.0217, 0.0173, 0.0166, 0.0153,\n",
      "        0.0141])\n",
      "{'sudden': tensor(0.0085)}\n",
      "max_probe is: tensor(0.0085)\n",
      "20\n",
      "the position of max probe is: 14\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unpopular but Mary is _ .\n",
      "['popular', 'not', 'unpopular', 'loved', 'beloved', 'misunderstood', 'controversial', 'liked', 'admired', 'revered']\n",
      "tensor([0.3744, 0.0771, 0.0336, 0.0323, 0.0181, 0.0164, 0.0138, 0.0134, 0.0117,\n",
      "        0.0097])\n",
      "{'popular': tensor(0.3744)}\n",
      "max_probe is: tensor(0.3744)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is epidemic but Mary is _ .\n",
      "['not', 'immune', 'contagious', 'unique', 'dying', 'divine', 'healthy', 'cure', 'salvation', 'special']\n",
      "tensor([0.1471, 0.0749, 0.0128, 0.0117, 0.0101, 0.0094, 0.0089, 0.0086, 0.0085,\n",
      "        0.0084])\n",
      "{'endemic': tensor(0.0004)}\n",
      "max_probe is: tensor(0.0004)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 305\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unnecessary but Mary is _ .\n",
      "['needed', 'indispensable', 'not', 'necessary', 'important', 'essential', '', 'beautiful', 'required', 'perfect']\n",
      "tensor([0.1126, 0.1107, 0.1051, 0.0838, 0.0541, 0.0433, 0.0154, 0.0138, 0.0105,\n",
      "        0.0101])\n",
      "{'necessary': tensor(0.0838)}\n",
      "max_probe is: tensor(0.0838)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is empirical but Mary is _ .\n",
      "['spiritual', 'not', 'metaphysical', 'symbolic', 'mystical', 'subjective', 'intuitive', 'religious', 'divine', 'theological']\n",
      "tensor([0.1967, 0.0582, 0.0505, 0.0338, 0.0282, 0.0256, 0.0229, 0.0218, 0.0209,\n",
      "        0.0205])\n",
      "{'theoretical': tensor(0.0068)}\n",
      "max_probe is: tensor(0.0068)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 26\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is peripheral but Mary is _ .\n",
      "['central', 'pivotal', 'important', 'integral', 'primary', 'essential', 'crucial', 'key', 'significant', 'indispensable']\n",
      "tensor([0.5947, 0.0249, 0.0240, 0.0226, 0.0160, 0.0141, 0.0115, 0.0107, 0.0103,\n",
      "        0.0096])\n",
      "{'central': tensor(0.5947)}\n",
      "max_probe is: tensor(0.5947)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unwilling but Mary is _ .\n",
      "['willing', 'ready', 'adamant', 'not', 'determined', 'convinced', 'desperate', 'unwilling', 'persuaded', 'strong']\n",
      "tensor([0.1197, 0.0974, 0.0933, 0.0616, 0.0400, 0.0302, 0.0270, 0.0197, 0.0182,\n",
      "        0.0127])\n",
      "{'willing': tensor(0.1197)}\n",
      "max_probe is: tensor(0.1197)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is spontaneous but Mary is _ .\n",
      "['not', 'disciplined', 'determined', 'thoughtful', 'predictable', 'cautious', 'controlled', 'patient', 'prepared', 'steadfast']\n",
      "tensor([0.0730, 0.0371, 0.0291, 0.0207, 0.0176, 0.0166, 0.0163, 0.0160, 0.0160,\n",
      "        0.0153])\n",
      "{'induced': tensor(2.0481e-05)}\n",
      "max_probe is: tensor(2.0481e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "the position of max probe is: 1982\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inexpensive but Mary is _ .\n",
      "['expensive', 'not', 'priceless', 'free', 'cheap', 'costly', 'beautiful', 'rich', 'pricey', 'indispensable']\n",
      "tensor([0.1856, 0.1128, 0.0640, 0.0551, 0.0203, 0.0185, 0.0166, 0.0165, 0.0145,\n",
      "        0.0096])\n",
      "{'expensive': tensor(0.1856)}\n",
      "max_probe is: tensor(0.1856)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unavailable but Mary is _ .\n",
      "['available', '', 'not', 'unavailable', 'present', 'there', '.', 'pregnant', 'alive', 'free']\n",
      "tensor([0.3276, 0.1094, 0.0484, 0.0420, 0.0283, 0.0269, 0.0186, 0.0183, 0.0144,\n",
      "        0.0116])\n",
      "{'available': tensor(0.3276)}\n",
      "max_probe is: tensor(0.3276)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is ineffective but Mary is _ .\n",
      "['not', 'effective', 'powerful', 'strong', '', 'beautiful', 'indispensable', 'faithful', 'successful', 'stronger']\n",
      "tensor([0.1767, 0.0422, 0.0355, 0.0224, 0.0195, 0.0136, 0.0125, 0.0080, 0.0079,\n",
      "        0.0077])\n",
      "{'effective': tensor(0.0422)}\n",
      "max_probe is: tensor(0.0422)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is cerebral but Mary is _ .\n",
      "['spiritual', 'not', 'intuitive', 'emotional', 'religious', 'psychic', 'practical', 'cerebral', 'physical', 'passionate']\n",
      "tensor([0.1042, 0.0998, 0.0550, 0.0478, 0.0200, 0.0173, 0.0164, 0.0161, 0.0123,\n",
      "        0.0098])\n",
      "{'emotional': tensor(0.0478)}\n",
      "max_probe is: tensor(0.0478)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is invalid but Mary is _ .\n",
      "['not', 'alive', 'pregnant', 'dead', 'innocent', 'valid', 'right', 'married', 'immortal', 'correct']\n",
      "tensor([0.5100, 0.0552, 0.0237, 0.0160, 0.0130, 0.0091, 0.0090, 0.0081, 0.0077,\n",
      "        0.0077])\n",
      "{'valid': tensor(0.0091)}\n",
      "max_probe is: tensor(0.0091)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unconstitutional but Mary is _ .\n",
      "['not', 'constitutional', 'unconstitutional', 'legal', 'divine', 'Constitutional', 'Catholic', '', 'sacred', 'illegal']\n",
      "tensor([0.6409, 0.0280, 0.0244, 0.0227, 0.0130, 0.0123, 0.0087, 0.0070, 0.0055,\n",
      "        0.0053])\n",
      "{'constitutional': tensor(0.0280)}\n",
      "max_probe is: tensor(0.0280)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is abnormal but Mary is _ .\n",
      "['normal', 'not', 'perfect', 'beautiful', 'special', 'ordinary', 'healthy', 'extraordinary', 'abnormal', 'unique']\n",
      "tensor([0.4020, 0.1354, 0.0817, 0.0320, 0.0173, 0.0157, 0.0144, 0.0136, 0.0124,\n",
      "        0.0109])\n",
      "{'normal': tensor(0.4020)}\n",
      "max_probe is: tensor(0.4020)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unmarried but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['married', 'pregnant', 'not', 'engaged', 'unmarried', 'divorced', 'single', 'Catholic', '', 'sterile']\n",
      "tensor([0.3514, 0.3246, 0.1566, 0.0515, 0.0099, 0.0096, 0.0060, 0.0058, 0.0051,\n",
      "        0.0026])\n",
      "{'married': tensor(0.3514)}\n",
      "max_probe is: tensor(0.3514)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is idle but Mary is _ .\n",
      "['busy', 'not', 'awake', 'active', 'working', 'asleep', 'restless', 'sleeping', 'ready', 'praying']\n",
      "tensor([0.2299, 0.0759, 0.0405, 0.0320, 0.0267, 0.0246, 0.0234, 0.0233, 0.0161,\n",
      "        0.0130])\n",
      "{'busy': tensor(0.2299)}\n",
      "max_probe is: tensor(0.2299)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is bisexual but Mary is _ .\n",
      "['not', 'gay', 'married', 'lesbian', 'heterosexual', 'homosexual', 'straight', 'single', 'Jewish', 'transgender']\n",
      "tensor([0.5020, 0.1214, 0.0635, 0.0533, 0.0411, 0.0396, 0.0296, 0.0137, 0.0087,\n",
      "        0.0072])\n",
      "{'heterosexual': tensor(0.0411)}\n",
      "max_probe is: tensor(0.0411)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uncomfortable but Mary is _ .\n",
      "['not', 'happy', 'worried', 'ready', 'excited', 'afraid', 'concerned', 'comfortable', 'hopeful', 'relieved']\n",
      "tensor([0.1973, 0.0609, 0.0212, 0.0185, 0.0184, 0.0107, 0.0099, 0.0094, 0.0093,\n",
      "        0.0083])\n",
      "{'comfortable': tensor(0.0094)}\n",
      "max_probe is: tensor(0.0094)\n",
      "the position of max probe is: 7\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unconventional but Mary is _ .\n",
      "['not', 'unconventional', 'traditional', 'perfect', 'conventional', 'orthodox', 'beautiful', 'pragmatic', 'devout', 'divine']\n",
      "tensor([0.1655, 0.0478, 0.0376, 0.0341, 0.0307, 0.0246, 0.0140, 0.0136, 0.0126,\n",
      "        0.0118])\n",
      "{'conventional': tensor(0.0307)}\n",
      "max_probe is: tensor(0.0307)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is incapable but Mary is _ .\n",
      "['not', 'capable', 'willing', 'pregnant', 'strong', 'able', 'ready', '', 'powerful', 'faithful']\n",
      "tensor([0.0793, 0.0765, 0.0609, 0.0574, 0.0529, 0.0366, 0.0349, 0.0182, 0.0164,\n",
      "        0.0157])\n",
      "{'capable': tensor(0.0765)}\n",
      "max_probe is: tensor(0.0765)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is incompatible but Mary is _ .\n",
      "['not', 'compatible', 'perfect', 'neither', 'both', 'different', 'incompatible', 'better', 'divine', 'pregnant']\n",
      "tensor([0.4958, 0.0934, 0.0198, 0.0085, 0.0079, 0.0074, 0.0073, 0.0064, 0.0064,\n",
      "        0.0064])\n",
      "{'compatible': tensor(0.0934)}\n",
      "max_probe is: tensor(0.0934)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is credible but Mary is _ .\n",
      "['not', 'unreliable', 'credible', 'dangerous', '', 'deceptive', 'delusional', 'more', 'lying', 'too']\n",
      "tensor([0.5301, 0.0332, 0.0133, 0.0117, 0.0110, 0.0103, 0.0103, 0.0086, 0.0066,\n",
      "        0.0066])\n",
      "{'incredible': tensor(0.0005)}\n",
      "max_probe is: tensor(0.0005)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 138\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is lawful but Mary is _ .\n",
      "['not', 'immoral', 'illegitimate', 'evil', 'unlawful', 'lawful', 'illegal', 'sinful', 'divine', 'forbidden']\n",
      "tensor([0.4473, 0.0653, 0.0493, 0.0306, 0.0300, 0.0282, 0.0269, 0.0169, 0.0094,\n",
      "        0.0087])\n",
      "{'unlawful': tensor(0.0300)}\n",
      "max_probe is: tensor(0.0300)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is undesirable but Mary is _ .\n",
      "['desirable', 'not', 'desired', 'indispensable', 'preferred', 'preferable', 'beautiful', 'attractive', 'undesirable', 'chosen']\n",
      "tensor([0.3095, 0.0981, 0.0276, 0.0250, 0.0232, 0.0191, 0.0175, 0.0137, 0.0106,\n",
      "        0.0106])\n",
      "{'desirable': tensor(0.3095)}\n",
      "max_probe is: tensor(0.3095)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is heterosexual but Mary is _ .\n",
      "['homosexual', 'bisexual', 'gay', 'not', 'lesbian', 'transgender', 'Catholic', 'married', 'pregnant', 'heterosexual']\n",
      "tensor([0.2982, 0.2937, 0.1462, 0.1079, 0.0399, 0.0144, 0.0140, 0.0122, 0.0050,\n",
      "        0.0041])\n",
      "{'homosexual': tensor(0.2982)}\n",
      "max_probe is: tensor(0.2982)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unfamiliar but Mary is _ .\n",
      "['not', 'familiar', '', 'known', '.', 'new', 'trusted', '..', 'unknown', 'friendly']\n",
      "tensor([0.3430, 0.0523, 0.0314, 0.0202, 0.0104, 0.0098, 0.0087, 0.0083, 0.0075,\n",
      "        0.0070])\n",
      "{'familiar': tensor(0.0523)}\n",
      "max_probe is: tensor(0.0523)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is ineligible but Mary is _ .\n",
      "['not', '', 'eligible', 'married', 'pregnant', 'alive', '.', 'exempt', 'free', 'allowed']\n",
      "tensor([0.4802, 0.0563, 0.0298, 0.0298, 0.0229, 0.0152, 0.0133, 0.0126, 0.0090,\n",
      "        0.0073])\n",
      "{'eligible': tensor(0.0298)}\n",
      "max_probe is: tensor(0.0298)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inexperienced but Mary is _ .\n",
      "['not', 'experienced', 'wise', 'strong', 'ready', 'wiser', 'powerful', 'inexperienced', 'older', 'patient']\n",
      "tensor([0.0906, 0.0473, 0.0307, 0.0282, 0.0268, 0.0178, 0.0155, 0.0145, 0.0145,\n",
      "        0.0138])\n",
      "{'experienced': tensor(0.0473)}\n",
      "max_probe is: tensor(0.0473)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unpredictable but Mary is _ .\n",
      "['not', 'predictable', 'unpredictable', 'reliable', 'stable', 'consistent', 'steadfast', 'trustworthy', 'determined', 'resilient']\n",
      "tensor([0.1919, 0.1009, 0.0483, 0.0464, 0.0294, 0.0241, 0.0226, 0.0205, 0.0203,\n",
      "        0.0179])\n",
      "{'predictable': tensor(0.1009)}\n",
      "max_probe is: tensor(0.1009)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is predictable but Mary is _ .\n",
      "['unpredictable', 'not', 'unexpected', 'different', 'surprising', 'mysterious', 'unconventional', 'unique', 'spontaneous', 'unusual']\n",
      "tensor([0.4670, 0.2216, 0.0257, 0.0178, 0.0130, 0.0113, 0.0082, 0.0072, 0.0046,\n",
      "        0.0041])\n",
      "{'unpredictable': tensor(0.4670)}\n",
      "max_probe is: tensor(0.4670)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nasty but Mary is _ .\n",
      "['kind', 'beautiful', 'sweet', 'lovely', 'nice', 'nicer', 'pretty', 'good', 'wonderful', 'better']\n",
      "tensor([0.0809, 0.0715, 0.0508, 0.0495, 0.0467, 0.0385, 0.0337, 0.0240, 0.0181,\n",
      "        0.0173])\n",
      "{'nice': tensor(0.0467)}\n",
      "max_probe is: tensor(0.0467)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inaccessible but Mary is _ .\n",
      "['not', 'accessible', 'available', 'free', 'indispensable', 'there', '', 'everywhere', 'safe', 'powerful']\n",
      "tensor([0.2194, 0.1021, 0.0680, 0.0233, 0.0232, 0.0216, 0.0152, 0.0128, 0.0115,\n",
      "        0.0104])\n",
      "{'accessible': tensor(0.1021)}\n",
      "max_probe is: tensor(0.1021)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is naive but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wise', 'strong', 'smart', 'not', 'cunning', 'clever', 'intelligent', 'wiser', 'brave', 'beautiful']\n",
      "tensor([0.1334, 0.0477, 0.0465, 0.0438, 0.0322, 0.0257, 0.0251, 0.0207, 0.0169,\n",
      "        0.0157])\n",
      "{'sophisticated': tensor(0.0037)}\n",
      "max_probe is: tensor(0.0037)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 37\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is affirmative but Mary is _ .\n",
      "['negative', 'silent', 'passive', 'affirmative', 'not', 'neutral', 'defensive', 'positive', 'ambiguous', 'undecided']\n",
      "tensor([0.4274, 0.1127, 0.0488, 0.0384, 0.0335, 0.0248, 0.0217, 0.0161, 0.0126,\n",
      "        0.0094])\n",
      "{'negative': tensor(0.4274)}\n",
      "max_probe is: tensor(0.4274)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is impractical but Mary is _ .\n",
      "['not', 'practical', 'beautiful', 'divine', 'perfect', 'right', 'real', 'pragmatic', 'true', 'impractical']\n",
      "tensor([0.1225, 0.0533, 0.0370, 0.0280, 0.0265, 0.0175, 0.0142, 0.0128, 0.0115,\n",
      "        0.0110])\n",
      "{'practical': tensor(0.0533)}\n",
      "max_probe is: tensor(0.0533)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is adoptive but Mary is _ .\n",
      "['not', 'adopted', 'biological', 'married', 'natural', 'maternal', 'Catholic', 'adoptive', 'pregnant', 'surrogate']\n",
      "tensor([0.5292, 0.0612, 0.0557, 0.0265, 0.0143, 0.0133, 0.0102, 0.0077, 0.0070,\n",
      "        0.0059])\n",
      "{'biological': tensor(0.0557)}\n",
      "max_probe is: tensor(0.0557)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unaffected but Mary is _ .\n",
      "['not', '', 'killed', '.', 'pregnant', 'devastated', 'affected', 'injured', 'ill', 'raped']\n",
      "tensor([0.1886, 0.1256, 0.0544, 0.0280, 0.0229, 0.0215, 0.0179, 0.0159, 0.0141,\n",
      "        0.0133])\n",
      "{'affected': tensor(0.0179)}\n",
      "max_probe is: tensor(0.0179)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unequal but Mary is _ .\n",
      "['equal', 'superior', 'better', 'perfect', 'not', 'unequal', 'right', 'greater', 'special', 'beautiful']\n",
      "tensor([0.3390, 0.0695, 0.0574, 0.0398, 0.0349, 0.0270, 0.0157, 0.0155, 0.0126,\n",
      "        0.0110])\n",
      "{'equal': tensor(0.3390)}\n",
      "max_probe is: tensor(0.3390)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is irrational but Mary is _ .\n",
      "['not', 'rational', 'sane', 'irrational', 'beautiful', 'wise', 'sensible', 'perfect', 'right', 'divine']\n",
      "tensor([0.1248, 0.1241, 0.0439, 0.0300, 0.0269, 0.0247, 0.0197, 0.0182, 0.0149,\n",
      "        0.0146])\n",
      "{'rational': tensor(0.1241)}\n",
      "max_probe is: tensor(0.1241)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is sensible but Mary is _ .\n",
      "['not', 'stupid', 'crazy', 'naive', 'beautiful', 'naÃ¯ve', 'stubborn', 'foolish', 'insane', 'passionate']\n",
      "tensor([0.0768, 0.0370, 0.0366, 0.0362, 0.0333, 0.0273, 0.0233, 0.0218, 0.0163,\n",
      "        0.0156])\n",
      "{'unreasonable': tensor(0.0028)}\n",
      "max_probe is: tensor(0.0028)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 59\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is involuntary but Mary is _ .\n",
      "['not', 'voluntary', 'involuntary', 'willing', 'conscious', 'unwilling', 'free', 'obedient', 'passive', 'voluntarily']\n",
      "tensor([0.3999, 0.2553, 0.0284, 0.0201, 0.0153, 0.0091, 0.0082, 0.0080, 0.0066,\n",
      "        0.0064])\n",
      "{'voluntary': tensor(0.2553)}\n",
      "max_probe is: tensor(0.2553)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uneasy but Mary is _ .\n",
      "['not', 'calm', 'happy', 'worried', 'relaxed', 'hopeful', 'excited', 'relieved', 'reassured', 'concerned']\n",
      "tensor([0.2076, 0.0719, 0.0617, 0.0509, 0.0302, 0.0285, 0.0262, 0.0200, 0.0155,\n",
      "        0.0144])\n",
      "{'easy': tensor(0.0001)}\n",
      "max_probe is: tensor(0.0001)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 390\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is immoral but Mary is _ .\n",
      "['virtuous', 'not', 'holy', 'moral', 'righteous', 'good', 'pure', 'immoral', 'beautiful', 'divine']\n",
      "tensor([0.1377, 0.1257, 0.0852, 0.0663, 0.0473, 0.0411, 0.0352, 0.0325, 0.0306,\n",
      "        0.0290])\n",
      "{'moral': tensor(0.0663)}\n",
      "max_probe is: tensor(0.0663)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is fractional but Mary is _ .\n",
      "['not', 'whole', 'absolute', 'exponential', 'total', 'complete', 'continuous', 'proportional', 'linear', 'full']\n",
      "tensor([0.1240, 0.0613, 0.0459, 0.0381, 0.0357, 0.0276, 0.0263, 0.0259, 0.0244,\n",
      "        0.0244])\n",
      "{'whole': tensor(0.0613)}\n",
      "max_probe is: tensor(0.0613)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is heterogeneous but Mary is _ .\n",
      "['not', 'consistent', 'universal', 'unified', 'immutable', 'uniform', '', 'singular', 'stable', 'unique']\n",
      "tensor([0.2986, 0.0542, 0.0272, 0.0207, 0.0154, 0.0140, 0.0130, 0.0124, 0.0120,\n",
      "        0.0118])\n",
      "homogeneousis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is unconditional but Mary is _ .\n",
      "['not', 'conditional', 'unconditional', 'selective', 'selfish', 'flexible', 'different', 'subjective', 'spiritual', 'conflicted']\n",
      "tensor([0.3180, 0.1042, 0.0706, 0.0058, 0.0058, 0.0054, 0.0042, 0.0040, 0.0038,\n",
      "        0.0037])\n",
      "{'conditional': tensor(0.1042)}\n",
      "max_probe is: tensor(0.1042)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unfavorable but Mary is _ .\n",
      "['favorable', 'unfavorable', 'not', 'supportive', 'neutral', 'friendly', 'undecided', 'sympathetic', 'favored', 'agreeable']\n",
      "tensor([0.5162, 0.0370, 0.0358, 0.0258, 0.0245, 0.0148, 0.0143, 0.0126, 0.0122,\n",
      "        0.0083])\n",
      "{'favorable': tensor(0.5162)}\n",
      "max_probe is: tensor(0.5162)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is atypical but Mary is _ .\n",
      "['not', 'typical', 'normal', 'unique', 'unusual', 'exceptional', 'average', '', 'rare', 'different']\n",
      "tensor([0.3936, 0.1036, 0.0445, 0.0395, 0.0323, 0.0224, 0.0146, 0.0122, 0.0097,\n",
      "        0.0093])\n",
      "{'typical': tensor(0.1036)}\n",
      "max_probe is: tensor(0.1036)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unnatural but Mary is _ .\n",
      "['not', 'divine', 'natural', 'perfect', 'God', 'unnatural', 'good', 'beautiful', 'blessed', 'heavenly']\n",
      "tensor([0.2928, 0.1784, 0.0600, 0.0495, 0.0200, 0.0198, 0.0163, 0.0159, 0.0146,\n",
      "        0.0142])\n",
      "{'natural': tensor(0.0600)}\n",
      "max_probe is: tensor(0.0600)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unreasonable but Mary is _ .\n",
      "['not', 'reasonable', 'beautiful', 'unreasonable', 'kind', 'wise', 'perfect', 'compassionate', 'right', 'patient']\n",
      "tensor([0.0803, 0.0546, 0.0402, 0.0285, 0.0279, 0.0243, 0.0191, 0.0182, 0.0181,\n",
      "        0.0163])\n",
      "{'reasonable': tensor(0.0546)}\n",
      "max_probe is: tensor(0.0546)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is displeased but Mary is _ .\n",
      "['not', 'happy', 'pleased', 'delighted', 'relieved', 'glad', 'ecstatic', 'satisfied', 'grateful', 'thrilled']\n",
      "tensor([0.2658, 0.1560, 0.1050, 0.0477, 0.0197, 0.0186, 0.0177, 0.0172, 0.0122,\n",
      "        0.0112])\n",
      "{'pleased': tensor(0.1050)}\n",
      "max_probe is: tensor(0.1050)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unrealistic but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['realistic', 'not', 'real', 'beautiful', 'unrealistic', 'sincere', 'perfect', 'practical', 'right', 'true']\n",
      "tensor([0.1635, 0.1139, 0.1119, 0.0298, 0.0191, 0.0176, 0.0171, 0.0162, 0.0145,\n",
      "        0.0143])\n",
      "{'realistic': tensor(0.1635)}\n",
      "max_probe is: tensor(0.1635)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is improbable but Mary is _ .\n",
      "['not', 'impossible', 'certain', 'unlikely', 'possible', 'sure', 'real', 'likely', 'inevitable', 'indispensable']\n",
      "tensor([0.2160, 0.0557, 0.0489, 0.0340, 0.0235, 0.0205, 0.0182, 0.0166, 0.0166,\n",
      "        0.0164])\n",
      "{'probable': tensor(0.0152)}\n",
      "max_probe is: tensor(0.0152)\n",
      "20\n",
      "the position of max probe is: 10\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is impartial but Mary is _ .\n",
      "['not', 'biased', 'conflicted', 'Catholic', 'involved', 'impartial', 'corrupt', 'religious', 'evil', 'loyal']\n",
      "tensor([0.3133, 0.1243, 0.0176, 0.0134, 0.0117, 0.0107, 0.0105, 0.0083, 0.0082,\n",
      "        0.0068])\n",
      "{'partial': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0003)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 302\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unhealthy but Mary is _ .\n",
      "['healthy', 'not', 'beautiful', 'strong', 'perfect', 'healthier', 'sick', 'happy', 'alive', 'blessed']\n",
      "tensor([0.2539, 0.0997, 0.0699, 0.0413, 0.0299, 0.0216, 0.0176, 0.0148, 0.0102,\n",
      "        0.0087])\n",
      "{'healthy': tensor(0.2539)}\n",
      "max_probe is: tensor(0.2539)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is irresponsible but Mary is _ .\n",
      "['not', 'responsible', 'reckless', 'irresponsible', 'courageous', 'beautiful', 'brave', 'wise', 'better', 'innocent']\n",
      "tensor([0.1481, 0.0556, 0.0353, 0.0328, 0.0187, 0.0163, 0.0131, 0.0129, 0.0122,\n",
      "        0.0107])\n",
      "{'responsible': tensor(0.0556)}\n",
      "max_probe is: tensor(0.0556)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unprepared but Mary is _ .\n",
      "['ready', 'prepared', 'not', '', 'strong', 'determined', 'willing', 'powerful', 'right', 'desperate']\n",
      "tensor([0.1932, 0.1397, 0.0981, 0.0220, 0.0202, 0.0200, 0.0129, 0.0124, 0.0090,\n",
      "        0.0078])\n",
      "{'prepared': tensor(0.1397)}\n",
      "max_probe is: tensor(0.1397)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is intangible but Mary is _ .\n",
      "['tangible', 'real', 'not', 'intangible', 'immortal', 'eternal', 'everywhere', 'visible', 'invisible', 'immutable']\n",
      "tensor([0.3114, 0.1741, 0.0498, 0.0296, 0.0254, 0.0172, 0.0159, 0.0154, 0.0134,\n",
      "        0.0101])\n",
      "{'tangible': tensor(0.3114)}\n",
      "max_probe is: tensor(0.3114)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is asymmetrical but Mary is _ .\n",
      "['not', 'proportional', 'spherical', 'perfect', 'linear', 'rectangular', 'normal', 'triangular', 'square', 'vertical']\n",
      "tensor([0.4225, 0.0456, 0.0259, 0.0223, 0.0169, 0.0165, 0.0159, 0.0148, 0.0126,\n",
      "        0.0099])\n",
      "symmetricalis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is undue but Mary is _ .\n",
      "['not', 'saved', 'right', 'alive', 'strong', 'more', 'good', 'happy', 'loved', 'king']\n",
      "tensor([0.1282, 0.0157, 0.0116, 0.0101, 0.0101, 0.0087, 0.0085, 0.0083, 0.0081,\n",
      "        0.0074])\n",
      "{'due': tensor(0.0001)}\n",
      "max_probe is: tensor(0.0001)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 959\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is insoluble but Mary is _ .\n",
      "['not', 'divine', 'flexible', 'immutable', 'strong', 'indispensable', 'steadfast', 'perfect', 'fragile', 'eternal']\n",
      "tensor([0.3959, 0.0199, 0.0112, 0.0111, 0.0108, 0.0102, 0.0101, 0.0087, 0.0087,\n",
      "        0.0086])\n",
      "{'soluble': tensor(0.0083)}\n",
      "max_probe is: tensor(0.0083)\n",
      "20\n",
      "the position of max probe is: 12\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is insensitive but Mary is _ .\n",
      "['not', 'kind', 'beautiful', 'compassionate', 'brave', 'courageous', 'wise', 'innocent', 'sensitive', 'naive']\n",
      "tensor([0.1000, 0.0627, 0.0402, 0.0322, 0.0209, 0.0199, 0.0161, 0.0132, 0.0117,\n",
      "        0.0116])\n",
      "{'sensitive': tensor(0.0117)}\n",
      "max_probe is: tensor(0.0117)\n",
      "the position of max probe is: 8\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unbelievable but Mary is _ .\n",
      "['not', 'unbelievable', 'amazing', 'real', 'too', 'better', 'beautiful', 'incredible', 'true', 'wonderful']\n",
      "tensor([0.0896, 0.0844, 0.0707, 0.0549, 0.0292, 0.0246, 0.0243, 0.0227, 0.0175,\n",
      "        0.0165])\n",
      "{'credible': tensor(0.0018)}\n",
      "max_probe is: tensor(0.0018)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 68\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unethical but Mary is _ .\n",
      "['not', 'ethical', 'virtuous', 'trustworthy', 'moral', 'honest', 'kind', 'beautiful', 'good', 'loyal']\n",
      "tensor([0.2241, 0.0337, 0.0284, 0.0282, 0.0260, 0.0243, 0.0224, 0.0202, 0.0175,\n",
      "        0.0147])\n",
      "{'ethical': tensor(0.0337)}\n",
      "max_probe is: tensor(0.0337)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unimportant but Mary is _ .\n",
      "['important', '', 'special', 'not', '.', 'indispensable', 'significant', '...', 'everything', '..']\n",
      "tensor([0.3486, 0.0814, 0.0315, 0.0284, 0.0279, 0.0176, 0.0129, 0.0114, 0.0107,\n",
      "        0.0089])\n",
      "{'important': tensor(0.3486)}\n",
      "max_probe is: tensor(0.3486)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is frivolous but Mary is _ .\n",
      "['faithful', 'not', 'devout', 'serious', 'devoted', 'sincere', 'beautiful', 'loyal', 'real', 'wise']\n",
      "tensor([0.0586, 0.0407, 0.0336, 0.0299, 0.0288, 0.0224, 0.0205, 0.0197, 0.0187,\n",
      "        0.0179])\n",
      "{'serious': tensor(0.0299)}\n",
      "max_probe is: tensor(0.0299)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unprofitable but Mary is _ .\n",
      "['not', 'profitable', '', 'wealthy', 'rich', '.', 'successful', 'free', 'beautiful', '..']\n",
      "tensor([0.2805, 0.1066, 0.0564, 0.0430, 0.0369, 0.0279, 0.0254, 0.0060, 0.0056,\n",
      "        0.0056])\n",
      "{'profitable': tensor(0.1066)}\n",
      "max_probe is: tensor(0.1066)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is pessimistic but Mary is _ .\n",
      "['optimistic', 'hopeful', 'not', 'positive', 'cheerful', 'upbeat', 'confident', 'enthusiastic', 'determined', 'happy']\n",
      "tensor([0.6230, 0.1861, 0.0223, 0.0190, 0.0096, 0.0085, 0.0078, 0.0058, 0.0043,\n",
      "        0.0034])\n",
      "{'optimistic': tensor(0.6230)}\n",
      "max_probe is: tensor(0.6230)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is high-pitched but Mary is _ .\n",
      "['not', 'low', 'lower', 'quiet', 'beautiful', 'sweet', 'soft', 'high', '', 'medium']\n",
      "tensor([0.2141, 0.0274, 0.0271, 0.0202, 0.0189, 0.0171, 0.0157, 0.0152, 0.0143,\n",
      "        0.0139])\n",
      "{'low': tensor(0.0274)}\n",
      "max_probe is: tensor(0.0274)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unfavourable but Mary is _ .\n",
      "['not', 'sympathetic', 'favourable', 'friendly', 'supportive', 'preferable', 'popular', 'good', 'favorable', '']\n",
      "tensor([0.1432, 0.0332, 0.0293, 0.0238, 0.0225, 0.0191, 0.0183, 0.0173, 0.0145,\n",
      "        0.0141])\n",
      "{'favorable': tensor(0.0145)}\n",
      "max_probe is: tensor(0.0145)\n",
      "the position of max probe is: 8\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unproductive but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', '', 'productive', '.', 'pregnant', 'beautiful', 'fertile', 'successful', 'brilliant', 'wonderful']\n",
      "tensor([0.1836, 0.0602, 0.0373, 0.0288, 0.0270, 0.0247, 0.0203, 0.0134, 0.0116,\n",
      "        0.0083])\n",
      "{'productive': tensor(0.0373)}\n",
      "max_probe is: tensor(0.0373)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is discontinuous but Mary is _ .\n",
      "['not', 'continuous', 'discrete', '', 'canonical', 'consistent', 'complete', 'transitional', 'explicit', 'persistent']\n",
      "tensor([0.5876, 0.1210, 0.0106, 0.0102, 0.0089, 0.0085, 0.0059, 0.0057, 0.0050,\n",
      "        0.0033])\n",
      "{'continuous': tensor(0.1210)}\n",
      "max_probe is: tensor(0.1210)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is dependable but Mary is _ .\n",
      "['not', 'unreliable', 'unpredictable', 'unstable', 'vulnerable', 'stubborn', 'loyal', 'trustworthy', 'dangerous', 'inconsistent']\n",
      "tensor([0.2462, 0.1445, 0.0743, 0.0234, 0.0107, 0.0100, 0.0099, 0.0089, 0.0088,\n",
      "        0.0083])\n",
      "{'unreliable': tensor(0.1445)}\n",
      "max_probe is: tensor(0.1445)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uninterested but Mary is _ .\n",
      "['', 'not', 'interested', '.', 'intrigued', 'concerned', 'fascinated', 'passionate', 'desperate', 'worried']\n",
      "tensor([0.1227, 0.0896, 0.0727, 0.0566, 0.0408, 0.0184, 0.0130, 0.0123, 0.0111,\n",
      "        0.0099])\n",
      "{'interested': tensor(0.0727)}\n",
      "max_probe is: tensor(0.0727)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unambiguous but Mary is _ .\n",
      "['not', 'ambiguous', 'silent', 'unclear', 'vague', 'inconsistent', 'uncertain', 'confused', 'misleading', 'contradictory']\n",
      "tensor([0.3183, 0.2963, 0.0392, 0.0303, 0.0171, 0.0114, 0.0102, 0.0082, 0.0076,\n",
      "        0.0069])\n",
      "{'ambiguous': tensor(0.2963)}\n",
      "max_probe is: tensor(0.2963)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is ineffectual but Mary is _ .\n",
      "['not', 'powerful', 'effective', 'beautiful', 'strong', 'indispensable', '', 'exemplary', 'perfect', 'divine']\n",
      "tensor([0.1236, 0.0378, 0.0351, 0.0216, 0.0167, 0.0144, 0.0134, 0.0119, 0.0118,\n",
      "        0.0101])\n",
      "{'effective': tensor(0.0351)}\n",
      "max_probe is: tensor(0.0351)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unattractive but Mary is _ .\n",
      "['beautiful', 'pretty', 'attractive', 'not', 'gorgeous', 'stunning', 'lovely', '', 'handsome', 'sexy']\n",
      "tensor([0.4686, 0.0870, 0.0742, 0.0400, 0.0192, 0.0144, 0.0134, 0.0132, 0.0088,\n",
      "        0.0085])\n",
      "{'attractive': tensor(0.0742)}\n",
      "max_probe is: tensor(0.0742)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is believable but Mary is _ .\n",
      "['not', 'unreliable', 'real', 'unbelievable', '', 'delusional', 'convincing', 'better', 'believable', 'more']\n",
      "tensor([0.6150, 0.0138, 0.0098, 0.0090, 0.0080, 0.0072, 0.0070, 0.0066, 0.0056,\n",
      "        0.0051])\n",
      "{'incredible': tensor(0.0011)}\n",
      "max_probe is: tensor(0.0011)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 64\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is asexual but Mary is _ .\n",
      "['not', 'bisexual', 'homosexual', 'heterosexual', 'gay', '', 'pregnant', 'lesbian', 'female', 'married']\n",
      "tensor([0.5307, 0.1797, 0.0552, 0.0240, 0.0211, 0.0132, 0.0123, 0.0073, 0.0068,\n",
      "        0.0067])\n",
      "{'sexual': tensor(0.0063)}\n",
      "max_probe is: tensor(0.0063)\n",
      "20\n",
      "the position of max probe is: 10\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inflexible but Mary is _ .\n",
      "['flexible', 'not', 'passionate', 'patient', 'free', 'receptive', 'tolerant', 'pragmatic', 'stubborn', 'gentle']\n",
      "tensor([0.6040, 0.0276, 0.0101, 0.0079, 0.0076, 0.0055, 0.0055, 0.0054, 0.0051,\n",
      "        0.0050])\n",
      "{'flexible': tensor(0.6040)}\n",
      "max_probe is: tensor(0.6040)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is impersonal but Mary is _ .\n",
      "['real', 'not', 'personal', 'alive', 'divine', 'human', 'spiritual', 'intimate', 'genuine', 'sincere']\n",
      "tensor([0.2774, 0.1970, 0.0486, 0.0221, 0.0206, 0.0196, 0.0101, 0.0088, 0.0076,\n",
      "        0.0067])\n",
      "{'personal': tensor(0.0486)}\n",
      "max_probe is: tensor(0.0486)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inconspicuous but Mary is _ .\n",
      "['not', '', 'conspicuous', '.', 'beautiful', 'obvious', 'known', 'visible', 'famous', 'invisible']\n",
      "tensor([0.4219, 0.0413, 0.0311, 0.0158, 0.0113, 0.0110, 0.0093, 0.0088, 0.0080,\n",
      "        0.0076])\n",
      "{'conspicuous': tensor(0.0311)}\n",
      "max_probe is: tensor(0.0311)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is incomparable but Mary is _ .\n",
      "['better', 'not', '', 'unique', 'perfect', '.', 'indispensable', 'greater', 'exceptional', 'more']\n",
      "tensor([0.0710, 0.0484, 0.0443, 0.0350, 0.0303, 0.0276, 0.0263, 0.0199, 0.0198,\n",
      "        0.0187])\n",
      "{'comparable': tensor(0.0037)}\n",
      "max_probe is: tensor(0.0037)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 44\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is implausible but Mary is _ .\n",
      "['not', 'plausible', 'real', 'believable', 'impossible', '', 'credible', 'convincing', 'true', 'unbelievable']\n",
      "tensor([0.2906, 0.0958, 0.0458, 0.0170, 0.0165, 0.0148, 0.0144, 0.0133, 0.0122,\n",
      "        0.0096])\n",
      "{'plausible': tensor(0.0958)}\n",
      "max_probe is: tensor(0.0958)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is invulnerable but Mary is _ .\n",
      "['not', 'vulnerable', 'unprotected', 'immune', '', 'protected', 'mortal', 'immortal', 'powerless', '.']\n",
      "tensor([0.4524, 0.1500, 0.0333, 0.0228, 0.0213, 0.0126, 0.0119, 0.0104, 0.0082,\n",
      "        0.0077])\n",
      "{'vulnerable': tensor(0.1500)}\n",
      "max_probe is: tensor(0.1500)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unsympathetic but Mary is _ .\n",
      "['not', 'sympathetic', '', 'supportive', 'concerned', 'hopeful', '.', 'more', 'worried', 'receptive']\n",
      "tensor([0.1592, 0.1169, 0.0426, 0.0190, 0.0155, 0.0151, 0.0151, 0.0107, 0.0100,\n",
      "        0.0088])\n",
      "{'sympathetic': tensor(0.1169)}\n",
      "max_probe is: tensor(0.1169)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is extrinsic but Mary is _ .\n",
      "['not', 'divine', 'canonical', 'intrinsic', 'canon', 'sacred', 'original', 'Jewish', 'Divine', 'auxiliary']\n",
      "tensor([0.3491, 0.1097, 0.0966, 0.0244, 0.0162, 0.0149, 0.0116, 0.0053, 0.0047,\n",
      "        0.0043])\n",
      "{'intrinsic': tensor(0.0244)}\n",
      "max_probe is: tensor(0.0244)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is undemocratic but Mary is _ .\n",
      "['not', 'democratic', 'neither', '', 'divine', 'one', 'popular', 'more', 'republican', 'authoritarian']\n",
      "tensor([0.3567, 0.0382, 0.0171, 0.0167, 0.0128, 0.0113, 0.0105, 0.0101, 0.0089,\n",
      "        0.0086])\n",
      "{'democratic': tensor(0.0382)}\n",
      "max_probe is: tensor(0.0382)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is illogical but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'logical', 'rational', 'divine', 'irrational', 'beautiful', 'right', 'pragmatic', 'brilliant', 'sensible']\n",
      "tensor([0.1584, 0.1346, 0.0434, 0.0387, 0.0288, 0.0207, 0.0155, 0.0149, 0.0141,\n",
      "        0.0134])\n",
      "{'logical': tensor(0.1346)}\n",
      "max_probe is: tensor(0.1346)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uninjured but Mary is _ .\n",
      "['', 'killed', 'injured', 'not', '.', 'wounded', 'shot', 'hurt', 'attacked', 'hospitalized']\n",
      "tensor([0.1980, 0.0877, 0.0561, 0.0510, 0.0300, 0.0256, 0.0248, 0.0229, 0.0215,\n",
      "        0.0176])\n",
      "{'injured': tensor(0.0561)}\n",
      "max_probe is: tensor(0.0561)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inedible but Mary is _ .\n",
      "['not', 'delicious', '', 'edible', 'tasty', 'vegetarian', '.', 'divine', 'beautiful', 'alive']\n",
      "tensor([0.3335, 0.1142, 0.0456, 0.0448, 0.0313, 0.0297, 0.0258, 0.0152, 0.0129,\n",
      "        0.0123])\n",
      "{'edible': tensor(0.0448)}\n",
      "max_probe is: tensor(0.0448)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inelastic but Mary is _ .\n",
      "['flexible', 'not', 'steadfast', 'rigid', 'firm', 'elastic', 'resilient', 'solid', 'strong', 'stable']\n",
      "tensor([0.2027, 0.1436, 0.0432, 0.0289, 0.0194, 0.0185, 0.0161, 0.0160, 0.0151,\n",
      "        0.0084])\n",
      "{'elastic': tensor(0.0185)}\n",
      "max_probe is: tensor(0.0185)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uncharacteristic but Mary is _ .\n",
      "['not', 'exemplary', 'typical', 'unique', 'exceptional', '', 'consistent', 'unusual', 'perfect', 'predictable']\n",
      "tensor([0.3271, 0.0490, 0.0446, 0.0309, 0.0305, 0.0224, 0.0217, 0.0168, 0.0132,\n",
      "        0.0123])\n",
      "{'characteristic': tensor(0.0018)}\n",
      "max_probe is: tensor(0.0018)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 51\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is theoretic but Mary is _ .\n",
      "['practical', 'pragmatic', 'intuitive', 'empirical', 'not', 'spiritual', 'philosophical', 'metaphysical', 'political', 'religious']\n",
      "tensor([0.2554, 0.1011, 0.0324, 0.0307, 0.0305, 0.0237, 0.0216, 0.0190, 0.0137,\n",
      "        0.0133])\n",
      "{'empirical': tensor(0.0307)}\n",
      "max_probe is: tensor(0.0307)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unscientific but Mary is _ .\n",
      "['not', 'scientific', '', 'devout', 'educated', 'religious', 'right', 'intelligent', '.', 'brilliant']\n",
      "tensor([0.2873, 0.0311, 0.0268, 0.0164, 0.0161, 0.0160, 0.0146, 0.0135, 0.0102,\n",
      "        0.0098])\n",
      "{'scientific': tensor(0.0311)}\n",
      "max_probe is: tensor(0.0311)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unimpressive but Mary is _ .\n",
      "['', 'not', '.', 'beautiful', '..', 'pretty', '...', 'stunning', 'Ģ¦', 'better']\n",
      "tensor([0.1049, 0.0536, 0.0344, 0.0291, 0.0246, 0.0170, 0.0149, 0.0140, 0.0108,\n",
      "        0.0108])\n",
      "{'impressive': tensor(0.0081)}\n",
      "max_probe is: tensor(0.0081)\n",
      "20\n",
      "the position of max probe is: 16\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unplayable but Mary is _ .\n",
      "['not', '', 'vulnerable', 'indispensable', 'unstoppable', 'underrated', 'dangerous', 'unpredictable', 'irresistible', 'better']\n",
      "tensor([0.1357, 0.0378, 0.0296, 0.0214, 0.0171, 0.0166, 0.0142, 0.0138, 0.0134,\n",
      "        0.0126])\n",
      "{'playable': tensor(0.0045)}\n",
      "max_probe is: tensor(0.0045)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 30\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unprofessional but Mary is _ .\n",
      "['not', 'professional', 'better', '', 'beautiful', 'more', 'good', 'competent', '..', 'perfect']\n",
      "tensor([0.2097, 0.0495, 0.0349, 0.0197, 0.0163, 0.0109, 0.0104, 0.0101, 0.0086,\n",
      "        0.0081])\n",
      "{'professional': tensor(0.0495)}\n",
      "max_probe is: tensor(0.0495)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unconcerned but Mary is _ .\n",
      "['worried', '', 'not', 'concerned', '.', 'terrified', 'upset', 'frightened', 'horrified', 'shocked']\n",
      "tensor([0.1742, 0.1571, 0.0867, 0.0425, 0.0425, 0.0214, 0.0175, 0.0175, 0.0168,\n",
      "        0.0155])\n",
      "{'concerned': tensor(0.0425)}\n",
      "max_probe is: tensor(0.0425)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nontraditional but Mary is _ .\n",
      "['not', 'traditional', 'conventional', 'orthodox', 'unconventional', '', 'neither', 'unique', 'divine', 'devout']\n",
      "tensor([0.4892, 0.1043, 0.0401, 0.0212, 0.0121, 0.0114, 0.0068, 0.0062, 0.0062,\n",
      "        0.0061])\n",
      "{'traditional': tensor(0.1043)}\n",
      "max_probe is: tensor(0.1043)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unsanitary but Mary is _ .\n",
      "['not', 'clean', '', 'beautiful', '.', 'cleaner', 'better', 'perfect', 'sterile', '..']\n",
      "tensor([0.2909, 0.0751, 0.0323, 0.0310, 0.0283, 0.0267, 0.0187, 0.0130, 0.0126,\n",
      "        0.0089])\n",
      "sanitaryis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is dishonorable but Mary is _ .\n",
      "['virtuous', 'not', 'honorable', 'beautiful', 'holy', 'righteous', 'innocent', 'perfect', 'pure', 'good']\n",
      "tensor([0.0867, 0.0804, 0.0698, 0.0571, 0.0300, 0.0265, 0.0211, 0.0200, 0.0174,\n",
      "        0.0164])\n",
      "{'honorable': tensor(0.0698)}\n",
      "max_probe is: tensor(0.0698)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inoperative but Mary is _ .\n",
      "['not', 'alive', '', 'pregnant', 'ready', 'healed', '.', 'fine', 'healthy', 'available']\n",
      "tensor([0.1569, 0.1111, 0.0497, 0.0307, 0.0178, 0.0148, 0.0141, 0.0122, 0.0116,\n",
      "        0.0112])\n",
      "{'operative': tensor(0.0007)}\n",
      "max_probe is: tensor(0.0007)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 163\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uncritical but Mary is _ .\n",
      "['not', 'devout', 'sympathetic', '', 'more', 'passionate', 'conflicted', 'sincere', 'enthusiastic', 'complicit']\n",
      "tensor([0.2284, 0.0253, 0.0161, 0.0157, 0.0124, 0.0106, 0.0090, 0.0071, 0.0070,\n",
      "        0.0067])\n",
      "{'critical': tensor(0.0037)}\n",
      "max_probe is: tensor(0.0037)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 37\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unfashionable but Mary is _ .\n",
      "['beautiful', 'not', 'fashionable', 'elegant', 'stylish', 'pretty', '', 'stunning', 'popular', '.']\n",
      "tensor([0.1768, 0.1089, 0.0721, 0.0344, 0.0261, 0.0239, 0.0226, 0.0189, 0.0178,\n",
      "        0.0174])\n",
      "{'fashionable': tensor(0.0721)}\n",
      "max_probe is: tensor(0.0721)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is noncommercial but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'commercial', '', 'religious', 'Catholic', 'Christian', '.', 'evangelical', 'advertising', 'a']\n",
      "tensor([0.3535, 0.1938, 0.0638, 0.0276, 0.0261, 0.0145, 0.0128, 0.0084, 0.0080,\n",
      "        0.0058])\n",
      "{'commercial': tensor(0.1938)}\n",
      "max_probe is: tensor(0.1938)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unsteady but Mary is _ .\n",
      "['not', 'strong', 'determined', 'ready', 'confident', 'stronger', 'steadfast', 'calm', 'steady', 'firm']\n",
      "tensor([0.1627, 0.0935, 0.0363, 0.0301, 0.0256, 0.0254, 0.0204, 0.0196, 0.0179,\n",
      "        0.0101])\n",
      "{'steady': tensor(0.0179)}\n",
      "max_probe is: tensor(0.0179)\n",
      "the position of max probe is: 8\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is invariable but Mary is _ .\n",
      "['not', 'variable', 'immutable', 'unstable', 'unpredictable', 'inconsistent', 'reversible', '', 'dynamic', 'transient']\n",
      "tensor([0.6854, 0.0552, 0.0383, 0.0244, 0.0183, 0.0067, 0.0051, 0.0045, 0.0039,\n",
      "        0.0033])\n",
      "{'variable': tensor(0.0552)}\n",
      "max_probe is: tensor(0.0552)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unneeded but Mary is _ .\n",
      "['needed', 'indispensable', 'not', 'important', 'necessary', '', 'essential', 'required', 'wanted', 'loved']\n",
      "tensor([0.3972, 0.0779, 0.0472, 0.0296, 0.0293, 0.0244, 0.0127, 0.0122, 0.0121,\n",
      "        0.0097])\n",
      "{'necessary': tensor(0.0293)}\n",
      "max_probe is: tensor(0.0293)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inaudible but Mary is _ .\n",
      "['not', '', 'heard', 'clear', '.', 'audible', '', '', 'understood', 'screaming']\n",
      "tensor([0.3002, 0.1400, 0.0449, 0.0416, 0.0323, 0.0257, 0.0097, 0.0096, 0.0088,\n",
      "        0.0081])\n",
      "{'audible': tensor(0.0257)}\n",
      "max_probe is: tensor(0.0257)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uncontroversial but Mary is _ .\n",
      "['controversial', 'not', '', 'divisive', 'disputed', 'debated', '.', 'contentious', '..', 'different']\n",
      "tensor([0.6554, 0.0728, 0.0433, 0.0267, 0.0149, 0.0111, 0.0063, 0.0062, 0.0049,\n",
      "        0.0045])\n",
      "{'controversial': tensor(0.6554)}\n",
      "max_probe is: tensor(0.6554)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unquestionable but Mary is _ .\n",
      "['not', 'questionable', 'controversial', 'doubtful', 'unreliable', 'suspect', 'uncertain', 'different', '', 'disputed']\n",
      "tensor([0.3756, 0.0320, 0.0286, 0.0263, 0.0145, 0.0140, 0.0134, 0.0091, 0.0089,\n",
      "        0.0070])\n",
      "{'questionable': tensor(0.0320)}\n",
      "max_probe is: tensor(0.0320)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is avoidable but Mary is _ .\n",
      "['not', '', 'unavoidable', 'impossible', 'inevitable', 'doomed', 'dangerous', 'problematic', '...', 'vulnerable']\n",
      "tensor([0.5097, 0.0358, 0.0267, 0.0157, 0.0138, 0.0112, 0.0100, 0.0087, 0.0082,\n",
      "        0.0070])\n",
      "{'inevitable': tensor(0.0138)}\n",
      "max_probe is: tensor(0.0138)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unenthusiastic but Mary is _ .\n",
      "['enthusiastic', 'not', '', 'excited', '.', 'delighted', 'hopeful', 'passionate', 'convinced', 'supportive']\n",
      "tensor([0.1651, 0.0920, 0.0470, 0.0377, 0.0313, 0.0226, 0.0224, 0.0220, 0.0187,\n",
      "        0.0174])\n",
      "{'enthusiastic': tensor(0.1651)}\n",
      "max_probe is: tensor(0.1651)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unwary but Mary is _ .\n",
      "['ready', 'not', 'wise', 'prepared', 'afraid', '', 'alert', 'worried', 'warned', 'awake']\n",
      "tensor([0.0687, 0.0636, 0.0467, 0.0348, 0.0277, 0.0247, 0.0229, 0.0206, 0.0182,\n",
      "        0.0166])\n",
      "{'wary': tensor(0.0143)}\n",
      "max_probe is: tensor(0.0143)\n",
      "20\n",
      "the position of max probe is: 10\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unready but Mary is _ .\n",
      "['ready', 'prepared', 'not', '', 'willing', 'waiting', 'pregnant', '.', 'perfect', 'patient']\n",
      "tensor([0.4764, 0.0720, 0.0690, 0.0365, 0.0214, 0.0138, 0.0117, 0.0108, 0.0087,\n",
      "        0.0060])\n",
      "{'ready': tensor(0.4764)}\n",
      "max_probe is: tensor(0.4764)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unapologetic but Mary is _ .\n",
      "['not', 'ashamed', '', 'forgiving', 'afraid', 'cautious', 'grateful', 'conflicted', 'humble', '.']\n",
      "tensor([0.1508, 0.0289, 0.0189, 0.0152, 0.0151, 0.0114, 0.0114, 0.0112, 0.0104,\n",
      "        0.0095])\n",
      "apologeticis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is impious but Mary is _ .\n",
      "['not', 'devout', 'beautiful', 'virtuous', 'pious', 'kind', 'patient', 'perfect', 'faithful', 'innocent']\n",
      "tensor([0.1358, 0.0307, 0.0292, 0.0285, 0.0213, 0.0208, 0.0193, 0.0166, 0.0142,\n",
      "        0.0139])\n",
      "{'pious': tensor(0.0213)}\n",
      "max_probe is: tensor(0.0213)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unfree but Mary is _ .\n",
      "['free', 'not', 'Free', 'freed', '', 'liberated', 'FREE', 'willing', 'happy', 'innocent']\n",
      "tensor([0.7472, 0.0452, 0.0146, 0.0048, 0.0041, 0.0037, 0.0036, 0.0029, 0.0028,\n",
      "        0.0027])\n",
      "{'free': tensor(0.7472)}\n",
      "max_probe is: tensor(0.7472)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unarmored but Mary is _ .\n",
      "['armed', 'not', 'armored', '', 'clothed', 'protected', '.', 'unarmed', 'prepared', 'pregnant']\n",
      "tensor([0.1640, 0.1175, 0.0801, 0.0591, 0.0495, 0.0407, 0.0363, 0.0333, 0.0201,\n",
      "        0.0091])\n",
      "{'armored': tensor(0.0801)}\n",
      "max_probe is: tensor(0.0801)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is effectual but Mary is _ .\n",
      "['not', 'ineffective', 'effective', 'weak', 'passive', 'useless', 'beautiful', 'evil', 'unreliable', 'deceptive']\n",
      "tensor([0.2612, 0.0180, 0.0133, 0.0124, 0.0099, 0.0087, 0.0083, 0.0070, 0.0068,\n",
      "        0.0065])\n",
      "{'ineffective': tensor(0.0180)}\n",
      "max_probe is: tensor(0.0180)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unpatriotic but Mary is _ .\n",
      "['not', 'patriotic', '', 'loyal', 'neither', 'devout', 'patriot', 'one', 'so', '.']\n",
      "tensor([0.3314, 0.1141, 0.0237, 0.0213, 0.0198, 0.0116, 0.0103, 0.0098, 0.0084,\n",
      "        0.0082])\n",
      "{'patriotic': tensor(0.1141)}\n",
      "max_probe is: tensor(0.1141)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unidentifiable but Mary is _ .\n",
      "['', 'not', 'known', '.', 'identified', 'identifiable', 'named', '', 'unknown', 'clear']\n",
      "tensor([0.2630, 0.1381, 0.0840, 0.0459, 0.0230, 0.0198, 0.0160, 0.0143, 0.0129,\n",
      "        0.0080])\n",
      "{'identifiable': tensor(0.0198)}\n",
      "max_probe is: tensor(0.0198)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inoffensive but Mary is _ .\n",
      "['not', 'beautiful', 'controversial', 'fascinating', 'terrifying', '', 'sexy', 'dangerous', 'interesting', '..']\n",
      "tensor([0.1319, 0.0237, 0.0166, 0.0164, 0.0148, 0.0132, 0.0106, 0.0093, 0.0092,\n",
      "        0.0091])\n",
      "{'offensive': tensor(0.0019)}\n",
      "max_probe is: tensor(0.0019)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 93\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unarmoured but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['armed', 'armoured', 'not', 'unarmed', '', 'clothed', 'prepared', '.', 'protected', 'armored']\n",
      "tensor([0.2706, 0.1430, 0.0929, 0.0571, 0.0337, 0.0253, 0.0242, 0.0241, 0.0146,\n",
      "        0.0130])\n",
      "{'armored': tensor(0.0130)}\n",
      "max_probe is: tensor(0.0130)\n",
      "the position of max probe is: 9\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is low-pitched but Mary is _ .\n",
      "['high', 'higher', 'not', 'medium', '.', 'lower', 'fast', 'better', '', 'faster']\n",
      "tensor([0.1138, 0.0964, 0.0437, 0.0313, 0.0226, 0.0217, 0.0198, 0.0167, 0.0111,\n",
      "        0.0101])\n",
      "{'high': tensor(0.1138)}\n",
      "max_probe is: tensor(0.1138)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is noninvasive but Mary is _ .\n",
      "['invasive', 'not', 'surgical', 'sterile', '', 'vaginal', 'intrusive', 'active', 'operative', 'aggressive']\n",
      "tensor([0.5761, 0.1206, 0.0262, 0.0177, 0.0175, 0.0127, 0.0127, 0.0072, 0.0035,\n",
      "        0.0031])\n",
      "{'invasive': tensor(0.5761)}\n",
      "max_probe is: tensor(0.5761)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonfunctional but Mary is _ .\n",
      "['not', 'alive', 'functional', '', 'perfect', 'pregnant', 'dead', 'good', 'strong', 'active']\n",
      "tensor([0.2018, 0.0699, 0.0520, 0.0316, 0.0281, 0.0217, 0.0136, 0.0091, 0.0089,\n",
      "        0.0082])\n",
      "{'functional': tensor(0.0520)}\n",
      "max_probe is: tensor(0.0520)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is ungrammatical but Mary is _ .\n",
      "['not', 'beautiful', 'perfect', '', '.', 'both', 'neither', 'correct', 'grammar', 'biblical']\n",
      "tensor([0.5889, 0.0297, 0.0199, 0.0150, 0.0125, 0.0066, 0.0065, 0.0064, 0.0060,\n",
      "        0.0058])\n",
      "grammaticalis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is ignoble but Mary is _ .\n",
      "['beautiful', 'not', 'divine', 'radiant', 'virtuous', 'holy', 'exemplary', 'perfect', 'magnificent', 'courageous']\n",
      "tensor([0.0874, 0.0792, 0.0592, 0.0273, 0.0257, 0.0245, 0.0217, 0.0177, 0.0112,\n",
      "        0.0109])\n",
      "{'noble': tensor(0.0085)}\n",
      "max_probe is: tensor(0.0085)\n",
      "20\n",
      "the position of max probe is: 17\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unemotional but Mary is _ .\n",
      "['not', 'emotional', '', '.', 'passionate', 'crying', 'vulnerable', 'sensitive', 'sentimental', 'beautiful']\n",
      "tensor([0.1468, 0.1046, 0.0849, 0.0380, 0.0230, 0.0167, 0.0147, 0.0137, 0.0133,\n",
      "        0.0116])\n",
      "{'emotional': tensor(0.1046)}\n",
      "max_probe is: tensor(0.1046)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonnative but Mary is _ .\n",
      "['native', 'not', 'American', 'English', 'white', 'Native', 'British', '', 'Canadian', 'Australian']\n",
      "tensor([0.3754, 0.2195, 0.0782, 0.0269, 0.0263, 0.0165, 0.0129, 0.0127, 0.0091,\n",
      "        0.0086])\n",
      "{'native': tensor(0.3754)}\n",
      "max_probe is: tensor(0.3754)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unimpaired but Mary is _ .\n",
      "['', 'blind', 'not', 'impaired', 'disabled', 'ill', '.', 'pregnant', 'deaf', 'paralyzed']\n",
      "tensor([0.2352, 0.0573, 0.0565, 0.0358, 0.0341, 0.0340, 0.0329, 0.0263, 0.0171,\n",
      "        0.0130])\n",
      "{'impaired': tensor(0.0358)}\n",
      "max_probe is: tensor(0.0358)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is dishonourable but Mary is _ .\n",
      "['not', 'virtuous', 'beautiful', 'honorable', 'righteous', 'innocent', 'holy', 'exemplary', 'noble', 'perfect']\n",
      "tensor([0.1094, 0.0741, 0.0459, 0.0416, 0.0319, 0.0308, 0.0260, 0.0209, 0.0184,\n",
      "        0.0171])\n",
      "{'honorable': tensor(0.0416)}\n",
      "max_probe is: tensor(0.0416)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inconsiderable but Mary is _ .\n",
      "['not', 'kind', 'beautiful', '', 'patient', 'devoted', 'compassionate', 'thoughtful', 'lovely', 'wonderful']\n",
      "tensor([0.1127, 0.0436, 0.0328, 0.0154, 0.0121, 0.0107, 0.0097, 0.0095, 0.0094,\n",
      "        0.0092])\n",
      "{'considerable': tensor(7.5719e-06)}\n",
      "max_probe is: tensor(7.5719e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "the position of max probe is: 3165\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is ahistorical but Mary is _ .\n",
      "['not', 'historical', 'real', '', 'Biblical', 'biblical', 'Jewish', 'divine', 'historic', 'factual']\n",
      "tensor([0.6184, 0.0659, 0.0177, 0.0117, 0.0111, 0.0094, 0.0091, 0.0089, 0.0070,\n",
      "        0.0066])\n",
      "{'historical': tensor(0.0659)}\n",
      "max_probe is: tensor(0.0659)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unquiet but Mary is _ .\n",
      "['not', 'quiet', 'worried', '', 'concerned', 'silent', 'asleep', 'terrified', 'afraid', 'praying']\n",
      "tensor([0.0980, 0.0603, 0.0596, 0.0229, 0.0189, 0.0178, 0.0162, 0.0135, 0.0132,\n",
      "        0.0124])\n",
      "{'quiet': tensor(0.0603)}\n",
      "max_probe is: tensor(0.0603)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is untraditional but Mary is _ .\n",
      "['not', 'traditional', 'conventional', 'orthodox', 'unconventional', '', 'divine', 'devout', 'unusual', 'religious']\n",
      "tensor([0.4250, 0.0858, 0.0354, 0.0237, 0.0227, 0.0171, 0.0124, 0.0116, 0.0067,\n",
      "        0.0065])\n",
      "{'traditional': tensor(0.0858)}\n",
      "max_probe is: tensor(0.0858)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is untroubled but Mary is _ .\n",
      "['', 'troubled', 'not', 'worried', '.', 'afraid', 'terrified', 'distraught', 'frightened', 'concerned']\n",
      "tensor([0.1178, 0.1075, 0.0868, 0.0648, 0.0415, 0.0336, 0.0250, 0.0184, 0.0175,\n",
      "        0.0134])\n",
      "{'troubled': tensor(0.1075)}\n",
      "max_probe is: tensor(0.1075)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unrighteous but Mary is _ .\n",
      "['righteous', 'holy', 'not', 'just', 'virtuous', 'good', 'pure', 'pious', 'faithful', 'devout']\n",
      "tensor([0.7956, 0.0387, 0.0171, 0.0134, 0.0128, 0.0100, 0.0094, 0.0056, 0.0044,\n",
      "        0.0043])\n",
      "{'righteous': tensor(0.7956)}\n",
      "max_probe is: tensor(0.7956)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is noncompetitive but Mary is _ .\n",
      "['competitive', 'not', '', '.', '..', 'ambitious', 'ruthless', 'Ģ¦', 'jealous', 'passionate']\n",
      "tensor([0.4064, 0.1018, 0.0789, 0.0339, 0.0120, 0.0110, 0.0083, 0.0080, 0.0079,\n",
      "        0.0075])\n",
      "{'competitive': tensor(0.4064)}\n",
      "max_probe is: tensor(0.4064)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unsystematic but Mary is _ .\n",
      "['not', 'systematic', '', '.', 'exemplary', 'pragmatic', '...', 'so', 'perfect', 'systemic']\n",
      "tensor([0.2470, 0.1076, 0.0553, 0.0159, 0.0146, 0.0138, 0.0103, 0.0103, 0.0096,\n",
      "        0.0077])\n",
      "{'systematic': tensor(0.1076)}\n",
      "max_probe is: tensor(0.1076)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is insensible but Mary is _ .\n",
      "['not', 'strong', 'powerful', '', 'vulnerable', 'alive', 'courageous', 'free', 'innocent', 'fearless']\n",
      "tensor([0.1428, 0.0436, 0.0171, 0.0169, 0.0143, 0.0121, 0.0115, 0.0106, 0.0099,\n",
      "        0.0095])\n",
      "{'sensible': tensor(0.0010)}\n",
      "max_probe is: tensor(0.0010)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 149\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonpolitical but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['political', 'not', 'Catholic', '', 'politically', 'religious', 'Presbyterian', 'devout', 'liberal', 'Jewish']\n",
      "tensor([0.2523, 0.2157, 0.0574, 0.0401, 0.0243, 0.0222, 0.0128, 0.0124, 0.0114,\n",
      "        0.0098])\n",
      "{'political': tensor(0.2523)}\n",
      "max_probe is: tensor(0.2523)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unambitious but Mary is _ .\n",
      "['ambitious', 'not', '.', '', 'determined', 'passionate', '..', 'driven', 'more', 'beautiful']\n",
      "tensor([0.1238, 0.1056, 0.0608, 0.0577, 0.0337, 0.0335, 0.0116, 0.0105, 0.0105,\n",
      "        0.0099])\n",
      "{'ambitious': tensor(0.1238)}\n",
      "max_probe is: tensor(0.1238)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unlikeable but Mary is _ .\n",
      "['not', 'beautiful', 'perfect', 'irresistible', 'lovely', 'wonderful', 'sympathetic', 'admirable', 'misunderstood', 'better']\n",
      "tensor([0.0748, 0.0410, 0.0302, 0.0278, 0.0166, 0.0156, 0.0151, 0.0146, 0.0132,\n",
      "        0.0123])\n",
      "{'sympathetic': tensor(0.0151)}\n",
      "max_probe is: tensor(0.0151)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is self-generated but Mary is _ .\n",
      "['not', '', 'born', 'artificial', 'programmed', 'human', 'real', 'divine', 'created', 'organic']\n",
      "tensor([0.7225, 0.0169, 0.0130, 0.0129, 0.0123, 0.0120, 0.0070, 0.0039, 0.0038,\n",
      "        0.0035])\n",
      "{'induced': tensor(7.9596e-05)}\n",
      "max_probe is: tensor(7.9596e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 417\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is indissoluble but Mary is _ .\n",
      "['not', 'divine', 'fragile', 'unstable', 'weak', '', 'indispensable', 'vulnerable', 'eternal', 'mortal']\n",
      "tensor([0.5464, 0.0152, 0.0095, 0.0089, 0.0084, 0.0072, 0.0071, 0.0066, 0.0050,\n",
      "        0.0044])\n",
      "{'soluble': tensor(0.0004)}\n",
      "max_probe is: tensor(0.0004)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 200\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonmilitary but Mary is _ .\n",
      "['not', 'military', '', 'Catholic', 'religious', 'a', 'married', 'one', 'pregnant', '.']\n",
      "tensor([0.1985, 0.1675, 0.0813, 0.0461, 0.0281, 0.0268, 0.0268, 0.0204, 0.0190,\n",
      "        0.0190])\n",
      "{'military': tensor(0.1675)}\n",
      "max_probe is: tensor(0.1675)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonprofessional but Mary is _ .\n",
      "['professional', 'not', '', 'one', 'competent', 'Ģ¦', '..', '.', 'good', 'a']\n",
      "tensor([0.3352, 0.1432, 0.0357, 0.0159, 0.0125, 0.0083, 0.0072, 0.0069, 0.0066,\n",
      "        0.0066])\n",
      "{'professional': tensor(0.3352)}\n",
      "max_probe is: tensor(0.3352)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is resistible but Mary is _ .\n",
      "['not', 'irresistible', 'unstoppable', 'resistant', 'indispensable', 'stronger', 'vulnerable', 'divine', 'strong', '']\n",
      "tensor([0.4196, 0.0476, 0.0197, 0.0163, 0.0152, 0.0148, 0.0121, 0.0110, 0.0109,\n",
      "        0.0085])\n",
      "{'irresistible': tensor(0.0476)}\n",
      "max_probe is: tensor(0.0476)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonsurgical but Mary is _ .\n",
      "['not', '', 'Catholic', 'surgical', 'sterile', 'religious', 'pregnant', 'baptized', '.', 'a']\n",
      "tensor([0.2713, 0.0962, 0.0886, 0.0746, 0.0177, 0.0154, 0.0153, 0.0125, 0.0116,\n",
      "        0.0105])\n",
      "{'surgical': tensor(0.0746)}\n",
      "max_probe is: tensor(0.0746)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonrenewable but Mary is _ .\n",
      "['', 'not', 'immortal', 'renewable', 'eternal', 'reusable', '.', '', 'forever', '!']\n",
      "tensor([0.2449, 0.1250, 0.0736, 0.0620, 0.0493, 0.0442, 0.0344, 0.0230, 0.0169,\n",
      "        0.0126])\n",
      "{'renewable': tensor(0.0620)}\n",
      "max_probe is: tensor(0.0620)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unspecialized but Mary is _ .\n",
      "['', 'not', '.', 'special', 'exceptional', 'trained', 'skilled', '...', '..', 'gifted']\n",
      "tensor([0.1963, 0.1185, 0.0884, 0.0768, 0.0248, 0.0126, 0.0111, 0.0109, 0.0088,\n",
      "        0.0082])\n",
      "{'specialized': tensor(0.0064)}\n",
      "max_probe is: tensor(0.0064)\n",
      "20\n",
      "the position of max probe is: 13\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unlikable but Mary is _ .\n",
      "['not', 'misunderstood', 'beautiful', '', 'sympathetic', 'lovely', 'perfect', 'charismatic', 'wonderful', 'irresistible']\n",
      "tensor([0.0932, 0.0424, 0.0336, 0.0208, 0.0207, 0.0180, 0.0171, 0.0166, 0.0134,\n",
      "        0.0133])\n",
      "{'sympathetic': tensor(0.0207)}\n",
      "max_probe is: tensor(0.0207)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nontechnical but Mary is _ .\n",
      "['technical', 'not', 'Technical', '', '..', 'brilliant', 'technically', '.', 'pragmatic', 'both']\n",
      "tensor([0.2365, 0.1782, 0.0323, 0.0290, 0.0110, 0.0108, 0.0101, 0.0100, 0.0090,\n",
      "        0.0089])\n",
      "{'technical': tensor(0.2365)}\n",
      "max_probe is: tensor(0.2365)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonclassical but Mary is _ .\n",
      "['classical', 'not', '', 'Classical', '.', '...', 'canonical', 'Catholic', 'Roman', 'Orthodox']\n",
      "tensor([0.2630, 0.2384, 0.0578, 0.0393, 0.0229, 0.0212, 0.0198, 0.0196, 0.0141,\n",
      "        0.0106])\n",
      "{'classical': tensor(0.2630)}\n",
      "max_probe is: tensor(0.2630)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is insanitary but Mary is _ .\n",
      "['not', 'beautiful', 'clean', 'divine', '', 'perfect', 'virtuous', 'better', 'holy', 'exemplary']\n",
      "tensor([0.2058, 0.0744, 0.0295, 0.0193, 0.0176, 0.0150, 0.0131, 0.0128, 0.0128,\n",
      "        0.0107])\n",
      "sanitaryis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is incautious but Mary is _ .\n",
      "['not', 'hopeful', 'optimistic', 'trusting', 'cautious', 'confident', 'worried', 'enthusiastic', 'ready', 'determined']\n",
      "tensor([0.3111, 0.0343, 0.0321, 0.0194, 0.0156, 0.0150, 0.0138, 0.0117, 0.0104,\n",
      "        0.0102])\n",
      "{'cautious': tensor(0.0156)}\n",
      "max_probe is: tensor(0.0156)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uncharitable but Mary is _ .\n",
      "['not', 'kind', '', '.', 'sympathetic', 'generous', 'beautiful', 'good', 'devout', 'compassionate']\n",
      "tensor([0.2201, 0.0863, 0.0452, 0.0164, 0.0144, 0.0124, 0.0123, 0.0112, 0.0092,\n",
      "        0.0090])\n",
      "{'charitable': tensor(0.0037)}\n",
      "max_probe is: tensor(0.0037)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 37\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is untypical but Mary is _ .\n",
      "['not', 'unusual', 'unique', 'typical', 'exceptional', '', 'different', 'rare', 'special', 'extraordinary']\n",
      "tensor([0.1885, 0.1270, 0.1067, 0.0772, 0.0404, 0.0304, 0.0211, 0.0177, 0.0139,\n",
      "        0.0111])\n",
      "{'typical': tensor(0.0772)}\n",
      "max_probe is: tensor(0.0772)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonmagnetic but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['magnetic', 'not', 'magnet', '', '.', 'Magnet', 'electromagnetic', 'Magnetic', 'metallic', 'one']\n",
      "tensor([0.8068, 0.0448, 0.0337, 0.0208, 0.0071, 0.0050, 0.0046, 0.0045, 0.0044,\n",
      "        0.0020])\n",
      "{'magnetic': tensor(0.8068)}\n",
      "max_probe is: tensor(0.8068)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonalcoholic but Mary is _ .\n",
      "['not', '', 'alcoholic', '.', 'Catholic', 'drinking', 'a', 'drunk', 'baptized', 'sober']\n",
      "tensor([0.4784, 0.1265, 0.0925, 0.0724, 0.0168, 0.0094, 0.0090, 0.0073, 0.0067,\n",
      "        0.0058])\n",
      "{'alcoholic': tensor(0.0925)}\n",
      "max_probe is: tensor(0.0925)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unsurprised but Mary is _ .\n",
      "['shocked', 'not', '', 'stunned', '.', 'horrified', 'surprised', 'disappointed', 'devastated', 'appalled']\n",
      "tensor([0.1288, 0.1212, 0.1143, 0.0656, 0.0654, 0.0334, 0.0260, 0.0229, 0.0210,\n",
      "        0.0191])\n",
      "{'surprised': tensor(0.0260)}\n",
      "max_probe is: tensor(0.0260)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unaccessible but Mary is _ .\n",
      "['not', 'accessible', '', 'available', 'inaccessible', '.', 'vulnerable', 'free', 'safe', 'alive']\n",
      "tensor([0.2424, 0.2072, 0.0646, 0.0398, 0.0193, 0.0193, 0.0123, 0.0098, 0.0089,\n",
      "        0.0086])\n",
      "{'accessible': tensor(0.2072)}\n",
      "max_probe is: tensor(0.2072)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is undependable but Mary is _ .\n",
      "['not', 'trustworthy', '', 'reliable', 'loyal', 'indispensable', 'unreliable', 'faithful', 'unpredictable', '.']\n",
      "tensor([0.1542, 0.0677, 0.0626, 0.0549, 0.0447, 0.0329, 0.0200, 0.0154, 0.0119,\n",
      "        0.0118])\n",
      "{'reliable': tensor(0.0549)}\n",
      "max_probe is: tensor(0.0549)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unmusical but Mary is _ .\n",
      "['musical', 'beautiful', 'not', '', '.', 'talented', 'singing', 'both', 'passionate', 'good']\n",
      "tensor([0.1059, 0.0948, 0.0775, 0.0633, 0.0431, 0.0253, 0.0181, 0.0179, 0.0142,\n",
      "        0.0104])\n",
      "{'musical': tensor(0.1059)}\n",
      "max_probe is: tensor(0.1059)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is undramatic but Mary is _ .\n",
      "['dramatic', 'not', '', 'tragic', 'passionate', '.', 'extraordinary', 'beautiful', 'charismatic', 'spectacular']\n",
      "tensor([0.1349, 0.0775, 0.0576, 0.0318, 0.0238, 0.0215, 0.0199, 0.0194, 0.0126,\n",
      "        0.0105])\n",
      "{'dramatic': tensor(0.1349)}\n",
      "max_probe is: tensor(0.1349)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonfictional but Mary is _ .\n",
      "['fictional', '', 'not', 'real', 'fiction', 'fictitious', '.', 'imaginary', 'true', 'factual']\n",
      "tensor([0.4688, 0.1357, 0.0721, 0.0708, 0.0288, 0.0198, 0.0145, 0.0100, 0.0070,\n",
      "        0.0061])\n",
      "{'fictional': tensor(0.4688)}\n",
      "max_probe is: tensor(0.4688)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is ungenerous but Mary is _ .\n",
      "['generous', 'not', 'kind', 'gracious', '', 'thoughtful', 'compassionate', 'patient', 'grateful', 'giving']\n",
      "tensor([0.2110, 0.0999, 0.0892, 0.0433, 0.0204, 0.0147, 0.0126, 0.0121, 0.0113,\n",
      "        0.0100])\n",
      "{'generous': tensor(0.2110)}\n",
      "max_probe is: tensor(0.2110)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is undiplomatic but Mary is _ .\n",
      "['not', 'diplomatic', '', 'persuasive', 'polite', '.', 'pragmatic', 'charming', 'cautious', 'discreet']\n",
      "tensor([0.1185, 0.0769, 0.0331, 0.0269, 0.0124, 0.0121, 0.0104, 0.0101, 0.0088,\n",
      "        0.0085])\n",
      "{'diplomatic': tensor(0.0769)}\n",
      "max_probe is: tensor(0.0769)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonresidential but Mary is _ .\n",
      "['not', 'resident', '', 'residential', 'a', 'local', 'married', 'home', '.', 'white']\n",
      "tensor([0.2638, 0.1193, 0.1020, 0.0722, 0.0262, 0.0125, 0.0115, 0.0106, 0.0101,\n",
      "        0.0075])\n",
      "{'residential': tensor(0.0722)}\n",
      "max_probe is: tensor(0.0722)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unkept but Mary is _ .\n",
      "['not', 'clean', '', 'beautiful', 'kept', 'protected', 'cherished', 'loved', 'blessed', 'pretty']\n",
      "tensor([0.1207, 0.0386, 0.0366, 0.0339, 0.0336, 0.0281, 0.0245, 0.0241, 0.0202,\n",
      "        0.0135])\n",
      "unbrokenis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is uncreative but Mary is _ .\n",
      "['creative', 'not', '', 'beautiful', 'brilliant', 'passionate', 'artistic', 'inspired', 'imaginative', '.']\n",
      "tensor([0.2665, 0.0965, 0.0346, 0.0252, 0.0209, 0.0181, 0.0150, 0.0126, 0.0124,\n",
      "        0.0116])\n",
      "{'creative': tensor(0.2665)}\n",
      "max_probe is: tensor(0.2665)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonproprietary but Mary is _ .\n",
      "['proprietary', 'not', 'private', '', 'patented', 'copyrighted', '.', 'free', 'a', 'so']\n",
      "tensor([0.2058, 0.1774, 0.1035, 0.0857, 0.0233, 0.0165, 0.0143, 0.0094, 0.0074,\n",
      "        0.0064])\n",
      "{'proprietary': tensor(0.2058)}\n",
      "max_probe is: tensor(0.2058)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonsexual but Mary is _ .\n",
      "['not', 'sexual', '', 'bisexual', 'homosexual', 'sexually', '.', 'heterosexual', 'lesbian', 'pregnant']\n",
      "tensor([0.1701, 0.1145, 0.1018, 0.1014, 0.0469, 0.0447, 0.0395, 0.0227, 0.0173,\n",
      "        0.0159])\n",
      "{'sexual': tensor(0.1145)}\n",
      "max_probe is: tensor(0.1145)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unadventurous but Mary is _ .\n",
      "['not', '.', 'adventurous', '', 'passionate', 'courageous', 'fearless', 'bold', 'brave', 'enthusiastic']\n",
      "tensor([0.1170, 0.1007, 0.0886, 0.0619, 0.0306, 0.0302, 0.0238, 0.0200, 0.0116,\n",
      "        0.0107])\n",
      "{'adventurous': tensor(0.0886)}\n",
      "max_probe is: tensor(0.0886)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is ill-formed but Mary is _ .\n",
      "['beautiful', 'not', 'perfect', 'strong', 'pretty', 'blessed', 'divine', 'radiant', '', 'lovely']\n",
      "tensor([0.1961, 0.1701, 0.0751, 0.0254, 0.0169, 0.0157, 0.0139, 0.0135, 0.0114,\n",
      "        0.0103])\n",
      "grammaticalis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is noninfectious but Mary is _ .\n",
      "['infected', '', 'infectious', 'immune', 'contagious', 'not', '.', 'susceptible', 'sterile', 'contaminated']\n",
      "tensor([0.2127, 0.1818, 0.0963, 0.0634, 0.0576, 0.0404, 0.0339, 0.0251, 0.0195,\n",
      "        0.0119])\n",
      "{'infectious': tensor(0.0963)}\n",
      "max_probe is: tensor(0.0963)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unaggressive but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aggressive', 'not', '', '.', 'violent', 'âĢ¦', 'angry', 'forceful', 'Ģ¦', 'passionate']\n",
      "tensor([0.1592, 0.1305, 0.0654, 0.0206, 0.0134, 0.0106, 0.0089, 0.0087, 0.0085,\n",
      "        0.0082])\n",
      "{'aggressive': tensor(0.1592)}\n",
      "max_probe is: tensor(0.1592)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is noncontroversial but Mary is _ .\n",
      "['controversial', '', 'not', 'divisive', 'popular', 'debated', '.', 'disputed', '..', 'contentious']\n",
      "tensor([0.6790, 0.0622, 0.0311, 0.0122, 0.0092, 0.0090, 0.0086, 0.0080, 0.0059,\n",
      "        0.0047])\n",
      "{'controversial': tensor(0.6790)}\n",
      "max_probe is: tensor(0.6790)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unsocial but Mary is _ .\n",
      "['not', 'lonely', 'social', '', 'friendly', 'shy', 'beautiful', '.', 'kind', '..']\n",
      "tensor([0.2265, 0.0469, 0.0468, 0.0423, 0.0320, 0.0145, 0.0113, 0.0110, 0.0099,\n",
      "        0.0082])\n",
      "{'social': tensor(0.0468)}\n",
      "max_probe is: tensor(0.0468)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unhealthful but Mary is _ .\n",
      "['not', 'pregnant', 'healthy', 'happy', 'ill', 'alive', '', 'fine', 'strong', 'sick']\n",
      "tensor([0.2179, 0.1459, 0.0667, 0.0478, 0.0233, 0.0215, 0.0186, 0.0161, 0.0155,\n",
      "        0.0130])\n",
      "sanitaryis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is unseeable but Mary is _ .\n",
      "['not', '', 'visible', 'seen', 'invisible', '.', 'real', 'beautiful', 'transparent', 'known']\n",
      "tensor([0.3461, 0.0650, 0.0610, 0.0367, 0.0282, 0.0232, 0.0135, 0.0109, 0.0083,\n",
      "        0.0064])\n",
      "{'visible': tensor(0.0610)}\n",
      "max_probe is: tensor(0.0610)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is synthetical but Mary is _ .\n",
      "['not', 'literal', 'plural', 'imperative', 'nominal', 'existential', 'personal', 'semantic', 'verbal', 'relational']\n",
      "tensor([0.4882, 0.0181, 0.0178, 0.0175, 0.0172, 0.0098, 0.0095, 0.0091, 0.0082,\n",
      "        0.0079])\n",
      "{'analytic': tensor(0.0039)}\n",
      "max_probe is: tensor(0.0039)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 22\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unobvious but Mary is _ .\n",
      "['not', '', 'transparent', 'invisible', 'obvious', 'visible', 'hidden', 'subtle', 'deceptive', 'vulnerable']\n",
      "tensor([0.2838, 0.0414, 0.0399, 0.0379, 0.0360, 0.0220, 0.0160, 0.0122, 0.0093,\n",
      "        0.0092])\n",
      "{'obvious': tensor(0.0360)}\n",
      "max_probe is: tensor(0.0360)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inconvertible but Mary is _ .\n",
      "['not', '', '.', 'convertible', 'immortal', 'pregnant', '!', '', '', 'divine']\n",
      "tensor([0.4552, 0.1374, 0.0496, 0.0122, 0.0085, 0.0075, 0.0048, 0.0042, 0.0042,\n",
      "        0.0041])\n",
      "{'convertible': tensor(0.0122)}\n",
      "max_probe is: tensor(0.0122)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unaesthetic but Mary is _ .\n",
      "['beautiful', 'not', 'elegant', 'graceful', 'radiant', 'exquisite', '', 'perfect', 'pretty', 'artistic']\n",
      "tensor([0.1617, 0.1602, 0.0373, 0.0326, 0.0242, 0.0216, 0.0161, 0.0123, 0.0117,\n",
      "        0.0115])\n",
      "{'aesthetic': tensor(0.0007)}\n",
      "max_probe is: tensor(0.0007)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 137\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonmusical but Mary is _ .\n",
      "['musical', '', 'not', '.', 'singing', 'beautiful', 'one', 'religious', 'Jewish', 'both']\n",
      "tensor([0.3357, 0.1051, 0.0799, 0.0616, 0.0185, 0.0165, 0.0163, 0.0122, 0.0114,\n",
      "        0.0108])\n",
      "{'musical': tensor(0.3357)}\n",
      "max_probe is: tensor(0.3357)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonfinancial but Mary is _ .\n",
      "['financial', 'not', '', 'financially', 'religious', 'wealthy', 'Jewish', 'so', 'spiritual', '.']\n",
      "tensor([0.3130, 0.1605, 0.0659, 0.0481, 0.0261, 0.0193, 0.0126, 0.0115, 0.0101,\n",
      "        0.0084])\n",
      "{'financial': tensor(0.3130)}\n",
      "max_probe is: tensor(0.3130)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unspecialised but Mary is _ .\n",
      "['not', '', '.', 'special', 'exceptional', 'extraordinary', 'trained', '...', 'skilled', 'brilliant']\n",
      "tensor([0.1683, 0.1191, 0.0833, 0.0783, 0.0308, 0.0152, 0.0102, 0.0093, 0.0091,\n",
      "        0.0088])\n",
      "{'specialized': tensor(0.0015)}\n",
      "max_probe is: tensor(0.0015)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 67\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is impalpable but Mary is _ .\n",
      "['not', '', '.', 'vulnerable', 'weak', 'beautiful', 'free', 'strong', '...', 'perfect']\n",
      "tensor([0.3266, 0.0453, 0.0292, 0.0191, 0.0116, 0.0107, 0.0087, 0.0083, 0.0078,\n",
      "        0.0074])\n",
      "{'tangible': tensor(1.0867e-05)}\n",
      "max_probe is: tensor(1.0867e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "the position of max probe is: 2879\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uncomparable but Mary is _ .\n",
      "['not', 'exceptional', 'exemplary', 'superior', 'perfect', '', 'indispensable', 'better', 'unique', 'beautiful']\n",
      "tensor([0.0739, 0.0435, 0.0350, 0.0348, 0.0326, 0.0279, 0.0271, 0.0267, 0.0255,\n",
      "        0.0189])\n",
      "{'comparable': tensor(0.0082)}\n",
      "max_probe is: tensor(0.0082)\n",
      "20\n",
      "the position of max probe is: 15\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonaggressive but Mary is _ .\n",
      "['aggressive', 'not', '', 'violent', '.', 'forceful', 'predatory', 'manipulative', 'âĢ¦', 'angry']\n",
      "tensor([0.5687, 0.0798, 0.0292, 0.0229, 0.0084, 0.0066, 0.0065, 0.0053, 0.0044,\n",
      "        0.0044])\n",
      "{'aggressive': tensor(0.5687)}\n",
      "max_probe is: tensor(0.5687)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is heterogenous but Mary is _ .\n",
      "['not', 'universal', 'consistent', 'unified', 'unique', 'stable', 'immutable', 'binary', 'static', 'singular']\n",
      "tensor([0.3309, 0.0298, 0.0218, 0.0172, 0.0154, 0.0123, 0.0090, 0.0087, 0.0080,\n",
      "        0.0075])\n",
      "homogeneousis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is nonindustrial but Mary is _ .\n",
      "['not', 'industrial', '', '.', 'one', 'a', 'Industrial', 'both', 'religious', 'Catholic']\n",
      "tensor([0.2597, 0.1158, 0.0589, 0.0309, 0.0173, 0.0170, 0.0118, 0.0096, 0.0077,\n",
      "        0.0075])\n",
      "{'industrial': tensor(0.1158)}\n",
      "max_probe is: tensor(0.1158)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonoperational but Mary is _ .\n",
      "['not', 'operational', '', '.', 'functional', 'alive', 'available', 'active', 'safe', 'operative']\n",
      "tensor([0.3035, 0.1572, 0.0966, 0.0236, 0.0160, 0.0145, 0.0119, 0.0064, 0.0063,\n",
      "        0.0060])\n",
      "{'operational': tensor(0.1572)}\n",
      "max_probe is: tensor(0.1572)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unmilitary but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'military', '', 'one', '.', 'devout', 'a', 'Muslim', 'religious', 'trained']\n",
      "tensor([0.1339, 0.0693, 0.0441, 0.0226, 0.0145, 0.0130, 0.0116, 0.0090, 0.0087,\n",
      "        0.0087])\n",
      "{'military': tensor(0.0693)}\n",
      "max_probe is: tensor(0.0693)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uncomplete but Mary is _ .\n",
      "['complete', '', 'incomplete', 'not', '.', 'full', 'missing', 'pregnant', 'included', 'completed']\n",
      "tensor([0.2301, 0.0786, 0.0644, 0.0635, 0.0217, 0.0195, 0.0174, 0.0172, 0.0147,\n",
      "        0.0130])\n",
      "{'complete': tensor(0.2301)}\n",
      "max_probe is: tensor(0.2301)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonspherical but Mary is _ .\n",
      "['', 'not', 'Jewish', '.', 'Orthodox', 'devout', 'Catholic', 'religious', 'a', 'one']\n",
      "tensor([0.1976, 0.1191, 0.0831, 0.0431, 0.0307, 0.0288, 0.0240, 0.0221, 0.0191,\n",
      "        0.0190])\n",
      "{'spherical': tensor(4.0723e-06)}\n",
      "max_probe is: tensor(4.0723e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "the position of max probe is: 3229\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uninfluential but Mary is _ .\n",
      "['', 'influential', 'powerful', 'not', '.', 'important', '..', 'popular', 'famous', '...']\n",
      "tensor([0.1277, 0.0950, 0.0755, 0.0673, 0.0661, 0.0208, 0.0128, 0.0124, 0.0120,\n",
      "        0.0100])\n",
      "{'influential': tensor(0.0950)}\n",
      "max_probe is: tensor(0.0950)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is antonymous but Mary is _ .\n",
      "['not', '', 't', '.', ',', 'also', 'distinct', 'the', 'unrelated', 'neither']\n",
      "tensor([0.8757, 0.0055, 0.0051, 0.0036, 0.0033, 0.0030, 0.0026, 0.0020, 0.0019,\n",
      "        0.0015])\n",
      "{'synonymous': tensor(0.0012)}\n",
      "max_probe is: tensor(0.0012)\n",
      "20\n",
      "the position of max probe is: 15\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is onymous but Mary is _ .\n",
      "['not', 'pregnant', 'divine', 'virgin', 'Mary', 'blessed', 'innocent', 'Jewish', '', 't']\n",
      "tensor([0.5059, 0.0595, 0.0087, 0.0080, 0.0075, 0.0072, 0.0060, 0.0059, 0.0054,\n",
      "        0.0047])\n",
      "{'anonymous': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0002)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 348\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is evitable but Mary is _ .\n",
      "['not', 'loyal', 'kind', 'honest', 'virtuous', 'devoted', '', 'beautiful', 'faithful', 'persistent']\n",
      "tensor([0.2351, 0.0168, 0.0153, 0.0121, 0.0117, 0.0103, 0.0091, 0.0084, 0.0081,\n",
      "        0.0080])\n",
      "{'inevitable': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0002)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 520\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonlinguistic but Mary is _ .\n",
      "['bilingual', 'fluent', 'not', '', 'English', '.', 'Jewish', 'Catholic', 'educated', 'German']\n",
      "tensor([0.2889, 0.2090, 0.1788, 0.0301, 0.0280, 0.0260, 0.0160, 0.0152, 0.0118,\n",
      "        0.0063])\n",
      "{'linguistic': tensor(0.0006)}\n",
      "max_probe is: tensor(0.0006)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 72\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unvoluntary but Mary is _ .\n",
      "['voluntary', 'not', 'voluntarily', 'involuntary', '', 'free', 'willing', 'nonviolent', 'conscientious', 'complicit']\n",
      "tensor([0.6902, 0.1367, 0.0210, 0.0135, 0.0068, 0.0065, 0.0047, 0.0037, 0.0031,\n",
      "        0.0029])\n",
      "{'voluntary': tensor(0.6902)}\n",
      "max_probe is: tensor(0.6902)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonreciprocal but Mary is _ .\n",
      "['reciprocal', '', 'not', '.', 'receptive', '', 'responsive', '', 'pregnant', 'bisexual']\n",
      "tensor([0.2587, 0.1359, 0.1108, 0.0155, 0.0134, 0.0076, 0.0062, 0.0060, 0.0059,\n",
      "        0.0058])\n",
      "{'reciprocal': tensor(0.2587)}\n",
      "max_probe is: tensor(0.2587)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonracial but Mary is _ .\n",
      "['white', 'not', '', 'Jewish', 'black', 'pregnant', 'mixed', 'Catholic', 'Caucasian', '.']\n",
      "tensor([0.2692, 0.1303, 0.1073, 0.0520, 0.0347, 0.0243, 0.0142, 0.0120, 0.0117,\n",
      "        0.0093])\n",
      "{'racial': tensor(0.0058)}\n",
      "max_probe is: tensor(0.0058)\n",
      "20\n",
      "the position of max probe is: 18\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is antimagnetic but Mary is _ .\n",
      "['magnetic', 'not', 'electromagnetic', 'metallic', 'electric', 'radioactive', 'magnet', 'nuclear', 'electron', '']\n",
      "tensor([0.4187, 0.2303, 0.1033, 0.0147, 0.0103, 0.0099, 0.0093, 0.0075, 0.0074,\n",
      "        0.0071])\n",
      "{'magnetic': tensor(0.4187)}\n",
      "max_probe is: tensor(0.4187)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonexplosive but Mary is _ .\n",
      "['not', '', 'active', '.', 'radiant', 'alive', 'immortal', 'radioactive', 'translucent', 'transparent']\n",
      "tensor([0.4578, 0.0482, 0.0459, 0.0142, 0.0095, 0.0084, 0.0076, 0.0073, 0.0071,\n",
      "        0.0069])\n",
      "{'explosive': tensor(0.0058)}\n",
      "max_probe is: tensor(0.0058)\n",
      "20\n",
      "the position of max probe is: 11\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unrespectable but Mary is _ .\n",
      "['beautiful', 'not', 'respected', '', 'admirable', 'respectable', 'better', 'perfect', '.', 'lovely']\n",
      "tensor([0.1442, 0.1207, 0.0321, 0.0274, 0.0189, 0.0185, 0.0178, 0.0120, 0.0118,\n",
      "        0.0110])\n",
      "{'respectable': tensor(0.0185)}\n",
      "max_probe is: tensor(0.0185)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is noninstitutional but Mary is _ .\n",
      "['institutional', 'not', '', 'Catholic', 'religious', '.', 'Presbyterian', 'one', 'institution', 'so']\n",
      "tensor([0.5900, 0.0897, 0.0320, 0.0288, 0.0162, 0.0083, 0.0065, 0.0065, 0.0061,\n",
      "        0.0049])\n",
      "{'institutional': tensor(0.5900)}\n",
      "max_probe is: tensor(0.5900)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uneatable but Mary is _ .\n",
      "['not', 'delicious', '', 'edible', '.', 'vegetarian', 'tasty', 'alive', 'irresistible', 'beautiful']\n",
      "tensor([0.1977, 0.1054, 0.0602, 0.0574, 0.0457, 0.0270, 0.0234, 0.0157, 0.0118,\n",
      "        0.0112])\n",
      "{'edible': tensor(0.0574)}\n",
      "max_probe is: tensor(0.0574)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is insusceptible but Mary is _ .\n",
      "['not', 'immune', 'vulnerable', 'susceptible', '', '.', 'resistant', 'weak', 'receptive', 'sensitive']\n",
      "tensor([0.3487, 0.0647, 0.0565, 0.0491, 0.0406, 0.0272, 0.0166, 0.0146, 0.0129,\n",
      "        0.0093])\n",
      "{'susceptible': tensor(0.0491)}\n",
      "max_probe is: tensor(0.0491)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unportable but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', '', 'portable', 'immortal', '.', 'safe', 'pregnant', 'mobile', 'alive', 'accessible']\n",
      "tensor([0.4129, 0.1075, 0.0325, 0.0271, 0.0238, 0.0101, 0.0072, 0.0070, 0.0066,\n",
      "        0.0062])\n",
      "{'portable': tensor(0.0325)}\n",
      "max_probe is: tensor(0.0325)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is noncontinuous but Mary is _ .\n",
      "['not', 'continuous', '', '.', 'consistent', 'so', '', '', 'always', 'eternal']\n",
      "tensor([0.3157, 0.1889, 0.1504, 0.0333, 0.0160, 0.0114, 0.0073, 0.0062, 0.0053,\n",
      "        0.0045])\n",
      "{'continuous': tensor(0.1889)}\n",
      "max_probe is: tensor(0.1889)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is undiversified but Mary is _ .\n",
      "['not', '', '.', 'rich', 'beautiful', 'blessed', 'devout', 'fertile', 'Jewish', 'divine']\n",
      "tensor([0.0951, 0.0835, 0.0562, 0.0202, 0.0185, 0.0177, 0.0169, 0.0162, 0.0162,\n",
      "        0.0116])\n",
      "diversifiedis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is undynamic but Mary is _ .\n",
      "['dynamic', 'alive', '', 'not', 'pregnant', 'active', 'restless', 'changing', 'lively', 'moving']\n",
      "tensor([0.0512, 0.0452, 0.0278, 0.0252, 0.0234, 0.0198, 0.0177, 0.0111, 0.0110,\n",
      "        0.0101])\n",
      "{'dynamic': tensor(0.0512)}\n",
      "max_probe is: tensor(0.0512)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is incurious but Mary is _ .\n",
      "['not', 'worried', 'concerned', 'curious', '', 'afraid', 'intrigued', 'suspicious', 'skeptical', 'interested']\n",
      "tensor([0.0745, 0.0596, 0.0447, 0.0375, 0.0278, 0.0190, 0.0177, 0.0162, 0.0149,\n",
      "        0.0140])\n",
      "{'curious': tensor(0.0375)}\n",
      "max_probe is: tensor(0.0375)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonhierarchical but Mary is _ .\n",
      "['hierarchical', 'not', '', '.', 'patriarchal', 'Orthodox', 'so', 'one', 'Catholic', 'authoritarian']\n",
      "tensor([0.2317, 0.1001, 0.0893, 0.0396, 0.0320, 0.0228, 0.0164, 0.0158, 0.0147,\n",
      "        0.0128])\n",
      "{'hierarchical': tensor(0.2317)}\n",
      "max_probe is: tensor(0.2317)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unmalicious but Mary is _ .\n",
      "['not', '', 'evil', '.', 'wicked', 'manipulative', 'dangerous', '..', 'Ģ¦', 'suspicious']\n",
      "tensor([0.1915, 0.1407, 0.0997, 0.0394, 0.0256, 0.0144, 0.0119, 0.0098, 0.0082,\n",
      "        0.0081])\n",
      "{'malicious': tensor(0.0070)}\n",
      "max_probe is: tensor(0.0070)\n",
      "20\n",
      "the position of max probe is: 12\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is concentrical but Mary is _ .\n",
      "['not', 'circular', 'spherical', 'rectangular', 'cubic', 'square', 'triangular', 'oval', 'round', 'angular']\n",
      "tensor([0.1903, 0.1217, 0.0899, 0.0752, 0.0713, 0.0698, 0.0595, 0.0464, 0.0286,\n",
      "        0.0257])\n",
      "{'eccentric': tensor(0.0006)}\n",
      "max_probe is: tensor(0.0006)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 53\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is noncritical but Mary is _ .\n",
      "['critical', 'not', '', 'skeptical', '.', 'concerned', 'more', 'angry', 'harsh', 'too']\n",
      "tensor([0.4116, 0.1161, 0.0331, 0.0216, 0.0185, 0.0075, 0.0071, 0.0066, 0.0062,\n",
      "        0.0053])\n",
      "{'critical': tensor(0.4116)}\n",
      "max_probe is: tensor(0.4116)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonspatial but Mary is _ .\n",
      "['', 'not', 'pregnant', 'sterile', '.', 'Catholic', 'a', 'Jewish', 'circumcised', '']\n",
      "tensor([0.1904, 0.0978, 0.0910, 0.0804, 0.0208, 0.0169, 0.0106, 0.0072, 0.0072,\n",
      "        0.0067])\n",
      "{'spatial': tensor(2.4464e-06)}\n",
      "max_probe is: tensor(2.4464e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "10240\n",
      "the position of max probe is: 5940\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unconvertible but Mary is _ .\n",
      "['', 'not', '.', 'convertible', 'pregnant', '!', '', 'immortal', 'Catholic', '']\n",
      "tensor([0.2588, 0.2063, 0.0736, 0.0240, 0.0129, 0.0096, 0.0080, 0.0077, 0.0065,\n",
      "        0.0064])\n",
      "{'convertible': tensor(0.0240)}\n",
      "max_probe is: tensor(0.0240)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonvoluntary but Mary is _ .\n",
      "['voluntary', 'not', 'voluntarily', 'involuntary', '', 'free', 'mandatory', 'nonviolent', 'willing', 'compelled']\n",
      "tensor([0.7512, 0.0815, 0.0260, 0.0237, 0.0074, 0.0049, 0.0036, 0.0030, 0.0025,\n",
      "        0.0025])\n",
      "{'voluntary': tensor(0.7512)}\n",
      "max_probe is: tensor(0.7512)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unhearable but Mary is _ .\n",
      "['not', 'deaf', '', 'heard', '.', 'mute', 'hearing', 'listening', 'silent', 'invisible']\n",
      "tensor([0.2232, 0.0841, 0.0731, 0.0532, 0.0424, 0.0309, 0.0152, 0.0152, 0.0102,\n",
      "        0.0087])\n",
      "{'audible': tensor(0.0078)}\n",
      "max_probe is: tensor(0.0078)\n",
      "20\n",
      "the position of max probe is: 11\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unsusceptible but Mary is _ .\n",
      "['not', '', '.', 'vulnerable', 'aware', 'invisible', '...', 'exposed', 'âĢ¦', '..']\n",
      "tensor([0.2356, 0.1295, 0.0659, 0.0151, 0.0108, 0.0097, 0.0093, 0.0064, 0.0059,\n",
      "        0.0057])\n",
      "{'susceptible': tensor(0.0040)}\n",
      "max_probe is: tensor(0.0040)\n",
      "20\n",
      "the position of max probe is: 16\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unpresidential but Mary is _ .\n",
      "['not', 'presidential', 'president', '', 'elected', 'President', 'resident', 'pregnant', '.', 'a']\n",
      "tensor([0.3071, 0.0553, 0.0535, 0.0453, 0.0333, 0.0112, 0.0110, 0.0079, 0.0073,\n",
      "        0.0054])\n",
      "{'presidential': tensor(0.0553)}\n",
      "max_probe is: tensor(0.0553)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is uneffective but Mary is _ .\n",
      "['effective', 'not', '', 'powerful', '.', 'strong', 'indispensable', 'perfect', 'beautiful', 'wonderful']\n",
      "tensor([0.1018, 0.0918, 0.0581, 0.0365, 0.0162, 0.0143, 0.0121, 0.0101, 0.0099,\n",
      "        0.0092])\n",
      "{'effective': tensor(0.1018)}\n",
      "max_probe is: tensor(0.1018)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is inaesthetic but Mary is _ .\n",
      "['not', '', '.', 'beautiful', 'alive', 'pregnant', 'happy', 't', 'healthy', '..']\n",
      "tensor([0.4570, 0.0415, 0.0217, 0.0152, 0.0128, 0.0097, 0.0064, 0.0042, 0.0042,\n",
      "        0.0036])\n",
      "{'aesthetic': tensor(4.6713e-05)}\n",
      "max_probe is: tensor(4.6713e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "the position of max probe is: 1300\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unrenewable but Mary is _ .\n",
      "['not', '', 'immortal', 'eternal', '.', 'forever', 'timeless', 'divine', 'Eternal', 'fertile']\n",
      "tensor([0.2327, 0.1666, 0.1493, 0.0834, 0.0344, 0.0174, 0.0119, 0.0102, 0.0096,\n",
      "        0.0090])\n",
      "{'renewable': tensor(0.0054)}\n",
      "max_probe is: tensor(0.0054)\n",
      "20\n",
      "the position of max probe is: 16\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonmechanical but Mary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mechanical', 'not', '', '.', 'one', 'a', 'both', 'so', 'Mechanical', 'practical']\n",
      "tensor([0.3557, 0.1654, 0.0518, 0.0246, 0.0201, 0.0113, 0.0094, 0.0092, 0.0088,\n",
      "        0.0078])\n",
      "{'mechanical': tensor(0.3557)}\n",
      "max_probe is: tensor(0.3557)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is undomestic but Mary is _ .\n",
      "['not', 'beautiful', '', 'passionate', 'devoted', '.', 'devout', 'radiant', 'divine', 'so']\n",
      "tensor([0.1343, 0.0568, 0.0362, 0.0262, 0.0212, 0.0212, 0.0211, 0.0174, 0.0107,\n",
      "        0.0083])\n",
      "{'domestic': tensor(0.0038)}\n",
      "max_probe is: tensor(0.0038)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 37\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is untechnical but Mary is _ .\n",
      "['not', 'brilliant', 'beautiful', '', 'clever', '.', 'intelligent', 'smart', 'perfect', 'divine']\n",
      "tensor([0.1367, 0.0606, 0.0439, 0.0370, 0.0307, 0.0295, 0.0199, 0.0139, 0.0133,\n",
      "        0.0130])\n",
      "{'technical': tensor(0.0007)}\n",
      "max_probe is: tensor(0.0007)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 176\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unthematic but Mary is _ .\n",
      "['not', '', '.', 'beautiful', 'pregnant', 'perfect', 'so', 'born', 'a', '...']\n",
      "tensor([0.1590, 0.1224, 0.0513, 0.0313, 0.0172, 0.0125, 0.0088, 0.0086, 0.0071,\n",
      "        0.0068])\n",
      "thematicis not in list\n",
      "{}\n",
      "==========================================================\n",
      "John is unhumorous but Mary is _ .\n",
      "['not', '', '.', 'married', 'fertile', 'bisexual', 'pregnant', 'devout', 'Catholic', 'receptive']\n",
      "tensor([0.3801, 0.0445, 0.0386, 0.0289, 0.0239, 0.0218, 0.0216, 0.0186, 0.0178,\n",
      "        0.0178])\n",
      "{'humorous': tensor(1.3159e-05)}\n",
      "max_probe is: tensor(1.3159e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "the position of max probe is: 1971\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is nonmodern but Mary is _ .\n",
      "['modern', 'not', 'Modern', '', '!', 'ancient', 'contemporary', 'medieval', '.', 'Christian']\n",
      "tensor([0.4311, 0.1296, 0.0257, 0.0237, 0.0202, 0.0181, 0.0167, 0.0140, 0.0103,\n",
      "        0.0076])\n",
      "{'modern': tensor(0.4311)}\n",
      "max_probe is: tensor(0.4311)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is noncellular but Mary is _ .\n",
      "['not', 'cellular', '', 'cell', 'nuclear', 'bacterial', 'so', 'spherical', 'circular', '']\n",
      "tensor([0.3923, 0.1642, 0.0570, 0.0213, 0.0156, 0.0117, 0.0111, 0.0080, 0.0080,\n",
      "        0.0077])\n",
      "{'cellular': tensor(0.1642)}\n",
      "max_probe is: tensor(0.1642)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is untheatrical but Mary is _ .\n",
      "['not', '', '.', 'pregnant', 'hot', 'fiery', 'radiant', 'beautiful', 'warm', 'alive']\n",
      "tensor([0.2211, 0.0776, 0.0397, 0.0256, 0.0136, 0.0117, 0.0097, 0.0094, 0.0080,\n",
      "        0.0078])\n",
      "{'theatrical': tensor(2.4338e-05)}\n",
      "max_probe is: tensor(2.4338e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "the position of max probe is: 2358\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is avertable but Mary is _ .\n",
      "['not', 'doomed', '', 'vulnerable', 'dead', 'impossible', 'lost', 'dangerous', 'unavoidable', '...']\n",
      "tensor([0.5503, 0.0671, 0.0176, 0.0109, 0.0096, 0.0082, 0.0061, 0.0056, 0.0051,\n",
      "        0.0048])\n",
      "{'inevitable': tensor(0.0038)}\n",
      "max_probe is: tensor(0.0038)\n",
      "20\n",
      "the position of max probe is: 11\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is adynamic but Mary is _ .\n",
      "['not', 'silent', 'lonely', 'quiet', 'pregnant', 'devout', 'virtuous', 'depressed', 'beautiful', 'innocent']\n",
      "tensor([0.2368, 0.0226, 0.0088, 0.0084, 0.0078, 0.0076, 0.0069, 0.0061, 0.0056,\n",
      "        0.0054])\n",
      "{'dynamic': tensor(6.1738e-05)}\n",
      "max_probe is: tensor(6.1738e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "the position of max probe is: 1396\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is unlogical but Mary is _ .\n",
      "['logical', 'not', 'divine', '', 'perfect', 'rational', 'right', 'correct', 'beautiful', 'pragmatic']\n",
      "tensor([0.3844, 0.2505, 0.0134, 0.0102, 0.0097, 0.0092, 0.0071, 0.0065, 0.0057,\n",
      "        0.0053])\n",
      "{'logical': tensor(0.3844)}\n",
      "max_probe is: tensor(0.3844)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "John is seeable but Mary is _ .\n",
      "['invisible', 'not', 'unseen', 'hidden', 'elusive', 'visible', 'unknown', '', 'seen', 'blind']\n",
      "tensor([0.3779, 0.3588, 0.0715, 0.0322, 0.0076, 0.0066, 0.0056, 0.0038, 0.0038,\n",
      "        0.0035])\n",
      "{'invisible': tensor(0.3779)}\n",
      "max_probe is: tensor(0.3779)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "    count  position\n",
      "5     110         0\n",
      "1      83         1\n",
      "8      34         2\n",
      "2      30         3\n",
      "21     17         4\n",
      "..    ...       ...\n",
      "60      1      2879\n",
      "53      1      3165\n",
      "61      1      3229\n",
      "68      1      5940\n",
      "0       1     12846\n",
      "\n",
      "[74 rows x 2 columns]\n",
      "==========================================================\n",
      "The antonym of antibiotic is _ .\n",
      "['antibiotic', 'and', ',', 'or', 'also', 'in', 'the', ':', 'antibiotics', '']\n",
      "tensor([0.1225, 0.1042, 0.0408, 0.0391, 0.0315, 0.0255, 0.0176, 0.0151, 0.0140,\n",
      "        0.0129])\n",
      "{'infection': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0002)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 484\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of good is _ .\n",
      "['evil', 'bad', 'good', 'great', 'excellent', 'and', 'right', 'moral', 'perfect', 'luck']\n",
      "tensor([0.3879, 0.2307, 0.0317, 0.0249, 0.0238, 0.0081, 0.0077, 0.0067, 0.0060,\n",
      "        0.0051])\n",
      "{'bad': tensor(0.2307)}\n",
      "max_probe is: tensor(0.2307)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of happy is _ .\n",
      "['sad', 'cheerful', 'joyful', 'happy', 'optimistic', 'positive', 'excited', 'ecstatic', 'melancholy', 'depressed']\n",
      "tensor([0.1534, 0.0727, 0.0490, 0.0362, 0.0345, 0.0343, 0.0341, 0.0249, 0.0156,\n",
      "        0.0123])\n",
      "{'unhappy': tensor(0.0026)}\n",
      "max_probe is: tensor(0.0026)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 49\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nice is _ .\n",
      "['nice', 'good', 'polite', 'pleasant', 'helpful', 'friendly', 'generous', 'kind', 'cool', 'convenient']\n",
      "tensor([0.1205, 0.0625, 0.0589, 0.0472, 0.0247, 0.0217, 0.0201, 0.0171, 0.0117,\n",
      "        0.0099])\n",
      "{'nasty': tensor(0.0008)}\n",
      "max_probe is: tensor(0.0008)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 158\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of able is _ .\n",
      "[',', 'also', 'and', 'called', '.', 'the', '', ':', 'or', 'pronounced']\n",
      "tensor([0.0857, 0.0749, 0.0437, 0.0292, 0.0224, 0.0218, 0.0138, 0.0122, 0.0113,\n",
      "        0.0110])\n",
      "{'unable': tensor(1.4050e-06)}\n",
      "max_probe is: tensor(1.4050e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "10240\n",
      "20480\n",
      "the position of max probe is: 16735\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of abundant is _ .\n",
      "['abundant', 'plentiful', 'also', 'and', ',', 'common', 'or', 'rare', 'ample', 'often']\n",
      "tensor([0.7335, 0.0142, 0.0099, 0.0096, 0.0095, 0.0044, 0.0037, 0.0034, 0.0032,\n",
      "        0.0032])\n",
      "meagreis not in list\n",
      "meagerlyis not in list\n",
      "stingyis not in list\n",
      "scrimpyis not in list\n",
      "{'scarce': tensor(0.0028), 'rare': tensor(0.0034), 'tight': tensor(2.1113e-06), 'meager': tensor(6.5811e-05), 'insufficient': tensor(0.0001), 'deficient': tensor(0.0001)}\n",
      "max_probe is: tensor(0.0034)\n",
      "the position of max probe is: 7\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of aware is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aware', 'Aware', 'also', 'active', ',', 'alert', 'conscious', 'mindful', 'the', 'and']\n",
      "tensor([0.3810, 0.0571, 0.0353, 0.0212, 0.0128, 0.0106, 0.0094, 0.0076, 0.0074,\n",
      "        0.0071])\n",
      "unmindfulis not in list\n",
      "insensibleis not in list\n",
      "{'unaware': tensor(0.0031), 'oblivious': tensor(0.0001), 'unconscious': tensor(0.0004), 'unsuspecting': tensor(1.3174e-05), 'asleep': tensor(0.0007), 'unwitting': tensor(2.4862e-05), 'ignorant': tensor(0.0002), 'indifferent': tensor(0.0001)}\n",
      "max_probe is: tensor(0.0031)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 24\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of beautiful is _ .\n",
      "['beautiful', 'elegant', 'handsome', 'perfect', 'attractive', 'gorgeous', 'pretty', 'brilliant', 'admirable', 'charming']\n",
      "tensor([0.3959, 0.0218, 0.0151, 0.0135, 0.0121, 0.0114, 0.0097, 0.0086, 0.0086,\n",
      "        0.0080])\n",
      "disfiguredis not in list\n",
      "evil-lookingis not in list\n",
      "fuglyis not in list\n",
      "repulsiveis not in list\n",
      "ill-favoredis not in list\n",
      "ill-favouredis not in list\n",
      "scrofulousis not in list\n",
      "unlovelyis not in list\n",
      "unpicturesqueis not in list\n",
      "unsightlyis not in list\n",
      "displeasingis not in list\n",
      "unattractiveis not in list\n",
      "{'ugly': tensor(0.0018), 'grotesque': tensor(0.0002), 'monstrous': tensor(6.0596e-05), 'hideous': tensor(8.3143e-05), 'awkward': tensor(0.0001)}\n",
      "max_probe is: tensor(0.0018)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 66\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of big is _ .\n",
      "['small', 'big', 'large', 'huge', 'little', 'tiny', 'great', ',', 'BIG', 'massive']\n",
      "tensor([0.3258, 0.2083, 0.0681, 0.0380, 0.0354, 0.0192, 0.0133, 0.0128, 0.0121,\n",
      "        0.0115])\n",
      "{'little': tensor(0.0354), 'small': tensor(0.3258)}\n",
      "max_probe is: tensor(0.3258)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of bright is _ .\n",
      "['bright', 'white', 'blue', 'yellow', 'green', 'cold', 'sunny', 'dark', 'strong', 'light']\n",
      "tensor([0.1232, 0.0601, 0.0331, 0.0330, 0.0208, 0.0203, 0.0185, 0.0170, 0.0153,\n",
      "        0.0143])\n",
      "colorlessis not in list\n",
      "colourlessis not in list\n",
      "bleachedis not in list\n",
      "washed-outis not in list\n",
      "washyis not in list\n",
      "drabis not in list\n",
      "somberis not in list\n",
      "sombreis not in list\n",
      "dulledis not in list\n",
      "greyedis not in list\n",
      "etiolateis not in list\n",
      "etiolatedis not in list\n",
      "luridis not in list\n",
      "waxenis not in list\n",
      "waxlikeis not in list\n",
      "waxyis not in list\n",
      "whitenedis not in list\n",
      "{'pale': tensor(0.0111), 'dull': tensor(0.0022), 'neutral': tensor(0.0018), 'white': tensor(0.0601), 'faded': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0601)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of cheap is _ .\n",
      "['cheap', 'free', 'inexpensive', 'expensive', 'affordable', 'poor', 'economical', 'cheaper', 'low', 'not']\n",
      "tensor([0.6396, 0.0675, 0.0194, 0.0159, 0.0137, 0.0060, 0.0048, 0.0031, 0.0030,\n",
      "        0.0028])\n",
      "big-ticketis not in list\n",
      "high-ticketis not in list\n",
      "high-pricedis not in list\n",
      "pricyis not in list\n",
      "dearly-wonis not in list\n",
      "overpricedis not in list\n",
      "{'expensive': tensor(0.0159), 'costly': tensor(0.0013), 'dear': tensor(4.9631e-05), 'pricey': tensor(0.0024), 'valuable': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0159)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of clean is _ .\n",
      "['clean', 'dirty', 'sterile', 'clear', 'green', 'pure', 'dry', 'white', 'wet', 'good']\n",
      "tensor([0.2370, 0.0693, 0.0475, 0.0333, 0.0226, 0.0162, 0.0117, 0.0115, 0.0109,\n",
      "        0.0088])\n",
      "soiledis not in list\n",
      "uncleanis not in list\n",
      "augeanis not in list\n",
      "bedraggledis not in list\n",
      "draggledis not in list\n",
      "befouledis not in list\n",
      "fouledis not in list\n",
      "begrimedis not in list\n",
      "dingyis not in list\n",
      "grimyis not in list\n",
      "grubbyis not in list\n",
      "grungyis not in list\n",
      "raunchyis not in list\n",
      "smuttyis not in list\n",
      "cobwebbyis not in list\n",
      "dirty-facedis not in list\n",
      "feculentis not in list\n",
      "flyblownis not in list\n",
      "squalidis not in list\n",
      "sordidis not in list\n",
      "greasyis not in list\n",
      "maculateis not in list\n",
      "muckyis not in list\n",
      "rattyis not in list\n",
      "scummyis not in list\n",
      "smudgyis not in list\n",
      "snottyis not in list\n",
      "snot-nosedis not in list\n",
      "sootyis not in list\n",
      "travel-soiledis not in list\n",
      "travel-stainedis not in list\n",
      "uncleanlyis not in list\n",
      "unsweptis not in list\n",
      "unwashedis not in list\n",
      "{'dirty': tensor(0.0693), 'black': tensor(0.0017), 'buggy': tensor(2.8215e-06), 'filthy': tensor(0.0022), 'foul': tensor(0.0005), 'nasty': tensor(0.0009), 'oily': tensor(0.0003), 'lousy': tensor(0.0001), 'muddy': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0693)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of clear is _ .\n",
      "['clear', 'transparent', 'clean', 'white', 'bright', 'green', 'plain', ',', 'obvious', '.']\n",
      "tensor([0.6006, 0.0240, 0.0131, 0.0130, 0.0119, 0.0100, 0.0092, 0.0078, 0.0077,\n",
      "        0.0067])\n",
      "{'unclear': tensor(0.0004)}\n",
      "max_probe is: tensor(0.0004)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 124\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of close is _ .\n",
      "['close', 'closed', 'open', 'also', ',', 'near', 'tight', 'short', 'called', '.']\n",
      "tensor([0.2839, 0.0694, 0.0415, 0.0367, 0.0290, 0.0160, 0.0149, 0.0139, 0.0129,\n",
      "        0.0125])\n",
      "farawayis not in list\n",
      "{'distant': tensor(0.0016), 'remote': tensor(0.0005), 'removed': tensor(3.3104e-05), 'far': tensor(0.0029), '': tensor(5.0398e-05)}\n",
      "max_probe is: tensor(0.0029)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 29\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of colorful is _ .\n",
      "['green', 'yellow', 'white', 'colorful', 'blue', 'purple', 'bright', 'colored', 'orange', 'red']\n",
      "tensor([0.0807, 0.0648, 0.0469, 0.0389, 0.0378, 0.0332, 0.0312, 0.0299, 0.0255,\n",
      "        0.0254])\n",
      "colorlessis not in list\n",
      "colourlessis not in list\n",
      "bleachedis not in list\n",
      "washed-outis not in list\n",
      "washyis not in list\n",
      "drabis not in list\n",
      "somberis not in list\n",
      "sombreis not in list\n",
      "dulledis not in list\n",
      "greyedis not in list\n",
      "etiolateis not in list\n",
      "etiolatedis not in list\n",
      "luridis not in list\n",
      "waxenis not in list\n",
      "waxlikeis not in list\n",
      "waxyis not in list\n",
      "whitenedis not in list\n",
      "{'dull': tensor(0.0012), 'neutral': tensor(0.0040), 'pale': tensor(0.0044), 'white': tensor(0.0469), 'faded': tensor(0.0005)}\n",
      "max_probe is: tensor(0.0469)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of common is _ .\n",
      "['common', ',', 'and', 'Common', 'rare', 'also', 'commonly', 'the', 'uncommon', 'or']\n",
      "tensor([0.6969, 0.0489, 0.0170, 0.0137, 0.0110, 0.0102, 0.0098, 0.0089, 0.0085,\n",
      "        0.0071])\n",
      "infrequentis not in list\n",
      "{'rare': tensor(0.0110), 'scarce': tensor(6.3388e-05), 'uncommon': tensor(0.0085), 'extraordinary': tensor(9.7780e-06)}\n",
      "max_probe is: tensor(0.0110)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of competent is _ .\n",
      "[',', 'also', 'competent', 'the', 'and', '.', ':', 'called', '', 'strong']\n",
      "tensor([0.0400, 0.0224, 0.0176, 0.0132, 0.0125, 0.0124, 0.0104, 0.0091, 0.0086,\n",
      "        0.0074])\n",
      "unskilledis not in list\n",
      "unqualifiedis not in list\n",
      "unqualifiedis not in list\n",
      "unskilledis not in list\n",
      "{'incompetent': tensor(0.0006), 'inefficient': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0006)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 278\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of concerned is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'also', 'and', 'the', 'called', '.', 'or', '', '\"', ':']\n",
      "tensor([0.1067, 0.0844, 0.0622, 0.0368, 0.0302, 0.0255, 0.0145, 0.0136, 0.0129,\n",
      "        0.0113])\n",
      "unconcernedis not in list\n",
      "blaseis not in list\n",
      "blitheis not in list\n",
      "insouciantis not in list\n",
      "nonchalantis not in list\n",
      "degageis not in list\n",
      "uninvolvedis not in list\n",
      "uninvolvedis not in list\n",
      "untroubledis not in list\n",
      "{'casual': tensor(1.1593e-06), 'detached': tensor(4.5105e-06), 'indifferent': tensor(3.3064e-06), 'careless': tensor(3.7523e-07)}\n",
      "max_probe is: tensor(4.5105e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "10240\n",
      "the position of max probe is: 8570\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of cooked is _ .\n",
      "['cooked', ',', 'heated', 'boiled', 'baked', 'hot', 'eaten', 'fried', 'called', 'raw']\n",
      "tensor([0.1768, 0.0741, 0.0508, 0.0440, 0.0308, 0.0284, 0.0247, 0.0225, 0.0200,\n",
      "        0.0196])\n",
      "half-bakedis not in list\n",
      "underdoneis not in list\n",
      "uncookedis not in list\n",
      "untoastedis not in list\n",
      "{'raw': tensor(0.0196), 'fresh': tensor(0.0011), 'natural': tensor(0.0001), 'rare': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0196)\n",
      "the position of max probe is: 9\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of dangerous is _ .\n",
      "['dangerous', 'aggressive', 'risky', 'deadly', 'reckless', 'lethal', 'volatile', 'vigilant', 'hazardous', 'toxic']\n",
      "tensor([0.1050, 0.0337, 0.0228, 0.0176, 0.0156, 0.0133, 0.0129, 0.0117, 0.0115,\n",
      "        0.0106])\n",
      "{'safe': tensor(0.0104)}\n",
      "max_probe is: tensor(0.0104)\n",
      "20\n",
      "the position of max probe is: 10\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of decisive is _ .\n",
      "['decisive', 'also', 'significant', ',', 'and', 'definitive', 'positive', 'the', 'or', 'negative']\n",
      "tensor([0.2157, 0.0204, 0.0158, 0.0135, 0.0134, 0.0125, 0.0118, 0.0090, 0.0071,\n",
      "        0.0069])\n",
      "hesitatingis not in list\n",
      "indecisiveis not in list\n",
      "inconclusiveis not in list\n",
      "irresoluteis not in list\n",
      "{'hesitant': tensor(1.6914e-05)}\n",
      "max_probe is: tensor(1.6914e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "the position of max probe is: 3659\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of dry is _ .\n",
      "['wet', 'hot', 'moist', 'damp', 'dry', 'humid', 'cold', 'warm', 'rainy', 'dusty']\n",
      "tensor([0.5296, 0.0906, 0.0432, 0.0293, 0.0270, 0.0213, 0.0135, 0.0132, 0.0071,\n",
      "        0.0067])\n",
      "bedewedis not in list\n",
      "dewyis not in list\n",
      "besprentis not in list\n",
      "boggyis not in list\n",
      "marshyis not in list\n",
      "miryis not in list\n",
      "muckyis not in list\n",
      "quaggyis not in list\n",
      "sloughyis not in list\n",
      "soggyis not in list\n",
      "squashyis not in list\n",
      "swampyis not in list\n",
      "waterloggedis not in list\n",
      "clammyis not in list\n",
      "dankis not in list\n",
      "dampishis not in list\n",
      "soddenis not in list\n",
      "soppyis not in list\n",
      "drippyis not in list\n",
      "drizzlyis not in list\n",
      "mistyis not in list\n",
      "muggyis not in list\n",
      "steamyis not in list\n",
      "reekingis not in list\n",
      "wateryis not in list\n",
      "rheumyis not in list\n",
      "showeryis not in list\n",
      "steamingis not in list\n",
      "tackyis not in list\n",
      "undriedis not in list\n",
      "{'wet': tensor(0.5296), 'muddy': tensor(0.0006), 'sloppy': tensor(0.0001), 'damp': tensor(0.0293), 'moist': tensor(0.0432), 'humid': tensor(0.0213), 'sticky': tensor(0.0009), 'rainy': tensor(0.0071), 'washed': tensor(0.0005)}\n",
      "max_probe is: tensor(0.5296)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of energetic is _ .\n",
      "['energetic', ',', 'energy', 'and', 'kinetic', 'also', 'or', 'effective', 'charged', 'called']\n",
      "tensor([0.3289, 0.0639, 0.0400, 0.0283, 0.0243, 0.0215, 0.0177, 0.0094, 0.0081,\n",
      "        0.0080])\n",
      "lethargicis not in list\n",
      "unergeticis not in list\n",
      "dazedis not in list\n",
      "foggyis not in list\n",
      "groggyis not in list\n",
      "logyis not in list\n",
      "stuporousis not in list\n",
      "dreamyis not in list\n",
      "lackadaisicalis not in list\n",
      "languidis not in list\n",
      "languorousis not in list\n",
      "listlessis not in list\n",
      "{'inactive': tensor(0.0007)}\n",
      "max_probe is: tensor(0.0007)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 105\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of familiar is _ .\n",
      "['familiar', ',', 'also', '.', 'common', 'the', 'and', 'called', 'often', 'named']\n",
      "tensor([0.2157, 0.0384, 0.0336, 0.0262, 0.0162, 0.0134, 0.0119, 0.0111, 0.0100,\n",
      "        0.0092])\n",
      "{'unfamiliar': tensor(0.0047)}\n",
      "max_probe is: tensor(0.0047)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 21\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of fat is _ .\n",
      "['fat', ',', 'cholesterol', 'glucose', 'and', 'water', 'protein', 'CHO', 'or', 'weight']\n",
      "tensor([0.1534, 0.0630, 0.0510, 0.0372, 0.0365, 0.0280, 0.0220, 0.0165, 0.0152,\n",
      "        0.0140])\n",
      "anorexicis not in list\n",
      "anorecticis not in list\n",
      "bonyis not in list\n",
      "cadaverousis not in list\n",
      "emaciatedis not in list\n",
      "gauntis not in list\n",
      "haggardis not in list\n",
      "pinchedis not in list\n",
      "deep-eyedis not in list\n",
      "hollow-eyedis not in list\n",
      "sunken-eyedis not in list\n",
      "ganglingis not in list\n",
      "ganglyis not in list\n",
      "lankyis not in list\n",
      "lankis not in list\n",
      "spindlyis not in list\n",
      "rawbonedis not in list\n",
      "reedyis not in list\n",
      "reedlikeis not in list\n",
      "twiggyis not in list\n",
      "twiglikeis not in list\n",
      "scarecrowishis not in list\n",
      "scraggyis not in list\n",
      "boneyis not in list\n",
      "scrawnyis not in list\n",
      "underweightis not in list\n",
      "weedyis not in list\n",
      "shriveledis not in list\n",
      "shrivelledis not in list\n",
      "shrunkenis not in list\n",
      "witheredis not in list\n",
      "wizenis not in list\n",
      "wizenedis not in list\n",
      "svelteis not in list\n",
      "slender-waistedis not in list\n",
      "slim-waistedis not in list\n",
      "wasp-waistedis not in list\n",
      "spindle-leggedis not in list\n",
      "spindle-shankedis not in list\n",
      "stringyis not in list\n",
      "wiryis not in list\n",
      "wisplikeis not in list\n",
      "wispyis not in list\n",
      "{'thin': tensor(0.0003), 'lean': tensor(0.0012), 'skeletal': tensor(5.5316e-05), 'wasted': tensor(1.1032e-06), 'skinny': tensor(2.1760e-05), 'slender': tensor(2.5115e-05), 'slight': tensor(2.2914e-06), 'slim': tensor(8.6478e-05), 'spare': tensor(4.8111e-06), 'trim': tensor(2.6368e-05)}\n",
      "max_probe is: tensor(0.0012)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 93\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of full is _ .\n",
      "['full', 'short', 'empty', ',', 'half', 'complete', 'long', 'also', 'flat', 'double']\n",
      "tensor([0.2592, 0.0519, 0.0299, 0.0290, 0.0143, 0.0135, 0.0113, 0.0106, 0.0085,\n",
      "        0.0080])\n",
      "{'empty': tensor(0.0299)}\n",
      "max_probe is: tensor(0.0299)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of gaseous is _ .\n",
      "['gas', ',', 'liquid', 'solid', 'cubic', 'and', 'charged', 'excited', 'or', 'water']\n",
      "tensor([0.0828, 0.0612, 0.0498, 0.0406, 0.0304, 0.0253, 0.0228, 0.0134, 0.0131,\n",
      "        0.0122])\n",
      "coagulatedis not in list\n",
      "solidifiedis not in list\n",
      "congealedis not in list\n",
      "jelledis not in list\n",
      "jelliedis not in list\n",
      "semisolidis not in list\n",
      "solid-stateis not in list\n",
      "{'solid': tensor(0.0406), 'hard': tensor(0.0001), 'concrete': tensor(0.0001), 'dry': tensor(0.0098)}\n",
      "max_probe is: tensor(0.0406)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of generous is _ .\n",
      "['generous', 'positive', 'conservative', 'flexible', 'greedy', 'modest', 'simple', ',', 'liberal', 'also']\n",
      "tensor([0.2070, 0.0204, 0.0188, 0.0112, 0.0099, 0.0097, 0.0096, 0.0091, 0.0081,\n",
      "        0.0076])\n",
      "stingyis not in list\n",
      "beggarlyis not in list\n",
      "chinchyis not in list\n",
      "chintzyis not in list\n",
      "cheeseparingis not in list\n",
      "penny-pinchingis not in list\n",
      "closefistedis not in list\n",
      "hardfistedis not in list\n",
      "tightfistedis not in list\n",
      "grudgingis not in list\n",
      "niggardlyis not in list\n",
      "scrimyis not in list\n",
      "mingyis not in list\n",
      "miserlyis not in list\n",
      "parsimoniousis not in list\n",
      "penuriousis not in list\n",
      "uncharitableis not in list\n",
      "ungenerousis not in list\n",
      "meanspiritedis not in list\n",
      "{'mean': tensor(0.0019), 'cheap': tensor(0.0012), 'close': tensor(7.5580e-05), 'near': tensor(7.6008e-05), 'skinny': tensor(5.5249e-05), 'tight': tensor(0.0003), 'selfish': tensor(0.0037)}\n",
      "max_probe is: tensor(0.0037)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 26\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of hard is _ .\n",
      "['hard', 'cold', 'soft', ',', 'strong', 'weak', 'sharp', 'heavy', 'harsh', 'tough']\n",
      "tensor([0.3421, 0.0611, 0.0584, 0.0337, 0.0303, 0.0266, 0.0171, 0.0120, 0.0077,\n",
      "        0.0076])\n",
      "{'easy': tensor(0.0025)}\n",
      "max_probe is: tensor(0.0025)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 32\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of hot is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cold', 'hot', ',', 'cool', 'warm', 'HOT', 'dry', 'heated', 'strong', 'heat']\n",
      "tensor([0.4351, 0.3121, 0.0346, 0.0242, 0.0183, 0.0132, 0.0091, 0.0070, 0.0040,\n",
      "        0.0037])\n",
      "frostyis not in list\n",
      "frigidis not in list\n",
      "{'cold': tensor(0.4351), 'chilly': tensor(0.0008), 'cool': tensor(0.0242)}\n",
      "max_probe is: tensor(0.4351)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of interesting is _ .\n",
      "['interesting', 'informative', 'fascinating', 'curious', 'intriguing', 'exciting', 'popular', 'interest', 'interested', 'useful']\n",
      "tensor([0.4638, 0.0619, 0.0451, 0.0306, 0.0237, 0.0222, 0.0138, 0.0093, 0.0087,\n",
      "        0.0084])\n",
      "uninterestingis not in list\n",
      "deadeningis not in list\n",
      "ho-humis not in list\n",
      "irksomeis not in list\n",
      "tiresomeis not in list\n",
      "wearisomeis not in list\n",
      "insipidis not in list\n",
      "jejuneis not in list\n",
      "narcoticis not in list\n",
      "soporiferousis not in list\n",
      "soporificis not in list\n",
      "prosaicis not in list\n",
      "prosyis not in list\n",
      "earthboundis not in list\n",
      "ponderousis not in list\n",
      "putdownableis not in list\n",
      "unexcitingis not in list\n",
      "unstimulatingis not in list\n",
      "{'dull': tensor(0.0005), 'boring': tensor(0.0026), 'slow': tensor(9.8663e-06), 'tedious': tensor(8.5867e-05)}\n",
      "max_probe is: tensor(0.0026)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 24\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of introvert is _ .\n",
      "['shy', 'obsessive', 'pessimistic', 'independent', 'depressive', 'analytic', 'ADD', 'nerd', 'the', 'minimalist']\n",
      "tensor([0.0692, 0.0421, 0.0331, 0.0209, 0.0169, 0.0165, 0.0158, 0.0139, 0.0121,\n",
      "        0.0118])\n",
      "extravertis not in list\n",
      "extrovertis not in list\n",
      "extrovertedis not in list\n",
      "sociableis not in list\n",
      "{'outgoing': tensor(0.0056), 'forthcoming': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0056)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 20\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of large is _ .\n",
      "['large', 'small', ',', 'big', 'huge', 'and', 'also', 'massive', 'great', 'tiny']\n",
      "tensor([0.3784, 0.2355, 0.0754, 0.0233, 0.0164, 0.0109, 0.0107, 0.0099, 0.0063,\n",
      "        0.0057])\n",
      "{'little': tensor(0.0017), 'small': tensor(0.2355)}\n",
      "max_probe is: tensor(0.2355)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of long is _ .\n",
      "['long', 'short', ',', 'and', 'or', 'also', 'n', 'to', '.', 'lat']\n",
      "tensor([0.4689, 0.3588, 0.0217, 0.0113, 0.0077, 0.0028, 0.0026, 0.0022, 0.0022,\n",
      "        0.0021])\n",
      "abbreviatedis not in list\n",
      "truncatedis not in list\n",
      "momentaneousis not in list\n",
      "momentaryis not in list\n",
      "short_and_sweetis not in list\n",
      "short-datedis not in list\n",
      "short-rangeis not in list\n",
      "short-runis not in list\n",
      "short-termis not in list\n",
      "abbreviatedis not in list\n",
      "curtalis not in list\n",
      "sawed-offis not in list\n",
      "sawn-offis not in list\n",
      "shortishis not in list\n",
      "short-rangeis not in list\n",
      "short-snoutedis not in list\n",
      "snubis not in list\n",
      "stubbyis not in list\n",
      "telescopedis not in list\n",
      "truncateis not in list\n",
      "truncatedis not in list\n",
      "chunkyis not in list\n",
      "dumpyis not in list\n",
      "low-setis not in list\n",
      "squattyis not in list\n",
      "stumpyis not in list\n",
      "heavysetis not in list\n",
      "stockyis not in list\n",
      "thicksetis not in list\n",
      "half-lengthis not in list\n",
      "pint-sizeis not in list\n",
      "pint-sizedis not in list\n",
      "runtyis not in list\n",
      "sawed-offis not in list\n",
      "sawn-offis not in list\n",
      "short-stalkedis not in list\n",
      "squabis not in list\n",
      "squabbyis not in list\n",
      "{'short': tensor(0.3588), 'shortened': tensor(0.0010), 'brief': tensor(8.2759e-05), 'clipped': tensor(2.3943e-07), 'fleeting': tensor(1.5449e-06), 'fugitive': tensor(1.9932e-07), 'close': tensor(0.0001), 'squat': tensor(9.0478e-05), 'compact': tensor(5.3795e-05), 'thick': tensor(0.0006)}\n",
      "max_probe is: tensor(0.3588)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of lumpy is _ .\n",
      "['cubic', ',', 'sticky', 'linear', 'also', 'dense', 'lump', 'lazy', 'bulky', 'smooth']\n",
      "tensor([0.0530, 0.0171, 0.0170, 0.0156, 0.0137, 0.0130, 0.0112, 0.0098, 0.0088,\n",
      "        0.0082])\n",
      "{'flat': tensor(0.0049), 'level': tensor(0.0001), 'plane': tensor(3.0895e-06), 'even': tensor(0.0011), '': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0049)\n",
      "20\n",
      "the position of max probe is: 15\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of noisy is _ .\n",
      "['noisy', 'loud', ',', 'silent', 'quiet', 'also', 'the', 'clear', 'noise', 'called']\n",
      "tensor([0.1967, 0.0242, 0.0206, 0.0151, 0.0149, 0.0120, 0.0113, 0.0104, 0.0090,\n",
      "        0.0084])\n",
      "uncommunicativeis not in list\n",
      "inarticulateis not in list\n",
      "unarticulateis not in list\n",
      "{'silent': tensor(0.0151), 'dumb': tensor(8.1372e-05), 'mute': tensor(0.0006)}\n",
      "max_probe is: tensor(0.0151)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of normal is _ .\n",
      "['normal', ',', 'and', 'regular', 'also', 'normalized', 'ordinary', 'standard', '.', 'high']\n",
      "tensor([0.3035, 0.0461, 0.0422, 0.0171, 0.0169, 0.0163, 0.0138, 0.0122, 0.0100,\n",
      "        0.0071])\n",
      "{'abnormal': tensor(0.0046)}\n",
      "max_probe is: tensor(0.0046)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 22\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of organized is _ .\n",
      "['called', ',', 'the', 'named', 'written', 'also', 'and', 'generalized', 'pronounced', '.']\n",
      "tensor([0.1620, 0.1042, 0.0414, 0.0315, 0.0313, 0.0274, 0.0217, 0.0169, 0.0162,\n",
      "        0.0145])\n",
      "unorganizedis not in list\n",
      "unstructuredis not in list\n",
      "uncoordinatedis not in list\n",
      "unformedis not in list\n",
      "unincorporatedis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of pale is _ .\n",
      "['yellow', 'white', 'red', 'green', 'blue', 'brown', 'black', 'purple', 'gray', 'orange']\n",
      "tensor([0.1363, 0.0810, 0.0805, 0.0700, 0.0654, 0.0550, 0.0462, 0.0411, 0.0368,\n",
      "        0.0354])\n",
      "tannedis not in list\n",
      "bronzedis not in list\n",
      "suntannedis not in list\n",
      "brunetis not in list\n",
      "brunetteis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of pretty is _ .\n",
      "['pretty', 'beautiful', 'cute', 'charming', 'lovely', 'cool', 'sexy', 'nice', 'adorable', 'attractive']\n",
      "tensor([0.2091, 0.1014, 0.0473, 0.0356, 0.0251, 0.0227, 0.0160, 0.0121, 0.0115,\n",
      "        0.0107])\n",
      "disfiguredis not in list\n",
      "evil-lookingis not in list\n",
      "fuglyis not in list\n",
      "repulsiveis not in list\n",
      "ill-favoredis not in list\n",
      "ill-favouredis not in list\n",
      "scrofulousis not in list\n",
      "unlovelyis not in list\n",
      "unpicturesqueis not in list\n",
      "unsightlyis not in list\n",
      "displeasingis not in list\n",
      "unattractiveis not in list\n",
      "{'ugly': tensor(0.0022), 'grotesque': tensor(3.1916e-05), 'monstrous': tensor(7.2004e-06), 'hideous': tensor(5.4789e-05), 'awkward': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0022)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 50\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of rich is _ .\n",
      "['rich', ',', 'also', 'wealthy', 'and', 'strong', 'poor', '.', 'called', 'the']\n",
      "tensor([0.2975, 0.0455, 0.0183, 0.0149, 0.0116, 0.0105, 0.0104, 0.0081, 0.0067,\n",
      "        0.0066])\n",
      "{'poor': tensor(0.0104)}\n",
      "max_probe is: tensor(0.0104)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of risky is _ .\n",
      "['risky', 'cautious', 'prudent', 'aggressive', 'safe', 'conservative', 'reckless', 'optimistic', 'bold', 'irresponsible']\n",
      "tensor([0.1359, 0.0550, 0.0384, 0.0328, 0.0276, 0.0275, 0.0197, 0.0145, 0.0111,\n",
      "        0.0105])\n",
      "fail-safeis not in list\n",
      "risk-freeis not in list\n",
      "risklessis not in list\n",
      "unhazardousis not in list\n",
      "safe-and-soundis not in list\n",
      "unhurtis not in list\n",
      "invulnerableis not in list\n",
      "uninjuredis not in list\n",
      "{'safe': tensor(0.0276), 'harmless': tensor(0.0004), 'secure': tensor(0.0027)}\n",
      "max_probe is: tensor(0.0276)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of sane is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sane', 'rational', 'normal', 'calm', 'sensible', 'lucid', 'reasonable', 'prudent', 'healthy', 'logical']\n",
      "tensor([0.1378, 0.0550, 0.0456, 0.0228, 0.0209, 0.0187, 0.0179, 0.0149, 0.0136,\n",
      "        0.0134])\n",
      "loonyis not in list\n",
      "looneyis not in list\n",
      "nutcaseis not in list\n",
      "weirdois not in list\n",
      "{'crazy': tensor(0.0083), 'mad': tensor(0.0008), 'insane': tensor(0.0098)}\n",
      "max_probe is: tensor(0.0098)\n",
      "20\n",
      "the position of max probe is: 12\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of short is _ .\n",
      "['long', 'short', ',', 'also', 'and', 'fast', 'shorter', 'tall', 'longer', 'or']\n",
      "tensor([0.5266, 0.2372, 0.0151, 0.0098, 0.0050, 0.0042, 0.0036, 0.0033, 0.0031,\n",
      "        0.0028])\n",
      "ganglingis not in list\n",
      "ganglyis not in list\n",
      "lankyis not in list\n",
      "rangyis not in list\n",
      "leggyis not in list\n",
      "long-leggedis not in list\n",
      "long-shankedis not in list\n",
      "tall-growingis not in list\n",
      "long-stalkedis not in list\n",
      "tall-stalkedis not in list\n",
      "statelyis not in list\n",
      "statuesqueis not in list\n",
      "tallishis not in list\n",
      "{'tall': tensor(0.0033), 'height': tensor(1.4822e-05), 'long': tensor(0.5266)}\n",
      "max_probe is: tensor(0.5266)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of simple is _ .\n",
      "['simple', 'complex', 'plain', 'straightforward', 'arithmetic', 'linear', 'complicated', 'simply', 'regular', 'compact']\n",
      "tensor([0.3701, 0.0997, 0.0229, 0.0229, 0.0157, 0.0142, 0.0128, 0.0124, 0.0114,\n",
      "        0.0114])\n",
      "{'difficult': tensor(0.0007), 'challenging': tensor(1.5559e-05), 'hard': tensor(0.0016), 'complicated': tensor(0.0128), 'demanding': tensor(1.6565e-05), 'daunting': tensor(1.6780e-05), 'taxing': tensor(1.4597e-06)}\n",
      "max_probe is: tensor(0.0128)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of sincere is _ .\n",
      "['sincere', 'honest', 'truthful', 'true', 'faithful', 'genuine', 'authentic', 'earnest', 'conscientious', 'trustworthy']\n",
      "tensor([0.1715, 0.0844, 0.0383, 0.0306, 0.0266, 0.0190, 0.0116, 0.0099, 0.0078,\n",
      "        0.0076])\n",
      "insincereis not in list\n",
      "bootlickingis not in list\n",
      "fawningis not in list\n",
      "obsequiousis not in list\n",
      "sycophanticis not in list\n",
      "toadyishis not in list\n",
      "butteryis not in list\n",
      "fulsomeis not in list\n",
      "oleaginousis not in list\n",
      "smarmyis not in list\n",
      "soapyis not in list\n",
      "unctuousis not in list\n",
      "dissimulativeis not in list\n",
      "feignedis not in list\n",
      "gildedis not in list\n",
      "meretriciousis not in list\n",
      "speciousis not in list\n",
      "imitativeis not in list\n",
      "dishonorableis not in list\n",
      "disingenuousis not in list\n",
      "artfulis not in list\n",
      "{'oily': tensor(6.8402e-06), 'false': tensor(0.0013), 'hypocritical': tensor(0.0004), 'plausible': tensor(0.0005), 'counterfeit': tensor(1.0230e-05), 'dishonest': tensor(0.0040), 'unreal': tensor(8.4370e-05)}\n",
      "max_probe is: tensor(0.0040)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 24\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of slow is _ .\n",
      "['fast', 'slow', ',', 'steady', 'short', 'sluggish', 'swift', 'brisk', 'linear', 'hot']\n",
      "tensor([0.2940, 0.2865, 0.0202, 0.0171, 0.0111, 0.0090, 0.0076, 0.0075, 0.0069,\n",
      "        0.0066])\n",
      "alacritousis not in list\n",
      "blisteringis not in list\n",
      "red-hotis not in list\n",
      "double-quickis not in list\n",
      "fast-breakingis not in list\n",
      "fast-pacedis not in list\n",
      "high-speedis not in list\n",
      "high-velocityis not in list\n",
      "hurryingis not in list\n",
      "scurryingis not in list\n",
      "straightawayis not in list\n",
      "meteoricis not in list\n",
      "wingedis not in list\n",
      "windyis not in list\n",
      "{'fast': tensor(0.2940), 'quick': tensor(0.0041), 'accelerated': tensor(0.0002), 'hot': tensor(0.0066), 'express': tensor(1.9937e-05), 'fleet': tensor(2.8987e-05), 'swift': tensor(0.0076), 'immediate': tensor(2.7628e-05), 'prompt': tensor(9.8684e-05), 'instantaneous': tensor(0.0001), 'instant': tensor(2.5171e-05), 'speedy': tensor(0.0025), 'rapid': tensor(0.0061)}\n",
      "max_probe is: tensor(0.2940)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of sweet is _ .\n",
      "['sour', 'bitter', 'salty', 'mild', 'sweet', 'acidic', 'honey', 'salt', 'dry', 'spicy']\n",
      "tensor([0.4784, 0.2131, 0.0630, 0.0157, 0.0150, 0.0101, 0.0098, 0.0081, 0.0074,\n",
      "        0.0059])\n",
      "acerbis not in list\n",
      "acerbicis not in list\n",
      "astringentis not in list\n",
      "acetoseis not in list\n",
      "acetousis not in list\n",
      "vinegaryis not in list\n",
      "vinegarishis not in list\n",
      "acidulentis not in list\n",
      "acidulousis not in list\n",
      "lemonyis not in list\n",
      "lemonlikeis not in list\n",
      "sourishis not in list\n",
      "tangyis not in list\n",
      "subacidis not in list\n",
      "{'sour': tensor(0.4784), 'acidic': tensor(0.0101), 'acid': tensor(0.0028), 'tart': tensor(0.0047), 'bitter': tensor(0.2131)}\n",
      "max_probe is: tensor(0.4784)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of tasty is _ .\n",
      "['spicy', 'delicious', 'sweet', 'sour', 'tasty', 'salty', 'tart', 'hot', 'bland', 'good']\n",
      "tensor([0.0701, 0.0649, 0.0632, 0.0525, 0.0378, 0.0233, 0.0218, 0.0212, 0.0159,\n",
      "        0.0158])\n",
      "tastelessis not in list\n",
      "flavorlessis not in list\n",
      "flavourlessis not in list\n",
      "insipidis not in list\n",
      "savorlessis not in list\n",
      "savourlessis not in list\n",
      "vapidis not in list\n",
      "unflavoredis not in list\n",
      "unflavouredis not in list\n",
      "nonflavoredis not in list\n",
      "nonflavouredis not in list\n",
      "unsaltedis not in list\n",
      "unseasonedis not in list\n",
      "unappetizingis not in list\n",
      "unappetisingis not in list\n",
      "unpalatableis not in list\n",
      "{'bland': tensor(0.0159), 'flat': tensor(0.0010)}\n",
      "max_probe is: tensor(0.0159)\n",
      "the position of max probe is: 8\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of tight is _ .\n",
      "['tight', 'short', 'flexible', 'narrow', ',', 'loose', 'tense', 'strict', 'relaxed', 'compact']\n",
      "tensor([0.3337, 0.0359, 0.0238, 0.0174, 0.0141, 0.0140, 0.0139, 0.0120, 0.0115,\n",
      "        0.0107])\n",
      "baggyis not in list\n",
      "loose-fittingis not in list\n",
      "flyawayis not in list\n",
      "{'loose': tensor(0.0140), 'lax': tensor(0.0064), 'sloppy': tensor(0.0002), 'free': tensor(0.0009), 'liberal': tensor(6.2991e-05), 'informal': tensor(0.0003), 'unofficial': tensor(1.1034e-05)}\n",
      "max_probe is: tensor(0.0140)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of warm is _ .\n",
      "['cold', 'hot', 'cool', 'warm', 'mild', 'strong', ',', 'dry', 'chilly', 'moist']\n",
      "tensor([0.5953, 0.1271, 0.0906, 0.0570, 0.0131, 0.0066, 0.0062, 0.0055, 0.0041,\n",
      "        0.0037])\n",
      "frostyis not in list\n",
      "frigidis not in list\n",
      "{'cool': tensor(0.0906), 'cold': tensor(0.5953), 'chilly': tensor(0.0041)}\n",
      "max_probe is: tensor(0.5953)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of white is _ .\n",
      "['black', 'blue', 'yellow', 'red', 'green', 'white', 'gray', 'grey', 'pink', 'brown']\n",
      "tensor([0.1721, 0.1352, 0.1219, 0.0905, 0.0722, 0.0713, 0.0605, 0.0480, 0.0261,\n",
      "        0.0249])\n",
      "{'black': tensor(0.1721)}\n",
      "max_probe is: tensor(0.1721)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of wide is _ .\n",
      "['wide', 'narrow', 'long', 'thin', 'large', ',', 'width', 'tall', 'thick', 'open']\n",
      "tensor([0.3322, 0.2206, 0.0388, 0.0283, 0.0137, 0.0124, 0.0122, 0.0118, 0.0117,\n",
      "        0.0115])\n",
      "constrictingis not in list\n",
      "constrictiveis not in list\n",
      "narrow-mouthedis not in list\n",
      "straitis not in list\n",
      "straplikeis not in list\n",
      "taperedis not in list\n",
      "taperingis not in list\n",
      "{'narrow': tensor(0.2206), 'narrowing': tensor(3.3077e-05), 'narrowed': tensor(0.0002), 'slender': tensor(0.0019), 'thin': tensor(0.0283), 'limited': tensor(0.0002)}\n",
      "max_probe is: tensor(0.2206)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of willing is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['willing', 'eager', 'and', 'ready', 'unwilling', 'also', 'wanting', 'willingness', 'the', 'not']\n",
      "tensor([0.3750, 0.0302, 0.0163, 0.0150, 0.0145, 0.0108, 0.0097, 0.0095, 0.0090,\n",
      "        0.0088])\n",
      "{'unwilling': tensor(0.0145)}\n",
      "max_probe is: tensor(0.0145)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of young is _ .\n",
      "['young', 'old', ',', 'also', 'and', 'youth', '.', 'youthful', 'new', 'the']\n",
      "tensor([0.4522, 0.1412, 0.0579, 0.0143, 0.0121, 0.0116, 0.0100, 0.0076, 0.0074,\n",
      "        0.0065])\n",
      "{'old': tensor(0.1412)}\n",
      "max_probe is: tensor(0.1412)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of new is _ .\n",
      "['new', 'old', 'and', ',', 'now', 'also', 'the', 'âĨĴ', 'used', 'or']\n",
      "tensor([0.4182, 0.2571, 0.0197, 0.0193, 0.0074, 0.0056, 0.0047, 0.0039, 0.0038,\n",
      "        0.0033])\n",
      "{'old': tensor(0.2571)}\n",
      "max_probe is: tensor(0.2571)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of other is _ .\n",
      "['and', 'also', ',', 'other', 'or', 'the', 'of', '.', 'is', 'equivalent']\n",
      "tensor([0.1809, 0.1245, 0.1034, 0.0926, 0.0667, 0.0186, 0.0145, 0.0123, 0.0101,\n",
      "        0.0074])\n",
      "{'same': tensor(0.0016)}\n",
      "max_probe is: tensor(0.0016)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 56\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of many is _ .\n",
      "['also', 'and', ',', '', 'often', 'the', 'many', '.', ':', 'called']\n",
      "tensor([0.1536, 0.0702, 0.0672, 0.0613, 0.0578, 0.0413, 0.0318, 0.0227, 0.0215,\n",
      "        0.0187])\n",
      "{'few': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0003)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 253\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of high is _ .\n",
      "['high', 'low', ',', 'long', 'and', 'also', 'High', 'short', 'or', 'called']\n",
      "tensor([0.6364, 0.1579, 0.0305, 0.0113, 0.0060, 0.0056, 0.0054, 0.0053, 0.0030,\n",
      "        0.0029])\n",
      "{'low': tensor(0.1579)}\n",
      "max_probe is: tensor(0.1579)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of same is _ .\n",
      "[',', 'and', 'also', 'written', 'called', '', 'the', ':', 'then', '']\n",
      "tensor([0.1581, 0.0862, 0.0847, 0.0444, 0.0407, 0.0362, 0.0259, 0.0240, 0.0169,\n",
      "        0.0166])\n",
      "{'other': tensor(5.7075e-05)}\n",
      "max_probe is: tensor(5.7075e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 765\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of general is _ .\n",
      "['general', 'generalized', ',', 'General', 'generic', 'also', 'and', 'special', 'the', 'universal']\n",
      "tensor([0.5265, 0.1259, 0.0578, 0.0293, 0.0290, 0.0169, 0.0109, 0.0067, 0.0048,\n",
      "        0.0047])\n",
      "{'specific': tensor(0.0023)}\n",
      "max_probe is: tensor(0.0023)\n",
      "20\n",
      "the position of max probe is: 19\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of international is _ .\n",
      "['international', 'global', 'world', 'continental', 'national', 'International', 'bilateral', 'worldwide', 'the', 'domestic']\n",
      "tensor([0.5849, 0.0842, 0.0482, 0.0414, 0.0116, 0.0081, 0.0080, 0.0080, 0.0062,\n",
      "        0.0059])\n",
      "{'national': tensor(0.0116)}\n",
      "max_probe is: tensor(0.0116)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of local is _ .\n",
      "['local', 'localized', 'global', ',', 'locale', 'locally', 'regional', 'Local', 'or', 'the']\n",
      "tensor([0.7124, 0.0465, 0.0099, 0.0094, 0.0068, 0.0067, 0.0060, 0.0044, 0.0036,\n",
      "        0.0034])\n",
      "{'national': tensor(0.0018)}\n",
      "max_probe is: tensor(0.0018)\n",
      "20\n",
      "the position of max probe is: 18\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of small is _ .\n",
      "['small', 'large', ',', 'big', 'tiny', 'also', 'and', 'little', 'or', '.']\n",
      "tensor([0.3990, 0.1557, 0.0919, 0.0258, 0.0161, 0.0159, 0.0121, 0.0102, 0.0075,\n",
      "        0.0064])\n",
      "{'big': tensor(0.0258), 'large': tensor(0.1557)}\n",
      "max_probe is: tensor(0.1557)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of much is _ .\n",
      "['also', 'much', 'often', 'and', ',', 'the', 'simply', '', 'that', 'called']\n",
      "tensor([0.1158, 0.0984, 0.0507, 0.0443, 0.0409, 0.0201, 0.0160, 0.0150, 0.0134,\n",
      "        0.0133])\n",
      "{'little': tensor(0.0021)}\n",
      "max_probe is: tensor(0.0021)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 66\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of old is _ .\n",
      "['old', ',', 'new', 'Old', 'young', 'modern', 'now', 'ancient', 'long', 'and']\n",
      "tensor([0.6857, 0.0392, 0.0354, 0.0301, 0.0265, 0.0198, 0.0189, 0.0093, 0.0068,\n",
      "        0.0061])\n",
      "{'young': tensor(0.0265)}\n",
      "max_probe is: tensor(0.0265)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of single is _ .\n",
      "['single', ',', 'and', 'also', 'double', 'singular', 'or', '/', 'plural', '=']\n",
      "tensor([0.1793, 0.0916, 0.0682, 0.0567, 0.0476, 0.0179, 0.0130, 0.0114, 0.0089,\n",
      "        0.0088])\n",
      "{'common': tensor(0.0027)}\n",
      "max_probe is: tensor(0.0027)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 37\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of different is _ .\n",
      "['different', 'and', ',', 'also', 'similar', 'distinct', 'identical', 'the', 'or', 'called']\n",
      "tensor([0.3695, 0.0612, 0.0469, 0.0290, 0.0180, 0.0176, 0.0144, 0.0136, 0.0091,\n",
      "        0.0085])\n",
      "{'same': tensor(0.0064)}\n",
      "max_probe is: tensor(0.0064)\n",
      "20\n",
      "the position of max probe is: 15\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of few is _ .\n",
      "['also', ',', 'many', 'and', 'small', '.', 'only', '1', 'few', 'the']\n",
      "tensor([0.0460, 0.0437, 0.0430, 0.0395, 0.0253, 0.0201, 0.0183, 0.0183, 0.0166,\n",
      "        0.0149])\n",
      "{'many': tensor(0.0430)}\n",
      "max_probe is: tensor(0.0430)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of popular is _ .\n",
      "['popular', 'the', 'popularity', ',', 'also', 'Popular', 'ubiquitous', 'called', 'hot', 'trendy']\n",
      "tensor([0.9084, 0.0070, 0.0044, 0.0043, 0.0040, 0.0025, 0.0025, 0.0022, 0.0014,\n",
      "        0.0014])\n",
      "{'unpopular': tensor(0.0001)}\n",
      "max_probe is: tensor(0.0001)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 108\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of black is _ .\n",
      "['white', 'red', 'blue', 'brown', 'black', 'gray', 'grey', 'green', 'purple', 'yellow']\n",
      "tensor([0.1951, 0.1662, 0.1097, 0.0876, 0.0720, 0.0681, 0.0546, 0.0449, 0.0357,\n",
      "        0.0320])\n",
      "{'white': tensor(0.1951)}\n",
      "max_probe is: tensor(0.1951)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of northern is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['northern', 'southern', 'western', ',', 'northeastern', 'eastern', 'northwestern', 'southeastern', 'north', 'Northern']\n",
      "tensor([0.3645, 0.1493, 0.1276, 0.0469, 0.0451, 0.0351, 0.0169, 0.0096, 0.0094,\n",
      "        0.0089])\n",
      "{'southern': tensor(0.1493)}\n",
      "max_probe is: tensor(0.1493)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of married is _ .\n",
      "['married', 'divorced', ',', 'and', 'also', 'unmarried', 'single', '', 'or', 'always']\n",
      "tensor([0.6470, 0.0766, 0.0141, 0.0128, 0.0126, 0.0113, 0.0105, 0.0083, 0.0065,\n",
      "        0.0064])\n",
      "{'unmarried': tensor(0.0113)}\n",
      "max_probe is: tensor(0.0113)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of southern is _ .\n",
      "['northern', 'southern', ',', 'western', 'eastern', 'and', 'or', 'southeastern', 'Southern', 'the']\n",
      "tensor([0.3275, 0.1408, 0.1317, 0.0704, 0.0256, 0.0176, 0.0136, 0.0118, 0.0117,\n",
      "        0.0115])\n",
      "{'northern': tensor(0.3275)}\n",
      "max_probe is: tensor(0.3275)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of little is _ .\n",
      "['little', 'small', ',', 'big', 'tiny', 'large', 'and', '.', 'very', 'or']\n",
      "tensor([0.3095, 0.0917, 0.0728, 0.0612, 0.0339, 0.0243, 0.0182, 0.0152, 0.0152,\n",
      "        0.0151])\n",
      "{'big': tensor(0.0612), 'large': tensor(0.0243)}\n",
      "max_probe is: tensor(0.0612)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of available is _ .\n",
      "['available', 'also', 'and', ',', 'called', 'the', 'accessible', 'or', 'found', 'free']\n",
      "tensor([0.4296, 0.0659, 0.0561, 0.0361, 0.0201, 0.0178, 0.0120, 0.0074, 0.0074,\n",
      "        0.0066])\n",
      "{'unavailable': tensor(0.0025)}\n",
      "max_probe is: tensor(0.0025)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 22\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of successful is _ .\n",
      "['successful', ',', 'also', 'unsuccessful', 'and', 'success', 'or', 'positive', 'effective', '']\n",
      "tensor([0.3459, 0.0321, 0.0312, 0.0258, 0.0232, 0.0102, 0.0089, 0.0079, 0.0070,\n",
      "        0.0064])\n",
      "{'unsuccessful': tensor(0.0258)}\n",
      "max_probe is: tensor(0.0258)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of native is _ .\n",
      "['native', ',', 'indigenous', 'natural', 'also', 'wild', 'local', 'cultivated', 'common', 'the']\n",
      "tensor([0.5919, 0.0366, 0.0214, 0.0181, 0.0093, 0.0093, 0.0070, 0.0068, 0.0068,\n",
      "        0.0054])\n",
      "{'foreign': tensor(0.0005)}\n",
      "max_probe is: tensor(0.0005)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 116\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of possible is _ .\n",
      "['possible', 'and', 'also', ',', 'likely', 'or', 'probable', 'possibly', 'always', 'hypothetical']\n",
      "tensor([0.2519, 0.0822, 0.0394, 0.0309, 0.0252, 0.0245, 0.0226, 0.0145, 0.0134,\n",
      "        0.0106])\n",
      "{'impossible': tensor(0.0080)}\n",
      "max_probe is: tensor(0.0080)\n",
      "20\n",
      "the position of max probe is: 13\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of natural is _ .\n",
      "['natural', ',', 'and', 'also', 'naturally', 'normal', 'or', 'Natural', ':', '.']\n",
      "tensor([0.5841, 0.0773, 0.0296, 0.0218, 0.0180, 0.0078, 0.0077, 0.0064, 0.0059,\n",
      "        0.0051])\n",
      "{'unnatural': tensor(0.0020)}\n",
      "max_probe is: tensor(0.0020)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 26\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of strong is _ .\n",
      "['strong', 'weak', 'powerful', ',', 'robust', 'vigorous', 'stronger', 'also', 'strongly', 'hard']\n",
      "tensor([0.6196, 0.1132, 0.0522, 0.0187, 0.0063, 0.0061, 0.0054, 0.0041, 0.0038,\n",
      "        0.0037])\n",
      "{'weak': tensor(0.1132)}\n",
      "max_probe is: tensor(0.1132)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of active is _ .\n",
      "['active', 'passive', 'inactive', 'reactive', 'Active', 'activated', ',', 'energetic', 'dormant', 'also']\n",
      "tensor([0.7613, 0.0427, 0.0380, 0.0118, 0.0113, 0.0090, 0.0086, 0.0055, 0.0033,\n",
      "        0.0030])\n",
      "{'inactive': tensor(0.0380)}\n",
      "max_probe is: tensor(0.0380)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of limited is _ .\n",
      "['limited', 'restricted', 'and', 'also', 'constrained', ',', 'called', 'finite', 'bounded', 'allowed']\n",
      "tensor([0.3704, 0.0458, 0.0207, 0.0205, 0.0181, 0.0177, 0.0109, 0.0109, 0.0093,\n",
      "        0.0077])\n",
      "{'unlimited': tensor(0.0044)}\n",
      "max_probe is: tensor(0.0044)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 24\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of low is _ .\n",
      "['high', 'low', ',', 'also', 'and', 'long', 'C', 'zero', 'positive', 'constant']\n",
      "tensor([0.5173, 0.0798, 0.0362, 0.0128, 0.0105, 0.0100, 0.0068, 0.0057, 0.0044,\n",
      "        0.0044])\n",
      "{'high': tensor(0.5173)}\n",
      "max_probe is: tensor(0.5173)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of foreign is _ .\n",
      "['foreign', 'English', ',', '', 'international', 'American', 'the', 'and', 'native', 'as']\n",
      "tensor([0.1663, 0.0481, 0.0262, 0.0216, 0.0169, 0.0152, 0.0141, 0.0135, 0.0132,\n",
      "        0.0113])\n",
      "{'domestic': tensor(0.0108)}\n",
      "max_probe is: tensor(0.0108)\n",
      "20\n",
      "the position of max probe is: 12\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of related is _ .\n",
      "['called', ',', 'and', 'the', 'also', 'related', 'named', 'or', 'of', '.']\n",
      "tensor([0.1612, 0.1197, 0.0774, 0.0541, 0.0346, 0.0315, 0.0288, 0.0189, 0.0161,\n",
      "        0.0157])\n",
      "{'unrelated': tensor(0.0017)}\n",
      "max_probe is: tensor(0.0017)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 56\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of legal is _ .\n",
      "['legal', 'valid', 'mandatory', 'constitutional', 'criminal', 'medical', 'civil', 'statutory', 'practical', 'just']\n",
      "tensor([0.0810, 0.0218, 0.0168, 0.0161, 0.0159, 0.0143, 0.0109, 0.0109, 0.0092,\n",
      "        0.0092])\n",
      "{'illegal': tensor(0.0082)}\n",
      "max_probe is: tensor(0.0082)\n",
      "20\n",
      "the position of max probe is: 13\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of true is _ .\n",
      "['false', 'true', 'False', 'and', ',', 'also', 'FALSE', 'always', 'truth', 'not']\n",
      "tensor([0.6290, 0.1981, 0.0197, 0.0136, 0.0088, 0.0066, 0.0047, 0.0039, 0.0035,\n",
      "        0.0022])\n",
      "{'false': tensor(0.6290)}\n",
      "max_probe is: tensor(0.6290)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of dead is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'dead', 'alive', 'cold', '.', 'death', 'grave', 'live', '/', 'empty']\n",
      "tensor([0.0809, 0.0653, 0.0496, 0.0442, 0.0402, 0.0145, 0.0134, 0.0118, 0.0117,\n",
      "        0.0115])\n",
      "{'alive': tensor(0.0496)}\n",
      "max_probe is: tensor(0.0496)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of specific is _ .\n",
      "[',', 'and', 'also', 'the', 'pronounced', 'or', '.', ':', '\"', 'called']\n",
      "tensor([0.1566, 0.1117, 0.0415, 0.0275, 0.0216, 0.0202, 0.0194, 0.0125, 0.0110,\n",
      "        0.0103])\n",
      "{'general': tensor(0.0006)}\n",
      "max_probe is: tensor(0.0006)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 179\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of likely is _ .\n",
      "['likely', 'probably', 'definitely', 'and', 'also', 'probable', 'or', 'certainly', 'possibly', 'possible']\n",
      "tensor([0.3331, 0.1056, 0.0481, 0.0309, 0.0270, 0.0258, 0.0254, 0.0251, 0.0201,\n",
      "        0.0194])\n",
      "{'unlikely': tensor(0.0123)}\n",
      "max_probe is: tensor(0.0123)\n",
      "20\n",
      "the position of max probe is: 10\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of difficult is _ .\n",
      "['difficult', 'hard', 'troublesome', 'daunting', 'tricky', 'easy', ',', 'challenging', 'complicated', 'and']\n",
      "tensor([0.1751, 0.0451, 0.0248, 0.0205, 0.0199, 0.0198, 0.0197, 0.0173, 0.0136,\n",
      "        0.0121])\n",
      "{'easy': tensor(0.0198)}\n",
      "max_probe is: tensor(0.0198)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of rural is _ .\n",
      "['rural', 'urban', 'suburban', 'residential', 'agricultural', 'metropolitan', 'industrial', 'commercial', 'city', 'municipal']\n",
      "tensor([0.3243, 0.2559, 0.1232, 0.0342, 0.0197, 0.0096, 0.0078, 0.0042, 0.0041,\n",
      "        0.0036])\n",
      "{'urban': tensor(0.2559)}\n",
      "max_probe is: tensor(0.2559)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of potential is _ .\n",
      "['potential', 'and', 'also', ',', 'probability', 'always', 'or', 'power', '=', 'simply']\n",
      "tensor([0.1186, 0.0934, 0.0598, 0.0294, 0.0234, 0.0114, 0.0101, 0.0091, 0.0088,\n",
      "        0.0073])\n",
      "{'actual': tensor(0.0004)}\n",
      "max_probe is: tensor(0.0004)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 307\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of necessary is _ .\n",
      "['necessary', 'required', 'needed', 'also', 'and', 'sufficient', 'always', ',', 'need', 'obligatory']\n",
      "tensor([0.2568, 0.0630, 0.0582, 0.0450, 0.0308, 0.0268, 0.0214, 0.0168, 0.0141,\n",
      "        0.0101])\n",
      "{'unnecessary': tensor(0.0068)}\n",
      "max_probe is: tensor(0.0068)\n",
      "20\n",
      "the position of max probe is: 14\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nuclear is _ .\n",
      "['electron', 'gamma', 'nuclear', 'atomic', 'and', ',', 'electric', 'radioactive', 'electromagnetic', 'positive']\n",
      "tensor([0.1650, 0.0832, 0.0690, 0.0284, 0.0241, 0.0190, 0.0183, 0.0140, 0.0133,\n",
      "        0.0133])\n",
      "{'conventional': tensor(0.0009)}\n",
      "max_probe is: tensor(0.0009)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 118\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unable is _ .\n",
      "[',', 'and', 'also', '.', 'the', 'or', ':', 'pronounced', '=', '']\n",
      "tensor([0.1076, 0.0775, 0.0713, 0.0229, 0.0221, 0.0201, 0.0156, 0.0149, 0.0135,\n",
      "        0.0133])\n",
      "{'able': tensor(9.1375e-06)}\n",
      "max_probe is: tensor(9.1375e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "the position of max probe is: 5064\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of bad is _ .\n",
      "['good', 'bad', 'evil', 'ugly', 'worse', 'terrible', 'awful', 'great', ',', 'excellent']\n",
      "tensor([0.3725, 0.1941, 0.0870, 0.0216, 0.0139, 0.0104, 0.0095, 0.0079, 0.0073,\n",
      "        0.0063])\n",
      "{'good': tensor(0.3725)}\n",
      "max_probe is: tensor(0.3725)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of positive is _ .\n",
      "['negative', 'positive', 'minus', 'and', ',', 'neutral', 'Negative', 'or', '+', 'constant']\n",
      "tensor([0.7718, 0.1307, 0.0116, 0.0098, 0.0080, 0.0026, 0.0022, 0.0021, 0.0019,\n",
      "        0.0017])\n",
      "{'negative': tensor(0.7718)}\n",
      "max_probe is: tensor(0.7718)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of internal is _ .\n",
      "['internal', 'external', ',', 'and', 'internally', 'or', 'integral', 'also', 'negative', 'exterior']\n",
      "tensor([0.3817, 0.3421, 0.0345, 0.0195, 0.0145, 0.0048, 0.0047, 0.0047, 0.0039,\n",
      "        0.0038])\n",
      "{'external': tensor(0.3421)}\n",
      "max_probe is: tensor(0.3421)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of effective is _ .\n",
      "['effective', ',', 'also', 'and', 'active', 'equivalent', 'effectively', 'efficient', 'potent', 'or']\n",
      "tensor([0.5539, 0.0387, 0.0266, 0.0162, 0.0131, 0.0120, 0.0111, 0.0101, 0.0081,\n",
      "        0.0079])\n",
      "{'ineffective': tensor(0.0008)}\n",
      "max_probe is: tensor(0.0008)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 83\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of actual is _ .\n",
      "['actual', 'real', 'and', ',', 'actually', 'also', 'nominal', 'practical', 'exact', 'the']\n",
      "tensor([0.3438, 0.0747, 0.0483, 0.0264, 0.0245, 0.0169, 0.0144, 0.0124, 0.0124,\n",
      "        0.0105])\n",
      "{'potential': tensor(0.0015)}\n",
      "max_probe is: tensor(0.0015)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 52\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of domestic is _ .\n",
      "['domestic', 'foreign', 'international', 'Domestic', ',', 'and', 'commercial', 'English', 'plural', 'masculine']\n",
      "tensor([0.3907, 0.0351, 0.0258, 0.0251, 0.0205, 0.0174, 0.0116, 0.0109, 0.0100,\n",
      "        0.0097])\n",
      "{'foreign': tensor(0.0351)}\n",
      "max_probe is: tensor(0.0351)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of formal is _ .\n",
      "['formal', 'informal', 'nominal', 'formally', 'procedural', ',', 'explicit', 'functional', 'simple', 'verbal']\n",
      "tensor([0.6377, 0.1778, 0.0091, 0.0087, 0.0048, 0.0036, 0.0027, 0.0026, 0.0023,\n",
      "        0.0023])\n",
      "{'informal': tensor(0.1778)}\n",
      "max_probe is: tensor(0.1778)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of external is _ .\n",
      "['external', 'internal', ',', 'and', 'External', 'also', 'externally', 'internally', 'physical', 'positive']\n",
      "tensor([0.6081, 0.1034, 0.0523, 0.0142, 0.0136, 0.0094, 0.0052, 0.0050, 0.0041,\n",
      "        0.0038])\n",
      "{'internal': tensor(0.1034)}\n",
      "max_probe is: tensor(0.1034)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of capable is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['also', ',', 'and', 'the', 'called', '.', '', 'or', ':', 'named']\n",
      "tensor([0.0729, 0.0550, 0.0315, 0.0278, 0.0239, 0.0148, 0.0126, 0.0101, 0.0075,\n",
      "        0.0070])\n",
      "{'incapable': tensor(2.6825e-05)}\n",
      "max_probe is: tensor(2.6825e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "the position of max probe is: 3261\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of easy is _ .\n",
      "['easy', 'simple', 'hard', 'difficult', 'straightforward', 'convenient', 'fast', 'accessible', 'free', 'flexible']\n",
      "tensor([0.1724, 0.0771, 0.0568, 0.0439, 0.0329, 0.0209, 0.0163, 0.0128, 0.0106,\n",
      "        0.0081])\n",
      "{'difficult': tensor(0.0439)}\n",
      "max_probe is: tensor(0.0439)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of affected is _ .\n",
      "[',', 'and', 'also', 'called', '.', 'the', 'pronounced', 'written', 'or', ':']\n",
      "tensor([0.1132, 0.1126, 0.0772, 0.0262, 0.0208, 0.0202, 0.0193, 0.0155, 0.0142,\n",
      "        0.0140])\n",
      "{'unaffected': tensor(6.5168e-06)}\n",
      "max_probe is: tensor(6.5168e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "10240\n",
      "the position of max probe is: 5297\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of experienced is _ .\n",
      "['experienced', 'called', ',', '.', 'also', 'learned', 'the', 'and', '', 'named']\n",
      "tensor([0.0659, 0.0279, 0.0203, 0.0164, 0.0154, 0.0143, 0.0124, 0.0122, 0.0119,\n",
      "        0.0097])\n",
      "{'inexperienced': tensor(0.0004)}\n",
      "max_probe is: tensor(0.0004)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 432\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unusual is _ .\n",
      "['unusual', 'rare', 'uncommon', 'exceptional', 'extraordinary', 'odd', 'peculiar', 'unique', 'bizarre', 'strange']\n",
      "tensor([0.2841, 0.1163, 0.0458, 0.0408, 0.0368, 0.0354, 0.0345, 0.0215, 0.0173,\n",
      "        0.0166])\n",
      "{'usual': tensor(0.0015)}\n",
      "max_probe is: tensor(0.0015)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 48\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of safe is _ .\n",
      "['safe', 'secure', 'prudent', 'reliable', 'good', 'sound', 'cautious', 'sane', 'neutral', 'strong']\n",
      "tensor([0.0945, 0.0733, 0.0595, 0.0468, 0.0238, 0.0210, 0.0138, 0.0121, 0.0117,\n",
      "        0.0110])\n",
      "{'dangerous': tensor(0.0004)}\n",
      "max_probe is: tensor(0.0004)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 274\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of visible is _ .\n",
      "['visible', 'invisible', 'also', 'and', ',', 'infrared', 'seen', 'red', 'audible', 'white']\n",
      "tensor([0.4802, 0.0446, 0.0207, 0.0196, 0.0187, 0.0152, 0.0128, 0.0126, 0.0119,\n",
      "        0.0114])\n",
      "{'invisible': tensor(0.0446)}\n",
      "max_probe is: tensor(0.0446)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of instrumental is _ .\n",
      "['instrumental', 'vocal', ',', 'piano', 'musical', 'and', 'the', 'also', 'pronounced', 'bass']\n",
      "tensor([0.1061, 0.1041, 0.0520, 0.0291, 0.0206, 0.0176, 0.0152, 0.0151, 0.0109,\n",
      "        0.0091])\n",
      "{'vocal': tensor(0.1041)}\n",
      "max_probe is: tensor(0.1041)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of illegal is _ .\n",
      "['illegal', 'legal', 'lawful', 'unlawful', 'criminal', 'illicit', 'forbidden', 'prohibited', 'obscene', 'unethical']\n",
      "tensor([0.3331, 0.1147, 0.0328, 0.0306, 0.0258, 0.0150, 0.0118, 0.0093, 0.0090,\n",
      "        0.0078])\n",
      "{'legal': tensor(0.1147)}\n",
      "max_probe is: tensor(0.1147)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of vocal is _ .\n",
      "['vocal', 'voiced', ',', 'voice', 'nasal', 'verbal', 'pronounced', 'or', 'also', 'and']\n",
      "tensor([0.2300, 0.0691, 0.0615, 0.0304, 0.0274, 0.0196, 0.0168, 0.0157, 0.0152,\n",
      "        0.0149])\n",
      "{'instrumental': tensor(0.0016)}\n",
      "max_probe is: tensor(0.0016)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 51\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of alive is _ .\n",
      "['alive', 'live', 'active', 'living', ',', 'also', 'life', 'healthy', 'dead', 'and']\n",
      "tensor([0.2040, 0.0679, 0.0558, 0.0459, 0.0247, 0.0149, 0.0121, 0.0106, 0.0101,\n",
      "        0.0100])\n",
      "{'dead': tensor(0.0101)}\n",
      "max_probe is: tensor(0.0101)\n",
      "the position of max probe is: 8\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of civilian is _ .\n",
      "['civilian', 'military', 'civil', ',', 'the', 'professional', 'public', ';', '', '.']\n",
      "tensor([0.0976, 0.0661, 0.0465, 0.0285, 0.0151, 0.0132, 0.0102, 0.0091, 0.0088,\n",
      "        0.0083])\n",
      "{'military': tensor(0.0661)}\n",
      "max_probe is: tensor(0.0661)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of conventional is _ .\n",
      "['conventional', ',', 'also', 'standard', 'and', 'the', ':', 'nominal', '', 'called']\n",
      "tensor([0.2234, 0.0508, 0.0316, 0.0278, 0.0277, 0.0206, 0.0134, 0.0116, 0.0113,\n",
      "        0.0107])\n",
      "{'unconventional': tensor(0.0039)}\n",
      "max_probe is: tensor(0.0039)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 22\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unsuccessful is _ .\n",
      "[',', 'also', 'and', '.', 'or', ':', 'the', '', 'called', 'pronounced']\n",
      "tensor([0.0889, 0.0668, 0.0602, 0.0165, 0.0149, 0.0145, 0.0132, 0.0116, 0.0114,\n",
      "        0.0082])\n",
      "{'successful': tensor(0.0032)}\n",
      "max_probe is: tensor(0.0032)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 31\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of false is _ .\n",
      "['true', 'false', 'False', 'truth', 'True', 'correct', ',', 'and', 'accurate', 'misleading']\n",
      "tensor([0.5795, 0.2863, 0.0065, 0.0063, 0.0061, 0.0055, 0.0042, 0.0034, 0.0031,\n",
      "        0.0023])\n",
      "{'true': tensor(0.5795)}\n",
      "max_probe is: tensor(0.5795)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of soft is _ .\n",
      "['soft', 'hard', 'smooth', ',', 'firm', 'strong', 'thick', 'flexible', 'coarse', 'weak']\n",
      "tensor([0.4652, 0.0666, 0.0273, 0.0203, 0.0191, 0.0136, 0.0131, 0.0121, 0.0119,\n",
      "        0.0116])\n",
      "{'hard': tensor(0.0666)}\n",
      "max_probe is: tensor(0.0666)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of stable is _ .\n",
      "['stable', 'unstable', ',', 'steady', 'stabilized', 'and', 'solid', 'constant', 'also', 'fixed']\n",
      "tensor([0.6398, 0.0344, 0.0202, 0.0148, 0.0135, 0.0131, 0.0125, 0.0107, 0.0102,\n",
      "        0.0100])\n",
      "{'unstable': tensor(0.0344)}\n",
      "max_probe is: tensor(0.0344)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of usual is _ .\n",
      "['also', ',', 'usual', 'called', 'usually', 'and', '', 'always', 'normal', 'the']\n",
      "tensor([0.0550, 0.0441, 0.0407, 0.0358, 0.0281, 0.0268, 0.0228, 0.0220, 0.0174,\n",
      "        0.0166])\n",
      "{'unusual': tensor(0.0043)}\n",
      "max_probe is: tensor(0.0043)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 33\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of impossible is _ .\n",
      "['impossible', 'improbable', 'possible', 'and', 'absurd', 'unthinkable', 'always', 'not', 'infinite', 'or']\n",
      "tensor([0.3483, 0.0600, 0.0480, 0.0254, 0.0246, 0.0136, 0.0112, 0.0091, 0.0085,\n",
      "        0.0084])\n",
      "{'possible': tensor(0.0480)}\n",
      "max_probe is: tensor(0.0480)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of endemic is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['endemic', ',', 'or', '.', 'the', ':', 'in', ';', 'also', 'rare']\n",
      "tensor([0.1863, 0.0598, 0.0261, 0.0239, 0.0194, 0.0177, 0.0139, 0.0125, 0.0109,\n",
      "        0.0108])\n",
      "{'epidemic': tensor(0.0006)}\n",
      "max_probe is: tensor(0.0006)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 178\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of ordinary is _ .\n",
      "['ordinary', 'normal', ',', 'also', 'and', 'regular', 'special', 'simply', 'called', 'just']\n",
      "tensor([0.2907, 0.0493, 0.0350, 0.0315, 0.0306, 0.0290, 0.0234, 0.0122, 0.0115,\n",
      "        0.0115])\n",
      "{'extraordinary': tensor(0.0045)}\n",
      "max_probe is: tensor(0.0045)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 25\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of vertical is _ .\n",
      "['horizontal', 'vertical', 'diagonal', 'horizontally', ',', 'linear', 'and', 'also', 'negative', 'square']\n",
      "tensor([0.7749, 0.0412, 0.0352, 0.0155, 0.0091, 0.0069, 0.0067, 0.0052, 0.0041,\n",
      "        0.0028])\n",
      "{'inclined': tensor(2.4626e-05)}\n",
      "max_probe is: tensor(2.4626e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 526\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of automatic is _ .\n",
      "['automatic', 'manual', 'auto', 'Automatic', 'automated', ',', 'active', 'linear', 'and', 'electric']\n",
      "tensor([0.3154, 0.0719, 0.0192, 0.0149, 0.0126, 0.0124, 0.0121, 0.0116, 0.0115,\n",
      "        0.0108])\n",
      "{'manual': tensor(0.0719)}\n",
      "max_probe is: tensor(0.0719)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of weak is _ .\n",
      "['weak', 'strong', ',', 'weaker', 'also', 'Weak', 'powerful', 'and', 'short', '.']\n",
      "tensor([0.7523, 0.0853, 0.0150, 0.0057, 0.0045, 0.0033, 0.0031, 0.0025, 0.0023,\n",
      "        0.0021])\n",
      "{'strong': tensor(0.0853)}\n",
      "max_probe is: tensor(0.0853)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of accessible is _ .\n",
      "['accessible', 'also', ',', 'the', 'and', 'called', '.', 'now', 'named', 'available']\n",
      "tensor([0.0842, 0.0474, 0.0394, 0.0355, 0.0345, 0.0228, 0.0131, 0.0101, 0.0097,\n",
      "        0.0090])\n",
      "{'inaccessible': tensor(0.0020)}\n",
      "max_probe is: tensor(0.0020)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 58\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of artificial is _ .\n",
      "['artificial', 'natural', 'synthetic', ',', 'and', 'also', 'real', 'the', 'exact', 'chemical']\n",
      "tensor([0.2521, 0.1158, 0.0659, 0.0341, 0.0282, 0.0184, 0.0110, 0.0073, 0.0071,\n",
      "        0.0067])\n",
      "{'natural': tensor(0.1158)}\n",
      "max_probe is: tensor(0.1158)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of empty is _ .\n",
      "['empty', 'void', 'zero', 'also', 'and', 'not', 'null', 'vacant', '', 'blank']\n",
      "tensor([0.3414, 0.1015, 0.0140, 0.0134, 0.0124, 0.0121, 0.0120, 0.0117, 0.0112,\n",
      "        0.0111])\n",
      "{'full': tensor(0.0067)}\n",
      "max_probe is: tensor(0.0067)\n",
      "20\n",
      "the position of max probe is: 13\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of emotional is _ .\n",
      "['motivational', 'emotional', 'positive', 'mental', 'passionate', 'rational', 'cognitive', 'psychological', 'sympathetic', 'pragmatic']\n",
      "tensor([0.0521, 0.0361, 0.0242, 0.0197, 0.0186, 0.0153, 0.0151, 0.0146, 0.0143,\n",
      "        0.0143])\n",
      "{'cerebral': tensor(0.0049)}\n",
      "max_probe is: tensor(0.0049)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 29\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of theoretical is _ .\n",
      "['theoretical', ',', 'and', 'the', 'of', 'also', 'always', ':', 'called', '.']\n",
      "tensor([0.0570, 0.0530, 0.0414, 0.0378, 0.0282, 0.0245, 0.0158, 0.0139, 0.0138,\n",
      "        0.0136])\n",
      "{'empirical': tensor(0.0024)}\n",
      "max_probe is: tensor(0.0024)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 74\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of eligible is _ .\n",
      "[',', 'and', 'also', '.', 'the', '=', 'or', 'k', ':', '']\n",
      "tensor([0.0528, 0.0328, 0.0317, 0.0269, 0.0161, 0.0143, 0.0130, 0.0122, 0.0104,\n",
      "        0.0096])\n",
      "{'ineligible': tensor(1.1772e-06)}\n",
      "max_probe is: tensor(1.1772e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "10240\n",
      "20480\n",
      "40960\n",
      "the position of max probe is: 20639\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of valid is _ .\n",
      "['valid', 'invalid', ',', 'validated', 'and', 'also', 'correct', 'positive', 'not', 'good']\n",
      "tensor([0.8137, 0.0119, 0.0050, 0.0049, 0.0044, 0.0042, 0.0037, 0.0030, 0.0022,\n",
      "        0.0021])\n",
      "{'invalid': tensor(0.0119)}\n",
      "max_probe is: tensor(0.0119)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of extraordinary is _ .\n",
      "['exceptional', 'extraordinary', 'remarkable', 'extreme', 'unusual', 'rare', 'special', 'phenomenal', 'uncommon', 'astounding']\n",
      "tensor([0.3536, 0.2203, 0.0564, 0.0202, 0.0198, 0.0172, 0.0136, 0.0129, 0.0114,\n",
      "        0.0114])\n",
      "{'ordinary': tensor(0.0065)}\n",
      "max_probe is: tensor(0.0065)\n",
      "20\n",
      "the position of max probe is: 16\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of busy is _ .\n",
      "['busy', 'frantic', 'bustling', 'cheerful', 'impatient', 'noisy', 'productive', 'energetic', 'active', 'hyper']\n",
      "tensor([0.1311, 0.0257, 0.0203, 0.0171, 0.0132, 0.0128, 0.0119, 0.0116, 0.0113,\n",
      "        0.0104])\n",
      "{'idle': tensor(0.0076)}\n",
      "max_probe is: tensor(0.0076)\n",
      "20\n",
      "the position of max probe is: 13\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of reliable is _ .\n",
      "['reliable', 'unreliable', 'trustworthy', 'accurate', 'reliability', ',', 'secure', 'also', 'safe', 'stable']\n",
      "tensor([0.6047, 0.0307, 0.0252, 0.0188, 0.0075, 0.0071, 0.0070, 0.0068, 0.0059,\n",
      "        0.0056])\n",
      "{'unreliable': tensor(0.0307)}\n",
      "max_probe is: tensor(0.0307)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of sudden is _ .\n",
      "['also', ',', 'and', 'pronounced', '.', 'the', 'or', '', ':', 'always']\n",
      "tensor([0.0936, 0.0841, 0.0732, 0.0327, 0.0226, 0.0195, 0.0148, 0.0139, 0.0126,\n",
      "        0.0099])\n",
      "{'gradual': tensor(7.5666e-05)}\n",
      "max_probe is: tensor(7.5666e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 1091\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unlikely is _ .\n",
      "['likely', 'unlikely', 'improbable', 'probably', 'also', 'possible', 'and', 'rare', 'probable', 'unlucky']\n",
      "tensor([0.1103, 0.0903, 0.0633, 0.0269, 0.0262, 0.0219, 0.0189, 0.0184, 0.0178,\n",
      "        0.0133])\n",
      "{'probable': tensor(0.0178)}\n",
      "max_probe is: tensor(0.0178)\n",
      "the position of max probe is: 8\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of voluntary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['voluntary', 'mandatory', 'compulsory', 'optional', 'involuntary', 'obligatory', 'free', 'volunteer', 'conscientious', 'voluntarily']\n",
      "tensor([0.3902, 0.0899, 0.0855, 0.0283, 0.0211, 0.0194, 0.0161, 0.0113, 0.0097,\n",
      "        0.0060])\n",
      "{'involuntary': tensor(0.0211)}\n",
      "max_probe is: tensor(0.0211)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of informal is _ .\n",
      "['formal', 'informal', 'casual', 'polite', 'direct', 'relaxed', 'professional', 'formally', 'explicit', 'practical']\n",
      "tensor([0.4320, 0.4062, 0.0233, 0.0082, 0.0041, 0.0040, 0.0023, 0.0019, 0.0017,\n",
      "        0.0016])\n",
      "{'formal': tensor(0.4320)}\n",
      "max_probe is: tensor(0.4320)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of reasonable is _ .\n",
      "['reasonable', 'prudent', 'pragmatic', 'just', 'practical', 'rational', 'sensible', 'appropriate', 'generous', 'adequate']\n",
      "tensor([0.1225, 0.0354, 0.0291, 0.0221, 0.0180, 0.0177, 0.0165, 0.0158, 0.0137,\n",
      "        0.0127])\n",
      "{'unreasonable': tensor(0.0047)}\n",
      "max_probe is: tensor(0.0047)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 27\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of sophisticated is _ .\n",
      "['simple', 'powerful', 'efficient', 'robust', 'dynamic', 'the', ',', '.', 'sophisticated', 'and']\n",
      "tensor([0.0201, 0.0140, 0.0122, 0.0114, 0.0105, 0.0101, 0.0098, 0.0092, 0.0086,\n",
      "        0.0081])\n",
      "{'naive': tensor(0.0006)}\n",
      "max_probe is: tensor(0.0006)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 299\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of compatible is _ .\n",
      "[',', 'and', 'also', 'called', 'written', 'the', '.', '', '=', ':']\n",
      "tensor([0.1187, 0.0914, 0.0866, 0.0243, 0.0152, 0.0152, 0.0140, 0.0132, 0.0126,\n",
      "        0.0119])\n",
      "{'incompatible': tensor(2.5543e-06)}\n",
      "max_probe is: tensor(2.5543e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "10240\n",
      "the position of max probe is: 8683\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of acceptable is _ .\n",
      "['acceptable', 'good', 'satisfactory', 'excellent', 'adequate', 'reasonable', 'unacceptable', 'appropriate', 'desirable', 'sufficient']\n",
      "tensor([0.2171, 0.0412, 0.0355, 0.0313, 0.0307, 0.0225, 0.0206, 0.0171, 0.0161,\n",
      "        0.0111])\n",
      "{'unacceptable': tensor(0.0206)}\n",
      "max_probe is: tensor(0.0206)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of comfortable is _ .\n",
      "['comfortable', 'relaxed', 'convenient', 'calm', 'flexible', 'easy', 'pleasant', 'safe', 'confident', 'cool']\n",
      "tensor([0.2359, 0.0881, 0.0187, 0.0176, 0.0163, 0.0158, 0.0156, 0.0151, 0.0122,\n",
      "        0.0117])\n",
      "{'uncomfortable': tensor(0.0102)}\n",
      "max_probe is: tensor(0.0102)\n",
      "20\n",
      "the position of max probe is: 12\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uncommon is _ .\n",
      "['rare', 'uncommon', 'common', 'unusual', ',', 'special', 'unique', 'scarce', 'exceptional', '']\n",
      "tensor([0.6636, 0.1213, 0.0754, 0.0187, 0.0063, 0.0036, 0.0030, 0.0027, 0.0022,\n",
      "        0.0019])\n",
      "{'common': tensor(0.0754)}\n",
      "max_probe is: tensor(0.0754)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of rational is _ .\n",
      "['rational', 'irrational', 'analytic', 'and', 'linear', ',', 'exponential', 'arithmetic', 'logical', 'also']\n",
      "tensor([0.3106, 0.1007, 0.0226, 0.0204, 0.0182, 0.0145, 0.0136, 0.0094, 0.0072,\n",
      "        0.0067])\n",
      "{'irrational': tensor(0.1007)}\n",
      "max_probe is: tensor(0.1007)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of supernatural is _ .\n",
      "['supernatural', ',', 'the', 'and', 'spiritual', 'or', 'psychic', 'fictional', 'real', 'extraordinary']\n",
      "tensor([0.2463, 0.0346, 0.0271, 0.0255, 0.0243, 0.0183, 0.0154, 0.0113, 0.0110,\n",
      "        0.0100])\n",
      "{'natural': tensor(0.0051)}\n",
      "max_probe is: tensor(0.0051)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 24\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unrelated is _ .\n",
      "['and', ',', 'the', 'also', 'equivalent', '.', 'or', 'similar', 'called', 'identical']\n",
      "tensor([0.0771, 0.0448, 0.0348, 0.0263, 0.0239, 0.0221, 0.0207, 0.0176, 0.0141,\n",
      "        0.0138])\n",
      "{'related': tensor(0.0082)}\n",
      "max_probe is: tensor(0.0082)\n",
      "20\n",
      "the position of max probe is: 16\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unconscious is _ .\n",
      "['unconscious', 'conscious', ',', 'sleep', 'also', 'silent', 'the', ';', 'and', 'implicit']\n",
      "tensor([0.0989, 0.0603, 0.0514, 0.0327, 0.0292, 0.0206, 0.0181, 0.0172, 0.0153,\n",
      "        0.0137])\n",
      "{'conscious': tensor(0.0603)}\n",
      "max_probe is: tensor(0.0603)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of homosexual is _ .\n",
      "['heterosexual', 'bisexual', ',', 'masculine', 'gay', 'and', 'queer', 'homosexual', 'or', 'lesbian']\n",
      "tensor([0.2354, 0.1934, 0.0870, 0.0550, 0.0449, 0.0435, 0.0306, 0.0301, 0.0167,\n",
      "        0.0158])\n",
      "{'bisexual': tensor(0.1934)}\n",
      "max_probe is: tensor(0.1934)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of invisible is _ .\n",
      "['invisible', 'visible', 'transparent', 'translucent', 'black', 'white', 'silent', 'invis', 'hidden', ',']\n",
      "tensor([0.2755, 0.1812, 0.1339, 0.0127, 0.0103, 0.0088, 0.0084, 0.0082, 0.0078,\n",
      "        0.0075])\n",
      "{'visible': tensor(0.1812)}\n",
      "max_probe is: tensor(0.1812)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of induced is _ .\n",
      "['induced', 'and', ',', 'also', 'written', 'in', 'of', 'called', 'or', 'the']\n",
      "tensor([0.2749, 0.0529, 0.0349, 0.0306, 0.0132, 0.0095, 0.0082, 0.0077, 0.0076,\n",
      "        0.0076])\n",
      "{'spontaneous': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0002)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 438\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unlimited is _ .\n",
      "['unlimited', 'infinite', 'finite', 'indefinite', 'Unlimited', 'limitless', 'limited', 'free', 'and', 'also']\n",
      "tensor([0.3561, 0.1018, 0.0680, 0.0492, 0.0176, 0.0172, 0.0154, 0.0146, 0.0104,\n",
      "        0.0065])\n",
      "{'limited': tensor(0.0154)}\n",
      "max_probe is: tensor(0.0154)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of incredible is _ .\n",
      "['amazing', 'awesome', 'extraordinary', 'incredible', 'remarkable', 'exceptional', 'astounding', 'astonishing', 'magnificent', 'phenomenal']\n",
      "tensor([0.1424, 0.0637, 0.0562, 0.0454, 0.0321, 0.0313, 0.0271, 0.0261, 0.0252,\n",
      "        0.0230])\n",
      "{'credible': tensor(3.5101e-05)}\n",
      "max_probe is: tensor(3.5101e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 1005\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unstable is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unstable', 'stable', 'volatile', ',', 'dynamic', 'and', 'constant', 'free', 'flexible', 'weak']\n",
      "tensor([0.5047, 0.1766, 0.0639, 0.0091, 0.0055, 0.0054, 0.0035, 0.0034, 0.0033,\n",
      "        0.0032])\n",
      "{'stable': tensor(0.1766)}\n",
      "max_probe is: tensor(0.1766)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unhappy is _ .\n",
      "['happy', 'cheerful', 'sad', 'positive', 'joyful', 'unhappy', 'excited', 'depressed', ',', '.']\n",
      "tensor([0.1188, 0.0575, 0.0366, 0.0361, 0.0216, 0.0216, 0.0199, 0.0179, 0.0161,\n",
      "        0.0131])\n",
      "{'happy': tensor(0.1188)}\n",
      "max_probe is: tensor(0.1188)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of gradual is _ .\n",
      "[',', 'also', 'linear', 'and', 'smooth', 'constant', 'exponential', '.', ':', 'the']\n",
      "tensor([0.0852, 0.0586, 0.0480, 0.0397, 0.0231, 0.0148, 0.0130, 0.0112, 0.0109,\n",
      "        0.0093])\n",
      "{'sudden': tensor(3.5478e-05)}\n",
      "max_probe is: tensor(3.5478e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "the position of max probe is: 1986\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unpopular is _ .\n",
      "['unpopular', 'popular', 'controversial', 'disliked', ',', 'unacceptable', 'unfortunate', '', 'annoying', 'disappointing']\n",
      "tensor([0.2234, 0.1361, 0.0283, 0.0176, 0.0105, 0.0085, 0.0074, 0.0073, 0.0059,\n",
      "        0.0053])\n",
      "{'popular': tensor(0.1361)}\n",
      "max_probe is: tensor(0.1361)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of epidemic is _ .\n",
      "['epidemic', 'influenza', 'disease', 'plague', 'and', 'infection', 'or', 'diarrhea', 'also', 'the']\n",
      "tensor([0.1808, 0.0370, 0.0313, 0.0206, 0.0163, 0.0148, 0.0141, 0.0105, 0.0100,\n",
      "        0.0094])\n",
      "{'endemic': tensor(0.0022)}\n",
      "max_probe is: tensor(0.0022)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 49\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unnecessary is _ .\n",
      "['unnecessary', 'necessary', 'optional', 'redundant', 'also', 'needed', 'and', 'insufficient', 'the', 'irrelevant']\n",
      "tensor([0.1641, 0.0531, 0.0235, 0.0234, 0.0164, 0.0160, 0.0138, 0.0128, 0.0114,\n",
      "        0.0109])\n",
      "{'necessary': tensor(0.0531)}\n",
      "max_probe is: tensor(0.0531)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of empirical is _ .\n",
      "['empirical', 'statistical', 'quantitative', 'experimental', 'theoretical', 'approximate', 'systematic', 'observational', 'scientific', 'exact']\n",
      "tensor([0.3406, 0.0388, 0.0358, 0.0338, 0.0148, 0.0124, 0.0124, 0.0115, 0.0105,\n",
      "        0.0098])\n",
      "{'theoretical': tensor(0.0148)}\n",
      "max_probe is: tensor(0.0148)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of peripheral is _ .\n",
      "['peripheral', 'central', 'medial', 'and', 'the', 'right', ',', 'visual', 'dental', 'radial']\n",
      "tensor([0.1192, 0.0648, 0.0243, 0.0208, 0.0163, 0.0145, 0.0133, 0.0123, 0.0117,\n",
      "        0.0116])\n",
      "{'central': tensor(0.0648)}\n",
      "max_probe is: tensor(0.0648)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unwilling is _ .\n",
      "['unwilling', 'willing', 'reluctant', 'and', 'also', 'available', 'not', ',', 'the', 'voluntary']\n",
      "tensor([0.2030, 0.1308, 0.0242, 0.0193, 0.0172, 0.0158, 0.0133, 0.0083, 0.0078,\n",
      "        0.0077])\n",
      "{'willing': tensor(0.1308)}\n",
      "max_probe is: tensor(0.1308)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of spontaneous is _ .\n",
      "['spontaneous', 'and', ',', 'also', 'called', 'the', 'or', 'reactive', 'free', 'pronounced']\n",
      "tensor([0.0797, 0.0595, 0.0509, 0.0380, 0.0169, 0.0150, 0.0126, 0.0112, 0.0090,\n",
      "        0.0077])\n",
      "{'induced': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0003)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 474\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inexpensive is _ .\n",
      "['cheap', ',', 'also', 'inexpensive', 'and', 'the', 'short', 'expensive', 'economical', '']\n",
      "tensor([0.0369, 0.0355, 0.0352, 0.0238, 0.0198, 0.0188, 0.0173, 0.0171, 0.0104,\n",
      "        0.0102])\n",
      "{'expensive': tensor(0.0171)}\n",
      "max_probe is: tensor(0.0171)\n",
      "the position of max probe is: 7\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unavailable is _ .\n",
      "['available', 'unavailable', 'also', 'and', ',', 'called', 'the', 'accessible', 'rare', 'used']\n",
      "tensor([0.1764, 0.0803, 0.0407, 0.0187, 0.0150, 0.0120, 0.0083, 0.0083, 0.0080,\n",
      "        0.0079])\n",
      "{'available': tensor(0.1764)}\n",
      "max_probe is: tensor(0.1764)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of ineffective is _ .\n",
      "['effective', 'ineffective', 'efficient', 'inefficient', ',', 'and', 'effectively', 'also', 'inactive', 'or']\n",
      "tensor([0.2800, 0.1480, 0.0320, 0.0261, 0.0184, 0.0161, 0.0135, 0.0126, 0.0077,\n",
      "        0.0076])\n",
      "{'effective': tensor(0.2800)}\n",
      "max_probe is: tensor(0.2800)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of cerebral is _ .\n",
      "['cerebral', 'cardiac', 'the', 'and', ',', 'polar', 'cubic', 'central', 'magnetic', 'or']\n",
      "tensor([0.5858, 0.0180, 0.0156, 0.0107, 0.0106, 0.0104, 0.0097, 0.0087, 0.0075,\n",
      "        0.0068])\n",
      "{'emotional': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0002)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 333\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of invalid is _ .\n",
      "['invalid', 'valid', 'null', 'void', 'positive', 'undefined', 'and', 'negative', 'not', 'empty']\n",
      "tensor([0.4216, 0.2454, 0.0253, 0.0163, 0.0054, 0.0053, 0.0039, 0.0036, 0.0034,\n",
      "        0.0033])\n",
      "{'valid': tensor(0.2454)}\n",
      "max_probe is: tensor(0.2454)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unconstitutional is _ .\n",
      "['constitutional', 'unconstitutional', 'illegal', 'Constitutional', 'null', 'statutory', 'unlawful', 'just', 'void', 'equal']\n",
      "tensor([0.1778, 0.1051, 0.1044, 0.0379, 0.0289, 0.0199, 0.0137, 0.0123, 0.0118,\n",
      "        0.0117])\n",
      "{'constitutional': tensor(0.1778)}\n",
      "max_probe is: tensor(0.1778)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of abnormal is _ .\n",
      "['abnormal', 'normal', 'pathological', 'unusual', 'extreme', 'rare', 'exceptional', 'bizarre', 'irregular', 'extraordinary']\n",
      "tensor([0.4192, 0.2012, 0.0197, 0.0159, 0.0123, 0.0113, 0.0085, 0.0077, 0.0076,\n",
      "        0.0076])\n",
      "{'normal': tensor(0.2012)}\n",
      "max_probe is: tensor(0.2012)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unmarried is _ .\n",
      "['unmarried', 'married', 'divorced', 'single', 'and', 'unemployed', ',', 'open', '/', 'alone']\n",
      "tensor([0.3645, 0.2137, 0.1128, 0.0312, 0.0085, 0.0084, 0.0084, 0.0072, 0.0070,\n",
      "        0.0062])\n",
      "{'married': tensor(0.2137)}\n",
      "max_probe is: tensor(0.2137)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of idle is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['idle', 'and', 'active', ',', 'inactive', 'lazy', 'called', 'sleep', 'id', 'also']\n",
      "tensor([0.3746, 0.0233, 0.0211, 0.0199, 0.0158, 0.0157, 0.0148, 0.0147, 0.0123,\n",
      "        0.0117])\n",
      "{'busy': tensor(0.0102)}\n",
      "max_probe is: tensor(0.0102)\n",
      "20\n",
      "the position of max probe is: 10\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of bisexual is _ .\n",
      "['bisexual', 'homosexual', 'gay', 'lesbian', 'queer', 'transgender', 'anal', 'and', 'heterosexual', 'LGBT']\n",
      "tensor([0.1967, 0.0758, 0.0635, 0.0426, 0.0382, 0.0297, 0.0198, 0.0195, 0.0191,\n",
      "        0.0166])\n",
      "{'heterosexual': tensor(0.0191)}\n",
      "max_probe is: tensor(0.0191)\n",
      "the position of max probe is: 8\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uncomfortable is _ .\n",
      "['uncomfortable', 'awkward', 'annoying', 'unpleasant', 'comfortable', 'tense', 'inconvenient', 'embarrassing', 'intolerable', 'boring']\n",
      "tensor([0.1435, 0.0880, 0.0282, 0.0244, 0.0151, 0.0149, 0.0134, 0.0111, 0.0103,\n",
      "        0.0092])\n",
      "{'comfortable': tensor(0.0151)}\n",
      "max_probe is: tensor(0.0151)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unconventional is _ .\n",
      "['also', ',', 'the', 'and', 'short', 'unconventional', 'or', 'called', '', '.']\n",
      "tensor([0.0393, 0.0326, 0.0194, 0.0191, 0.0190, 0.0111, 0.0093, 0.0092, 0.0087,\n",
      "        0.0074])\n",
      "{'conventional': tensor(0.0050)}\n",
      "max_probe is: tensor(0.0050)\n",
      "20\n",
      "the position of max probe is: 13\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of incapable is _ .\n",
      "[',', 'also', 'and', 'the', '.', 'called', 'or', 'in', 'a', ':']\n",
      "tensor([0.0445, 0.0384, 0.0292, 0.0209, 0.0155, 0.0151, 0.0081, 0.0066, 0.0064,\n",
      "        0.0063])\n",
      "{'capable': tensor(4.8130e-05)}\n",
      "max_probe is: tensor(4.8130e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "the position of max probe is: 2620\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of incompatible is _ .\n",
      "['incompatible', 'compatible', 'and', 'also', ',', 'always', 'inconsistent', 'equivalent', 'not', 'the']\n",
      "tensor([0.1723, 0.0811, 0.0351, 0.0324, 0.0259, 0.0148, 0.0106, 0.0080, 0.0077,\n",
      "        0.0071])\n",
      "{'compatible': tensor(0.0811)}\n",
      "max_probe is: tensor(0.0811)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of credible is _ .\n",
      "['reliable', 'trustworthy', 'credible', 'unreliable', 'accurate', 'true', 'verified', 'truthful', 'proven', 'false']\n",
      "tensor([0.2028, 0.0528, 0.0466, 0.0323, 0.0157, 0.0138, 0.0133, 0.0109, 0.0105,\n",
      "        0.0099])\n",
      "{'incredible': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0002)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 586\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of lawful is _ .\n",
      "['lawful', 'legal', 'valid', 'just', 'prudent', 'appropriate', 'proper', 'mandatory', 'permissible', 'constitutional']\n",
      "tensor([0.2808, 0.0251, 0.0241, 0.0222, 0.0201, 0.0163, 0.0120, 0.0106, 0.0101,\n",
      "        0.0087])\n",
      "{'unlawful': tensor(0.0083)}\n",
      "max_probe is: tensor(0.0083)\n",
      "20\n",
      "the position of max probe is: 10\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of undesirable is _ .\n",
      "['undesirable', 'desirable', ',', 'unacceptable', 'also', 'and', 'unwanted', 'negative', 'bad', 'rare']\n",
      "tensor([0.3004, 0.0562, 0.0256, 0.0255, 0.0189, 0.0167, 0.0162, 0.0108, 0.0098,\n",
      "        0.0093])\n",
      "{'desirable': tensor(0.0562)}\n",
      "max_probe is: tensor(0.0562)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of heterosexual is _ .\n",
      "['homosexual', 'gay', 'bisexual', 'lesbian', 'heterosexual', 'queer', 'LGBT', 'masculine', 'and', 'bi']\n",
      "tensor([0.6428, 0.0550, 0.0486, 0.0263, 0.0187, 0.0116, 0.0107, 0.0074, 0.0073,\n",
      "        0.0067])\n",
      "{'homosexual': tensor(0.6428)}\n",
      "max_probe is: tensor(0.6428)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unfamiliar is _ .\n",
      "[',', 'unfamiliar', 'uncertain', '.', 'also', 'familiar', 'and', 'unknown', 'the', 'confusing']\n",
      "tensor([0.0300, 0.0272, 0.0213, 0.0206, 0.0188, 0.0172, 0.0144, 0.0124, 0.0098,\n",
      "        0.0075])\n",
      "{'familiar': tensor(0.0172)}\n",
      "max_probe is: tensor(0.0172)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of ineligible is _ .\n",
      "[',', 'also', 'and', '.', 'the', 'or', '', ':', 'called', '\"']\n",
      "tensor([0.0911, 0.0754, 0.0570, 0.0320, 0.0231, 0.0171, 0.0146, 0.0143, 0.0118,\n",
      "        0.0113])\n",
      "{'eligible': tensor(1.8447e-06)}\n",
      "max_probe is: tensor(1.8447e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "10240\n",
      "20480\n",
      "the position of max probe is: 14667\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inexperienced is _ .\n",
      "[',', 'also', 'the', 'called', '.', 'and', '', ':', ';', 'or']\n",
      "tensor([0.0365, 0.0215, 0.0185, 0.0168, 0.0153, 0.0132, 0.0122, 0.0116, 0.0072,\n",
      "        0.0067])\n",
      "{'experienced': tensor(0.0038)}\n",
      "max_probe is: tensor(0.0038)\n",
      "20\n",
      "the position of max probe is: 16\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unpredictable is _ .\n",
      "['unpredictable', 'predictable', 'volatile', 'unstable', 'unreliable', 'unexpected', 'erratic', 'uncertain', 'inconsistent', 'optimistic']\n",
      "tensor([0.3274, 0.0331, 0.0262, 0.0211, 0.0128, 0.0108, 0.0090, 0.0088, 0.0070,\n",
      "        0.0069])\n",
      "{'predictable': tensor(0.0331)}\n",
      "max_probe is: tensor(0.0331)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of predictable is _ .\n",
      "['also', ',', 'and', 'called', '.', 'pronounced', '', 'the', 'in', 'of']\n",
      "tensor([0.0619, 0.0511, 0.0466, 0.0187, 0.0184, 0.0172, 0.0152, 0.0138, 0.0091,\n",
      "        0.0087])\n",
      "{'unpredictable': tensor(0.0007)}\n",
      "max_probe is: tensor(0.0007)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 198\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nasty is _ .\n",
      "['nasty', 'sour', 'mean', 'naughty', 'annoying', 'disgusting', 'unpleasant', 'bad', 'evil', 'good']\n",
      "tensor([0.0638, 0.0359, 0.0311, 0.0226, 0.0193, 0.0189, 0.0186, 0.0168, 0.0147,\n",
      "        0.0147])\n",
      "{'nice': tensor(0.0142)}\n",
      "max_probe is: tensor(0.0142)\n",
      "20\n",
      "the position of max probe is: 12\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inaccessible is _ .\n",
      "[',', 'and', 'also', 'the', '.', 'called', 'or', ':', '', '=']\n",
      "tensor([0.1253, 0.0989, 0.0976, 0.0237, 0.0200, 0.0169, 0.0139, 0.0130, 0.0117,\n",
      "        0.0104])\n",
      "{'accessible': tensor(4.9650e-05)}\n",
      "max_probe is: tensor(4.9650e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "the position of max probe is: 1291\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of naive is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['naive', 'naÃ¯ve', 'explicit', 'simple', 'pragmatic', 'also', ',', 'and', 'the', 'optimistic']\n",
      "tensor([0.1708, 0.0237, 0.0222, 0.0138, 0.0127, 0.0123, 0.0119, 0.0101, 0.0076,\n",
      "        0.0076])\n",
      "{'sophisticated': tensor(0.0005)}\n",
      "max_probe is: tensor(0.0005)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 276\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of affirmative is _ .\n",
      "['negative', 'positive', 'affirmative', 'definite', 'neutral', 'conditional', 'minus', 'imperative', 'and', 'passive']\n",
      "tensor([0.4888, 0.1303, 0.0676, 0.0190, 0.0135, 0.0102, 0.0098, 0.0078, 0.0069,\n",
      "        0.0062])\n",
      "{'negative': tensor(0.4888)}\n",
      "max_probe is: tensor(0.4888)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of impractical is _ .\n",
      "['practical', 'pragmatic', 'impractical', 'and', 'optimistic', ',', 'also', 'flexible', 'logical', 'hypothetical']\n",
      "tensor([0.1059, 0.0422, 0.0302, 0.0122, 0.0112, 0.0099, 0.0092, 0.0081, 0.0072,\n",
      "        0.0069])\n",
      "{'practical': tensor(0.1059)}\n",
      "max_probe is: tensor(0.1059)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of adoptive is _ .\n",
      "['adoptive', 'adaptive', 'and', 'also', 'adopted', ',', 'the', 'or', 'developmental', 'in']\n",
      "tensor([0.1775, 0.0260, 0.0254, 0.0242, 0.0215, 0.0118, 0.0112, 0.0086, 0.0076,\n",
      "        0.0067])\n",
      "{'biological': tensor(0.0015)}\n",
      "max_probe is: tensor(0.0015)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 72\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unaffected is _ .\n",
      "['and', 'also', ',', 'or', '=', '', ':', 'the', '.', '/']\n",
      "tensor([0.1533, 0.1046, 0.0902, 0.0217, 0.0164, 0.0155, 0.0142, 0.0120, 0.0109,\n",
      "        0.0101])\n",
      "{'affected': tensor(7.1642e-06)}\n",
      "max_probe is: tensor(7.1642e-06)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "the position of max probe is: 4317\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unequal is _ .\n",
      "['equal', 'unequal', 'also', ',', 'and', 'inferior', 'always', 'equitable', 'exactly', 'the']\n",
      "tensor([0.5077, 0.1014, 0.0177, 0.0140, 0.0131, 0.0089, 0.0083, 0.0075, 0.0063,\n",
      "        0.0060])\n",
      "{'equal': tensor(0.5077)}\n",
      "max_probe is: tensor(0.5077)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of irrational is _ .\n",
      "['irrational', 'rational', 'exponential', 'absurd', 'logical', 'and', 'arbitrary', 'arithmetic', 'normal', ',']\n",
      "tensor([0.4120, 0.2364, 0.0165, 0.0100, 0.0094, 0.0078, 0.0060, 0.0053, 0.0050,\n",
      "        0.0049])\n",
      "{'rational': tensor(0.2364)}\n",
      "max_probe is: tensor(0.2364)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of sensible is _ .\n",
      "['sensible', 'rational', 'simple', 'practical', 'pragmatic', 'logical', 'flexible', 'positive', 'strict', 'prudent']\n",
      "tensor([0.0571, 0.0389, 0.0275, 0.0207, 0.0189, 0.0182, 0.0144, 0.0123, 0.0115,\n",
      "        0.0101])\n",
      "{'unreasonable': tensor(5.5996e-05)}\n",
      "max_probe is: tensor(5.5996e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "the position of max probe is: 1711\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of involuntary is _ .\n",
      "['involuntary', 'voluntary', 'spontaneous', 'compulsory', 'habitual', 'mandatory', 'obligatory', 'intentional', 'optional', 'voluntarily']\n",
      "tensor([0.4074, 0.2254, 0.0210, 0.0167, 0.0153, 0.0130, 0.0092, 0.0053, 0.0053,\n",
      "        0.0048])\n",
      "{'voluntary': tensor(0.2254)}\n",
      "max_probe is: tensor(0.2254)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uneasy is _ .\n",
      "[',', 'tense', '.', 'also', 'the', 'positive', 'strong', 'and', 'relaxed', 'energetic']\n",
      "tensor([0.0167, 0.0149, 0.0099, 0.0096, 0.0081, 0.0069, 0.0058, 0.0054, 0.0048,\n",
      "        0.0048])\n",
      "{'easy': tensor(0.0005)}\n",
      "max_probe is: tensor(0.0005)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 385\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of immoral is _ .\n",
      "['moral', 'indecent', 'immoral', 'unethical', 'obscene', 'illegal', 'ethical', 'vulgar', 'corrupt', 'unacceptable']\n",
      "tensor([0.0905, 0.0584, 0.0480, 0.0442, 0.0256, 0.0252, 0.0211, 0.0155, 0.0123,\n",
      "        0.0117])\n",
      "{'moral': tensor(0.0905)}\n",
      "max_probe is: tensor(0.0905)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of fractional is _ .\n",
      "['cubic', 'also', 'and', 'exponential', ',', 'linear', 'proportional', 'simply', 'always', 'just']\n",
      "tensor([0.0783, 0.0710, 0.0384, 0.0330, 0.0271, 0.0262, 0.0185, 0.0143, 0.0130,\n",
      "        0.0107])\n",
      "{'whole': tensor(0.0001)}\n",
      "max_probe is: tensor(0.0001)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 642\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of heterogeneous is _ .\n",
      "['and', 'generalized', 'dense', 'pure', 'vector', ',', 'cubic', 'normal', 'the', 'linear']\n",
      "tensor([0.0281, 0.0243, 0.0167, 0.0151, 0.0138, 0.0136, 0.0126, 0.0113, 0.0111,\n",
      "        0.0101])\n",
      "homogeneousis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of unconditional is _ .\n",
      "['unconditional', 'conditional', 'absolute', 'indefinite', 'positive', 'universal', 'implicit', 'and', 'reciprocal', 'explicit']\n",
      "tensor([0.6575, 0.0251, 0.0230, 0.0140, 0.0078, 0.0078, 0.0067, 0.0064, 0.0059,\n",
      "        0.0058])\n",
      "{'conditional': tensor(0.0251)}\n",
      "max_probe is: tensor(0.0251)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unfavorable is _ .\n",
      "['and', ',', 'also', 'or', 'positive', '.', 'pronounced', ':', 'the', '+']\n",
      "tensor([0.1009, 0.0862, 0.0470, 0.0198, 0.0168, 0.0140, 0.0139, 0.0116, 0.0105,\n",
      "        0.0103])\n",
      "{'favorable': tensor(0.0007)}\n",
      "max_probe is: tensor(0.0007)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 177\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of atypical is _ .\n",
      "['and', 'also', ',', 'exponential', 'or', 'the', 'normal', 'simply', 'in', 'always']\n",
      "tensor([0.0485, 0.0379, 0.0236, 0.0227, 0.0169, 0.0131, 0.0098, 0.0096, 0.0089,\n",
      "        0.0074])\n",
      "{'typical': tensor(0.0013)}\n",
      "max_probe is: tensor(0.0013)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 124\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unnatural is _ .\n",
      "['unnatural', 'natural', ',', 'abnormal', 'normal', 'and', 'unusual', 'or', 'not', 'also']\n",
      "tensor([0.2572, 0.0775, 0.0388, 0.0295, 0.0260, 0.0152, 0.0118, 0.0113, 0.0105,\n",
      "        0.0102])\n",
      "{'natural': tensor(0.0775)}\n",
      "max_probe is: tensor(0.0775)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unreasonable is _ .\n",
      "['unreasonable', 'reasonable', 'absurd', 'ridiculous', 'excessive', 'arbitrary', 'extreme', 'rational', 'irrational', 'unacceptable']\n",
      "tensor([0.4197, 0.1021, 0.0224, 0.0157, 0.0121, 0.0115, 0.0113, 0.0106, 0.0099,\n",
      "        0.0096])\n",
      "{'reasonable': tensor(0.1021)}\n",
      "max_probe is: tensor(0.1021)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of displeased is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annoyed', 'irritated', 'dissatisfied', 'disappointed', 'disgusted', 'angry', 'frustrated', 'upset', 'agitated', 'unhappy']\n",
      "tensor([0.1360, 0.0722, 0.0701, 0.0682, 0.0376, 0.0286, 0.0285, 0.0206, 0.0190,\n",
      "        0.0174])\n",
      "{'pleased': tensor(0.0090)}\n",
      "max_probe is: tensor(0.0090)\n",
      "20\n",
      "the position of max probe is: 14\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unrealistic is _ .\n",
      "['unrealistic', 'realistic', 'optimistic', 'ideal', 'pessimistic', 'unreal', 'and', ',', 'also', 'unreasonable']\n",
      "tensor([0.4393, 0.0805, 0.0204, 0.0119, 0.0112, 0.0091, 0.0088, 0.0073, 0.0062,\n",
      "        0.0052])\n",
      "{'realistic': tensor(0.0805)}\n",
      "max_probe is: tensor(0.0805)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of improbable is _ .\n",
      "['improbable', 'unlikely', 'likely', 'probability', 'probable', 'also', 'and', 'optimistic', 'uncertain', 'unfortunate']\n",
      "tensor([0.1855, 0.0237, 0.0226, 0.0220, 0.0216, 0.0207, 0.0196, 0.0119, 0.0115,\n",
      "        0.0107])\n",
      "{'probable': tensor(0.0216)}\n",
      "max_probe is: tensor(0.0216)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of impartial is _ .\n",
      "['neutral', 'impartial', 'unbiased', 'positive', ',', 'biased', 'and', 'also', 'the', 'independent']\n",
      "tensor([0.0781, 0.0429, 0.0347, 0.0232, 0.0199, 0.0140, 0.0123, 0.0119, 0.0079,\n",
      "        0.0070])\n",
      "{'partial': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0002)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 832\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unhealthy is _ .\n",
      "['healthy', 'unhealthy', 'normal', 'good', 'fat', ',', 'energetic', 'happy', 'obese', 'hot']\n",
      "tensor([0.5750, 0.0407, 0.0173, 0.0110, 0.0084, 0.0064, 0.0061, 0.0055, 0.0052,\n",
      "        0.0048])\n",
      "{'healthy': tensor(0.5750)}\n",
      "max_probe is: tensor(0.5750)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of irresponsible is _ .\n",
      "['irresponsible', 'reckless', 'responsible', 'prudent', 'cautious', 'honest', 'careless', 'risky', 'conscientious', 'greedy']\n",
      "tensor([0.1102, 0.1001, 0.0742, 0.0520, 0.0378, 0.0255, 0.0130, 0.0127, 0.0097,\n",
      "        0.0091])\n",
      "{'responsible': tensor(0.0742)}\n",
      "max_probe is: tensor(0.0742)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unprepared is _ .\n",
      "[',', 'called', 'the', 'and', '.', 'also', 'prepared', '', 'in', 'used']\n",
      "tensor([0.0281, 0.0279, 0.0197, 0.0181, 0.0172, 0.0158, 0.0101, 0.0093, 0.0075,\n",
      "        0.0070])\n",
      "{'prepared': tensor(0.0101)}\n",
      "max_probe is: tensor(0.0101)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of intangible is _ .\n",
      "['intangible', 'invisible', 'implicit', 'subjective', 'explicit', 'abstract', 'tangible', 'measurable', 'also', 'ubiquitous']\n",
      "tensor([0.1759, 0.0370, 0.0152, 0.0141, 0.0112, 0.0110, 0.0101, 0.0100, 0.0098,\n",
      "        0.0095])\n",
      "{'tangible': tensor(0.0101)}\n",
      "max_probe is: tensor(0.0101)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of asymmetrical is _ .\n",
      "['cubic', 'linear', 'diagonal', 'proportional', 'triangular', 'and', 'exponential', 'regular', 'ordered', 'square']\n",
      "tensor([0.0826, 0.0484, 0.0348, 0.0289, 0.0235, 0.0225, 0.0195, 0.0180, 0.0160,\n",
      "        0.0155])\n",
      "symmetricalis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of undue is _ .\n",
      "[',', 'also', 'and', 'the', '.', 'called', 'or', '', ':', 'in']\n",
      "tensor([0.0574, 0.0496, 0.0441, 0.0323, 0.0260, 0.0125, 0.0117, 0.0098, 0.0092,\n",
      "        0.0081])\n",
      "{'due': tensor(5.6602e-05)}\n",
      "max_probe is: tensor(5.6602e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "the position of max probe is: 1855\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of insoluble is _ .\n",
      "['soluble', ',', 'liquid', 'and', 'also', 'or', 'salt', 'in', 'dissolved', 'insol']\n",
      "tensor([0.7133, 0.0172, 0.0126, 0.0122, 0.0081, 0.0073, 0.0068, 0.0065, 0.0058,\n",
      "        0.0057])\n",
      "{'soluble': tensor(0.7133)}\n",
      "max_probe is: tensor(0.7133)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of insensitive is _ .\n",
      "['insensitive', 'sensitive', 'aggressive', 'appropriate', 'the', 'positive', ',', 'blunt', 'also', 'and']\n",
      "tensor([0.2974, 0.0227, 0.0165, 0.0075, 0.0072, 0.0069, 0.0058, 0.0052, 0.0048,\n",
      "        0.0045])\n",
      "{'sensitive': tensor(0.0227)}\n",
      "max_probe is: tensor(0.0227)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unbelievable is _ .\n",
      "['absurd', 'unbelievable', 'impossible', 'ridiculous', 'true', 'improbable', 'ludicrous', 'possible', 'real', 'unrealistic']\n",
      "tensor([0.0883, 0.0433, 0.0384, 0.0369, 0.0332, 0.0326, 0.0185, 0.0154, 0.0139,\n",
      "        0.0131])\n",
      "{'credible': tensor(0.0027)}\n",
      "max_probe is: tensor(0.0027)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 55\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unethical is _ .\n",
      "['unethical', 'dishonest', 'honest', 'ethical', 'moral', 'irresponsible', 'conscientious', 'immoral', 'illegal', 'greedy']\n",
      "tensor([0.1414, 0.0767, 0.0689, 0.0577, 0.0243, 0.0185, 0.0179, 0.0167, 0.0151,\n",
      "        0.0137])\n",
      "{'ethical': tensor(0.0577)}\n",
      "max_probe is: tensor(0.0577)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unimportant is _ .\n",
      "['important', 'irrelevant', 'trivial', 'insignificant', 'also', ',', 'significant', 'and', 'the', '.']\n",
      "tensor([0.1423, 0.0485, 0.0410, 0.0366, 0.0251, 0.0232, 0.0212, 0.0170, 0.0168,\n",
      "        0.0121])\n",
      "{'important': tensor(0.1423)}\n",
      "max_probe is: tensor(0.1423)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of frivolous is _ .\n",
      "['frivolous', 'irresponsible', 'reckless', 'prudent', 'lazy', 'selfish', 'ironic', 'fun', 'playful', 'careless']\n",
      "tensor([0.0328, 0.0325, 0.0124, 0.0123, 0.0097, 0.0095, 0.0092, 0.0086, 0.0085,\n",
      "        0.0081])\n",
      "{'serious': tensor(0.0032)}\n",
      "max_probe is: tensor(0.0032)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 44\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unprofitable is _ .\n",
      "['profitable', 'profitability', 'and', 'negative', 'unsustainable', 'not', ',', 'profit', 'unacceptable', 'bankrupt']\n",
      "tensor([0.3255, 0.0380, 0.0201, 0.0164, 0.0159, 0.0127, 0.0117, 0.0104, 0.0084,\n",
      "        0.0079])\n",
      "{'profitable': tensor(0.3255)}\n",
      "max_probe is: tensor(0.3255)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of pessimistic is _ .\n",
      "['and', 'also', 'positive', ',', 'negative', '', '.', 'the', 'of', 'P']\n",
      "tensor([0.0365, 0.0356, 0.0347, 0.0299, 0.0229, 0.0118, 0.0116, 0.0091, 0.0064,\n",
      "        0.0061])\n",
      "{'optimistic': tensor(0.0060)}\n",
      "max_probe is: tensor(0.0060)\n",
      "20\n",
      "the position of max probe is: 10\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of high-pitched is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['high', 'low', ',', 'called', 'and', 'HIGH', 'the', 'pronounced', 'or', '']\n",
      "tensor([0.5506, 0.1682, 0.0161, 0.0124, 0.0093, 0.0067, 0.0065, 0.0049, 0.0048,\n",
      "        0.0045])\n",
      "{'low': tensor(0.1682)}\n",
      "max_probe is: tensor(0.1682)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unfavourable is _ .\n",
      "['favourable', 'unfavorable', 'undesirable', 'neutral', 'favorable', 'negative', 'positive', 'and', ',', 'unacceptable']\n",
      "tensor([0.2564, 0.0497, 0.0440, 0.0361, 0.0331, 0.0296, 0.0262, 0.0209, 0.0142,\n",
      "        0.0069])\n",
      "{'favorable': tensor(0.0331)}\n",
      "max_probe is: tensor(0.0331)\n",
      "the position of max probe is: 4\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unproductive is _ .\n",
      "['productive', 'inefficient', 'counterproductive', 'disruptive', 'negative', 'and', 'lazy', 'productivity', 'ineffective', 'boring']\n",
      "tensor([0.1201, 0.0296, 0.0191, 0.0162, 0.0158, 0.0152, 0.0147, 0.0114, 0.0098,\n",
      "        0.0098])\n",
      "{'productive': tensor(0.1201)}\n",
      "max_probe is: tensor(0.1201)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of discontinuous is _ .\n",
      "['continuous', 'indefinite', 'linear', 'and', ',', 'finite', 'discrete', 'also', 'the', 'always']\n",
      "tensor([0.2415, 0.0699, 0.0373, 0.0314, 0.0304, 0.0109, 0.0107, 0.0102, 0.0097,\n",
      "        0.0095])\n",
      "{'continuous': tensor(0.2415)}\n",
      "max_probe is: tensor(0.2415)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of dependable is _ .\n",
      "['reliable', 'stable', 'predictable', 'resilient', 'reliability', 'durable', 'unreliable', 'consistent', 'dependent', 'and']\n",
      "tensor([0.5786, 0.0278, 0.0256, 0.0225, 0.0198, 0.0190, 0.0118, 0.0091, 0.0066,\n",
      "        0.0059])\n",
      "{'unreliable': tensor(0.0118)}\n",
      "max_probe is: tensor(0.0118)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uninterested is _ .\n",
      "['interested', 'not', 'interest', 'indifferent', 'neutral', 'curious', 'the', 'undecided', 'and', 'also']\n",
      "tensor([0.1784, 0.0274, 0.0212, 0.0205, 0.0189, 0.0179, 0.0130, 0.0123, 0.0113,\n",
      "        0.0099])\n",
      "{'interested': tensor(0.1784)}\n",
      "max_probe is: tensor(0.1784)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unambiguous is _ .\n",
      "['explicit', 'ambiguous', 'absolute', 'clear', 'unconditional', 'implicit', 'straightforward', 'arbitrary', 'and', 'simple']\n",
      "tensor([0.0784, 0.0627, 0.0575, 0.0539, 0.0195, 0.0147, 0.0134, 0.0106, 0.0105,\n",
      "        0.0104])\n",
      "{'ambiguous': tensor(0.0627)}\n",
      "max_probe is: tensor(0.0627)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of ineffectual is _ .\n",
      "['effective', 'ineffective', 'in', 'and', 'efficient', ',', 'neutral', 'effectively', 'also', 'disruptive']\n",
      "tensor([0.1401, 0.0719, 0.0160, 0.0154, 0.0122, 0.0120, 0.0089, 0.0087, 0.0085,\n",
      "        0.0085])\n",
      "{'effective': tensor(0.1401)}\n",
      "max_probe is: tensor(0.1401)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unattractive is _ .\n",
      "['attractive', 'ugly', 'and', ',', 'unacceptable', 'undesirable', 'or', '.', 'bland', 'unfortunate']\n",
      "tensor([0.0598, 0.0555, 0.0255, 0.0226, 0.0174, 0.0149, 0.0138, 0.0131, 0.0129,\n",
      "        0.0129])\n",
      "{'attractive': tensor(0.0598)}\n",
      "max_probe is: tensor(0.0598)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of believable is _ .\n",
      "['true', 'false', 'reliable', 'also', 'trustworthy', 'not', 'plausible', 'probably', 'truthful', 'likely']\n",
      "tensor([0.0700, 0.0236, 0.0198, 0.0196, 0.0192, 0.0170, 0.0155, 0.0129, 0.0119,\n",
      "        0.0116])\n",
      "{'incredible': tensor(0.0007)}\n",
      "max_probe is: tensor(0.0007)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 228\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of asexual is _ .\n",
      "['sexual', ',', 'and', 'a', 'bisexual', 'the', 'or', 'anal', 'in', 'masculine']\n",
      "tensor([0.0689, 0.0457, 0.0297, 0.0201, 0.0188, 0.0179, 0.0154, 0.0145, 0.0132,\n",
      "        0.0130])\n",
      "{'sexual': tensor(0.0689)}\n",
      "max_probe is: tensor(0.0689)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inflexible is _ .\n",
      "['flexible', 'rigid', 'elastic', ',', 'indefinite', 'and', 'linear', 'also', 'finite', 'compact']\n",
      "tensor([0.5089, 0.0378, 0.0285, 0.0137, 0.0117, 0.0112, 0.0096, 0.0065, 0.0059,\n",
      "        0.0057])\n",
      "{'flexible': tensor(0.5089)}\n",
      "max_probe is: tensor(0.5089)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of impersonal is _ .\n",
      "['equivalent', 'void', 'and', 'also', ',', 'indefinite', 'arbitrary', 'generic', 'not', 'neutral']\n",
      "tensor([0.0292, 0.0257, 0.0192, 0.0184, 0.0162, 0.0113, 0.0110, 0.0106, 0.0104,\n",
      "        0.0098])\n",
      "{'personal': tensor(0.0005)}\n",
      "max_probe is: tensor(0.0005)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 316\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inconspicuous is _ .\n",
      "['discreet', 'conspicuous', 'invisible', 'subtle', 'transparent', 'obvious', 'casual', 'innocuous', 'obscure', 'not']\n",
      "tensor([0.1063, 0.0979, 0.0329, 0.0165, 0.0142, 0.0130, 0.0119, 0.0105, 0.0098,\n",
      "        0.0096])\n",
      "{'conspicuous': tensor(0.0979)}\n",
      "max_probe is: tensor(0.0979)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of incomparable is _ .\n",
      "['equivalent', 'comparable', 'equal', 'identical', 'extraordinary', '', 'and', 'also', 'superior', '.']\n",
      "tensor([0.0764, 0.0485, 0.0347, 0.0210, 0.0180, 0.0164, 0.0158, 0.0116, 0.0110,\n",
      "        0.0104])\n",
      "{'comparable': tensor(0.0485)}\n",
      "max_probe is: tensor(0.0485)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of implausible is _ .\n",
      "['improbable', 'impossible', 'plausible', 'absurd', 'unlikely', 'ridiculous', 'unbelievable', 'logical', 'ludicrous', 'unrealistic']\n",
      "tensor([0.1078, 0.0551, 0.0475, 0.0423, 0.0203, 0.0201, 0.0188, 0.0171, 0.0132,\n",
      "        0.0120])\n",
      "{'plausible': tensor(0.0475)}\n",
      "max_probe is: tensor(0.0475)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of invulnerable is _ .\n",
      "['vulnerable', 'resilient', 'protected', 'also', 'invincible', 'and', 'unprotected', 'passive', 'the', ',']\n",
      "tensor([0.0600, 0.0275, 0.0224, 0.0219, 0.0189, 0.0131, 0.0127, 0.0086, 0.0082,\n",
      "        0.0081])\n",
      "{'vulnerable': tensor(0.0600)}\n",
      "max_probe is: tensor(0.0600)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unsympathetic is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sympathetic', 'indifferent', 'neutral', 'dismissive', 'pessimistic', 'cynical', 'compassionate', 'negative', 'cold', 'skeptical']\n",
      "tensor([0.0914, 0.0850, 0.0268, 0.0261, 0.0243, 0.0195, 0.0161, 0.0147, 0.0119,\n",
      "        0.0099])\n",
      "{'sympathetic': tensor(0.0914)}\n",
      "max_probe is: tensor(0.0914)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of extrinsic is _ .\n",
      "['and', ',', 'also', 'or', 'cubic', 'the', 'equivalent', 'intrinsic', 'in', 'reciprocal']\n",
      "tensor([0.1028, 0.0585, 0.0436, 0.0382, 0.0179, 0.0160, 0.0159, 0.0130, 0.0128,\n",
      "        0.0126])\n",
      "{'intrinsic': tensor(0.0130)}\n",
      "max_probe is: tensor(0.0130)\n",
      "the position of max probe is: 7\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of undemocratic is _ .\n",
      "['democratic', 'authoritarian', 'democracy', 'totalitarian', 'democrat', 'egalitarian', 'parliamentary', 'republican', 'populist', 'not']\n",
      "tensor([0.5657, 0.1240, 0.0442, 0.0245, 0.0093, 0.0076, 0.0054, 0.0038, 0.0038,\n",
      "        0.0038])\n",
      "{'democratic': tensor(0.5657)}\n",
      "max_probe is: tensor(0.5657)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of illogical is _ .\n",
      "['logical', 'irrational', 'rational', 'absurd', 'arbitrary', 'nonsensical', 'ironic', 'inconsistent', 'ridiculous', 'logic']\n",
      "tensor([0.2677, 0.2489, 0.0511, 0.0410, 0.0189, 0.0149, 0.0074, 0.0073, 0.0059,\n",
      "        0.0058])\n",
      "{'logical': tensor(0.2677)}\n",
      "max_probe is: tensor(0.2677)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uninjured is _ .\n",
      "['injured', 'not', 'unaffected', 'unprotected', 'healthy', 'free', 'in', 'at', 'the', 'wounded']\n",
      "tensor([0.1753, 0.0334, 0.0291, 0.0163, 0.0129, 0.0122, 0.0107, 0.0094, 0.0088,\n",
      "        0.0088])\n",
      "{'injured': tensor(0.1753)}\n",
      "max_probe is: tensor(0.1753)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inedible is _ .\n",
      "['edible', 'in', 'acidic', 'not', 'or', 'and', 'unacceptable', 'sterile', 'also', ',']\n",
      "tensor([0.3095, 0.0360, 0.0117, 0.0103, 0.0087, 0.0083, 0.0082, 0.0071, 0.0066,\n",
      "        0.0065])\n",
      "{'edible': tensor(0.3095)}\n",
      "max_probe is: tensor(0.3095)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inelastic is _ .\n",
      "['linear', 'elastic', 'in', 'and', 'exponential', 'flexible', ',', 'constant', 'also', 'rigid']\n",
      "tensor([0.0653, 0.0600, 0.0468, 0.0350, 0.0290, 0.0252, 0.0246, 0.0194, 0.0157,\n",
      "        0.0132])\n",
      "{'elastic': tensor(0.0600)}\n",
      "max_probe is: tensor(0.0600)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uncharacteristic is _ .\n",
      "['unusual', 'inconsistent', 'exceptional', 'and', 'unpredictable', 'unexpected', 'confounding', 'not', 'erratic', 'surprising']\n",
      "tensor([0.0376, 0.0299, 0.0240, 0.0169, 0.0160, 0.0155, 0.0125, 0.0124, 0.0122,\n",
      "        0.0115])\n",
      "{'characteristic': tensor(0.0016)}\n",
      "max_probe is: tensor(0.0016)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 88\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of theoretic is _ .\n",
      "['and', ',', 'written', 'the', 'also', 'of', 'in', 'called', 'defined', 'that']\n",
      "tensor([0.1540, 0.0838, 0.0460, 0.0401, 0.0362, 0.0275, 0.0223, 0.0187, 0.0179,\n",
      "        0.0158])\n",
      "{'empirical': tensor(0.0001)}\n",
      "max_probe is: tensor(0.0001)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 514\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unscientific is _ .\n",
      "['scientific', 'misleading', 'not', 'science', 'controversial', 'absurd', 'experimental', 'sterile', 'irresponsible', 'unethical']\n",
      "tensor([0.0899, 0.0215, 0.0137, 0.0133, 0.0129, 0.0099, 0.0091, 0.0085, 0.0078,\n",
      "        0.0070])\n",
      "{'scientific': tensor(0.0899)}\n",
      "max_probe is: tensor(0.0899)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unimpressive is _ .\n",
      "['disappointing', ',', 'and', 'impressive', '.', 'also', 'bland', 'not', 'the', 'or']\n",
      "tensor([0.0392, 0.0385, 0.0213, 0.0179, 0.0166, 0.0147, 0.0091, 0.0088, 0.0085,\n",
      "        0.0084])\n",
      "{'impressive': tensor(0.0179)}\n",
      "max_probe is: tensor(0.0179)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unplayable is _ .\n",
      "['playable', 'and', 'not', 'free', '.', 'called', ',', 'undefined', 'broken', 'also']\n",
      "tensor([0.0415, 0.0166, 0.0148, 0.0142, 0.0134, 0.0133, 0.0127, 0.0123, 0.0122,\n",
      "        0.0120])\n",
      "{'playable': tensor(0.0415)}\n",
      "max_probe is: tensor(0.0415)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unprofessional is _ .\n",
      "['professional', 'informal', 'casual', 'incompetent', 'unacceptable', 'amateur', 'unethical', 'inappropriate', 'irresponsible', 'rude']\n",
      "tensor([0.1759, 0.0686, 0.0589, 0.0386, 0.0194, 0.0151, 0.0134, 0.0102, 0.0100,\n",
      "        0.0095])\n",
      "{'professional': tensor(0.1759)}\n",
      "max_probe is: tensor(0.1759)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unconcerned is _ .\n",
      "['concerned', 'indifferent', 'worried', 'cautious', 'concern', 'neutral', 'not', 'reserved', 'relaxed', 'anxious']\n",
      "tensor([0.3032, 0.0309, 0.0287, 0.0170, 0.0103, 0.0097, 0.0096, 0.0074, 0.0072,\n",
      "        0.0059])\n",
      "{'concerned': tensor(0.3032)}\n",
      "max_probe is: tensor(0.3032)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nontraditional is _ .\n",
      "['conventional', 'unconventional', 'and', 'traditional', 'not', 'transitional', 'flexible', 'the', 'unusual', 'ubiquitous']\n",
      "tensor([0.0322, 0.0175, 0.0165, 0.0118, 0.0101, 0.0099, 0.0086, 0.0083, 0.0079,\n",
      "        0.0068])\n",
      "{'traditional': tensor(0.0118)}\n",
      "max_probe is: tensor(0.0118)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unsanitary is _ .\n",
      "['sterile', 'disgusting', 'clean', 'filthy', 'san', 'unacceptable', 'dirty', 'sanitation', 'gross', 'hazardous']\n",
      "tensor([0.1441, 0.0518, 0.0271, 0.0270, 0.0264, 0.0246, 0.0216, 0.0197, 0.0181,\n",
      "        0.0181])\n",
      "sanitaryis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of dishonorable is _ .\n",
      "['honorable', 'shameful', 'despicable', 'unfortunate', 'the', 'and', 'excellent', 'or', ',', 'exemplary']\n",
      "tensor([0.2040, 0.0466, 0.0296, 0.0249, 0.0158, 0.0139, 0.0137, 0.0093, 0.0084,\n",
      "        0.0084])\n",
      "{'honorable': tensor(0.2040)}\n",
      "max_probe is: tensor(0.2040)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inoperative is _ .\n",
      "['in', 'and', 'or', 'the', 'also', 'operative', 'indefinite', ',', 'open', 'now']\n",
      "tensor([0.2265, 0.0331, 0.0265, 0.0215, 0.0189, 0.0157, 0.0155, 0.0149, 0.0124,\n",
      "        0.0107])\n",
      "{'operative': tensor(0.0157)}\n",
      "max_probe is: tensor(0.0157)\n",
      "the position of max probe is: 5\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uncritical is _ .\n",
      "['hypocritical', 'neutral', 'not', 'critical', 'conservative', 'pure', 'ubiquitous', 'skeptical', 'transparent', 'independent']\n",
      "tensor([0.0437, 0.0184, 0.0172, 0.0117, 0.0110, 0.0093, 0.0092, 0.0089, 0.0081,\n",
      "        0.0079])\n",
      "{'critical': tensor(0.0117)}\n",
      "max_probe is: tensor(0.0117)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unfashionable is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fashionable', 'trendy', 'stylish', 'boring', 'cool', 'fashion', 'chic', 'eccentric', 'hot', 'casual']\n",
      "tensor([0.1388, 0.0755, 0.0429, 0.0221, 0.0196, 0.0192, 0.0175, 0.0155, 0.0144,\n",
      "        0.0143])\n",
      "{'fashionable': tensor(0.1388)}\n",
      "max_probe is: tensor(0.1388)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of noncommercial is _ .\n",
      "['commercial', 'Commercial', 'not', 'free', 'corporate', 'public', 'advertising', 'and', 'the', 'non']\n",
      "tensor([0.6948, 0.0298, 0.0154, 0.0066, 0.0055, 0.0047, 0.0040, 0.0036, 0.0032,\n",
      "        0.0031])\n",
      "{'commercial': tensor(0.6948)}\n",
      "max_probe is: tensor(0.6948)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unsteady is _ .\n",
      "['unstable', 'shaky', 'steady', 'uncertain', 'erratic', 'slippery', 'and', 'clumsy', 'stable', 'inconsistent']\n",
      "tensor([0.1075, 0.0907, 0.0312, 0.0176, 0.0127, 0.0122, 0.0110, 0.0091, 0.0084,\n",
      "        0.0082])\n",
      "{'steady': tensor(0.0312)}\n",
      "max_probe is: tensor(0.0312)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of invariable is _ .\n",
      "['and', ',', 'also', 'always', 'constant', 'in', 'of', 'written', 'simply', 'by']\n",
      "tensor([0.1128, 0.0599, 0.0431, 0.0313, 0.0235, 0.0215, 0.0203, 0.0179, 0.0137,\n",
      "        0.0121])\n",
      "{'variable': tensor(0.0015)}\n",
      "max_probe is: tensor(0.0015)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 97\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unneeded is _ .\n",
      "['unnecessary', 'needed', 'unwanted', 'necessary', 'indispensable', 'need', 'irrelevant', 'useless', 'inconvenient', 'used']\n",
      "tensor([0.2883, 0.1498, 0.0662, 0.0267, 0.0252, 0.0202, 0.0129, 0.0118, 0.0110,\n",
      "        0.0110])\n",
      "{'necessary': tensor(0.0267)}\n",
      "max_probe is: tensor(0.0267)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inaudible is _ .\n",
      "['audible', 'pronounced', 'in', 'and', 'also', 'the', 'silent', '', '.', ',']\n",
      "tensor([0.2258, 0.0610, 0.0309, 0.0203, 0.0202, 0.0170, 0.0133, 0.0130, 0.0118,\n",
      "        0.0115])\n",
      "{'audible': tensor(0.2258)}\n",
      "max_probe is: tensor(0.2258)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uncontroversial is _ .\n",
      "['controversial', 'and', 'controversy', 'also', 'disputed', 'the', 'contentious', ',', 'undeniable', 'popular']\n",
      "tensor([0.4363, 0.0175, 0.0157, 0.0154, 0.0144, 0.0101, 0.0085, 0.0082, 0.0079,\n",
      "        0.0079])\n",
      "{'controversial': tensor(0.4363)}\n",
      "max_probe is: tensor(0.4363)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unquestionable is _ .\n",
      "['undeniable', 'absolute', 'sure', 'certain', 'proven', 'absolutely', 'uncertain', 'definitive', 'true', 'trustworthy']\n",
      "tensor([0.1385, 0.0371, 0.0270, 0.0248, 0.0169, 0.0168, 0.0154, 0.0118, 0.0113,\n",
      "        0.0110])\n",
      "{'questionable': tensor(0.0034)}\n",
      "max_probe is: tensor(0.0034)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 38\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of avoidable is _ .\n",
      "['avoid', 'unavoidable', 'avoided', 'and', 'also', 'possible', 'inevitable', 'not', 'impossible', 'likely']\n",
      "tensor([0.0692, 0.0583, 0.0413, 0.0204, 0.0192, 0.0152, 0.0147, 0.0138, 0.0125,\n",
      "        0.0121])\n",
      "{'inevitable': tensor(0.0147)}\n",
      "max_probe is: tensor(0.0147)\n",
      "the position of max probe is: 6\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unenthusiastic is _ .\n",
      "['pessimistic', 'enthusiastic', 'skeptical', 'optimistic', 'negative', 'indifferent', 'impatient', 'dismissive', 'and', 'cheerful']\n",
      "tensor([0.0968, 0.0397, 0.0385, 0.0365, 0.0209, 0.0135, 0.0117, 0.0104, 0.0086,\n",
      "        0.0084])\n",
      "{'enthusiastic': tensor(0.0397)}\n",
      "max_probe is: tensor(0.0397)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unwary is _ .\n",
      "['the', 'foolish', 'naive', 'ignorant', 'and', 'vigilant', 'reckless', 'alert', 'unlucky', 'naÃ¯ve']\n",
      "tensor([0.0322, 0.0241, 0.0185, 0.0148, 0.0136, 0.0135, 0.0117, 0.0108, 0.0107,\n",
      "        0.0103])\n",
      "{'wary': tensor(0.0049)}\n",
      "max_probe is: tensor(0.0049)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 30\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unready is _ .\n",
      "['ready', 'available', 'also', 'called', ',', 'and', 'prepared', 'the', 'now', '.']\n",
      "tensor([0.1377, 0.0379, 0.0302, 0.0205, 0.0153, 0.0135, 0.0124, 0.0117, 0.0115,\n",
      "        0.0096])\n",
      "{'ready': tensor(0.1377)}\n",
      "max_probe is: tensor(0.1377)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unapologetic is _ .\n",
      "['shameless', 'arrogant', 'entitled', 'irresponsible', 'honest', 'hypocritical', 'authentic', 'fearless', 'ironic', 'narcissistic']\n",
      "tensor([0.0307, 0.0268, 0.0223, 0.0156, 0.0152, 0.0150, 0.0137, 0.0132, 0.0120,\n",
      "        0.0092])\n",
      "apologeticis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of impious is _ .\n",
      "['imperfect', 'and', 'the', 'positive', 'or', 'also', 'vulgar', 'perfect', 'imp', ';']\n",
      "tensor([0.0351, 0.0153, 0.0150, 0.0144, 0.0112, 0.0109, 0.0091, 0.0083, 0.0078,\n",
      "        0.0077])\n",
      "{'pious': tensor(0.0008)}\n",
      "max_probe is: tensor(0.0008)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 199\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unfree is _ .\n",
      "['free', 'also', ',', 'Free', 'and', '.', 'undefined', 'called', 'freed', 'the']\n",
      "tensor([0.2289, 0.0260, 0.0204, 0.0174, 0.0164, 0.0111, 0.0098, 0.0098, 0.0083,\n",
      "        0.0075])\n",
      "{'free': tensor(0.2289)}\n",
      "max_probe is: tensor(0.2289)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unarmored is _ .\n",
      "['armored', 'unarmed', 'equipped', 'unprotected', 'the', ',', 'armor', 'naked', 'not', 'and']\n",
      "tensor([0.0949, 0.0760, 0.0251, 0.0246, 0.0200, 0.0199, 0.0197, 0.0168, 0.0164,\n",
      "        0.0164])\n",
      "{'armored': tensor(0.0949)}\n",
      "max_probe is: tensor(0.0949)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of effectual is _ .\n",
      "['effective', 'also', ',', 'functional', 'and', 'energetic', 'equivalent', 'effect', 'potent', 'efficient']\n",
      "tensor([0.1234, 0.0331, 0.0229, 0.0217, 0.0213, 0.0209, 0.0186, 0.0177, 0.0151,\n",
      "        0.0137])\n",
      "{'ineffective': tensor(0.0008)}\n",
      "max_probe is: tensor(0.0008)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 172\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unpatriotic is _ .\n",
      "['patriotic', 'patriot', 'selfish', 'nationalist', 'imperialist', 'stupid', 'American', 'fascist', 'hypocritical', 'partisan']\n",
      "tensor([0.2999, 0.0266, 0.0231, 0.0157, 0.0150, 0.0137, 0.0136, 0.0134, 0.0123,\n",
      "        0.0122])\n",
      "{'patriotic': tensor(0.2999)}\n",
      "max_probe is: tensor(0.2999)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unidentifiable is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unknown', 'ambiguous', 'undefined', 'unidentified', 'anonymous', 'indefinite', 'unspecified', 'uncertain', 'undocumented', 'not']\n",
      "tensor([0.2753, 0.0315, 0.0315, 0.0309, 0.0271, 0.0184, 0.0124, 0.0122, 0.0118,\n",
      "        0.0117])\n",
      "{'identifiable': tensor(0.0027)}\n",
      "max_probe is: tensor(0.0027)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 46\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inoffensive is _ .\n",
      "['offensive', 'polite', 'agreeable', 'neutral', 'obnoxious', 'in', 'bland', 'appropriate', 'innocuous', 'acceptable']\n",
      "tensor([0.0344, 0.0249, 0.0215, 0.0208, 0.0191, 0.0162, 0.0153, 0.0150, 0.0140,\n",
      "        0.0134])\n",
      "{'offensive': tensor(0.0344)}\n",
      "max_probe is: tensor(0.0344)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unarmoured is _ .\n",
      "['unarmed', 'armoured', 'unprotected', 'unmanned', 'light', 'unmarked', 'protected', 'naked', 'unrestricted', 'armed']\n",
      "tensor([0.3175, 0.0612, 0.0395, 0.0367, 0.0334, 0.0208, 0.0085, 0.0083, 0.0082,\n",
      "        0.0074])\n",
      "{'armored': tensor(0.0064)}\n",
      "max_probe is: tensor(0.0064)\n",
      "20\n",
      "the position of max probe is: 11\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of low-pitched is _ .\n",
      "['low', 'high', ',', 'and', 'called', 'the', '.', 'or', 'lower', 'C']\n",
      "tensor([0.3763, 0.1409, 0.0226, 0.0153, 0.0152, 0.0118, 0.0073, 0.0068, 0.0063,\n",
      "        0.0052])\n",
      "{'high': tensor(0.1409)}\n",
      "max_probe is: tensor(0.1409)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of noninvasive is _ .\n",
      "['invasive', 'not', 'and', 'surgical', 'in', 'or', 'procedural', 'sterile', 'no', ',']\n",
      "tensor([0.3352, 0.0277, 0.0200, 0.0178, 0.0138, 0.0126, 0.0091, 0.0087, 0.0082,\n",
      "        0.0074])\n",
      "{'invasive': tensor(0.3352)}\n",
      "max_probe is: tensor(0.3352)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonfunctional is _ .\n",
      "['functional', 'function', ',', 'neutral', 'not', 'and', 'null', 'void', 'negative', 'also']\n",
      "tensor([0.3935, 0.0407, 0.0287, 0.0208, 0.0155, 0.0115, 0.0092, 0.0082, 0.0076,\n",
      "        0.0064])\n",
      "{'functional': tensor(0.3935)}\n",
      "max_probe is: tensor(0.3935)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of ungrammatical is _ .\n",
      "['and', ',', 'or', 'indefinite', 'not', '.', 'always', 'the', 'also', 'in']\n",
      "tensor([0.1279, 0.0817, 0.0286, 0.0281, 0.0212, 0.0202, 0.0184, 0.0156, 0.0135,\n",
      "        0.0132])\n",
      "grammaticalis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of ignoble is _ .\n",
      "['unfortunate', 'shameful', 'vile', 'evil', 'grave', 'absurd', 'embarrassing', 'appalling', 'heroic', 'despicable']\n",
      "tensor([0.0293, 0.0140, 0.0139, 0.0131, 0.0115, 0.0097, 0.0096, 0.0083, 0.0082,\n",
      "        0.0081])\n",
      "{'noble': tensor(0.0023)}\n",
      "max_probe is: tensor(0.0023)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 66\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unemotional is _ .\n",
      "['emotional', 'neutral', 'not', ',', 'and', '.', 'also', 'emotionally', 'emotion', 'sentimental']\n",
      "tensor([0.1277, 0.0250, 0.0223, 0.0207, 0.0174, 0.0114, 0.0085, 0.0077, 0.0070,\n",
      "        0.0069])\n",
      "{'emotional': tensor(0.1277)}\n",
      "max_probe is: tensor(0.1277)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonnative is _ .\n",
      "['native', 'natural', 'indigenous', 'not', 'non', 'Native', 'invasive', 'no', ',', 'national']\n",
      "tensor([0.5792, 0.0263, 0.0205, 0.0155, 0.0132, 0.0090, 0.0077, 0.0077, 0.0061,\n",
      "        0.0042])\n",
      "{'native': tensor(0.5792)}\n",
      "max_probe is: tensor(0.5792)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unimpaired is _ .\n",
      "['impaired', 'and', 'retarded', 'the', '', 'unaffected', 'or', 'called', ',', 'disabled']\n",
      "tensor([0.1499, 0.0340, 0.0283, 0.0204, 0.0168, 0.0163, 0.0161, 0.0155, 0.0133,\n",
      "        0.0125])\n",
      "{'impaired': tensor(0.1499)}\n",
      "max_probe is: tensor(0.1499)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of dishonourable is _ .\n",
      "['honorable', 'shameful', 'despicable', 'unfortunate', 'unworthy', 'the', 'disgrace', 'deserving', 'excellent', 'and']\n",
      "tensor([0.2863, 0.0426, 0.0281, 0.0231, 0.0161, 0.0150, 0.0119, 0.0112, 0.0111,\n",
      "        0.0093])\n",
      "{'honorable': tensor(0.2863)}\n",
      "max_probe is: tensor(0.2863)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inconsiderable is _ .\n",
      "['insensitive', 'polite', 'rude', 'unfortunate', 'unacceptable', 'not', 'reasonable', 'generous', 'awkward', 'trivial']\n",
      "tensor([0.0583, 0.0235, 0.0141, 0.0134, 0.0114, 0.0114, 0.0112, 0.0110, 0.0087,\n",
      "        0.0085])\n",
      "{'considerable': tensor(0.0001)}\n",
      "max_probe is: tensor(0.0001)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 817\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of ahistorical is _ .\n",
      "['historical', 'and', ',', 'the', 'also', 'historic', 'a', 'in', 'or', 'of']\n",
      "tensor([0.1035, 0.0444, 0.0320, 0.0283, 0.0245, 0.0162, 0.0151, 0.0146, 0.0133,\n",
      "        0.0100])\n",
      "{'historical': tensor(0.1035)}\n",
      "max_probe is: tensor(0.1035)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unquiet is _ .\n",
      "['quiet', 'silence', 'calm', 'silent', 'noise', 'Quiet', 'peace', 'discontent', 'loud', 'noisy']\n",
      "tensor([0.3174, 0.1086, 0.0249, 0.0229, 0.0081, 0.0073, 0.0069, 0.0066, 0.0064,\n",
      "        0.0051])\n",
      "{'quiet': tensor(0.3174)}\n",
      "max_probe is: tensor(0.3174)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of untraditional is _ .\n",
      "['unconventional', 'conventional', 'unusual', 'traditional', 'and', 'irregular', 'ordinary', 'unorthodox', 'not', 'standard']\n",
      "tensor([0.0832, 0.0294, 0.0188, 0.0158, 0.0110, 0.0102, 0.0097, 0.0095, 0.0092,\n",
      "        0.0088])\n",
      "{'traditional': tensor(0.0158)}\n",
      "max_probe is: tensor(0.0158)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of untroubled is _ .\n",
      "['not', 'troubled', 'unaffected', 'unclear', 'neutral', 'straightforward', 'independent', 'undone', 'transparent', 'free']\n",
      "tensor([0.0130, 0.0120, 0.0094, 0.0067, 0.0063, 0.0060, 0.0056, 0.0055, 0.0054,\n",
      "        0.0053])\n",
      "{'troubled': tensor(0.0120)}\n",
      "max_probe is: tensor(0.0120)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unrighteous is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['righteous', 'wicked', 'unjust', 'just', 'unlawful', 'evil', 'unworthy', 'wrongful', 'sinful', 'immoral']\n",
      "tensor([0.4394, 0.0644, 0.0514, 0.0256, 0.0219, 0.0156, 0.0147, 0.0106, 0.0104,\n",
      "        0.0094])\n",
      "{'righteous': tensor(0.4394)}\n",
      "max_probe is: tensor(0.4394)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of noncompetitive is _ .\n",
      "['competitive', 'not', 'also', 'and', 'aggressive', ',', 'neutral', '', '.', 'the']\n",
      "tensor([0.4640, 0.0179, 0.0131, 0.0131, 0.0119, 0.0105, 0.0096, 0.0084, 0.0069,\n",
      "        0.0065])\n",
      "{'competitive': tensor(0.4640)}\n",
      "max_probe is: tensor(0.4640)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unsystematic is _ .\n",
      "['systematic', 'chaotic', 'linear', 'modular', 'and', 'arbitrary', 'not', 'system', 'unstable', 'simple']\n",
      "tensor([0.1338, 0.0405, 0.0195, 0.0181, 0.0152, 0.0124, 0.0098, 0.0091, 0.0082,\n",
      "        0.0074])\n",
      "{'systematic': tensor(0.1338)}\n",
      "max_probe is: tensor(0.1338)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of insensible is _ .\n",
      "['in', 'indefinite', 'and', 'or', ',', 'also', ';', 'the', '=', 'saturated']\n",
      "tensor([0.0343, 0.0309, 0.0257, 0.0203, 0.0184, 0.0164, 0.0115, 0.0098, 0.0095,\n",
      "        0.0084])\n",
      "{'sensible': tensor(0.0009)}\n",
      "max_probe is: tensor(0.0009)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 165\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonpolitical is _ .\n",
      "['political', 'neutral', 'not', 'democratic', 'nonpartisan', 'pragmatic', 'libertarian', 'progressive', 'no', 'non']\n",
      "tensor([0.2698, 0.0384, 0.0280, 0.0213, 0.0204, 0.0142, 0.0102, 0.0097, 0.0095,\n",
      "        0.0086])\n",
      "{'political': tensor(0.2698)}\n",
      "max_probe is: tensor(0.2698)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unambitious is _ .\n",
      "['ambitious', 'aggressive', 'optimistic', 'irresponsible', 'humble', 'modest', 'mediocre', 'impatient', 'visionary', 'boring']\n",
      "tensor([0.2728, 0.0249, 0.0141, 0.0133, 0.0123, 0.0113, 0.0100, 0.0083, 0.0077,\n",
      "        0.0071])\n",
      "{'ambitious': tensor(0.2728)}\n",
      "max_probe is: tensor(0.2728)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unlikeable is _ .\n",
      "['unfortunate', 'undesirable', 'annoying', 'admirable', 'boring', 'unacceptable', 'interesting', 'disappointing', 'awful', 'unlucky']\n",
      "tensor([0.0535, 0.0437, 0.0287, 0.0252, 0.0247, 0.0200, 0.0156, 0.0130, 0.0113,\n",
      "        0.0111])\n",
      "{'sympathetic': tensor(0.0009)}\n",
      "max_probe is: tensor(0.0009)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 181\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of self-generated is _ .\n",
      "['generated', 'self', 'generator', ',', 'also', 'and', '', 'called', ':', 'written']\n",
      "tensor([0.0902, 0.0579, 0.0379, 0.0353, 0.0322, 0.0296, 0.0257, 0.0251, 0.0151,\n",
      "        0.0115])\n",
      "{'induced': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0002)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 461\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of indissoluble is _ .\n",
      "['soluble', ',', 'and', 'also', 'chloride', 'in', 'or', 'saturated', 'liquid', 'salt']\n",
      "tensor([0.1970, 0.0700, 0.0496, 0.0332, 0.0242, 0.0220, 0.0162, 0.0135, 0.0125,\n",
      "        0.0097])\n",
      "{'soluble': tensor(0.1970)}\n",
      "max_probe is: tensor(0.1970)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonmilitary is _ .\n",
      "['military', 'civilian', 'not', 'the', 'civil', 'USAF', 'non', 'enlisted', 'naval', 'Military']\n",
      "tensor([0.4447, 0.0439, 0.0183, 0.0152, 0.0148, 0.0109, 0.0108, 0.0103, 0.0098,\n",
      "        0.0087])\n",
      "{'military': tensor(0.4447)}\n",
      "max_probe is: tensor(0.4447)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonprofessional is _ .\n",
      "['professional', 'informal', 'casual', 'not', 'freelance', 'Professional', 'non', 'amateur', 'unofficial', 'formal']\n",
      "tensor([0.2988, 0.0597, 0.0448, 0.0299, 0.0236, 0.0175, 0.0153, 0.0123, 0.0106,\n",
      "        0.0079])\n",
      "{'professional': tensor(0.2988)}\n",
      "max_probe is: tensor(0.2988)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of resistible is _ .\n",
      "['also', ',', 'resistant', 'and', 'reactive', 'resilient', 'of', 'soluble', 'resist', 'in']\n",
      "tensor([0.0605, 0.0487, 0.0241, 0.0236, 0.0172, 0.0163, 0.0140, 0.0117, 0.0112,\n",
      "        0.0103])\n",
      "{'irresistible': tensor(5.0978e-05)}\n",
      "max_probe is: tensor(5.0978e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "the position of max probe is: 1651\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonsurgical is _ .\n",
      "['procedural', 'surgical', 'dental', 'sterile', 'and', 'standardized', 'standard', 'not', 'kosher', 'also']\n",
      "tensor([0.0313, 0.0232, 0.0174, 0.0167, 0.0163, 0.0145, 0.0142, 0.0136, 0.0133,\n",
      "        0.0132])\n",
      "{'surgical': tensor(0.0232)}\n",
      "max_probe is: tensor(0.0232)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonrenewable is _ .\n",
      "['renewable', 'indefinite', 'radioactive', 'finite', 'not', 'also', ',', 'and', 'natural', 'nuclear']\n",
      "tensor([0.1659, 0.0401, 0.0227, 0.0223, 0.0186, 0.0130, 0.0128, 0.0115, 0.0108,\n",
      "        0.0101])\n",
      "{'renewable': tensor(0.1659)}\n",
      "max_probe is: tensor(0.1659)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unspecialized is _ .\n",
      "['specialized', 'special', 'called', 'classified', 'generalized', 'the', 'and', 'specialization', 'reserved', ',']\n",
      "tensor([0.2089, 0.0285, 0.0274, 0.0259, 0.0223, 0.0165, 0.0144, 0.0127, 0.0125,\n",
      "        0.0112])\n",
      "{'specialized': tensor(0.2089)}\n",
      "max_probe is: tensor(0.2089)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unlikable is _ .\n",
      "['annoying', 'disliked', 'undesirable', 'unpopular', 'boring', 'intolerable', 'despicable', 'awkward', 'unpleasant', 'dislike']\n",
      "tensor([0.0880, 0.0561, 0.0496, 0.0325, 0.0272, 0.0219, 0.0216, 0.0197, 0.0177,\n",
      "        0.0177])\n",
      "{'sympathetic': tensor(0.0006)}\n",
      "max_probe is: tensor(0.0006)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 208\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nontechnical is _ .\n",
      "['technical', 'technically', 'not', 'Technical', 'formal', 'also', 'informal', ',', 'the', 'technological']\n",
      "tensor([0.4976, 0.0225, 0.0215, 0.0181, 0.0180, 0.0100, 0.0070, 0.0061, 0.0055,\n",
      "        0.0044])\n",
      "{'technical': tensor(0.4976)}\n",
      "max_probe is: tensor(0.4976)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonclassical is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classical', 'Classical', ',', 'and', 'also', 'Byzantine', 'Latin', 'or', '...', 'not']\n",
      "tensor([0.0806, 0.0421, 0.0316, 0.0213, 0.0197, 0.0170, 0.0168, 0.0163, 0.0109,\n",
      "        0.0104])\n",
      "{'classical': tensor(0.0806)}\n",
      "max_probe is: tensor(0.0806)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of insanitary is _ .\n",
      "['sterile', 'intolerable', 'san', 'humane', 'unacceptable', 'obscene', 'in', 'disgusting', 'ironic', 'shameful']\n",
      "tensor([0.0661, 0.0233, 0.0160, 0.0149, 0.0114, 0.0097, 0.0085, 0.0081, 0.0080,\n",
      "        0.0076])\n",
      "sanitaryis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of incautious is _ .\n",
      "['and', 'imperative', ',', 'or', 'positive', 'the', 'optimistic', 'conditional', 'inconsistent', 'insensitive']\n",
      "tensor([0.0249, 0.0103, 0.0102, 0.0101, 0.0092, 0.0090, 0.0086, 0.0085, 0.0085,\n",
      "        0.0079])\n",
      "{'cautious': tensor(0.0049)}\n",
      "max_probe is: tensor(0.0049)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 24\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uncharitable is _ .\n",
      "['charitable', 'unethical', 'despicable', 'neutral', 'unacceptable', 'shameful', 'ethical', 'hypocritical', 'undesirable', 'not']\n",
      "tensor([0.0849, 0.0397, 0.0362, 0.0200, 0.0160, 0.0144, 0.0137, 0.0117, 0.0109,\n",
      "        0.0109])\n",
      "{'charitable': tensor(0.0849)}\n",
      "max_probe is: tensor(0.0849)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of untypical is _ .\n",
      "['unusual', 'unique', 'rare', 'and', 'normal', 'also', ',', 'or', 'undefined', 'irregular']\n",
      "tensor([0.0320, 0.0297, 0.0239, 0.0200, 0.0133, 0.0126, 0.0115, 0.0115, 0.0110,\n",
      "        0.0105])\n",
      "{'typical': tensor(0.0022)}\n",
      "max_probe is: tensor(0.0022)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 67\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonmagnetic is _ .\n",
      "['magnetic', ',', 'and', 'also', 'neutral', 'metallic', 'magnet', 'or', 'not', 'electromagnetic']\n",
      "tensor([0.6375, 0.0240, 0.0188, 0.0168, 0.0108, 0.0096, 0.0077, 0.0069, 0.0064,\n",
      "        0.0062])\n",
      "{'magnetic': tensor(0.6375)}\n",
      "max_probe is: tensor(0.6375)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonalcoholic is _ .\n",
      "['alcoholic', 'sober', 'not', 'alcohol', 'and', 'non', 'neutral', 'without', 'no', ',']\n",
      "tensor([0.2169, 0.0806, 0.0410, 0.0377, 0.0256, 0.0237, 0.0219, 0.0184, 0.0179,\n",
      "        0.0166])\n",
      "{'alcoholic': tensor(0.2169)}\n",
      "max_probe is: tensor(0.2169)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unsurprised is _ .\n",
      "['surprised', 'astonished', 'shocked', 'surprise', 'stunned', 'surprising', 'and', 'also', ',', 'baffled']\n",
      "tensor([0.2465, 0.1316, 0.0665, 0.0344, 0.0195, 0.0135, 0.0102, 0.0092, 0.0087,\n",
      "        0.0084])\n",
      "{'surprised': tensor(0.2465)}\n",
      "max_probe is: tensor(0.2465)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unaccessible is _ .\n",
      "['inaccessible', 'accessible', 'available', 'unavailable', 'accessibility', 'also', 'not', 'access', 'accessed', 'and']\n",
      "tensor([0.3629, 0.2683, 0.0202, 0.0167, 0.0106, 0.0088, 0.0087, 0.0068, 0.0067,\n",
      "        0.0051])\n",
      "{'accessible': tensor(0.2683)}\n",
      "max_probe is: tensor(0.2683)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of undependable is _ .\n",
      "['unreliable', 'reliable', 'inconsistent', 'reliability', 'unpredictable', ',', 'durable', 'unstable', 'independent', 'stable']\n",
      "tensor([0.3106, 0.2716, 0.0208, 0.0208, 0.0093, 0.0078, 0.0073, 0.0067, 0.0064,\n",
      "        0.0058])\n",
      "{'reliable': tensor(0.2716)}\n",
      "max_probe is: tensor(0.2716)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unmusical is _ .\n",
      "['musical', ',', 'not', '.', 'and', 'also', 'Musical', 'ironic', 'harmonic', 'the']\n",
      "tensor([0.0957, 0.0403, 0.0201, 0.0159, 0.0144, 0.0120, 0.0107, 0.0101, 0.0077,\n",
      "        0.0074])\n",
      "{'musical': tensor(0.0957)}\n",
      "max_probe is: tensor(0.0957)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of undramatic is _ .\n",
      "['dramatic', 'and', ',', 'negative', 'also', 'the', 'or', '.', 'linear', 'in']\n",
      "tensor([0.0757, 0.0247, 0.0198, 0.0172, 0.0121, 0.0093, 0.0087, 0.0084, 0.0079,\n",
      "        0.0072])\n",
      "{'dramatic': tensor(0.0757)}\n",
      "max_probe is: tensor(0.0757)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonfictional is _ .\n",
      "['fictional', 'fiction', 'fictitious', 'factual', 'not', 'false', 'hypothetical', 'and', ',', 'Fiction']\n",
      "tensor([0.2828, 0.1170, 0.0371, 0.0244, 0.0230, 0.0167, 0.0152, 0.0126, 0.0095,\n",
      "        0.0080])\n",
      "{'fictional': tensor(0.2828)}\n",
      "max_probe is: tensor(0.2828)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of ungenerous is _ .\n",
      "['generous', 'greedy', 'selfish', 'rude', 'insensitive', 'gracious', 'generosity', 'dismissive', 'humble', 'inappropriate']\n",
      "tensor([0.3306, 0.0601, 0.0414, 0.0182, 0.0172, 0.0109, 0.0095, 0.0080, 0.0070,\n",
      "        0.0064])\n",
      "{'generous': tensor(0.3306)}\n",
      "max_probe is: tensor(0.3306)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of undiplomatic is _ .\n",
      "['diplomatic', 'blunt', 'vulgar', 'arrogant', 'aggressive', 'clumsy', 'polite', 'subtle', 'authoritarian', 'insidious']\n",
      "tensor([0.0603, 0.0284, 0.0233, 0.0144, 0.0129, 0.0113, 0.0110, 0.0105, 0.0101,\n",
      "        0.0079])\n",
      "{'diplomatic': tensor(0.0603)}\n",
      "max_probe is: tensor(0.0603)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonresidential is _ .\n",
      "['residential', 'Residential', 'rental', ',', 'also', 'and', '', 'commercial', 'not', 'urban']\n",
      "tensor([0.7952, 0.0140, 0.0081, 0.0059, 0.0050, 0.0047, 0.0041, 0.0041, 0.0036,\n",
      "        0.0033])\n",
      "{'residential': tensor(0.7952)}\n",
      "max_probe is: tensor(0.7952)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unkept is _ .\n",
      "['kept', 'unwanted', 'keep', 'the', 'neglected', 'forgotten', 'not', '.', 'keeping', ',']\n",
      "tensor([0.3327, 0.0187, 0.0145, 0.0096, 0.0088, 0.0085, 0.0076, 0.0068, 0.0065,\n",
      "        0.0064])\n",
      "unbrokenis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of uncreative is _ .\n",
      "['recursive', 'creative', 'constructive', 'destructive', 'functional', 'passive', 'chaotic', 'void', 'disruptive', 'and']\n",
      "tensor([0.1312, 0.0393, 0.0248, 0.0227, 0.0147, 0.0147, 0.0086, 0.0086, 0.0084,\n",
      "        0.0077])\n",
      "{'creative': tensor(0.0393)}\n",
      "max_probe is: tensor(0.0393)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonproprietary is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['proprietary', 'patented', 'patent', 'generic', 'NP', 'also', 'private', 'not', 'and', 'commercial']\n",
      "tensor([0.4019, 0.0671, 0.0337, 0.0244, 0.0224, 0.0167, 0.0111, 0.0110, 0.0082,\n",
      "        0.0059])\n",
      "{'proprietary': tensor(0.4019)}\n",
      "max_probe is: tensor(0.4019)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonsexual is _ .\n",
      "['not', 'sexual', ',', 'neutral', 'non', 'and', 'no', 'or', 'male', 'heterosexual']\n",
      "tensor([0.0964, 0.0687, 0.0482, 0.0386, 0.0287, 0.0280, 0.0233, 0.0173, 0.0114,\n",
      "        0.0108])\n",
      "{'sexual': tensor(0.0687)}\n",
      "max_probe is: tensor(0.0687)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unadventurous is _ .\n",
      "['adventurous', 'timid', 'cautious', 'irresponsible', 'reckless', 'impatient', 'prudent', 'pessimistic', 'boring', 'aggressive']\n",
      "tensor([0.2590, 0.0396, 0.0363, 0.0146, 0.0126, 0.0101, 0.0099, 0.0092, 0.0079,\n",
      "        0.0076])\n",
      "{'adventurous': tensor(0.2590)}\n",
      "max_probe is: tensor(0.2590)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of ill-formed is _ .\n",
      "['formed', 'defective', 'ugly', 'imperfect', 'not', 'ill', 'awkward', ',', 'called', 'the']\n",
      "tensor([0.0639, 0.0230, 0.0179, 0.0128, 0.0086, 0.0081, 0.0075, 0.0073, 0.0072,\n",
      "        0.0071])\n",
      "grammaticalis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of noninfectious is _ .\n",
      "['infectious', 'sterile', 'not', 'viral', 'neutral', 'NO', 'NOT', 'no', ',', 'and']\n",
      "tensor([0.1357, 0.0522, 0.0508, 0.0314, 0.0264, 0.0238, 0.0216, 0.0198, 0.0159,\n",
      "        0.0150])\n",
      "{'infectious': tensor(0.1357)}\n",
      "max_probe is: tensor(0.1357)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unaggressive is _ .\n",
      "['aggressive', 'passive', ',', 'aggressively', 'not', 'also', 'neutral', 'and', 'the', '.']\n",
      "tensor([0.3764, 0.0179, 0.0148, 0.0117, 0.0093, 0.0076, 0.0064, 0.0064, 0.0060,\n",
      "        0.0060])\n",
      "{'aggressive': tensor(0.3764)}\n",
      "max_probe is: tensor(0.3764)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of noncontroversial is _ .\n",
      "['controversial', 'controversy', 'problematic', 'not', 'and', 'also', 'contentious', 'popular', 'questionable', ',']\n",
      "tensor([0.6899, 0.0175, 0.0104, 0.0083, 0.0077, 0.0070, 0.0060, 0.0050, 0.0047,\n",
      "        0.0043])\n",
      "{'controversial': tensor(0.6899)}\n",
      "max_probe is: tensor(0.6899)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unsocial is _ .\n",
      "['social', 'awkward', 'rude', 'polite', 'socially', 'lonely', 'not', 'friendly', 'informal', 'casual']\n",
      "tensor([0.0817, 0.0277, 0.0267, 0.0214, 0.0213, 0.0203, 0.0195, 0.0187, 0.0167,\n",
      "        0.0162])\n",
      "{'social': tensor(0.0817)}\n",
      "max_probe is: tensor(0.0817)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unhealthful is _ .\n",
      "['unhealthy', 'healthy', 'toxic', 'dangerous', 'obese', 'harmful', 'unsafe', 'unacceptable', 'and', ',']\n",
      "tensor([0.3943, 0.1667, 0.0146, 0.0121, 0.0096, 0.0086, 0.0079, 0.0069, 0.0063,\n",
      "        0.0058])\n",
      "sanitaryis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of unseeable is _ .\n",
      "['visible', 'and', 'opaque', 'seen', 'invisible', 'undefined', 'observable', 'also', 'void', 'not']\n",
      "tensor([0.0386, 0.0295, 0.0267, 0.0265, 0.0258, 0.0206, 0.0187, 0.0184, 0.0152,\n",
      "        0.0149])\n",
      "{'visible': tensor(0.0386)}\n",
      "max_probe is: tensor(0.0386)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of synthetical is _ .\n",
      "['and', ',', 'the', 'always', 'or', 'equivalent', 'in', 'also', 'written', 'of']\n",
      "tensor([0.1606, 0.0387, 0.0297, 0.0238, 0.0224, 0.0187, 0.0175, 0.0169, 0.0147,\n",
      "        0.0143])\n",
      "{'analytic': tensor(0.0028)}\n",
      "max_probe is: tensor(0.0028)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 50\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unobvious is _ .\n",
      "['transparent', 'obvious', 'opaque', 'invisible', 'visible', ',', 'and', 'also', 'clear', 'ubiquitous']\n",
      "tensor([0.3065, 0.0838, 0.0306, 0.0251, 0.0235, 0.0199, 0.0161, 0.0158, 0.0154,\n",
      "        0.0142])\n",
      "{'obvious': tensor(0.0838)}\n",
      "max_probe is: tensor(0.0838)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inconvertible is _ .\n",
      "['cubic', ',', 'also', 'and', 'equivalent', 'always', 'simply', 'or', 'in', 'of']\n",
      "tensor([0.0852, 0.0620, 0.0545, 0.0454, 0.0157, 0.0150, 0.0126, 0.0115, 0.0109,\n",
      "        0.0098])\n",
      "{'convertible': tensor(0.0013)}\n",
      "max_probe is: tensor(0.0013)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 112\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unaesthetic is _ .\n",
      "['aesthetic', 'vulgar', 'ugly', 'awkward', 'grotesque', 'not', ',', 'sterile', 'inappropriate', 'obscene']\n",
      "tensor([0.0412, 0.0395, 0.0262, 0.0251, 0.0246, 0.0144, 0.0112, 0.0107, 0.0085,\n",
      "        0.0082])\n",
      "{'aesthetic': tensor(0.0412)}\n",
      "max_probe is: tensor(0.0412)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonmusical is _ .\n",
      "['musical', ',', 'not', 'harmonic', 'and', 'Musical', '.', 'also', 'nominal', 'or']\n",
      "tensor([0.3181, 0.0408, 0.0289, 0.0226, 0.0168, 0.0125, 0.0121, 0.0114, 0.0077,\n",
      "        0.0072])\n",
      "{'musical': tensor(0.3181)}\n",
      "max_probe is: tensor(0.3181)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonfinancial is _ .\n",
      "['financial', 'Financial', 'not', 'and', 'finance', 'also', 'the', 'monetary', 'economic', 'fiscal']\n",
      "tensor([0.3937, 0.0260, 0.0249, 0.0187, 0.0113, 0.0103, 0.0099, 0.0080, 0.0069,\n",
      "        0.0066])\n",
      "{'financial': tensor(0.3937)}\n",
      "max_probe is: tensor(0.3937)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unspecialised is _ .\n",
      "['specialist', 'special', 'specialized', 'ordinary', 'specialty', 'limited', 'the', 'not', 'and', 'reserved']\n",
      "tensor([0.1343, 0.0514, 0.0396, 0.0193, 0.0109, 0.0104, 0.0099, 0.0097, 0.0091,\n",
      "        0.0085])\n",
      "{'specialized': tensor(0.0396)}\n",
      "max_probe is: tensor(0.0396)\n",
      "the position of max probe is: 2\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of impalpable is _ .\n",
      "['and', ',', 'also', 'in', 'or', 'indefinite', 'of', ';', 'transparent', 'the']\n",
      "tensor([0.0513, 0.0507, 0.0256, 0.0169, 0.0168, 0.0161, 0.0122, 0.0095, 0.0093,\n",
      "        0.0083])\n",
      "{'tangible': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0003)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 441\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uncomparable is _ .\n",
      "['equivalent', 'comparable', 'equal', 'and', 'identical', '.', 'also', ',', 'synonymous', 'or']\n",
      "tensor([0.0668, 0.0512, 0.0339, 0.0336, 0.0274, 0.0227, 0.0189, 0.0159, 0.0141,\n",
      "        0.0113])\n",
      "{'comparable': tensor(0.0512)}\n",
      "max_probe is: tensor(0.0512)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonaggressive is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aggressive', 'aggressively', 'passive', 'active', ',', 'not', 'insensitive', 'reactive', 'conservative', 'also']\n",
      "tensor([0.6508, 0.0132, 0.0076, 0.0060, 0.0060, 0.0054, 0.0045, 0.0044, 0.0044,\n",
      "        0.0042])\n",
      "{'aggressive': tensor(0.6508)}\n",
      "max_probe is: tensor(0.6508)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of heterogenous is _ .\n",
      "['volatile', 'and', 'chaotic', 'generalized', 'dynamic', 'ubiquitous', 'unstable', 'linear', 'not', 'neutral']\n",
      "tensor([0.0201, 0.0184, 0.0168, 0.0134, 0.0129, 0.0112, 0.0110, 0.0105, 0.0087,\n",
      "        0.0085])\n",
      "homogeneousis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of nonindustrial is _ .\n",
      "['industrial', ',', 'not', 'and', '.', 'or', 'also', 'Industrial', 'industry', 'no']\n",
      "tensor([0.3661, 0.0323, 0.0306, 0.0160, 0.0148, 0.0137, 0.0124, 0.0112, 0.0091,\n",
      "        0.0090])\n",
      "{'industrial': tensor(0.3661)}\n",
      "max_probe is: tensor(0.3661)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonoperational is _ .\n",
      "['and', ',', 'linear', 'functional', 'not', 'rational', 'exponential', 'operator', 'also', 'or']\n",
      "tensor([0.0329, 0.0309, 0.0218, 0.0197, 0.0195, 0.0192, 0.0192, 0.0188, 0.0143,\n",
      "        0.0116])\n",
      "{'operational': tensor(0.0114)}\n",
      "max_probe is: tensor(0.0114)\n",
      "20\n",
      "the position of max probe is: 11\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unmilitary is _ .\n",
      "['military', 'unarmed', 'militia', 'enlisted', 'paramilitary', 'not', 'irregular', 'the', 'independent', 'civilian']\n",
      "tensor([0.0690, 0.0415, 0.0390, 0.0229, 0.0221, 0.0214, 0.0161, 0.0158, 0.0123,\n",
      "        0.0111])\n",
      "{'military': tensor(0.0690)}\n",
      "max_probe is: tensor(0.0690)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uncomplete is _ .\n",
      "['also', 'complete', ',', 'empty', '.', 'always', 'optional', 'and', 'simply', 'not']\n",
      "tensor([0.0356, 0.0350, 0.0236, 0.0205, 0.0204, 0.0178, 0.0166, 0.0158, 0.0118,\n",
      "        0.0105])\n",
      "{'complete': tensor(0.0350)}\n",
      "max_probe is: tensor(0.0350)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonspherical is _ .\n",
      "['and', 'cubic', 'exponential', 'also', 'linear', 'or', 'the', ',', 'binary', 'regular']\n",
      "tensor([0.0527, 0.0254, 0.0226, 0.0220, 0.0190, 0.0182, 0.0154, 0.0136, 0.0122,\n",
      "        0.0114])\n",
      "{'spherical': tensor(0.0040)}\n",
      "max_probe is: tensor(0.0040)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 33\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uninfluential is _ .\n",
      "['influential', 'neutral', 'and', 'ubiquitous', 'powerful', 'also', ',', 'disruptive', 'the', 'not']\n",
      "tensor([0.1530, 0.0251, 0.0229, 0.0227, 0.0193, 0.0187, 0.0181, 0.0175, 0.0087,\n",
      "        0.0076])\n",
      "{'influential': tensor(0.1530)}\n",
      "max_probe is: tensor(0.1530)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of antonymous is _ .\n",
      "['and', 'also', ',', 'always', 'or', ':', 'written', '.', 'pronounced', 'the']\n",
      "tensor([0.2369, 0.0842, 0.0789, 0.0615, 0.0351, 0.0311, 0.0159, 0.0153, 0.0153,\n",
      "        0.0149])\n",
      "{'synonymous': tensor(0.0012)}\n",
      "max_probe is: tensor(0.0012)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 69\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of onymous is _ .\n",
      "['and', 'also', ',', 'or', ':', 'in', '.', 'the', '/', '+']\n",
      "tensor([0.1552, 0.0897, 0.0889, 0.0635, 0.0213, 0.0210, 0.0175, 0.0147, 0.0138,\n",
      "        0.0128])\n",
      "{'anonymous': tensor(2.5285e-05)}\n",
      "max_probe is: tensor(2.5285e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "the position of max probe is: 1778\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of evitable is _ .\n",
      "['exponential', 'efficient', 'and', 'in', 'the', 'effective', 'predictive', 'greedy', 'also', 'energetic']\n",
      "tensor([0.0224, 0.0196, 0.0151, 0.0123, 0.0098, 0.0097, 0.0088, 0.0087, 0.0085,\n",
      "        0.0079])\n",
      "{'inevitable': tensor(0.0020)}\n",
      "max_probe is: tensor(0.0020)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 72\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonlinguistic is _ .\n",
      "['linguistic', 'bilingual', 'not', 'and', 'fluent', 'semantic', ',', '.', 'analytic', 'or']\n",
      "tensor([0.1761, 0.0998, 0.0477, 0.0458, 0.0248, 0.0215, 0.0197, 0.0166, 0.0136,\n",
      "        0.0132])\n",
      "{'linguistic': tensor(0.1761)}\n",
      "max_probe is: tensor(0.1761)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unvoluntary is _ .\n",
      "['voluntary', 'involuntary', 'mandatory', 'optional', 'compulsory', 'voluntarily', 'not', 'informal', 'explicit', 'free']\n",
      "tensor([0.3831, 0.2362, 0.0260, 0.0229, 0.0199, 0.0110, 0.0101, 0.0092, 0.0060,\n",
      "        0.0058])\n",
      "{'voluntary': tensor(0.3831)}\n",
      "max_probe is: tensor(0.3831)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonreciprocal is _ .\n",
      "['reciprocal', 'and', 'not', 'inverse', 'also', 'mutual', 'reciproc', 'equitable', 'equivalent', 'circular']\n",
      "tensor([0.7585, 0.0100, 0.0077, 0.0072, 0.0061, 0.0056, 0.0056, 0.0051, 0.0045,\n",
      "        0.0039])\n",
      "{'reciprocal': tensor(0.7585)}\n",
      "max_probe is: tensor(0.7585)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonracial is _ .\n",
      "['racial', 'white', 'black', 'not', 'neutral', 'and', 'Caucasian', ',', 'race', 'non']\n",
      "tensor([0.1741, 0.1022, 0.0305, 0.0296, 0.0270, 0.0238, 0.0187, 0.0168, 0.0159,\n",
      "        0.0152])\n",
      "{'racial': tensor(0.1741)}\n",
      "max_probe is: tensor(0.1741)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of antimagnetic is _ .\n",
      "['magnetic', 'charged', 'and', 'also', ',', 'or', 'electromagnetic', 'electric', 'electron', 'neutral']\n",
      "tensor([0.1986, 0.1047, 0.0682, 0.0405, 0.0286, 0.0281, 0.0201, 0.0186, 0.0155,\n",
      "        0.0102])\n",
      "{'magnetic': tensor(0.1986)}\n",
      "max_probe is: tensor(0.1986)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonexplosive is _ .\n",
      "['negative', 'and', 'positive', 'void', ',', 'inclusive', 'exponential', 'continuous', 'explicit', 'indefinite']\n",
      "tensor([0.0274, 0.0232, 0.0218, 0.0177, 0.0163, 0.0146, 0.0126, 0.0124, 0.0107,\n",
      "        0.0099])\n",
      "{'explosive': tensor(0.0004)}\n",
      "max_probe is: tensor(0.0004)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 373\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unrespectable is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unacceptable', 'respectable', 'despicable', 'shameful', 'embarrassing', 'unfortunate', ',', 'honorable', 'acceptable', 'pathetic']\n",
      "tensor([0.0662, 0.0627, 0.0328, 0.0172, 0.0164, 0.0153, 0.0148, 0.0148, 0.0112,\n",
      "        0.0102])\n",
      "{'respectable': tensor(0.0627)}\n",
      "max_probe is: tensor(0.0627)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of noninstitutional is _ .\n",
      "['institutional', 'informal', 'not', 'educational', 'and', 'public', 'formal', 'the', 'organizational', 'in']\n",
      "tensor([0.6767, 0.0146, 0.0116, 0.0092, 0.0066, 0.0062, 0.0062, 0.0053, 0.0049,\n",
      "        0.0044])\n",
      "{'institutional': tensor(0.6767)}\n",
      "max_probe is: tensor(0.6767)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uneatable is _ .\n",
      "['edible', 'vegan', ',', 'also', 'and', 'vegetarian', 'not', 'unacceptable', 'in', '.']\n",
      "tensor([0.0617, 0.0354, 0.0279, 0.0257, 0.0256, 0.0235, 0.0182, 0.0151, 0.0115,\n",
      "        0.0115])\n",
      "{'edible': tensor(0.0617)}\n",
      "max_probe is: tensor(0.0617)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of insusceptible is _ .\n",
      "['soluble', 'in', 'insensitive', 'also', 'or', 'and', 'sticky', 'flexible', ',', 'the']\n",
      "tensor([0.1223, 0.0347, 0.0237, 0.0220, 0.0179, 0.0156, 0.0153, 0.0145, 0.0118,\n",
      "        0.0101])\n",
      "{'susceptible': tensor(0.0037)}\n",
      "max_probe is: tensor(0.0037)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 25\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unportable is _ .\n",
      "[',', 'also', 'and', 'portable', 'not', '.', 'ubiquitous', 'the', 'removable', 'in']\n",
      "tensor([0.0446, 0.0347, 0.0293, 0.0242, 0.0168, 0.0116, 0.0116, 0.0104, 0.0102,\n",
      "        0.0091])\n",
      "{'portable': tensor(0.0242)}\n",
      "max_probe is: tensor(0.0242)\n",
      "the position of max probe is: 3\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of noncontinuous is _ .\n",
      "['continuous', 'indefinite', 'linear', 'constant', 'finite', 'and', ',', 'exponential', 'also', 'simply']\n",
      "tensor([0.2866, 0.0637, 0.0351, 0.0289, 0.0208, 0.0183, 0.0173, 0.0125, 0.0086,\n",
      "        0.0083])\n",
      "{'continuous': tensor(0.2866)}\n",
      "max_probe is: tensor(0.2866)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of undiversified is _ .\n",
      "['and', 'called', 'segregated', 'classified', 'the', 'diversity', ',', 'modified', 'also', 'distributed']\n",
      "tensor([0.0154, 0.0140, 0.0140, 0.0136, 0.0131, 0.0125, 0.0123, 0.0121, 0.0118,\n",
      "        0.0108])\n",
      "diversifiedis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of undynamic is _ .\n",
      "[',', 'and', 'also', 'called', 'the', 'cubic', 'linear', 'of', '', 'in']\n",
      "tensor([0.0685, 0.0535, 0.0524, 0.0196, 0.0151, 0.0132, 0.0130, 0.0096, 0.0089,\n",
      "        0.0086])\n",
      "{'dynamic': tensor(0.0058)}\n",
      "max_probe is: tensor(0.0058)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 20\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of incurious is _ .\n",
      "['ironic', 'curious', 'indifferent', 'insensitive', 'in', 'infamous', 'the', 'unfortunate', 'invasive', 'or']\n",
      "tensor([0.0618, 0.0604, 0.0239, 0.0152, 0.0090, 0.0088, 0.0081, 0.0068, 0.0060,\n",
      "        0.0055])\n",
      "{'curious': tensor(0.0604)}\n",
      "max_probe is: tensor(0.0604)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonhierarchical is _ .\n",
      "['hierarchical', ',', 'and', 'egalitarian', 'or', 'not', 'authoritarian', 'the', '.', 'horizontal']\n",
      "tensor([0.1226, 0.0349, 0.0322, 0.0157, 0.0155, 0.0151, 0.0136, 0.0110, 0.0105,\n",
      "        0.0091])\n",
      "{'hierarchical': tensor(0.1226)}\n",
      "max_probe is: tensor(0.1226)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unmalicious is _ .\n",
      "['malicious', 'benign', 'insidious', 'innocuous', 'neutral', 'benevolent', 'not', 'innocent', 'evil', 'suspicious']\n",
      "tensor([0.0950, 0.0491, 0.0263, 0.0175, 0.0160, 0.0158, 0.0097, 0.0090, 0.0088,\n",
      "        0.0080])\n",
      "{'malicious': tensor(0.0950)}\n",
      "max_probe is: tensor(0.0950)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of concentrical is _ .\n",
      "['cubic', 'and', ',', 'also', 'linear', 'the', 'square', 'triangular', 'or', 'called']\n",
      "tensor([0.1522, 0.0728, 0.0589, 0.0320, 0.0277, 0.0230, 0.0220, 0.0162, 0.0142,\n",
      "        0.0137])\n",
      "{'eccentric': tensor(0.0005)}\n",
      "max_probe is: tensor(0.0005)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "the position of max probe is: 202\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of noncritical is _ .\n",
      "['critical', 'neutral', ',', 'constant', 'and', 'negative', 'not', 'positive', 'C', 'also']\n",
      "tensor([0.1292, 0.0328, 0.0308, 0.0201, 0.0179, 0.0150, 0.0146, 0.0117, 0.0115,\n",
      "        0.0110])\n",
      "{'critical': tensor(0.1292)}\n",
      "max_probe is: tensor(0.1292)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonspatial is _ .\n",
      "['and', 'sterile', 'in', 'also', ',', 'or', 'the', 'not', 'nominal', 'neutral']\n",
      "tensor([0.0368, 0.0343, 0.0173, 0.0173, 0.0152, 0.0141, 0.0132, 0.0074, 0.0072,\n",
      "        0.0069])\n",
      "{'spatial': tensor(0.0002)}\n",
      "max_probe is: tensor(0.0002)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 666\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unconvertible is _ .\n",
      "[',', 'also', 'and', 'simply', 'equivalent', 'cubic', 'always', 'of', '', '.']\n",
      "tensor([0.0993, 0.0704, 0.0543, 0.0223, 0.0194, 0.0193, 0.0171, 0.0146, 0.0144,\n",
      "        0.0129])\n",
      "{'convertible': tensor(0.0022)}\n",
      "max_probe is: tensor(0.0022)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 59\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonvoluntary is _ .\n",
      "['voluntary', 'involuntary', 'mandatory', 'optional', 'compulsory', 'not', 'voluntarily', 'explicit', 'informal', 'consensual']\n",
      "tensor([0.5570, 0.1023, 0.0189, 0.0165, 0.0136, 0.0126, 0.0125, 0.0069, 0.0062,\n",
      "        0.0055])\n",
      "{'voluntary': tensor(0.5570)}\n",
      "max_probe is: tensor(0.5570)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unhearable is _ .\n",
      "['audible', ',', 'heard', 'deaf', 'and', 'silent', 'pronounced', 'hearing', 'not', '.']\n",
      "tensor([0.1878, 0.0304, 0.0267, 0.0242, 0.0206, 0.0193, 0.0152, 0.0122, 0.0120,\n",
      "        0.0120])\n",
      "{'audible': tensor(0.1878)}\n",
      "max_probe is: tensor(0.1878)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unsusceptible is _ .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['also', ',', 'unknown', 'ubiquitous', 'transparent', 'and', 'not', 'in', 'or', 'invisible']\n",
      "tensor([0.0511, 0.0340, 0.0321, 0.0314, 0.0259, 0.0209, 0.0164, 0.0159, 0.0151,\n",
      "        0.0112])\n",
      "{'susceptible': tensor(0.0010)}\n",
      "max_probe is: tensor(0.0010)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 138\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unpresidential is _ .\n",
      "['and', ',', 'residential', 'also', 'indefinite', 'called', 'the', 'in', '', 'not']\n",
      "tensor([0.0434, 0.0411, 0.0333, 0.0249, 0.0205, 0.0166, 0.0152, 0.0136, 0.0126,\n",
      "        0.0103])\n",
      "{'presidential': tensor(9.0418e-05)}\n",
      "max_probe is: tensor(9.0418e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "the position of max probe is: 1238\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of uneffective is _ .\n",
      "['effective', ',', 'also', 'ineffective', 'effectively', 'and', '.', 'called', 'equivalent', 'or']\n",
      "tensor([0.2456, 0.0562, 0.0303, 0.0276, 0.0263, 0.0261, 0.0138, 0.0104, 0.0086,\n",
      "        0.0076])\n",
      "{'effective': tensor(0.2456)}\n",
      "max_probe is: tensor(0.2456)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of inaesthetic is _ .\n",
      "['in', 'and', 'the', 'also', 'IPA', 'or', ';', 'anesthesia', ',', 'a']\n",
      "tensor([0.2583, 0.0354, 0.0260, 0.0237, 0.0181, 0.0132, 0.0128, 0.0124, 0.0106,\n",
      "        0.0096])\n",
      "{'aesthetic': tensor(0.0030)}\n",
      "max_probe is: tensor(0.0030)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 26\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unrenewable is _ .\n",
      "['renewable', 'indefinite', 'finite', 'radioactive', 'reusable', 'perpetual', 'entropy', ',', 'energy', 'void']\n",
      "tensor([0.2137, 0.0555, 0.0465, 0.0218, 0.0147, 0.0131, 0.0115, 0.0100, 0.0088,\n",
      "        0.0082])\n",
      "{'renewable': tensor(0.2137)}\n",
      "max_probe is: tensor(0.2137)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonmechanical is _ .\n",
      "['and', ',', 'also', 'not', 'always', 'simply', 'equivalent', 'or', 'in', 'proportional']\n",
      "tensor([0.0692, 0.0626, 0.0439, 0.0187, 0.0153, 0.0142, 0.0140, 0.0131, 0.0131,\n",
      "        0.0125])\n",
      "{'mechanical': tensor(0.0035)}\n",
      "max_probe is: tensor(0.0035)\n",
      "20\n",
      "40\n",
      "80\n",
      "the position of max probe is: 47\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of undomestic is _ .\n",
      "['humble', 'domestic', 'modest', 'entitled', 'mundane', 'timid', 'ubiquitous', 'egalitarian', 'eccentric', 'the']\n",
      "tensor([0.0570, 0.0256, 0.0150, 0.0137, 0.0128, 0.0113, 0.0093, 0.0089, 0.0080,\n",
      "        0.0079])\n",
      "{'domestic': tensor(0.0256)}\n",
      "max_probe is: tensor(0.0256)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of untechnical is _ .\n",
      "['indefinite', 'and', ',', 'or', 'arbitrary', 'also', 'not', 'equivalent', 'approximate', 'in']\n",
      "tensor([0.0595, 0.0487, 0.0429, 0.0259, 0.0244, 0.0217, 0.0170, 0.0138, 0.0120,\n",
      "        0.0095])\n",
      "{'technical': tensor(0.0003)}\n",
      "max_probe is: tensor(0.0003)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "the position of max probe is: 486\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unthematic is _ .\n",
      "[',', 'and', 'also', 'written', 'called', 'the', '', 'or', 'of', '.']\n",
      "tensor([0.1109, 0.0857, 0.0657, 0.0459, 0.0293, 0.0173, 0.0150, 0.0136, 0.0127,\n",
      "        0.0121])\n",
      "thematicis not in list\n",
      "{}\n",
      "==========================================================\n",
      "The antonym of unhumorous is _ .\n",
      "['vegan', ',', 'undesirable', 'bitter', 'or', 'disgusting', 'edible', 'hairy', 'and', 'not']\n",
      "tensor([0.0220, 0.0188, 0.0149, 0.0138, 0.0135, 0.0124, 0.0119, 0.0117, 0.0111,\n",
      "        0.0093])\n",
      "{'humorous': tensor(0.0037)}\n",
      "max_probe is: tensor(0.0037)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 34\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of nonmodern is _ .\n",
      "['modern', ',', 'Modern', 'archaic', 'not', 'nominal', 'primitive', 'and', ':', 'also']\n",
      "tensor([0.5655, 0.0292, 0.0214, 0.0142, 0.0131, 0.0081, 0.0072, 0.0069, 0.0065,\n",
      "        0.0061])\n",
      "{'modern': tensor(0.5655)}\n",
      "max_probe is: tensor(0.5655)\n",
      "the position of max probe is: 0\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of noncellular is _ .\n",
      "['nuclear', 'cellular', 'n', 'not', ',', 'molecular', 'non', 'cubic', 'N', 'NOT']\n",
      "tensor([0.1121, 0.0357, 0.0351, 0.0304, 0.0302, 0.0219, 0.0194, 0.0180, 0.0150,\n",
      "        0.0145])\n",
      "{'cellular': tensor(0.0357)}\n",
      "max_probe is: tensor(0.0357)\n",
      "the position of max probe is: 1\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of untheatrical is _ .\n",
      "[',', 'and', 'also', 'or', 'indefinite', 'called', '.', 'the', 'of', 'not']\n",
      "tensor([0.0686, 0.0649, 0.0423, 0.0277, 0.0194, 0.0175, 0.0125, 0.0123, 0.0092,\n",
      "        0.0086])\n",
      "{'theatrical': tensor(2.0411e-05)}\n",
      "max_probe is: tensor(2.0411e-05)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "320\n",
      "640\n",
      "1280\n",
      "2560\n",
      "5120\n",
      "the position of max probe is: 2996\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of avertable is _ .\n",
      "['and', 'payable', 'also', 'available', 'or', 'the', 'avert', 'avoid', 'in', 'equivalent']\n",
      "tensor([0.0363, 0.0327, 0.0300, 0.0156, 0.0149, 0.0124, 0.0120, 0.0117, 0.0115,\n",
      "        0.0095])\n",
      "{'inevitable': tensor(0.0012)}\n",
      "max_probe is: tensor(0.0012)\n",
      "20\n",
      "40\n",
      "80\n",
      "160\n",
      "the position of max probe is: 112\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of adynamic is _ .\n",
      "['also', ',', 'called', 'and', 'exponential', 'cubic', 'now', 'linear', 'the', 'AD']\n",
      "tensor([0.0543, 0.0388, 0.0350, 0.0315, 0.0223, 0.0175, 0.0159, 0.0157, 0.0150,\n",
      "        0.0133])\n",
      "{'dynamic': tensor(0.0085)}\n",
      "max_probe is: tensor(0.0085)\n",
      "20\n",
      "the position of max probe is: 11\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of unlogical is _ .\n",
      "['linear', 'and', ',', 'cubic', 'also', 'simply', 'always', 'exponential', 'just', '.']\n",
      "tensor([0.0675, 0.0510, 0.0506, 0.0235, 0.0224, 0.0181, 0.0149, 0.0137, 0.0135,\n",
      "        0.0118])\n",
      "{'logical': tensor(0.0066)}\n",
      "max_probe is: tensor(0.0066)\n",
      "20\n",
      "40\n",
      "the position of max probe is: 21\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "==========================================================\n",
      "The antonym of seeable is _ .\n",
      "['visible', 'readable', 'seen', 'see', 'observable', 'clear', 'also', 'and', 'transparent', 'measurable']\n",
      "tensor([0.0999, 0.0686, 0.0638, 0.0572, 0.0400, 0.0304, 0.0255, 0.0219, 0.0171,\n",
      "        0.0151])\n",
      "{'invisible': tensor(0.0058)}\n",
      "max_probe is: tensor(0.0058)\n",
      "20\n",
      "the position of max probe is: 17\n",
      "-----------------------------------------------------\n",
      "*****************************************************\n",
      "    count  position\n",
      "8     116         0\n",
      "1      70         1\n",
      "12     11         2\n",
      "9      13         3\n",
      "13     10         4\n",
      "..    ...       ...\n",
      "15      1      8570\n",
      "66      1      8683\n",
      "74      1     14667\n",
      "4       1     16735\n",
      "61      1     20639\n",
      "\n",
      "[121 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_dict = copy.deepcopy(final_antonym_dict)\n",
    "\n",
    "for temp_num in range(2):\n",
    "    count_dict = {}\n",
    "  \n",
    "        \n",
    "        \n",
    "    for (key,value) in final_antonym_dict.items():\n",
    "    \n",
    "        # 没有预测结果的标记\n",
    "        no_predict = 0\n",
    "\n",
    "          # 处理模板\n",
    "        print(\"==========================================================\")\n",
    "        text = templates[temp_num].replace('*',key)\n",
    "        print(text)\n",
    "    \n",
    "    \n",
    "        # module\n",
    "        if mask_token is not None:\n",
    "            text = text.replace(' _ ', ' %s ' % mask_token)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(tokenizer.encode(text, add_special_tokens=True))\n",
    "        tokens = ['*' if token in ['*', 'Ġ*'] else token for token in tokens]\n",
    "        marker = '*'\n",
    "        if marker in tokens:\n",
    "            assert tokens.count(marker) == 2, str(tokens)\n",
    "            p, h = [i for i, token in enumerate(tokens) if token == marker]\n",
    "            tokens = [token for token in tokens if token != marker]\n",
    "            h -= 1\n",
    "            print(tokens[p], tokens[h])\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        pred_idx = [i for i, token in enumerate(tokens) if token == mask_token] if mask_token is not None else [-1]\n",
    "        tokens = ['@' + token if not token.startswith('Ġ') and token not in ['<s>', '</s>', '<mask>'] else token.replace('Ġ', '') \n",
    "                  for token in tokens] \n",
    "        #print(tokens)\n",
    "\n",
    "        input_ids = torch.tensor([token_ids])\n",
    "        with torch.no_grad():\n",
    "            logits, attns = model(input_ids, output_attentions=True)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        for i in pred_idx:\n",
    "            top_probs, top_indexes = probs[0][i].topk(10)\n",
    "            top_tokens = tokenizer.convert_ids_to_tokens(top_indexes) \n",
    "\n",
    "\n",
    "            # remove G\n",
    "            ans = []\n",
    "            for word in top_tokens:\n",
    "                ans.append(word[1:])\n",
    "            print(ans)\n",
    "            print(top_probs)\n",
    "\n",
    "\n",
    "            # 找到每个同义词位于预测的第几个位置，先找到概率最大的，再去找最大的是预测的第几个\n",
    "            # 找到每个同义词对应的概率\n",
    "            word_probe = {}\n",
    "            for word in value:\n",
    "                word_id = tokenizer._convert_token_to_id('Ġ'+ word)\n",
    "                if (word_id != 3):\n",
    "                    word_probe[word] = probs[0][i][word_id]\n",
    "                else:\n",
    "                    print(word + 'is not in list')\n",
    "\n",
    "            print(word_probe)\n",
    "\n",
    "            # 找到同义词中概率最大的词和值\n",
    "\n",
    "            # 没有反义词在预测的结果里\n",
    "            # 保存计算结果的json文件中写为 -1\n",
    "            if (len(word_probe)==0):\n",
    "                no_predict = 1\n",
    "                break\n",
    "\n",
    "\n",
    "            max_word = max(word_probe, key=word_probe.get)\n",
    "            max_probe = word_probe[max_word]\n",
    "\n",
    "            print('max_probe is: ',end='')\n",
    "            print(max_probe)\n",
    "\n",
    "            # 判断概率最大的同义词是预测的第几个\n",
    "            # 不要陷入死循环\n",
    "            # k的值不要超过 tensor 的长度\n",
    "            k = 10\n",
    "            probe_get = 0\n",
    "            while(probe_get == 0):\n",
    "                top_probs, top_indexes = probs[0][i].topk(k)\n",
    "                #print(top_probs)\n",
    "                if max_probe in top_probs:\n",
    "                    print('the position of max probe is: ',end='')\n",
    "                    print((top_probs == max_probe).nonzero().item())\n",
    "                    print('-----------------------------------------------------')\n",
    "\n",
    "                    probe_get = 1\n",
    "                else:\n",
    "                    k=k*2\n",
    "                    print(k)\n",
    "                    if (k >= list(probs[0][i].size())[0]):\n",
    "                        top_probs, top_indexes = probs[0][i].topk(probs[0][i].size())\n",
    "                        print(top_probs)\n",
    "                        print('the position of max probe is: ',end='')\n",
    "                        print((top_probs == max_probe).nonzero().item())\n",
    "                        print('-----------------------------------------------------')\n",
    "                        probe_get = 1\n",
    "\n",
    "\n",
    "            print('*****************************************************')\n",
    "\n",
    "            \n",
    "        # 没有预测结果\n",
    "        if(no_predict == 1):\n",
    "            # 写入结果文件\n",
    "            if (temp_num == 0):\n",
    "                result_dict[key] = [result_dict[key],-1]\n",
    "            else:\n",
    "                result_dict[key].append(-1)\n",
    "            continue\n",
    "\n",
    "            \n",
    "        # 有预测结果\n",
    "        position = (top_probs == max_probe).nonzero().item()\n",
    "        # 写入结果文件\n",
    "        if (temp_num == 0):\n",
    "            result_dict[key] = [result_dict[key],position]\n",
    "        else:\n",
    "            result_dict[key].append(position)\n",
    "\n",
    "\n",
    "        if position not in count_dict:\n",
    "            count_dict[position] = 1\n",
    "        else:\n",
    "            count_dict[position]+=1\n",
    "\n",
    "       \n",
    "    \n",
    "    \n",
    "    # 画图\n",
    "    count_dict_keys = count_dict.keys()\n",
    "    count_dict_values = count_dict.values()\n",
    "\n",
    "    data = {\n",
    "        'count':Series(count_dict_values),\n",
    "        'position':Series(count_dict_keys)\n",
    "    }\n",
    "\n",
    "    df = DataFrame(data)\n",
    "    df.sort_values(\"position\",inplace=True)\n",
    "    print(df)\n",
    "    # plt.bar(count_dict_keys,count_dict_values)\n",
    "    df.plot(x='position',y='count',kind='bar')\n",
    "    \n",
    "    \n",
    "    \n",
    "# 保存到json文件\n",
    "with open(\"result_antonym.json\", \"w\") as outfile:  \n",
    "    json.dump(result_dict, outfile)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析结束，结果文件: antonym_result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
