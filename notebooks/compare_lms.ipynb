{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = [\"julia\", \"best\", \"tseb\", \"for\", \"ailuj\"]\n",
    "sum(a == b[::-1] for a, b in combinations(test_list, 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "str1 = \"data\"\n",
    "d = defaultdict(int)\n",
    "for c in str1:\n",
    "    d[c] += 1\n",
    "max(d.items(), key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(d.items(), key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from collections import defaultdict, OrderedDict\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizer, GPT2LMHeadModel, GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('/home/kf/projects/transformer-xl/checkpoints/tf/novelGpt2-ao3-100G-TPU512-mem384-dim1600-32layers-preLnorm/novelGpt2-ao3-100G-TPU512-mem384-dim1600-32layers-preLnorm-8-64-old.log').readlines()\n",
    "a = [float(line.split()[line.split().index('ppl') + 2][:-1]) for line in lines if 'ppl' in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('/home/xd/b.out').readlines()\n",
    "steps = [int(line.split()[line.split().index('step') + 2][:-1]) for line in lines]\n",
    "a = [float(line.split()[line.split().index('ppl') + 2][:-1]) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9944f24bd0>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABGCElEQVR4nO29d5gc1ZX+/97OYbJmRhppJEZZCFBiyCInGTBgg7/AOgI267V/NvbiAGsbbONl8eK1AQdsDAaDbbBJBpNBJAFCIKGAEsphFCbn0KHq/v6outXV3dXTPd3V3VXT5/M8etRd1eFWT9Wpc8895z2Mcw6CIAjCfjiKPQCCIAgiO8iAEwRB2BQy4ARBEDaFDDhBEIRNIQNOEARhU1yF/LLa2lre1NRUyK8kCIKwPWvWrOngnNclbi+oAW9qasLq1asL+ZUEQRC2hzG212g7hVAIgiBsChlwgiAIm0IGnCAIwqaQAScIgrApZMAJgiBsChlwgiAIm0IGnCAIwqbYxoDv7RzEq5tbiz0MgiAIy1DQQp5cOP2ONwAAe26/sLgDIQiCsAi28MB7hyPFHgJBEITlsIUB7xoMF3sIBEEQlsMWBrxP54HLMrWAIwiCAGxiwPUhlIgsF3EkBEEQ1sF2BjwqkQdOEAQB2NCARyTywAmCIABbGnDywAmCIACbGPC+EfLAidHZ0NIDzunmTpQWtjDgg6Go9phi4EQir2xuxcW/eQePr2kp9lAIoqDYwoD/7NJj8H+fWQgACJMHTiSwt3MQALDpYF+RR0IQhcUWBhwAAh4nACBKaYREAl6XchqHonRuEKVFWgPOGPsTY6yNMbZRt+0OxthWxtgGxthTjLGqvI4SgMupDDUSpRAKEY/DwQAAYTLgRImRiQf+IIBlCdteAXA053wBgG0AbjJ5XEm4ncpFSoU8RCLDYQkAhdeI0iOtAeecvwWgK2Hby5xzsbL4HoDGPIwtDrfqgdMiJpFI/4hyKoYiUpFHQhCFxYwY+DUAXki1kzF2HWNsNWNsdXt7e9ZfIgw4pRESeiSZ49EP9gEAeki1kigxcjLgjLEfAIgC+Guq13DO7+WcN3POm+vq6rL+LpcIoZABJ3Q8tfYAWvtCAOLTTQmiFMi6oQNj7EsALgJwNi9ABYXbITxwCqEQMULRWNhExMIJolTIyoAzxpYB+B6A0znnQ+YOyRi3S/HAo+SBEzr06sJDZMCJEiOTNMJHAKwEMJcx1sIYuxbAbwCUA3iFMbaOMfb7PI8TLtUDp0yD0uOXL3+MNz5uM9zXOxRr9jEUphAKUVqk9cA551cZbL4/D2MZFQ9loZQsd7+2A4BxP9Te4QgCHie+eHIT7l+xu9BDI4iiYptKTFrEJIzoGYqg0u9GwO1EWJKx5NZX0N4fKvawCKIg2M+AU0u1kkJK8/fuGVYMuF+VWugaDOOU21/Dod7hQgyPIIqKbQx4LIRCHngpoc8yMaI3wYADyjrJbc9vzffQCKLo2MaAi0Ie0rsoLdKlBg6HJQS9Lk3sTOBW9VEIYjxDBpywNCNp/t7DEQk+t0M7PwQi5EYQ+WZX+wC+89j6oqzP2ciAq4pzFEIpKUYM9E0W/fRlfP7+Vdp+n9uJUCT+vHA5bXNqEzbnpic/wuNrWvDh3u6Cf7dtznLGGLwuB3ngJYZRCKVnKIIV2zsA6Ax4wnlBIRSiUIjZX7rZYj6wjQEHAI/LQaL9JUa6RcyRiAy/24lLFk3GpYsma9vJAycKhc+tnGt9RRBTs9VZ7nU5KIRSYgyHU/+9OedaDDzodeHOKxdr+5zkgRMFwutWFtA7Bgpff2ArA+5xUgil1BAxcLfBomRE4pBkDr/bmbSPzhOiULhUZ6EYBjxrNcJi4KEYeMkxooZQXA4Hnlrbgmk1gaR9PgMDTqE2ohBsa+3H0+sOAgA6+sNpXm0+ZMAJSyMWMV1Ohm//fX3cvsdWtwAwNuB0nhCF4L+e/Eh7PFAEMTV7hVAoBl5yiJV9o4j2rc9uBhBvwP9y7QkA0i9+EoQZBL0xH3ioCA1F7GXAKQZecgjphL6R1BeHyAIAgKWza3FkQwWFUAjTaOkeSlmkUxVwa4+LoUdvLwPucpBnVWJkol2WuIjppXRTwiQ6B0JY+vPX8d/PbTHcrzfsQ2EJrX0jhRoaANsZcCd54CVGJt36EmPgXpeDOtQTptCtNgx5a7txQ/aeoQgWNFbiE0dPwkcHenHCbcsLqoRpKwNOnlXpIWdgwPVxSEDJy6XzhDCDqDoFdKWoK+gZiqC+3Icy3Tn40sbDBRkbYDMDTouYpUcmIZTJlb6453SjJ8xCdABzOoxNZc9QGFWBeDnjH/9rM1bv6SrI+GxlwL20iFlypGvo4HE6UFvmjdtGIRTCLNJ54P0jUZT7XIgktHosVFGPrQw45YGXHuli4A1VPjgSLq6Ax0kd6glTEI6AkTQD5xxDEQkBjxPDCTngHldhTKutDDhjDG39IWw51FfsoRAFIl0IpS7B+waAgMdFHeoJUxB1CHoP/LuPrcc7OzoQlmRIMkfA48Jwwowvg6UbU7CVAe8bUdS+/vLe3iKPhCgU6RYxa4KepG3kgRNmIbR4xCxPkjkeW9OCz963SqsS9rudWqw89r7CRApsZcC/f/48AIWbnhDFJ50HnsqAR2VO4TYiZ0IJHri+DkU4CQGPEz+++ChcedxUbZ9RI5J8YCtLOG1CAFOq/OgbpulxqZAuBl5tYMD9HiWlKzGM0jEQoqbYxJgYSYiB6z1rYcD9Hiem1gRw+2ULtH2JIZV8YSsDDgAVfjd6iyCcThSHdFkokyp8SduCakqXPowyFI6i+Wev4kdPbzJ3gMS4JnERU2/Q9SGURMgDT0GFz6XFwonxz2j2uyrgxpXHT03a7jcw4OJie3HjIXMHSIxr9CGUAz3D6Fc1eZyMaV52wBMr4plZFwRg3AowH9jOgFf63WlbF0UkGW983FagERH5ZLQQyo3L5sHrSvZ+AgYhFMaoQw8xdoQnHZY4Trn9Ndzw2Dr1uYwP1GIdfRHP8hvOgMvBNK36fGM7A16RgQH/7es78KUHPsCKFPoFhH0YLQvFkcIoG4VQCCIbRMy7Uy3M2XgglsJ8x0sfA1AWMfX43M5RWwGaif0MuM89qrQoABzqURTBDnQXTlSGyA+jhVBSOdXCIzKaxhYoPZcYJ4isk0O9qVUGDQ04xcCNKfe5MBCKQh7lyhb60IX6EYn8MZoHXlueXMQDxMStBqmYh8gREQPvGkzdLs2fYMD9HgctYqaiLIOL0yc8MDLgtieV/b7388fijDl1hvs8TuW01ueBZyJLSxCJRDNQU6vwueOe+1xOMuCp0LyrUOofSKT1jFAM1PZIMjfsSH/eUZNSLkyKlC/9xScekh0nxkK6G399uTdJj97voRBKSoJe5ccaGKX/nPhBR6gSz/bInCd5OOlwqQZfH2bjFP0msiBdHcKUan/SNmURkwy4IVoIZRQDLjzwQv2IRP6QeUyHYkFjZUbvMfLAyfMmsiFdBGVKVbIB97udBXMebWfAgxkYcOGBUQzc/nDO4WDAlp8uw9++cmJG73Gp4vtSXAiFa59HEJmSTkytsTqQtM3ndhQsfOtK/xJrITzw0UIoYupcqIUEIn/InMPBGPwe56iZR3pGjYGbPkJiPJPunDMKofgpjTA1maSIid+cDLj9kXmsYCexcUMqnJr0J2WhELmRzmdoNDLgVlrEZIz9iTHWxhjbqNtWwxh7hTG2Xf2/Or/DjBFbxEz9A4mpM1Xi2R+Z85QFO6lwaQY8to3sN5EN6UIokyuNFzGtlEb4IIBlCdtuBLCccz4bwHL1eUHIZBFT/OiJIuuE/ZBlnrJkPhVGHngm3e0JIpF0502qLBTLGHDO+VsAElssXwLgz+rjPwO41NxhpcbvdsLrcqCjP3XTUPGjS3TR2h4lhDK29zhZ6hg4BcGJsSCPkkzy7DeWag6lHr/biYjEC6I9n20MfCLnXOhyHgYwMdULGWPXMcZWM8ZWt7fnLi7FGMPUmgD2dw+lfI343dLlcBLWR+Y849i3wOFgcLD4vz/FwIlsGM0JrAoY1yf4C1iHknMWCuecM8ZSHiXn/F4A9wJAc3OzKVfRtJoA9namNuDCA6dps/3hPF518Nql0zGzrizt+1wOh7EHThBjYLQbv5GUMaDTYgpLhh66mWT76a2MsQbO+SHGWAOAgopvT6sJYNWuTnDODcupReoPeeD2R1bzwAU/umh+Ru9zOBIqMelmTmSB3oQ4WPzzVL15tUrwAsTBsw2hPAPgi+rjLwJ42pzhZMbM+jIMhiUcTCHxKKY9ZMDtj8gDHyupPHA6I4ixII0yixOiaYn4Cyiml0ka4SMAVgKYyxhrYYxdC+B2AOcyxrYDOEd9XjDmN1QAAG7+50bD/cLzykRJjLA2Ms+um47TweJj4KBKTGLspArD/v5zxybJyApEaCUUsUAMnHN+VYpdZ5s8loyZN6kcALB8axuGwtG4nnRA7E4ZoQ7ktmJv5yDWt/Ti4oWTtW1KGuHYP8vlYIjq0wjpVCCygHOlcYjejrudDMuOnpTyPS6tEti6WShFJeh14dNLpgAA+oaT88FFCCVCaoS24rJ7VuKbj6xN0jDJJoSS6IFrWii5D5MoISSZoybgGdN7RB1CIZIobGnAAeDMufUAgH6DDvUihBKmQh5b0TscVv+P/U31aoRjIdGAE0Q2yJxjYoUPAHD89JqM3qN54AWwP7Y14BV+JQezz8iACw+cQii2otKveDr69lWJWSiZ4nSwhEVMMubE2JE5R6XfjdU/PAc3Z5gBFasEJgOeknKfEvc2DKGodpsMuL0QhRF6A56YB54prqQQSu7jI0oPmSsGubbMm3LRMhEhZ12IJArbGnDRpYU88PFDlT/ZgJvtgZMjTowFvZhaqrTBRJwGevT5wr4G3K964CPJHnjMgHNKG7MRVQHjEEo2aYQuhwOSLgZJpwGRDbLMtZCIVy3cSXcuuQz06POFfQ248MCHkz1w/Z0vQguZtqFS9cC7h3QGXB67mBWgLmJyvQEXWSh0PhCZo9ejF5WX6c4gIzXMfGFbA+51OeB2MvSP4oEDFEaxE6L7fEhXwWZeGmHu4yNKD30IL1XpfCLkgWcAYwwBjwvDBp159BcuaYLbB3Hf1ad/yjw2hR0LFAMnzEDS6dGLGPgps2pHfU8hs1Bs1xNTT6rec/rfLUweuG0QIY9wVN+IIbtSeiULRd9SLffxEaWHPgvK5XTglW+fZtjEQY+zgHng9jbgHieGDfQGZJlCKHZEeMlhKXZT5rlkoUjJMXCCGAsS53Do4hSzJ5anfQ/lgWeI3+00DqFQDNyWaBW0CR54VnngTha3FkIxcCIbslmDcYk0QiqlH51U3Z/1FysZcPsg/m7xBjxbDzxRTpa0UIixk00hmZMWMTND8cANDLjuhwtH6ZK1C7EQSsyAS3J2eeDOxJZquQ+PKEEkeeyL6CILRbJwT0xL4HM7MWRgwCWKgdsSzYBH9bHrbPPAHXExcNJCIbJBX4mZKc4CltLbehEz4HEati2iPHB7IpJGwpKMUFRCW18o6zTCRC0UbRGT7DgxBrIJobgojTAzUqcR6kIoZMBtQ8wDl/DDpzbisTUtmFjhzS6E4kysxFT/JwtOjAFJ5nBSDDw/+D3GMXAqpbcnsi4P/L3dnQCA1r4QqRESBWE4LCWJ48kJaYSZ4CIxq8wYLQtFzLqpK4990LJQJBnVui4o2bVUcyRlsxDEaHzirrew4Mcvx23LJo1VnK/kgafB73YiIvGkOLfMudZYlGLg9kHvgQthKyC7PHCf2xG3PqKJWZEdJ1Kwp3MIQHzRVzZ54IyxpErgfGFrAx5QBdYTM1EkmcPnVg6NYuAKezoG8f3HNyBq4d9DTDkjEtekZQGMOQsAUG7u8QY85+ERJUJrX0h7nG0dgiNBiydf2NqAl3mVNdjBUHw1psw5fG7hgdOVCwD//vAa/H31fuxoHyj2UFKiiVlFZfh0ym/ZeeBOjERlzZuiGDiRDrH4uKsjdo1IMs+qJ6vLweL06POFvQ242lZtZ4JRkuWY+LqVPc5CcrB3GADgc2XWFqoYCA88FJXjZk5jzQIAlBCKJHPtBk4xcCIdE4LKrK9zIPeWfolqmPnC1gY8qHrgn7//fbR0D2nbpTgPnAw4AE03PVqAuFy26NMIQzqRsrFmAQDQ/v4jUSnus8mME6lwq3KxiYvf2dYhFMJpsLUBL/fG0tiXb2nTHsucw6tewOESC6F8fLgf963YBQAIRSXs7hiMS7UshFeQLVyXhaL3wLPJA9cMuEGWEkEYIQx1KJoo5ZDNZzmoEjMdIoQCAFsP92uPZTlmwMejB76/awh9IxEcNbkyad+lv30HwxEJV58yHbc+uxl/eW9f3H4rN7jQ64GHojHDm80ikmbAw8rfP9bQwbrHTxQX0U1ef+5lG0IpVAzc3gZc54HrFzLjQijjMA/81P99HQCw5/YLk/aJvPjBcBQf7O5O2m9lD1zWLTj26nqdZptGCOhCKOPvNCBMxq3G6kKJIRSKgeeHcm8sV1hvwGUZ8DgZGBufHvhoiL6SQyEJE8o8SfsLkZuaLfrzfXtrbGE6GwPuTwihUAycSIfwwPUxcCnLNEKXk/LA0xL0xjIq+vUGXE2+dzsd4zoGbpRhI8p4B0JRVAeTDbiV0yr1MsB6L0jMpsaCeM+K7R0AyHAT6RF+Qigq4b+e+ggLfvwSeJYt/cgDzwCXMzb8uBCKquHrcTrGnQe+vyuWbdMzHEnar3ng4aihgS+EPkO2pJLurAm6kzemQYRQ7njpYwAU+ybSIy6XUETG31btQ5+auWWGGma+sLUBB4AHrj4OS6ZVJcXAHQ4Gt5ONOwN+2h2va4+7B8NJ+0Uq1EAoqqUO6rHy7yHJPK6EXqCvysyURK9dXEtkx4lUyLo6BD1mdITKF7Y34GfOrcfcSeUYCMVWjiOSDI/TAfc49MD1BqhrFAP+3cc2oH8kijPm1qFR10Xbyh445zA04NVZGPD4z+VUyEOkRWRBhaISPPpK4Cw98EIUEdregANA0OOK88CjEofbqcbAx3FLtc4EAz4UjmrTvQM9w+gYCKHc50bQE8vWsXQMnBt74NmEUKbXBrXHoahMnjeRFn1T7fpyr7Y9ezE1MuAZEfS6MByRdGJIsrqAKeOJD1vGlRfefES19njzwT7t8UhEwvybX8KBnmFt26HekbhUS8DaHriUwoAbbUtHwOPCTy4+CoCyPkIxcCIdMo+FUDxOvRbP2D8r4HFhKJwcwjSbcWHAhZE66X+WYzAURTiqGPD2fkVVbPmW1mIOz1QikozT59RhYWMl3t/dpW036g0KABV+F06ZVas9t3IpPedAhS9mrKsCyuNy39gNOBCvVmnh+xZhESSdAdeHTbLxwAMe4369ZmPrQh5Bc5Pilbb1h7CrfRARNYQiGAyNn3LqsMThcTlwZEMFlm+NyQekmmU0VPjwuROPwKlzanH1Ax9YuhJT5srf7cmvnYyZtWWQOMeqXZ2YWOHL6vOEVs5QWCIPnEiL8G1C0fjzJTsD7iqIAR8XHvjiadV49htLAQAHeoa0EMr3l80DABzuG8HPX9yK/3l+SzGHaQpigba2zIuuwXBc3M6IyVV+uJwOzJlYDsDiIRRZyd9fMq0alQE3aoIefOKYhqw/z6964IPhKHngRFo0NcxIghpmFjEUxQOnEErGTKlSMi1auocRlTncTgf+44yZqAq4cbh3BPe8sRN/eGtXkUeZO0p4iKG2zANJ5ugeUhYy9foNM3QLeJPV30V0yo5YPISSzYp/KsTi7VBIoiwUIi2aFo8kx6thZhMD9zoxaHUPnDH2bcbYJsbYRsbYI4yx7Oa6JlAVcCPgcWKv2hZJpAFNqvDhUO9IsYZlOhFJhsflQK26Sv7M+oMYDktxuas1ugpMYcCFF2F9D9y8zwvoPHCy30Q6xGx2JBJ/PTmz0DMOuF0IR+W8pxJmbcAZY1MAfBNAM+f8aABOAFeaNbAsxoNJlT7sUysVRQy80u9G73ByvrRdEeGhCUHFgP/kX5tx56vb4kIo+hL6anUhUAj1WD0Gnk28MRUiBj4clsCpmL6odAyEsHpPV/oXFhExS9vWOhAnppZNGquQ+RjKs5xxriEUFwA/Y8wFIADgYO5Dyp76cq+WRic0QfweJw72jB8PPKRm2NTp8lT7RiJxHsOEoL6fpGIQneoNzSpZKFFJxn8/txmHemNpj7LpIRSKgVuFZXe+hct/v7LYwxiVVLPTCWVew+2jEVDDdz98amNOY0pH1gacc34AwC8A7ANwCEAv5/zlxNcxxq5jjK1mjK1ub2/PfqQZUF/uw0HVgLvVEIrf7YzLjbY7EUmG1+WIK1SpK/fFeeAifHRcUyxnXMTArSIn+/6eLvxxxe64EzzbBrKpCHiNY+DU5KHwdAxYfxac6tKoMRCFS4fQ4nlmfX592lxCKNUALgEwHcBkAEHG2OcSX8c5v5dz3sw5b66rq8t+pBlQX+7VUnc8qsfpz0LJzsooKZIOOB0Mb3//TADAUCga54HvaBvAG985Aw9dc4K2TTPgFgmhiEUiM7SXUyH+9okx8F4DETAif/xLZ8SsnM4pyTyp8A0AaoNj98BFDUq+ySWEcg6A3Zzzds55BMCTAE42Z1jZUV8R+6GFJojPE2/A7dzkWJI5JDXDBgAaqwOoLfNiMCwleeBNtUEtjQ6ILWJaxQMXMgD6FC1Z5llJd6bC6WDwuR1JeeA9Q2TAC8WejkF845G12nOrnH9GSJwbetsV/rGXy3xqyRQAQLkvv6U2uRjwfQBOZIwFmHLVnQ2gqInWE4LJBjzRAx+xcYceUayjF9op8zqV6lNJmXn84IIjccflC5PeyxgrmMBOJrT2KesScQY8y/ZVoxFUS5r1dkOkXhLms2ZvF17edBiA4nC0dMeHL60sayHLXMtc0pONU1Ff7sNnT5im2aF8kfXtgXO+ijH2OIAPAUQBrAVwr1kDywZ9j8xUBnw4LBlOk+yAKC7QV5kGVCEvEZK4cEFD3AKnHmeBNIozQUwx9cUOSgdwc78n4HUqMfCy2HG39o3g0t++g6+ePgPLjs6+UIhI5rJ7lIXKPbdfiBv+sQ7/XBcfA7a6mJpX5xw98pUTMXdSedafV+Z1YSCU32KenCwZ5/wWALeYNJac0XepF0bOn3BHtfMClujvGe+Bu7C9bUA7Tv2+RNzOwmgUZ0KP6gXrJXHNTiMEVKXKBA/83rd2YdPBPjy2uoUMeB5JNN6AdUOYiuQwcNqcOpw7fyI+f2ITKgPZafAIgl4lF1yk/uYDe7qiKQh6kz1wIezvUlsc2dmACw9cr5QW9Dqxr2tIy38fzYA7LRRCETeSrsFYPFqWs5uujkbA40R7fwgvbdqubdukqjjOqAumehsxCt96dC0mV/nxPVWqwgjOOWbUBrGrYzBuu1UciETEsFwOB/6/s2ab8pnCHg2Golk1JcmEcVNKDxgbcJGNIn7AQmj0ms1NT36ET//uHURUbXN3nAGPvwd7R/XAC9OnLxNEWl//SCRum9mOStDr0qpzgfjwk1V+C7vxz3UH8bs3do76muGIBK9BBphVY+AitGjm+VemFvPkM4wyrgy4fsXX41IuVJGmJqRJh23ogT/y/j58uK8HGw70AIjluAPJUqueUc5AxQO3htHShIOisjYrkvIQQvG7nXGNL/SekFXWA8YjfcNR9A6FcdmSxrjtVo2BC4fC1EIyzQPPn80ZVwbcyAMXxkGUlNsxhCLG/tY2pRBKb6TnTCyLe+1oIQiXwzot5vTD6BgIgXOuiFmZbMATUwardM0hyAMfO/p01dFyuh94dzd6hyOa4ySwSggvEc0Dz4OUA3ngGRLQTdlEKb24SEV+p9088GV3voVu1Qi9vb0DQPzCrH6VXCgypsLndiQ1bC0W+srIpT9/XSu0MduAL5pWFfe8QmfAJYt6g1amR6cr1Dec2jD94c1dGAxLcTdMwFoeuD4DSigRZiMdm4oyXQw8X4wrA66f/ogQytWnTMdnjm3Ef5wxC4D9PPCth/u1xwdVVUX9RdF8RA0uXjgZT33tZCy/4fRRP8vndlrm+BO9X3EBmVlKDwDfO39u3PO43qnkgY+ZlzYe1h639AzF7TPyyCsDbjz7jaU4e149AOto8by+tQ3zb34J6/f3AAC4OiwzF9GFnDEZ8CxorA4AUNQI7/jMQi032ioGLBf001KPy4G7r1qMxdOqtYybVPjcToxErXH8coLxFBIIZsYgAcCVsCagT1uULGJM7MSPnt6kPV65s1N7vK21H9Nvej7p9ZMqfDh6SiU+f9IRAKzjgS/fqrRZXLO3G4DOAzfx9CujEMrY+fyJR+D7y+YlGTOfS8TE7XPR/vKVbYbbs2nyCyghlOECiMxngiTzuEXnrYeU1D6zQygA8MR/nIyls2rx2ROmacdfFXCTB54j7+2KycOuUz1ZID6VVXSCEus2VlmDEZMFcQbEslDMjIGrWjx5NODjKg8cAG699GjD7SJubKcY+N3LY7nLjMVOumyb/PrdTnQPWkMHROIcdWVe9I8oJ/dvXt8BADh1du1ob8uKY4+oxl++rAh7fWrxFDz30SG8vb2DslCywMEAr8uJk2dOiFP51Jeg15XFZJ2n1igzYTETskoWlBhH16BSEZzPLJT93cN4eOUenHXkxLTrVGNl3HngqfC5lBPMriGUSbrGvtl6CV6LhVAmVfrwqysU3ZYV2zvQNCGAo6dU5vV7m5tqcMsnj4LLQlWpdoFzRWzsmqVNaKjy4bBOy12fGaWXchDnqstprZZ+bf3KelJrn2LA85GF4nU54HIwbGjpwY+e3oSdbQOmfbagZAy4w8HgcTps5YHri07MqOTyuZxxvf6KicQ5nA6mTbEBc44xU1wW0oWxC2FJhiRzBDwuNFT60T0U0RwifXZTvWrA63WG3GodoURtgBBVE+eCmR44YyyukGxCmfnnd8kYcEBNo7OIAcsE0dUDiOm8uHI4wXxu69zAZLUDfYUuHGRm/DEdTkf+qlJf2nQYF9y1Immh1u6I9QO/26nNCD/567fRPRiOm9mKcIpe3ll44FbJAxeLqX2qNrwIT5rpgQPKQmabKtw2IQtd8XSUmAG3ThpdJuiNrTBuZ8zNvimGlY4/Kise+JQqPxqrlbhgIcemeOD5MSbfeWw9Nh/qG3eNI0SmUMDj1OoPtrcNYNXuzjiZ5kVTqzCjNoifXHyUtk0U1oUtYsDFzbVPXYPR0lhNtoj6dYJsOvuko6QMuN/jtIwHmg5J5nFVb8dNr8FXT5+JX3wmWes7U/yqAbdCVxRJNeAOB8Ovr1oMoLAGPJ+yAmJWMV50x4WxEwbc73HiqMkVca8J6f52LqcDr33nDBx7RI22za154MU/94CYwd7dMYin1x2IhVDykAUlGE1oLltKyoD7XNbxQNMhxrloahUAYGFjJW78xLyc4sQ+twMyt0Yurr59Wr06HZ9s8gr9aLic+YuBi/TI8WLAP3XPu/i3P76nVS763U4wxvDit04FoHix4nwt97mwZFp10mdoWSgWWcTU/+2vf3SdloVidhjvj19oNvXzEhl3aYSj4fM4MWyTGLiYKXx6yRT86opFcU2Ms0Xkxg9HpLx4A2NBeOCAIgFw91WLccrMCQX7fqfDgaicn5u58MA7bdDINxNEteIrm5XiF7E2I+LgAyNRjERkOBiw4ZbzDKsZ3erf2grOA5AsZJaPLBQAOHf+xCQ9GDMpLQPuctjGAxcLRj630xTjDUCT9wxFJCDLYiCzkHn8iv/FCycX9PvzmYUynjxwfbjt8TUtAGI1FaLSsF/1wH2qZ25ELA/cGg5U4t/+w31KRabZlcAAsPLGs03/TEFJGXC/xxlXSm1lxI0msSVcLojPGrJANaYkc1PLlsdKPrNQhGBWl0WKpnLhowO92uNDqhaPyDJxOR0IeJzY3TGAobA0qpSDiIFb1QO/RZUIyMfMNLErmJmUlAG3Uwz8MeHtmGjAa4KqYRkKownF7UYjyTwv3k6m5DMLRaR66pX77MrFv3knaZteAqHM69Jap02u9CW9VmC1LBSJc9SVe7XerF6XA9GwhJMLGMYzg9JaxHQ7bKOFcu9buwCYe/euK1MuMHHSFhP9ImYxyKcHLj43bBHp3mzRy63qqS+PGWp9I3GjDjzaPpcDjFmnElqSOZYdNQk/umg+AGAwLOHyYxvhdeXPW84HJWbA7eOBC8z0WGrLlQyWjoHiG/CobhGzGOQzBi4Em+ziLKRi2Z0rtMeiVH5C0BMXZhjRheNGi/kzxhBwOy0RvgNii+jnHzVR21adx8XGfFFyBnw4IuFAzzCabnwOr6qr6lZD7/ksmZqckpUtohKso7/4U3u5yAbc6XBoOclbDvXh2gc/MM1jFp8bsojuTLaIRtkAMLFSOXcmVsSHSa44bpr2uPmI0c9Vv8dlKQPuYAyN1QF8QZW6LaSUg1mUVgzcrWiBbFDToh79YB/OmT9x9DcVAWFg77h8ASpN9Ao8LgeqAm5LeOBCC6VY6D3wG5/YgPUtvdh4sNcwh3msiFxnq3Q/yoZE2deGCj/2dw3HCVUBwPXnzMZVJ0xF71AkbbZUwOPEcIqwTKGRZK6V9wvVQKsUGY2FEvPAHQhLsi4swfCHN3fiC396v6jjSqR9QFntT7xYzGB6bRArd3UWXadDeEDFwumMxcBF3HM0nZyuwXDGNz6RaWEn3Z1EEj1lripnC9kDPfXlPsyeWJ7UPCORgMdCIRRdA22hr2+VIqOxUGIGXLlQhT4BY8D/vLAVb21rL7pBEwyFo2jpVsaXDwN+RfNU7GgbwM5286Utx0KxQyj6LBSvO32GxJJbX0Hzz17N6LNjHrg1jFU2JK4VnavOVK9dOj3rz7SSlIUkcy1b6HMnHoErmqfimlOyP7ZiUVohFHXxZX+XYiD1RQVdQ2HUlplvMFPxm9e24/Q59TimMV7/ev7NL2mPmyaYn+onBPaLnQ9f7BCKPgvFq3VrMse4aB64jUMoiZ7yOUdOxJeXzsgp9dNSHrgujbXM68LPL19Q5BFlR0l64PvVxRlRmAAAh3WP8w3nHL94eRs++Zu347brbygNlT4tNmcmYrrYk6CUt6vAHrks51c4KB36GLgIoaRKm9MvbmYyUxN/R3sb8PjfwuVw5Jy373dbYxFTzlPZfDEoKQMucqpFdZm+4/uhAhrwVFP1gz2xMcyoy0+hTbUqadmjS/l6ZXMrzvq/N/GiruN4NnDONYH8dCgeeE5flxOKFopqwNUQimjvlkhLdywbI5PyePG5IYuEC7JBzEbuunIR/veyBZg2IZDzZ1plEVP8fVzFLAU2iZIy4MLT6h2O4JiE1l2ZGh4zSJWutrdrUHs8tTr3C8aIKuGBD8U88A/2KM1pd3Xk5oU/+O4enHDbcmw51Id/rT+YUraWc67m4Rbv9DPywFMZ8MO6c6MtgyIoEUKxcyGP8JSnVPnx/46baspnWiWEovW/JA/cXvjcscO96YJ5cfsKWeCTamqtnwXkYwETUC4it5PFhVBEV5JsmyUL3t3ZCQD4z3+sxzceWYuXU+TZiyhEsSsxJZnH3WSEAf9wXzeabnxOW+jt0/1Wmdzox0cIJSamZhZ+j1MTaSsmwgMv5gzQLMbBIWSOqCY7sqECJ8+sxcPXHo9bPqmU0hbyxErlmQ2GYh5gvgw4YwyVfo/mgW9v7cc6NS8+V3MaVENULeoaw97OQcPXSRa4gEQGgr5xxpZDffjxM5vwhfuVtNInVD0afWcdEUIZCEVTShJoIZRxkIUSMFHKodzrwkA4WvRepLHzz/7mr6SyUETs+fgmpVjj1Nl1OHV2Hf77uS0F7daeyjPTG/CyPCxgCiYEPWjrGwHnHOf+6i3D788Gv6oTLQxY95CxGp82hS1mFopOHU8Urby5rR1vbmvXXrO9bQARSUbfcOx3eWTVfsgy8Ie3dmJb6wD23H5h0meLz7NrHjjnHNc/ug5AfF/WXKkt94JzJQMqXw5KJsQWMYs2BNOw/y1oDJw2uw63Xno0brrgyLjtPrcTw+HCXWx6D/wn/9qkPR7UzQLy2XBh/uQKbDjQi+89viFu+2COsxAhGSpyfe95Yycefm9v0uvyJZ4/FkQ2Tt9IJOWM6JXNrZj9gxfw1vZ2iHvN+3u6cMNj67GtVQmvGN30JNneaYQDumMyUw1TpOkWW0wtFkKxvwUvKQPucDB8/sQjkuJ6PrezwB547LseeGcP2tS4qjAG1QE3TpqRP1nLhY2VaO8P4am1B+K2D+XogQ+Gkn/DH/1zY9JippSn9lVjoUbVvegaDKcVDFuxvUMz+Insak8OE2mLmJJsmQKxsaCP8+ulY3NFeN3FlnKItU+zv/mz/xGYgN/jiFNVyzfCM/uyWtW2V40ZD4SimFLlx9qbz8OEPBYVzawvA4AkOdVcPfBUIZiPW/vjngujVswsAJFO2T0YRkSSUZ4mZFWRwoAbVbTqS7Kton89Flr7FAP76HUnmhrmqrOcB17UYZjCODiE3PG5CuuBiyn77ImKId3bqRjwoZCEoDf/esT6itPzdGJeqQpZMmUgFMWSaVVJ2/d0DMU9lywwha1RDfiXHvgAIxEpbUw2lQdulJUSlbgWcrFjHFwUtSUqD+ZKrfob3/DY+pQppoVAHkeLmPY/AhModHqTCKFMry0DY8C+zkFwztE1GM5L9WUiemN1/PQa7Ln9QhzZUGEYAhkLA6Eogl4X1t18Lp782smaEfvqX9bgta2tuO6h1TjcO2IJA16thlDCkow9nUOacQEUwaYLFzTEvX52fTl+dNF8fOXU6dh12wX4v88sBGDsTUYkWfs72jETReS9T6wwdxZY5nWhSS0I0i8MD4aieGlTbkVkY8EKWVBmkZO1YIxVAbgPwNEAOIBrOOcrTRhXQVFarRV+EbPM68KEoAdvbGuH3+PC+3u6MDNPFZh6qnW6x0IDuczrNMUDb6j0oSrgwZJpHuy87QJMv+l5AMA1D64GACw7ehJOUttWFdOA6zuFt/eHMK0mVjj19vfPAgCcNnsfhsMS1rf04vvL5qJe55Fedmwj7lq+HW39ITy8cg/OP3qS1qkmKnPUeF3oH4naciHz48P9mFLlNzUDRfDtc+fg+kfXoX0gpEklf/fx9Xj+o8N44ztnoMmkBt6jEbVACM8scv0L3QXgRc755YwxD4D8lA/mGZ/HGVeskW/ERe1xOVDhd2NDSy82tCjl/TsNFsXMRm84RWVmwONK0kcZK8NhKe6iN+pQPhKRLZGF4k5wv4y0cPTNCoyoK/dixfZ2PLP+IN7a3oE/fqEZUUk5vnKfC4d67eWBRyUZc374AmSuiFflAxG+6xwIYZa6FrN2Xw+AwmXtiEVMVymHUBhjlQBOA3A/AHDOw5zzHpPGVVB8LkdRKjG9LgeCCV5OkwmaE5kgFu3EYl7Q68w5CyUUlZPSH688bmpcyOaZ9Qew9OevAyhuHjgAPP31U7THHQMh3PeFZjz3zaUZv7++3KvluovZi0ihFDMbO7VV29UxqFXJzp1UlpfvmFAm2vrFNGVEcdRggXRSROOGUg+hTAfQDuABxthCAGsAXM85j3MhGWPXAbgOAKZNG92jKRZ+T2F7ZeoNuKxbzDnnyIm47dNHF2QMz19/Kl7d0opFU6sAKB54rjoV4aikSbMKbr9Mkenc1tqPi+5+G+/t6tL2dRY5nUy/MBmKymPuzqS/MZV7lc8Saymiv6KdQiibD/ZpjydXJTduMAPNAx9U/vZvfNym3eSGclyDWbmzEy9sPIRPL2nEE2ta8NNLjjKcBZIWioILwBIA93DOFwMYBHBj4os45/dyzps55811dXU5fF3+8LkKKzQf1gy4M66s+PJjp8R1/M4nU2sCuPqU6Vo4JehxxhVwZENYkrVinkTmTCzXUur+64J5OHFGDc6cV5/T9+WK3oBn09C2TpfNI/TVxU2wyq94mlYMoYSiEr716FpNVlmwvS2W7jnJ5AwUQXXAA6eD4WDPCFZsb8eXHvhA25fr+XfVH9/DQyv34vP3rcLD7+3VGrckIo0jNcJcPPAWAC2c81Xq88dhYMDtgL/AKmniova4HHEG/OgEhcRCEvC6cl7EjEg8owrSC45pwHWnzczpu8xAn9v9r29kHjoR6D3wvV1KJpFmwIPW9cDX7O3GP9cdxKHeEfz930/StuszQ8xOIRQ4HQxHTa7A2n3d+Nuq+CrdXKUcPC4HwlEZ/ern7GwfRKOBqud4WsTM2gPnnB8GsJ8xNlfddDaAzaaMqsCUeV0YDEULlps6HJbAWLwBf+Dq4wxPtkIR9DgRkXjWEqiSrEjEepzp89in5Gl6PlbE7GPR1Kqsfnu9AW/tC2Hpz1/Hyl2KIqPI9LFiHrhYaE6Uz9V7wPky4ADQfEQN3t/Thb6E78/VgQgmCG899O4eHDTwwmkRM8Y3APyVMbYBwCIAt+U8oiJQ5nNB5oVbcGrtG0FdmRdOB9NanM2uz8+iUaaIvOWeoTBueXrjmKvlwrrMmlTc+Il5+NyJ0wzjksVi5U1n4W9fOSGr94pioHmTyvGLzyzEUDiKu17dBiCW3WPFEIoQ2+obic860hv0CUEP8sX0uiCMfKWBHGPgiTUUy7e24ez/ezPpdcJpGgf2O7c0Qs75OgDN5gyleIg/fH8oonXtyYWRiIQbHluPG5fN0wy0nkO9I2ioVDycO69YhLd3dBTV+wagZcM8s/4g/rxyL/pHovjlFYsyfr+Ib6eKgQPAV08vftgkkYbK7GcDk9S/4XnzJ+LyYxuxZm83Hnl/H4BYFooIobT1jyDocRWkUCsdYsH+UO8Ieocj2lrAQCiC45qq8eh1J+U1Q0i/dnD7p49BVcCNr/31w9zVMA2Et4YjEobC0bj0ViuksZrFOLgH5Y5Iqcu1ElGwYnsHnttwCD9+ZpPh/sO9I5rhqA568MmFk0353lwIqCX8Ih9+rIu6YV1mTanQUOnHOzeehW+dMwcAMENXhJKYhXL8fy/Hv/3xvcIP0gCRKSPJHJ/63Tva9oFQFOU+d94LrOp1FZ7TagJYdnQDgl5XzouYQ2HJUATuf57fivX7e/DNR9YiFJVoEXO8IbyigRQttcaKyC9NFIsSHO4dwSmzak35LrMQHninmk0hj3E9QHjg+ZTBtSL6eH5teXKFaygioV8NVaxXi7WKzYhunWNX+6DmhQ+GJJTV5t8k1OvWDkQ1ZtCT+yJ633AE8xrKceulR+PxNS34/Zs7AQAPv7dXkzU+eeYE/OGtXQBKfBFzPCGaJ+TqAQiEtrhR55HuwTD6Q1E0VltjIU8gOq/8dZUSAhjreq7wwBMrHEsJvUiY8MB/9twW7GjLrdeo2YgQys0XKd2odrQNYCQiYXfHIMpMlI9NhX7xVyz2Br3OnGbAkszRH4qiwufGrPoyfH/ZXKz43plJr7vxyY+wu0MpVRkPeuDkgcN8Ay5acOllRQU7VPnRmUVetExk7qTyuOdjDaFEStQD16M34PoURaG7XlEA45gJIfVvu3Cqkra6s20AD63cAyD3tnqZ4HU5sbCxEhsP9mkLwWU5hlDE+SquZcZYSifp0kWTMRiWML0Auiv5xhpnVJEREq7bWvtx7hir8RLpHAhh62Gloi3RA5dkjs/8XtH6mlVnLQNeFfDgSyc34cF39wBQ4vhf++sa/O6zx2b0fi0LhTxwAPFrAQ+tVKbvNXnM7BgLIttqWo1iwH7wz4+0JhSF0up+6munoG8kojVXCXhcOS1iipuSV9e4nDGG33/uWMyqD0LmwHlq+8CvnjET8yZV5DB661C6V5sOMW2846WPc/qcUFTCsT97VbtgE6eE+tJxq+RC60nUxH7+o8MZ58aLxTp3CXvgNUEPjpgQwPeXzQNjDPd+Pv7mZ5WinhFNr0WZJQjj7XU58IMLj0z5PjNxOJi2TgAo61C5NBQJpVhEX3b0JMyqL49Tm5xpMecpF8gDR3xaU/9IBOW+sZdVA8CaPd1xz/d2DiIiyVpcuE31bu6+anHRhZyMqFWFhiZWeLWuLN1DkYw8RxFC8ZawB+50MLz53Vjc9byjJmHuxHKtI5FZi+S5MhyR4HKwpPWKO69YhCMmFCesUOZ15uSBi5tSYrtEgX77eFqnGT9HkgOMMdx15SIAxrKimbLlcHzrsMGwhG8+shbf/vs6AEouMADLLWAKRK7sMVMq8fvPLQEAHOg21pNIJJNCnlJEr7cyEI5aokfmSEQ2NHSzJ5YbvLowBNRq6De3taPpxueSdFrSkcoDH++U1tGOgsjLPpSLAT8UU3MT09MXNh7GU2sP4OPD/fjDm0r6Un2a9l3FQijQnTq7TitA2tuVmT45GXBj3C5lpjUh6AHnwFABRdNSMRKV4HMn/50KJWVsRJnXhcFwFP9YvR+AotcyFkI6gbhUPHzt8XjxW6dmP0gLQlebiqiM3Jtw51+zt0vrGj8aGw/04vmPDmFqjWIEP3tCvHTu+Xe+hVW7FSnV2jw2LM6FY4+oxsvfPg1fOOkIzKovQ03Qg2fWHczovRGJ0giNEDc2kfHQP1K4xiGpGIlISYbuwauPg6uIf7ugx4WRiKytuUTG2AxahFBG88BPnV03bhYvBXS1qUyq9GFShQ/3r9ilbeOc47J7VuJTv3t31Pfet2IXLvr123A5GP589fF4/Ksn4T/PnZvy9anidFZgzsRyMMbgdTlx4TENeHtHR0bT/lIt5ElHSGtgrYQnOnWNDIpF92BYS3P88tLpqPS7ccbc4kr7ikwwkYLbMcbfSfPADWYW45nSOtpRcDsduOK4qdjTOaR5TSIvNZWusOBnz20BANz4iSMxo64MzU01KYsE7FQ8MK+hHENhCQd7jY9/f9cQhsJRvLzpMDar4aNSTiM0QpxLcyYqmQ8dCU0sOOdYs7eroF3ad3cMamX/P7xoPtbfcl7BvjsVIn/7nR2KmmNrBrNePVoa4SghlPEIXW06RGfyHrXFU6ZeQE3Qg3KvC/+vuTHta+20yDJH9Rq3tyZXEsoyx6n/+zq+/OfVuO7hNVp8X7TMIhSam6oBAEc2KFP3xHPqL6v24bJ7VuK1rW0FGU84KmN/9zBmFKB59lg476hJcc8ffHcP7n97d8bvFx64UWx/PFNaR5sGUf4s+hzqixqMdIUBpTindziCL57clBRD/O75c3HanDq8cH1s4eS8HAuFCsncSeVgDFjf0pO0T6REvruzU9tWW+bJSydzO/Oji+bjhetP1Zp1JHrgz65X1hh6TWyq3dY/ghv+sd5QW2R/9xAkmVuuCrHGQNTt1mczby8wQh44IXQZujUPPHaxXXD3CsP3dA2GIck8qQgGAL5+5iw8dM3xWnbHJYsmaz0i7UCFz435DRV4b1dn0r59BmleRtK5pY7X5cSRDRUIepzwuR3oSKh0FL9jrlKqen71yjY88WELnl1/KGnfrnYlq8hqBhyISRHP1aUzjrWQzE4zXDMoraNNg0j9EyEUvQfeMxQx7FZzxb1KafxoxS6Vfjc2//R83HnFIksvYBqxdFYt1uztRu9QvIdoaMCLrGluZRhjmBD0amqPIsYr1lm6h8zPTgkZZHK88JFi1GfUWq8aURQ6fe3MmVoWV3uGja8zSSMcj5AB1xHzwJWLaW9nvJHSL6xc8+AH+MpDqzP2aAIel6U60WTKBcc0ICJxLN/aGrf9xY3J3t008sBHpcLvRv9IFE9+2IITbluO93Z1al1wRFNkMxCtwkIJOefbW/vxpCqsVZlFE+d8893z5+K4pmqcOa8eFy1Qwinr9vVk9F7R+YiyUEoY4UW/v7sL97+9GzvbBzCrvgw3nKsI9ouLLCLJeG1rG17ZrBi1Ty2eUtSGxPnkmCmVCHic2KBqWYeiEt7f3YVXt7RB3I8WNCrHLnLgCWPKfS70j0Tw5rZ2ANDOHyA26zMDiRsLUwmH5Ox5xU0ZTMXsieV47Ksno8LnRnNTNSr9bry48XBG7xUCXRRCKWF8bifqyr14au0B3PrsZqxv6cFRkytwymyl+UKXepF9nFAyf9Tk8VUcoMfhYJg7qRwvbjyMjoEQ5v7wRXzuvlXwuBxYf8t5WPG9M7VWVrm0JysFylXJVBHW/WBPl7avy4QQiixz3PL0RvxN1XRPTMU7pD6/7dPH5Pxd+cbtdGDprFqt+M2IVbs6Nc87FJHgcTlsOcvNBUoZSGB6bVDzXHqGIlg8tQo1amhln5ojvq013oBboc9hPlnYWIW1+/ag+WevAlCKdmbUBlHhc6PC58b02iBW7e7SFmsJY8p8LvS3RXFIzavf0NILB1O6tJvhgb+8+TD+rCphAsCH+3oQjsrg4OgZimDt3m44HcyylcCJLJ5Whec+OoS2vhHUV/ji9n18uB9X3PseLlvSiCc+bAFjpbkGM74tTxbMqA3ifd1d/9PHNmoe0y3PbML2tn5MSjiZrKptYhbfPX+uphMuaNTFu2/+5HxctGAyZlmsSYXVKPe50DEQivOMp9cGMaXaH+eNZ8vGA31xz/d1DWHOD1/A0lm1eHtHBwBFMsIuxWTNTTUAgJW7OnHJoilx+0Rx2RMftgBQOkg1WTCzJt9QCCWBs4+Mz9NWvMzYfe6faw/ioE7w6rIljTjLojFFswh6XVgyrQoAcNGCBgDAlKrYTSzgcWHpbGv1+LQiZV43hsISQlEZv7piIS4/thFfP3MWqgMe9JgQQtneFpsZXnBMrDBGGG8AtpolLZhSidoyD17dklzkZKRPVEwxrmJBHngC586fiN/+2xJ8/W8fatv0cbWBUBR/W7UPtWVeXHbsFPznuXNKIu72xy8040DPMByMYXvrAE6fU1fsIdmOctURmFYTwEULJuNTi5XK3QPd2zEQiiIclbPWkmntG8Gavd2YXV+G6oAH3z1/Hp7/KHkBcGKFfWaLDgfDmXPr8dKmw3G6+gDQYiBz3FQkLfNiQgbcgAsXNGBP51ycNjtmpF674XS8trVN0z2ZP7kCN32iMN1LrMCEMi8mqLHTl759WpFHY0/6VCXCCxc0xBmjajX7qWconBTrzQTOOa57aDWGwxIe+NIiHNNYmbIAxmezPOmzj6zHY2tasG5/D45TQyojESkug0fQVFt6HjiFUFLw9TNn4ZjGWGrgjLoyfKZ5qvb8jsvtU1FJWAORJ5/Yd1XUH3RluZB5zi/fxPqWXtx4wZHaOaufFeoXLS9ZPCXp/VZmyTRFS2bjASWNdc3ebvzmtR3YmpAJBqBo3YSKCXngY6DS78Y//v0k1JZ5MDELT4koba46bhqWzqpNMjSi/uC3r+/Er69aPKbPlGWOnWox2SWL4rVE/vHvJ8HjcmB6bRA//OdG/PDCI2133taVe1Fb5sHyLW1orA7gKw+tBgAsnFqFX1+5GAd7h3Hlve8BoCwUIgOOn15T7CEQNsXhYIZe4uJpVWiaEMDKnR3gnMd5z29ua8dxTdUpRcKECNYtn5yPioRervpzdaw3BqvAGMOCxiq8trUtrjvUtJoApk1Q/j321ZPwwZ6uktSiL70jJgiL4XM78aWTm9AxENZUHgFgZ/sAvvin93HL05tSvldohRiJqY0X7r5qMdxOhv1dsYVLfV/Z45pq8LUzZhVjaEWHDDhBWIBjGqsAAO/ujKX8tarpqkbxXoEoj6+zSXFONpR5XfjSyU04d/5ELWV3vNdeZAqFUAjCAiyeWoUZdUE8+v5+Lb2wRdWgd6QovBkOS1pMeDx74ADwgwvnA1D0iG5/YUvSQnCpQh44QVgAh4PhuCNqsKsjFucVuc7r9/fgkff3ads55/jKQ6tx5M0vatvsVKCTCzVBD/738oVoLMEFSyPIgBOERWio8qFjIKTpzu/rjBnzm578SMvtbu8PxeVB21FnnjAHMuAEYREmV/rBeUxFcOvhfkyt8WPR1CoAQL/a/GFLQky8VLxvIhky4ARhERpUfZmDPcOISDJ2tg/ggmMa8KWTmwAA96/YjagkY+uheNGqRHE1onSgRUyCsAhCy+M3r+9AVcCDiMRx1ORKTFALfe5avh0VfnecHv1lSxrjUuqI0oIMOEFYhMZqPxoqfVixXUkldDsZTp9TFyc/+96uTrR0D+PkmRNw+6cXYFoJKvARMSiEQhAWgTGGk2ZO0J5PqfKj0u+Oy3l+ZXMrPj7ch4VTq8h4E+SBE4SV+OklR+Nw7wje3dmJGXVKg4yqgAdP/MdJCEVkfOORtZhQ5sHVpzQVd6CEJWCpZCcz/gDGnABWAzjAOb9otNc2Nzfz1atX5/R9BDHeiUgyfvHSx7hm6fQk8alErRSiNGCMreGcNyduN8MDvx7AFgDjt7MvQRQQt9OBmy4w1pon403oySkGzhhrBHAhgPvMGQ5BEASRKbkuYt4J4HsA5FQvYIxdxxhbzRhb3d7enuPXEQRBEIKsDThj7CIAbZzzNaO9jnN+L+e8mXPeXFdHfRQJgiDMIhcP/BQAFzPG9gB4FMBZjLG/mDIqgiAIIi1ZG3DO+U2c80bOeROAKwG8xjn/nGkjIwiCIEaFCnkIgiBsiimFPJzzNwC8YcZnEQRBEJlBHjhBEIRNybkSc0xfxlg7gL1Zvr0WQEfaV9kDOhZrQsdiXcbT8WRzLEdwzpPS+ApqwHOBMbbaqJTUjtCxWBM6Fusyno7HzGOhEApBEIRNIQNOEARhU+xkwO8t9gBMhI7FmtCxWJfxdDymHYttYuAEQRBEPHbywAmCIAgdZMAJgiBsii0MOGNsGWPsY8bYDsbYjcUeTzoYY39ijLUxxjbqttUwxl5hjG1X/69WtzPG2N3qsW1gjC0p3siTYYxNZYy9zhjbzBjbxBi7Xt1uu+NhjPkYY+8zxtarx/ITdft0xtgqdcx/Z4x51O1e9fkOdX9TUQ/AAMaYkzG2ljH2rPrclsfCGNvDGPuIMbaOMbZa3Wa7cwwAGGNVjLHHGWNbGWNbGGMn5etYLG/A1ZZtvwXwCQDzAVzFGJtf3FGl5UEAyxK23QhgOed8NoDl6nNAOa7Z6r/rANxToDFmShTADZzz+QBOBPB19fe34/GEAJzFOV8IYBGAZYyxEwH8HMCvOOezAHQDuFZ9/bUAutXtv1JfZzVERyyBnY/lTM75Il2OtB3PMQC4C8CLnPN5ABZC+fvk51g455b+B+AkAC/pnt8E4KZijyuDcTcB2Kh7/jGABvVxA4CP1cd/AHCV0eus+A/A0wDOtfvxAAgA+BDACVCq4lyJ5xuAlwCcpD52qa9jxR677hgaVWNwFoBnATAbH8seALUJ22x3jgGoBLA78bfN17FY3gMHMAXAft3zFnWb3ZjIOT+kPj4MYKL62DbHp067FwNYBZsejxpyWAegDcArAHYC6OGcR9WX6MerHYu6vxfAhIIOeHTuRHxHrAmw77FwAC8zxtYwxq5Tt9nxHJsOoB3AA2po6z7GWBB5OhY7GPBxB1dutbbK32SMlQF4AsC3OOd9+n12Oh7OucQ5XwTFez0ewLzijig7Mu2IZSOWcs6XQAkpfJ0xdpp+p43OMReAJQDu4ZwvBjCIWLgEgLnHYgcDfgDAVN3zRnWb3WhljDUAgPp/m7rd8sfHGHNDMd5/5Zw/qW627fEAAOe8B8DrUMIMVYwxIa2sH692LOr+SgCdhR1pSpI6YkGJvdrxWMA5P6D+3wbgKSg3VzueYy0AWjjnq9Tnj0Mx6Hk5FjsY8A8AzFZX1z1Quv88U+QxZcMzAL6oPv4ilFiy2P4FdTX6RAC9uqlW0WGMMQD3A9jCOf+lbpftjocxVscYq1If+6HE8rdAMeSXqy9LPBZxjJdD6TplCS+QG3fE+ixseCyMsSBjrFw8BnAegI2w4TnGOT8MYD9jbK666WwAm5GvYyl20D/DhYELAGyDEq/8QbHHk8F4HwFwCEAEyh35WijxxuUAtgN4FUCN+loGJctmJ4CPADQXe/wJx7IUynRvA4B16r8L7Hg8ABYAWKsey0YAN6vbZwB4H8AOAI8B8KrbferzHer+GcU+hhTHdQaAZ+16LOqY16v/Nolr3I7nmDq+RQBWq+fZPwFU5+tYqJSeIAjCptghhEIQBEEYQAacIAjCppABJwiCsClkwAmCIGwKGXCCIAibQgacIAjCppABJwiCsCn/Px36MCNa73uFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a[15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "cache_dir = '/nas/xd/.cache/torch/transformers/'  # for models besides t5-3b/11b\n",
    "proxies = {'http': '192.168.50.1:1081'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cached_path: url_or_filename = https://huggingface.co/gpt2-xl/resolve/main/config.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/d2de8fec009fa9b9196047559bcac6c1f02a9c500718b4346bc516354965b1ca.81d9c13b9ee3f2b22faaba04ca49e09b13f9fea3a7910768ed6664ec141e3c8b\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2-xl/resolve/main/pytorch_model.bin\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/96569b907e56747ce3e593c6a13d8475b8c733a64aab8af8f602b90d94c4af71.8fbbcdf404c82c5967934d411f1462fa0574d639f2aa398aa3754fced1bb26c0\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/vocab.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/merges.txt\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/added_tokens.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/special_tokens_map.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/tokenizer_config.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/gpt2/resolve/main/tokenizer.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2-xl'  # medium / large / xl\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name, cache_dir=cache_dir)  \n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir=cache_dir)\n",
    "models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using mask_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# model, tokenizer, device = models['t5-11b']\n",
    "# model, tokenizer, device = models['roberta-large']\n",
    "# model, tokenizer, device = models['gpt2-xl']\n",
    "# model, tokenizer, device = models['gpt2-medium']\n",
    "# model, tokenizer, device = models['gpt2-large']\n",
    "\n",
    "masked_lm = tokenizer.mask_token is not None and len(tokenizer.additional_special_tokens) == 0\n",
    "if masked_lm:\n",
    "    mask_token = tokenizer.mask_token  # '<mask>' for roberta\n",
    "elif len(tokenizer.additional_special_tokens) > 0:\n",
    "    mask_token = tokenizer.additional_special_tokens[0]  # '<sxtra_id_0>' for t5\n",
    "else:\n",
    "    mask_token = ''  # for gpt2\n",
    "if masked_lm: nlp = pipeline('fill-mask', model=model, tokenizer=tokenizer, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'EleutherAI/gpt-neo-2.7B'\n",
    "model_name = 'gpt2-xl'\n",
    "model, tokenizer = models[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 5 6 -> 1\n",
      "4 5 90 -> 9\n",
      "40 9 5 -> 4\n",
      "4 7 80 -> 8\n",
      "3 4 60 -> 6\n",
      "3 4 80 -> 8\n",
      "6 70 4 -> 7\n",
      "5 2 90 -> 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Ġ9', 0.23945137858390808),\n",
       " ('Ġ10', 0.1267591416835785),\n",
       " ('Ġ8', 0.12185506522655487),\n",
       " ('Ġ6', 0.10871698707342148),\n",
       " ('Ġ7', 0.1033550277352333)]"
      ]
     },
     "execution_count": 1076,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    " '''\n",
    "10 5 6 -> 1\n",
    "4 5 90 -> 9\n",
    "40 9 5 -> 4\n",
    "4 7 80 -> 8\n",
    "3 4 60 -> 6\n",
    "3 4 80 -> 8\n",
    "6 70 4 -> 7\n",
    "5 2 90 ->''',\n",
    "]\n",
    "\n",
    "_text = texts[0]#.lower()\n",
    "# if '_' in _text: _text = texts.replace('_', mask_token).rstrip()\n",
    "\n",
    "if masked_lm:\n",
    "    print(_text, ['%s %.3f' % (i['token_str'], i['score']) for i in nlp(_text)])\n",
    "    print(tokenizer.tokenize(_text))\n",
    "else:\n",
    "    inputs = tokenizer.encode_plus(_text, return_tensors='pt')\n",
    "    inputs = tokenizer(_text, return_tensors=\"pt\")\n",
    "    inputs = prepare_inputs(inputs, model.device)\n",
    "    max_length = 1 + (inputs['input_ids'].size(1) if mask_token == '' else 0)\n",
    "    outputs = model.generate(**inputs, max_length=max_length, top_k=1)\n",
    "#     print(_text)\n",
    "    print(tokenizer.decode(outputs[0]))\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
    "    values, indices = logits[0, -1].softmax(dim=-1).topk(5)\n",
    "    list(zip(tokenizer.convert_ids_to_tokens(indices), values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/config.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/42252c2220ae3f9f1ea86a994b63e1dcab20953ba8982117c2384587f7c01c5d.0481f2d6b709486a0897fbfb2477d85f33e6a2843fd79a2261982c19c5b42624\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/pytorch_model.bin\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/7c5fac9d60b015cbc7c007ab8fe6d0512787fbaef81968922959898c49468d73.4c6a483fbfb5a25ac384bfcd71a1ff15245f06583a00c4ab4c44ed0f761f0b08\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/vocab.json\n",
      "In cached_path: output_path = /home/xd/.cache/huggingface/transformers/6111bc9bbed617156dc5c0b9fa9d6793147619aad08053f03b3697f1a5027973.a1b97b074a5ac71fad0544c8abc1b3581803d73832476184bde6cff06a67b6bb\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/merges.txt\n",
      "In cached_path: output_path = /home/xd/.cache/huggingface/transformers/ec80888cdc98108f625f7ec7a29ec449eb361ae1325aa1e7e63006ce962c071c.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/added_tokens.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/special_tokens_map.json\n",
      "In cached_path: output_path = /home/xd/.cache/huggingface/transformers/1ae5a53fe395100a9213705940d92cc94554a2269777c062d951d1b710c39bb8.3ae9ae72462581d20e36bc528e9c47bb30cd671bb21add40ca0b24a0be9fac22\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/tokenizer_config.json\n",
      "In cached_path: output_path = /home/xd/.cache/huggingface/transformers/5fe35a59019a6fb05bfa29a31b59d407cd81ae59da93e6953772a783b740b4c0.c31b6b7d3225be0c43bc0f8e5d84d03a8b49fdb6b9f6009bbfff1f9cc5ec18bc\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/config.json\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/3c80ef2946e1aacc6dd37cb986ea989c29c92775701655bedf14d8791825a30b.180e94c8adf77aa69b51b48271e6cd2b143ce422d10bdefa9ace1512346c33c1\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/pytorch_model.bin\n",
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/0839a11efa893f2a554f8f540f904b0db0e5320a2b1612eb02c3fd25471c189a.a144c17634fa6a7823e398888396dd623e204dce9e33c3175afabfbf24bd8f56\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/vocab.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40beef27b11e4f62911aa4fd9946d94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/d4455fdc7c8e2bcf94a0bfe134b748a93c37ecadb7b8f6b0eb508ffdd433a61e.a1b97b074a5ac71fad0544c8abc1b3581803d73832476184bde6cff06a67b6bb\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/merges.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6562b48a584c55a15bd5c728d41006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/5660be25091706bde0cfb60f17ae72c7a2aa40223d68954d4d8ffd1fc6995643.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/added_tokens.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e2a95c857e41249967accc551804de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/953b5ce47652cf8b6e945b3570bfa7621164c337e05419b954dbe0a4d16a7480.3ae9ae72462581d20e36bc528e9c47bb30cd671bb21add40ca0b24a0be9fac22\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69211c36f7a4057acb211be86f5a040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cached_path: output_path = /nas/xd/.cache/torch/transformers/57ccc3b8af045ea106fffa36bcc8b764e9702b5f4c1f7b3aad70ccfcaa931221.c31b6b7d3225be0c43bc0f8e5d84d03a8b49fdb6b9f6009bbfff1f9cc5ec18bc\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "# for Shawn Guo\n",
    "model_name = \"EleutherAI/gpt-neo-2.7B\"\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name, proxies=proxies, cache_dir=cache_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Shawn Guo\n",
    "for path in ['/nas/qsj/code/transformer-xl/pytorch/utils', '/nas/qsj/code/transformer-xl/pytorch']:\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "# model_path = '/home/kf/projects/transformer-xl/checkpoints/torch/novelGpt2-ao3-100G-TPU512-mem384-dim1600-32layers-preLnorm/model.ckpt-700000*.bin'\n",
    "model_path = '/nas2/xiaomeng/models/TPU512-mem384-dim1600-32layers-preLnorm/model.ckpt-850000.bin'\n",
    "model = torch.load(open(model_path, 'rb'))\n",
    "model.backward_compatible()\n",
    "model = model.to(device)\n",
    "_ = model.eval()\n",
    "# model.reset_length(384, 0, 1280)\n",
    "model.reset_length(2048, 0, 2048)\n",
    "\n",
    "model_name = 'tr-xl-1.1B'\n",
    "model.device = torch.device('cpu')\n",
    "models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kf/miniconda3/lib/python3.7/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'mem_transformer.MemTransformerLM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/kf/projects/transformer-xl/checkpoints/torch/novel-90G-TPU512-mem384-dim1536-36layers-preLnorm/model.ckpt-270000.bin'\n",
    "model = torch.load(open(model_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.0981, 0.0945, 0.0795, '---', 0.1276, 0.0903, 0.0919),\n",
       " (1, 0.1926, 0.0916, 0.0771, '---', 0.2044, 0.0915, 0.0914),\n",
       " (2, 0.2064, 0.0933, 0.0794, '---', 0.3061, 0.0927, 0.0916),\n",
       " (3, 0.223, 0.0942, 0.0794, '---', 0.4141, 0.0935, 0.0915),\n",
       " (4, 0.2346, 0.0951, 0.0812, '---', 0.4984, 0.094, 0.0917),\n",
       " (5, 0.2676, 0.0963, 0.0813, '---', 0.5568, 0.0943, 0.0917),\n",
       " (6, 0.3005, 0.0951, 0.0824, '---', 0.6, 0.0946, 0.0917),\n",
       " (7, 0.3241, 0.0943, 0.0825, '---', 0.64, 0.0948, 0.0917),\n",
       " (8, 0.351, 0.0958, 0.0833, '---', 0.6598, 0.0949, 0.0917),\n",
       " (9, 0.3832, 0.0948, 0.0843, '---', 0.6898, 0.095, 0.0915),\n",
       " (10, 0.4281, 0.0939, 0.0834, '---', 0.7059, 0.0949, 0.0914),\n",
       " (11, 0.4071, 0.0947, 0.0844, '---', 0.7155, 0.0947, 0.0911),\n",
       " (12, 0.4165, 0.0948, 0.0872, '---', 0.7654, 0.095, 0.0914),\n",
       " (13, 0.4137, 0.0947, 0.0899, '---', 0.7846, 0.0951, 0.0915),\n",
       " (14, 0.4411, 0.0933, 0.0897, '---', 0.814, 0.0949, 0.0914),\n",
       " (15, 0.45, 0.0938, 0.0945, '---', 0.8274, 0.0949, 0.0913),\n",
       " (16, 0.4343, 0.0935, 0.0964, '---', 0.8414, 0.0949, 0.0913),\n",
       " (17, 0.4546, 0.0927, 0.0978, '---', 0.8658, 0.0949, 0.0913),\n",
       " (18, 0.453, 0.092, 0.0981, '---', 0.9152, 0.095, 0.0916),\n",
       " (19, 0.4237, 0.0927, 0.1029, '---', 0.9362, 0.0951, 0.0919),\n",
       " (20, 0.4635, 0.0918, 0.103, '---', 0.9888, 0.0953, 0.092),\n",
       " (21, 0.4567, 0.0919, 0.1082, '---', 1.033, 0.0955, 0.0922),\n",
       " (22, 0.4308, 0.0917, 0.1092, '---', 1.0812, 0.0957, 0.0927),\n",
       " (23, 0.4267, 0.0921, 0.1103, '---', 1.1658, 0.0962, 0.0935),\n",
       " (24, 0.4242, 0.0919, 0.1148, '---', 1.2277, 0.0966, 0.094),\n",
       " (25, 0.4236, 0.0917, 0.1143, '---', 1.3305, 0.0972, 0.095),\n",
       " (26, 0.4168, 0.0927, 0.1161, '---', 1.43, 0.0979, 0.0958),\n",
       " (27, 0.3978, 0.0917, 0.1178, '---', 1.5202, 0.0985, 0.0965),\n",
       " (28, 0.3899, 0.0936, 0.117, '---', 1.5939, 0.0989, 0.0971),\n",
       " (29, 0.4151, 0.0922, 0.1201, '---', 1.6712, 0.0995, 0.0979),\n",
       " (30, 0.4098, 0.0943, 0.1182, '---', 1.7733, 0.1002, 0.099),\n",
       " (31, 0.4305, 0.0938, 0.1184, '---', 1.8992, 0.1011, 0.1005),\n",
       " (32, 0.4713, 0.0948, 0.1178, '---', 2.0769, 0.1026, 0.1031),\n",
       " (33, 0.5483, 0.0975, 0.1165, '---', 2.3011, 0.1047, 0.1074),\n",
       " (34, 0.7122, 0.0939, 0.1238, '---', 2.3795, 0.1061, 0.1132),\n",
       " (35, 0.7627, 0.0907, 0.1248, '---', 2.0302, 0.106, 0.1162)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, wm(layer.dec_attn.layer_norm), wm(layer.dec_attn.qkv_net), wm(layer.dec_attn.o_net), '---', \n",
    "  wm(layer.pos_ff.layer_norm), wm(layer.pos_ff.CoreNet[0]), wm(layer.pos_ff.CoreNet[3])) \n",
    " for i, layer in enumerate(model.layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocabulary import NovelVocab, NovelGpt2Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/nas/qsj/respository/learning-test/transformer-xl/pytorch/model_cache/'\n",
    "model_path = base_dir + 'big-model-100G-TPU1024-mem384-24layers-preLnorm-preemptible/model.pt'\n",
    "model = torch.load(open(model_path, 'rb'))\n",
    "model.backward_compatible()\n",
    "model = model.to(device)\n",
    "_ = model.eval()\n",
    "model.reset_length(384, 0, 1280)\n",
    "tokenizer = NovelVocab(base_dir + 'vocab_file.txt')\n",
    "\n",
    "model_name = 'tr-xl-zh24l'\n",
    "model.device = torch.device('cpu')\n",
    "models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kf/miniconda3/lib/python3.7/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'mem_transformer.MemTransformerLM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/home/kf/projects/transformer-xl/checkpoints/torch/'\n",
    "model_path = base_dir + 'novel-90G-TPU512-mem384-dim1536-36layers-preLnorm/model.ckpt-720000.bin'\n",
    "model = torch.load(open(model_path, 'rb'))\n",
    "model.backward_compatible()\n",
    "model = model.to(device)\n",
    "_ = model.eval()\n",
    "model.reset_length(384, 0, 1280)\n",
    "tokenizer = NovelVocab('/nas/qsj/code/transformer-xl/pytorch/model_cache/vocab_file_new.txt')\n",
    "\n",
    "model_name = 'tr-xl-zh36l'\n",
    "model.device = torch.device('cpu')\n",
    "models[model_name] = model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'tr-xl-1.1B'\n",
    "model, tokenizer = models[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1600, out_features=6400, bias=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].pos_ff.CoreNet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wm(param): return round(param.weight.abs().mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.075, 0.1625, 0.1342, '---', 0.1443, 0.1519, 0.1502),\n",
       " (1, 0.1157, 0.1609, 0.1348, '---', 0.1991, 0.1522, 0.1495),\n",
       " (2, 0.1509, 0.1581, 0.1333, '---', 0.2806, 0.1516, 0.1481),\n",
       " (3, 0.2006, 0.1571, 0.1365, '---', 0.3573, 0.1517, 0.1484),\n",
       " (4, 0.2285, 0.1577, 0.1376, '---', 0.4287, 0.152, 0.1486),\n",
       " (5, 0.2758, 0.1542, 0.1409, '---', 0.4744, 0.152, 0.149),\n",
       " (6, 0.2819, 0.1542, 0.1434, '---', 0.5195, 0.1519, 0.1489),\n",
       " (7, 0.2875, 0.1532, 0.1499, '---', 0.5388, 0.1519, 0.1489),\n",
       " (8, 0.2808, 0.1529, 0.1523, '---', 0.5902, 0.152, 0.149),\n",
       " (9, 0.3142, 0.1519, 0.1543, '---', 0.6543, 0.1521, 0.1496),\n",
       " (10, 0.3342, 0.1515, 0.163, '---', 0.7048, 0.1524, 0.15),\n",
       " (11, 0.3262, 0.1519, 0.1613, '---', 0.7186, 0.1523, 0.1502),\n",
       " (12, 0.3313, 0.1526, 0.164, '---', 0.7507, 0.1525, 0.1505),\n",
       " (13, 0.3229, 0.1521, 0.167, '---', 0.7634, 0.1527, 0.1507),\n",
       " (14, 0.3248, 0.1517, 0.168, '---', 0.816, 0.1527, 0.151),\n",
       " (15, 0.3268, 0.1522, 0.1704, '---', 0.8372, 0.1526, 0.1509),\n",
       " (16, 0.3145, 0.152, 0.1704, '---', 0.8696, 0.1526, 0.151),\n",
       " (17, 0.3096, 0.1524, 0.1746, '---', 0.8926, 0.1527, 0.1512),\n",
       " (18, 0.2983, 0.1523, 0.1749, '---', 0.9385, 0.1529, 0.1515),\n",
       " (19, 0.3036, 0.1532, 0.1795, '---', 0.9797, 0.153, 0.1518),\n",
       " (20, 0.2978, 0.1534, 0.181, '---', 1.0298, 0.1533, 0.1523),\n",
       " (21, 0.2904, 0.1546, 0.1818, '---', 1.0739, 0.1534, 0.1526),\n",
       " (22, 0.2969, 0.1533, 0.1887, '---', 1.1209, 0.1535, 0.1527),\n",
       " (23, 0.3035, 0.1541, 0.193, '---', 1.1911, 0.1538, 0.1534),\n",
       " (24, 0.3165, 0.1537, 0.2002, '---', 1.2923, 0.1541, 0.1539),\n",
       " (25, 0.3207, 0.1535, 0.2025, '---', 1.3509, 0.1543, 0.1543),\n",
       " (26, 0.3277, 0.153, 0.2046, '---', 1.4332, 0.1546, 0.1554),\n",
       " (27, 0.3311, 0.1563, 0.2088, '---', 1.5982, 0.1555, 0.1575),\n",
       " (28, 0.4011, 0.1563, 0.2159, '---', 2.0033, 0.1586, 0.1632),\n",
       " (29, 0.6083, 0.153, 0.2127, '---', 2.5011, 0.1622, 0.1695),\n",
       " (30, 0.7637, 0.1533, 0.2196, '---', 2.7457, 0.1648, 0.1739),\n",
       " (31, 0.8617, 0.1509, 0.2175, '---', 2.5837, 0.1636, 0.1739)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, wm(layer.dec_attn.layer_norm), wm(layer.dec_attn.qkv_net), wm(layer.dec_attn.o_net), '---', \n",
    "  wm(layer.pos_ff.layer_norm), wm(layer.pos_ff.CoreNet[0]), wm(layer.pos_ff.CoreNet[3])) \n",
    " for i, layer in enumerate(model.layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2-xl'\n",
    "model, tokenizer = models[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Block(\n",
       "  (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "  (attn): GPT2Attention(\n",
       "    (c_attn): Conv1D()\n",
       "    (c_proj): Conv1D()\n",
       "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "  (mlp): GPT2MLP(\n",
       "    (c_fc): Conv1D()\n",
       "    (c_proj): Conv1D()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.0978, 0.0391, 0.0123, '---', 0.4133, 0.0285, 0.0212),\n",
       " (1, 0.3581, 0.0298, 0.0215, '---', 0.5312, 0.0304, 0.0255),\n",
       " (2, 0.4426, 0.03, 0.0221, '---', 0.6714, 0.0309, 0.0266),\n",
       " (3, 0.4759, 0.031, 0.0226, '---', 0.6935, 0.0311, 0.0275),\n",
       " (4, 0.5256, 0.0311, 0.0236, '---', 0.6904, 0.0311, 0.0277),\n",
       " (5, 0.5392, 0.0319, 0.0237, '---', 0.6896, 0.0311, 0.0276),\n",
       " (6, 0.5418, 0.0323, 0.0238, '---', 0.6907, 0.0311, 0.0276),\n",
       " (7, 0.5364, 0.0328, 0.0235, '---', 0.7011, 0.0311, 0.0275),\n",
       " (8, 0.5715, 0.033, 0.0239, '---', 0.7065, 0.0311, 0.0275),\n",
       " (9, 0.5763, 0.0336, 0.0235, '---', 0.7162, 0.0311, 0.0273),\n",
       " (10, 0.6045, 0.0333, 0.0246, '---', 0.7231, 0.0311, 0.0275),\n",
       " (11, 0.583, 0.0332, 0.0252, '---', 0.7286, 0.0311, 0.0275),\n",
       " (12, 0.6021, 0.0336, 0.0253, '---', 0.7347, 0.0311, 0.0275),\n",
       " (13, 0.6251, 0.033, 0.0257, '---', 0.7353, 0.0311, 0.0277),\n",
       " (14, 0.6106, 0.0333, 0.0259, '---', 0.7245, 0.031, 0.0278),\n",
       " (15, 0.6302, 0.0332, 0.0273, '---', 0.7188, 0.0311, 0.0277),\n",
       " (16, 0.6643, 0.0318, 0.0274, '---', 0.7142, 0.0311, 0.028),\n",
       " (17, 0.6811, 0.0316, 0.0288, '---', 0.7161, 0.0309, 0.0288),\n",
       " (18, 0.6657, 0.032, 0.0288, '---', 0.7083, 0.0308, 0.0291),\n",
       " (19, 0.6866, 0.0316, 0.0313, '---', 0.7023, 0.0307, 0.0294),\n",
       " (20, 0.7074, 0.0313, 0.0317, '---', 0.7009, 0.0307, 0.0296),\n",
       " (21, 0.6973, 0.0315, 0.0316, '---', 0.7018, 0.0306, 0.03),\n",
       " (22, 0.6902, 0.0315, 0.0316, '---', 0.7062, 0.0306, 0.0305),\n",
       " (23, 0.6862, 0.0315, 0.0318, '---', 0.7089, 0.0306, 0.0309),\n",
       " (24, 0.6687, 0.0318, 0.0312, '---', 0.7075, 0.0306, 0.0312),\n",
       " (25, 0.6796, 0.0319, 0.0311, '---', 0.714, 0.0306, 0.0318),\n",
       " (26, 0.6719, 0.0322, 0.0309, '---', 0.7215, 0.0305, 0.0324),\n",
       " (27, 0.6645, 0.032, 0.0312, '---', 0.7283, 0.0306, 0.0329),\n",
       " (28, 0.6816, 0.0319, 0.0328, '---', 0.7352, 0.0307, 0.0337),\n",
       " (29, 0.6747, 0.0321, 0.0314, '---', 0.7422, 0.0307, 0.0341),\n",
       " (30, 0.6568, 0.0323, 0.0314, '---', 0.752, 0.0308, 0.0343),\n",
       " (31, 0.6694, 0.0325, 0.0319, '---', 0.7583, 0.0308, 0.0348),\n",
       " (32, 0.6712, 0.0323, 0.0319, '---', 0.7683, 0.0308, 0.0352),\n",
       " (33, 0.6813, 0.0323, 0.0321, '---', 0.777, 0.0309, 0.0355),\n",
       " (34, 0.6865, 0.0326, 0.0326, '---', 0.7838, 0.0309, 0.0359),\n",
       " (35, 0.6982, 0.0326, 0.0333, '---', 0.7955, 0.031, 0.0363),\n",
       " (36, 0.6915, 0.0328, 0.032, '---', 0.8039, 0.0311, 0.0367),\n",
       " (37, 0.6904, 0.0328, 0.0329, '---', 0.8123, 0.0312, 0.0371),\n",
       " (38, 0.7131, 0.0328, 0.0337, '---', 0.8212, 0.0312, 0.0375),\n",
       " (39, 0.7055, 0.0328, 0.0338, '---', 0.8323, 0.0313, 0.0379),\n",
       " (40, 0.7237, 0.0329, 0.0343, '---', 0.844, 0.0314, 0.0384),\n",
       " (41, 0.7218, 0.033, 0.0337, '---', 0.8528, 0.0315, 0.0387),\n",
       " (42, 0.733, 0.0328, 0.0341, '---', 0.8663, 0.0317, 0.0392),\n",
       " (43, 0.7513, 0.0331, 0.0347, '---', 0.8834, 0.0319, 0.0397),\n",
       " (44, 0.7672, 0.0328, 0.0345, '---', 0.9023, 0.0322, 0.0403),\n",
       " (45, 0.7695, 0.0329, 0.0338, '---', 0.9297, 0.0329, 0.0412),\n",
       " (46, 0.7832, 0.0327, 0.033, '---', 0.9634, 0.0337, 0.0423),\n",
       " (47, 0.7545, 0.0329, 0.0318, '---', 0.9404, 0.0343, 0.0428)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, wm(layer.ln_1), wm(layer.attn.c_attn), wm(layer.attn.c_proj), '---', \n",
    "  wm(layer.ln_2), wm(layer.mlp.c_fc), wm(layer.mlp.c_proj)) \n",
    " for i, layer in enumerate(model.transformer.h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'EleutherAI/gpt-neo-1.3B'\n",
    "model, tokenizer = models[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.2656, 0.044, 0.0438, 0.0455, 0.0426, '---', 0.8917, 0.0551, 0.0405),\n",
       " (1, 0.4886, 0.0512, 0.0515, 0.0463, 0.0441, '---', 1.3031, 0.0582, 0.043),\n",
       " (2, 0.5846, 0.0461, 0.0469, 0.0505, 0.0474, '---', 1.3098, 0.0567, 0.0429),\n",
       " (3, 0.4617, 0.0428, 0.0424, 0.0567, 0.0469, '---', 1.0418, 0.0423, 0.0263),\n",
       " (4, 0.6966, 0.051, 0.0493, 0.0562, 0.0493, '---', 1.5204, 0.0601, 0.0432),\n",
       " (5, 0.7229, 0.0533, 0.052, 0.0537, 0.0495, '---', 1.7158, 0.0612, 0.0444),\n",
       " (6, 0.7553, 0.0543, 0.0539, 0.0522, 0.0503, '---', 1.6902, 0.0605, 0.0444),\n",
       " (7, 0.7578, 0.0549, 0.0537, 0.0536, 0.0516, '---', 1.433, 0.0588, 0.044),\n",
       " (8, 0.7471, 0.0486, 0.0493, 0.0573, 0.0543, '---', 1.4936, 0.0582, 0.0449),\n",
       " (9, 0.7453, 0.0457, 0.0449, 0.0629, 0.0603, '---', 1.311, 0.0574, 0.0459),\n",
       " (10, 0.8439, 0.046, 0.0469, 0.0657, 0.0624, '---', 1.3876, 0.0569, 0.047),\n",
       " (11, 0.7679, 0.0458, 0.0452, 0.0666, 0.0645, '---', 1.3403, 0.0566, 0.0487),\n",
       " (12, 0.753, 0.0452, 0.0457, 0.0644, 0.0639, '---', 1.3968, 0.0567, 0.0485),\n",
       " (13, 0.7037, 0.0448, 0.0442, 0.0664, 0.065, '---', 1.2934, 0.0565, 0.0517),\n",
       " (14, 0.7061, 0.0435, 0.0443, 0.0688, 0.0667, '---', 1.3405, 0.0566, 0.0529),\n",
       " (15, 0.6406, 0.0447, 0.0443, 0.0663, 0.0646, '---', 1.2959, 0.0566, 0.0559),\n",
       " (16, 0.6472, 0.0418, 0.0428, 0.0709, 0.068, '---', 1.3136, 0.0567, 0.0573),\n",
       " (17, 0.5855, 0.0449, 0.0449, 0.0648, 0.0627, '---', 1.2438, 0.0563, 0.0598),\n",
       " (18, 0.5693, 0.0426, 0.0435, 0.0697, 0.0664, '---', 1.2314, 0.0564, 0.0617),\n",
       " (19, 0.5213, 0.0466, 0.0475, 0.0599, 0.058, '---', 1.199, 0.0563, 0.0626),\n",
       " (20, 0.5053, 0.0438, 0.0447, 0.069, 0.0663, '---', 1.1654, 0.056, 0.0635),\n",
       " (21, 0.5052, 0.0446, 0.0455, 0.0614, 0.0597, '---', 1.1076, 0.0556, 0.0635),\n",
       " (22, 0.518, 0.0392, 0.0399, 0.0732, 0.0672, '---', 1.0656, 0.0551, 0.062),\n",
       " (23, 0.523, 0.0363, 0.0366, 0.0651, 0.0546, '---', 0.9504, 0.0538, 0.0569)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, wm(layer.ln_1), wm(layer.attn.attention.q_proj), wm(layer.attn.attention.k_proj), wm(layer.attn.attention.v_proj), wm(layer.attn.attention.out_proj), '---', \n",
    "  wm(layer.ln_2), wm(layer.mlp.c_fc), wm(layer.mlp.c_proj)) \n",
    " for i, layer in enumerate(model.transformer.h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.2835, 0.0356, 0.0356, 0.0349, 0.0329, '---', 0.9101, 0.045, 0.0321),\n",
       " (1, 0.4845, 0.04, 0.041, 0.0362, 0.0341, '---', 1.2614, 0.0477, 0.0334),\n",
       " (2, 0.632, 0.0393, 0.0401, 0.039, 0.0383, '---', 1.3314, 0.0469, 0.0337),\n",
       " (3, 0.5238, 0.0341, 0.0346, 0.0417, 0.0365, '---', 1.324, 0.0396, 0.0261),\n",
       " (4, 0.6214, 0.0377, 0.0366, 0.046, 0.039, '---', 1.3798, 0.0415, 0.0279),\n",
       " (5, 0.6594, 0.0411, 0.0408, 0.0425, 0.0379, '---', 1.5954, 0.0499, 0.0352),\n",
       " (6, 0.7038, 0.0427, 0.0428, 0.042, 0.0398, '---', 1.5804, 0.0498, 0.0356),\n",
       " (7, 0.7157, 0.044, 0.044, 0.0412, 0.0395, '---', 1.494, 0.0489, 0.0368),\n",
       " (8, 0.7216, 0.0421, 0.0429, 0.0425, 0.0416, '---', 1.514, 0.0488, 0.0364),\n",
       " (9, 0.7012, 0.0405, 0.0413, 0.0444, 0.0427, '---', 1.2791, 0.0479, 0.0363),\n",
       " (10, 0.7733, 0.0387, 0.0398, 0.0463, 0.0438, '---', 1.371, 0.0475, 0.0363),\n",
       " (11, 0.742, 0.0362, 0.0366, 0.0511, 0.049, '---', 1.2435, 0.0471, 0.0369),\n",
       " (12, 0.8328, 0.0371, 0.0382, 0.0526, 0.0504, '---', 1.2891, 0.0467, 0.0377),\n",
       " (13, 0.7251, 0.0365, 0.037, 0.0521, 0.0506, '---', 1.2454, 0.0466, 0.0388),\n",
       " (14, 0.766, 0.0364, 0.0372, 0.0531, 0.0516, '---', 1.2912, 0.0467, 0.0395),\n",
       " (15, 0.6785, 0.0359, 0.0364, 0.052, 0.051, '---', 1.2575, 0.0466, 0.0411),\n",
       " (16, 0.6903, 0.036, 0.0369, 0.0513, 0.0511, '---', 1.2813, 0.0467, 0.0414),\n",
       " (17, 0.6435, 0.0351, 0.0356, 0.0532, 0.0517, '---', 1.2163, 0.0464, 0.0434),\n",
       " (18, 0.6555, 0.0348, 0.0361, 0.0539, 0.0526, '---', 1.2787, 0.0467, 0.044),\n",
       " (19, 0.5878, 0.0371, 0.0377, 0.0494, 0.048, '---', 1.267, 0.0467, 0.0451),\n",
       " (20, 0.6167, 0.0354, 0.0367, 0.0534, 0.0513, '---', 1.2662, 0.0468, 0.0457),\n",
       " (21, 0.5766, 0.0366, 0.0373, 0.0496, 0.0478, '---', 1.2334, 0.0466, 0.047),\n",
       " (22, 0.5845, 0.0349, 0.0363, 0.0545, 0.052, '---', 1.2405, 0.0467, 0.0477),\n",
       " (23, 0.5676, 0.0365, 0.0377, 0.0479, 0.0464, '---', 1.2062, 0.0465, 0.0484),\n",
       " (24, 0.5656, 0.034, 0.0354, 0.0552, 0.0518, '---', 1.1908, 0.0465, 0.0492),\n",
       " (25, 0.5392, 0.0364, 0.0377, 0.0487, 0.0471, '---', 1.1803, 0.0464, 0.0497),\n",
       " (26, 0.5381, 0.0339, 0.0353, 0.0529, 0.0497, '---', 1.1591, 0.0463, 0.05),\n",
       " (27, 0.5545, 0.0343, 0.0358, 0.0481, 0.0465, '---', 1.1319, 0.0462, 0.0502),\n",
       " (28, 0.5351, 0.0325, 0.0341, 0.051, 0.0481, '---', 1.1022, 0.046, 0.0501),\n",
       " (29, 0.5413, 0.0332, 0.0349, 0.0478, 0.0455, '---', 1.0681, 0.0458, 0.0494),\n",
       " (30, 0.5229, 0.0316, 0.033, 0.0467, 0.0429, '---', 1.0247, 0.0455, 0.0477),\n",
       " (31, 0.495, 0.0303, 0.0318, 0.0437, 0.0353, '---', 0.972, 0.0445, 0.0435)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'EleutherAI/gpt-neo-2.7B'\n",
    "model, tokenizer = models[model_name]\n",
    "[(i, wm(layer.ln_1), wm(layer.attn.attention.q_proj), wm(layer.attn.attention.k_proj), wm(layer.attn.attention.v_proj), wm(layer.attn.attention.out_proj), '---', \n",
    "  wm(layer.ln_2), wm(layer.mlp.c_fc), wm(layer.mlp.c_proj)) \n",
    " for i, layer in enumerate(model.transformer.h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_len, mem_len = 384, 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(xl_model):\n",
    "    def inner(data, *mems):\n",
    "        if not mems: mems = xl_model.init_mems()\n",
    "        # pdb.set_trace()\n",
    "        hidden, new_mems = xl_model._forward(data, mems=mems)\n",
    "        pro_layer = xl_model.crit\n",
    "        hidden = pro_layer._compute_logit(hidden, pro_layer.out_layers[0].weight, pro_layer.out_layers[0].bias, pro_layer.out_projs[0])\n",
    "        return [hidden] + new_mems\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/kf/data/formal_data/books3_cleaned/'\n",
    "fnames = os.listdir(data_dir)\n",
    "# fnames = [line.strip().replace('/mnt/nvme1/kf/data/formal_data/', '') \n",
    "#           for line in open(data_dir + 'allfile.filelist.shuffed.valid').readlines()\n",
    "#           if 'ao3_General_Audiences_Teen_And_Up_selected/' in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len(text, is_zh):\n",
    "    if not is_zh: return len(text.split())\n",
    "    else: return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tokenizer, text):\n",
    "    eos_token = '&'\n",
    "    eos_id = tokenizer.convert_text_to_ids(eos_token)[0]  # 111\n",
    "    ids = tokenizer.convert_text_to_ids(text.replace('\\n', eos_token))\n",
    "    return [tokenizer.eos() if i == eos_id else i for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "def convert_text_to_ids(tokenizer, text):\n",
    "    eos, eod = tokenizer.eos(), tokenizer.eod()\n",
    "    ids = []\n",
    "    for l in text.split(\"\\n\"):\n",
    "        if l.strip() == '': continue\n",
    "        ids += reduce(lambda x, y: x + [eod] + y, [tokenizer.convert_text_to_ids(s) for s in l.split('<eod>')]) + [eos]\n",
    "    ids.pop()  # pos last eos\n",
    "    return ids\n",
    "\n",
    "def convert_ids_to_tokens(tokenizer, ids):\n",
    "    return [token.replace('[unused10]', '/n') for token in tokenizer.convert_ids_to_tokens(ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = ''\n",
    "fnames = test_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/elderberry_shared/69shuba/20210403_69shu_novel_dev1/13012-重生之诱君欢-似是故人来\n",
      "/elderberry_shared/69shuba/20210403_69shu_novel_dev1/13012-重生之诱君欢-似是故人来 7339\n",
      "skip [0, 1]\n",
      "input_len = 1382\n"
     ]
    }
   ],
   "source": [
    "is_zh = isinstance(tokenizer, NovelVocab)\n",
    "# bad_books, good_books = [], []\n",
    "# for fname in fnames:\n",
    "# if True:\n",
    "\n",
    "fname = random.choice(fnames)\n",
    "print(fname)\n",
    "lines = open(data_dir + fname).readlines()\n",
    "print(fname, len(lines))\n",
    "\n",
    "# i = random.randint(0, len(lines) - 30)\n",
    "# text, _text = '', ''\n",
    "# while get_len(text, is_zh=True) < 768 and i < len(lines) - 1:\n",
    "#     text += lines[i]\n",
    "#     if lines[i].strip() not in ['', '……', '…'] and '-分页-' not in lines[i]: _text += lines[i]\n",
    "#     i += 1\n",
    "# print('len(_text.split()) =', get_len(text, is_zh=True))\n",
    "\n",
    "if is_zh:\n",
    "    _text_lengths = [0, 1]\n",
    "    while len(set(_text_lengths)) > 1:\n",
    "        print('skip', _text_lengths)\n",
    "        i = random.randint(0, len(lines) - 30)\n",
    "        text, _text = '', ''\n",
    "        while get_len(text, is_zh=True) < 1280 and i < len(lines) - 1:\n",
    "            text += lines[i]\n",
    "            line = lines[i].strip()\n",
    "            if line not in ['', '……', '…'] and '-分页-' not in line and not line.isdigit():\n",
    "                _text += line + '\\n'\n",
    "            i += 1\n",
    "        _text_lengths = [len(convert_text_to_ids(tokenizer, _text)) \n",
    "                         for model_name, (model, tokenizer) in models.items() if 'zh' in model_name]\n",
    "    input_len = _text_lengths[0]\n",
    "    print('input_len =', input_len)\n",
    "# else:\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "#     print('input_len =', inputs.input_ids.size(1))\n",
    "#     input_ids = inputs.input_ids[:, -1024:]\n",
    "#     shift_labels = input_ids.clone()[:, 1:]\n",
    "#     shift_labels[:, :-tgt_len] = -100\n",
    "\n",
    "#     if text != _text:\n",
    "#         _inputs = tokenizer(_text, return_tensors=\"pt\")\n",
    "#         _input_ids = _inputs.input_ids[:, -1024:]\n",
    "#         _shift_labels = _input_ids.clone()[:, 1:]\n",
    "#         _shift_labels[:, :-tgt_len] = -100\n",
    "tgt_len = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "title, category = '', ''\n",
    "text = '''明月几时有？把酒问青天。\n",
    "不知天上宫阙，今夕是何年？\n",
    "我欲乘风归去，又恐琼楼玉宇，高处不胜寒。\n",
    "起舞弄清影，何似在人间？'''\n",
    "# text = '''赵客缦胡缨，吴钩霜雪明。\n",
    "# 银鞍照白马，飒沓如流星。\n",
    "# 十步杀一人，千里不留行。\n",
    "# 事了拂衣去，深藏身与名。'''\n",
    "tgt_lengths = [len(convert_text_to_ids(tokenizer, text)) for model_name, (model, tokenizer) in models.items() if 'zh' in model_name]\n",
    "assert len(set(tgt_lengths)) == 1, str(tgt_lengths)\n",
    "tgt_len = tgt_lengths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr-xl-zh24l ppl 7.4983679663759\n",
      "tr-xl-zh36l ppl 6.787260554053457\n",
      "0.711107412322443\n"
     ]
    }
   ],
   "source": [
    "# for Shawn Guo\n",
    "for _input_len in [768, ]:\n",
    "    results = defaultdict(dict)\n",
    "    for model_name, (model, tokenizer) in models.items():\n",
    "        if is_zh and 'zh' not in model_name: continue\n",
    "        if 'zh' in model_name:\n",
    "    #         _prompt = padding_texts[model_name] % (title, category)\n",
    "    #         _text = _prompt + text\n",
    "            input_ids = torch.LongTensor([convert_text_to_ids(tokenizer, _text)[-_input_len:]])\n",
    "        elif 'tr-xl' in model_name:\n",
    "            input_ids = tokenizer(_text, return_tensors=\"pt\").input_ids\n",
    "        else:\n",
    "            input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "        shift_labels = input_ids.clone()[:, 1:]\n",
    "        shift_labels[:, :-tgt_len] = -100\n",
    "        with torch.no_grad():\n",
    "            logits = infer(model)(input_ids.t().to(model.device), *tuple())[0].permute(1, 0, 2) \\\n",
    "                if 'tr-xl' in model_name else model(input_ids.to(model.device))[0]\n",
    "        shift_logits = logits[:, :-1, :]\n",
    "        loss = CrossEntropyLoss(reduction='none')(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1).to(model.device))\n",
    "        loss = loss[-tgt_len:]\n",
    "        results[model_name]['logits'] = shift_logits[0, -tgt_len:].cpu()\n",
    "        results[model_name]['labels'] = shift_labels[0, -tgt_len:].tolist()\n",
    "        results[model_name]['loss'] = loss.cpu()\n",
    "        results[model_name]['ppl'] = math.exp(loss.mean().item())\n",
    "        print(model_name, 'ppl', results[model_name]['ppl'])\n",
    "    print(results['tr-xl-zh24l']['ppl'] - results['tr-xl-zh36l']['ppl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f98dc2cba10>]"
      ]
     },
     "execution_count": 955,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss0, loss1 = results['tr-xl-zh24l']['loss'], results['tr-xl-zh36l']['loss']\n",
    "dloss = loss1 - loss0\n",
    "plt.plot(dloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 26, 124]"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([9.9074, 6.2428, 8.6429])"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([6.8178, 0.7307, 4.4178])"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th = 3\n",
    "indices = (dloss.abs() > th).nonzero()[:, 0].tolist()\n",
    "indices\n",
    "loss0[(dloss.abs() > th)]\n",
    "loss1[(dloss.abs() > th)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21, '三绝吧？”'), (26, '/n冯侍郎有'), (124, '绝，床技无')]"
      ]
     },
     "execution_count": 957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, ''.join(convert_ids_to_tokens(tokenizer, shift_labels[0, -tgt_len:][i - 2: i + 3].tolist()))) for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr-xl-zh24l\n",
      "21 吧 {'，': 0.7278, '：': 0.0944, '。': 0.0747, '之': 0.0314, '-': 0.0212}\n",
      "26 侍 {'丞': 0.9896, '侍': 0.0019, '家': 0.0006, '明': 0.0005, '氏': 0.0002}\n",
      "124 床 {'就': 0.1123, '那': 0.1114, '能': 0.0956, '是': 0.0704, '便': 0.0505}\n",
      "tr-xl-zh36l\n",
      "21 吧 {'，': 0.5987, '。': 0.1186, '—': 0.0789, '：': 0.0585, '之': 0.0496}\n",
      "26 侍 {'侍': 0.4816, '丞': 0.2717, '大': 0.0135, '府': 0.0119, '夫': 0.0114}\n",
      "124 床 {'那': 0.1189, '是': 0.0567, '就': 0.0468, '能': 0.0435, '便': 0.0434}\n"
     ]
    }
   ],
   "source": [
    "for model_name in ['tr-xl-zh24l', 'tr-xl-zh36l']:\n",
    "    model, tokenizer = models[model_name]\n",
    "    logits, labels = results[model_name]['logits'], results[model_name]['labels']\n",
    "    probs = logits.softmax(dim=-1)\n",
    "    target_tokens = convert_ids_to_tokens(tokenizer, labels)\n",
    "    print(model_name)\n",
    "#     for i in range(tgt_len):\n",
    "    for i in [21, 26, 124]:\n",
    "        values, indices = probs[i].topk(5)\n",
    "        values, indices = values.numpy().round(4), indices.tolist()\n",
    "        print(i, target_tokens[i], dict(OrderedDict(zip(convert_ids_to_tokens(tokenizer, indices), values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看着熟悉又陌生的人，一瞬间，冯丞斐怀疑，自己眼睛花了，将另一个人看成禇明锦了。\n",
      "禇明锦抬眼看到冯丞斐时，几乎要击掌大赞。\n",
      "高挑秀逸的身材，宽大的月白广袖轻柔的垂着，随着微风吹动轻摆，袖口约一寸半宽的银色镶边上纹着暗光精美丝线，仿若浮云悄然飘动，又似淡月一样柔和。\n",
      "往上，同样镶边云纹样的领口微微敞开，露出光滑精致的锁骨，优美的脖颈，再往上，是一张美得让禇明锦觉得世间所有的词语都不足以贴切地描述形容的脸，远山藏黛眉，绿水锁春波，丹唇点朱砂，如厮美貌，却又毫不娘气，整个人带给人的是一种蓝天白云的旷远悠然，高山流水的出尘离俗感觉。\n",
      "此人容色如此秀美绝伦，会不会就是几个妹妹赞不绝口的冯侍郎？也即自己的挂名郎君？\n",
      "冯丞斐在对上禇明锦的眼神后，心头的疑惑更深。\n",
      "袍裾起伏，冯丞斐缓走几步，唇角微翘，带出一丝迷离的浅笑，朝禇明锦拱了拱手，道：“在下李怀瑾，公子风采，令人折服，不知可否同座？”\n",
      "李怀瑾？这人不是冯丞斐。禇明锦略微缓得一缓，学着冯丞斐的样子拱手回礼，笑道：“幸会，李兄请坐。”\n",
      "“有扰。”冯丞斐的笑容更深了，潇洒地撩起袍角，双腿盘膝坐了下去。\n",
      "禇明锦此时方看清，对方身上的衣裳料子竟是雪蚕丝所织成的布，制作得非常精雅。这样的衣料，平常人穿不上，李姓据她所知是国姓，此人难道是哪个皇子或是王爷？\n",
      "若是如此，这般样貌再加上身份尊贵，不至于给冯丞斐压下吧？为何没听几个妹妹提过？\n",
      "伙计服务周到，茶杯茶点不需禇明锦开口便送过来了，冯丞斐伸了手握茶杯，长袖滑落，意态从容优雅，握着青花瓷杯的手指修-长匀称，指甲透明柔润，禇明锦微微眼直，脱口问道：“听闻冯侍郎有倾国倾城之貌，李兄与冯侍郎，未知谁高谁下？”\n",
      "他的夫人问他，自己与自己比，谁高谁下？冯丞斐一口茶几乎喷出来，偏头看着禇明锦微微一笑，漫声道：“兄台这话让人好生难答，依兄所见呢？”\n",
      "舒雅慵懒的靡丽语气，却并不让人反感，只因眼前之人，容色秀美高雅，污浊之气也因他而荡涤一空。\n",
      "禇明锦笑道：“在下没见过冯侍郎，不过以李兄之貌，若是尚在冯侍郎之下，那冯侍郎，岂不是要羞煞神仙？倾倒世间所有男女？”\n",
      "冯丞斐心道：羞煞神仙也许有可能，倾倒世间所有男女却未必，至少你就没被倾倒。\n",
      "面对面坐着，又说了这么多话，冯丞斐很肯定，眼前之人是禇明锦无疑，她难道以为自己加浓了眉毛，抹了粉饼，稍为改变了声音，自己便认不出来？\n",
      "冯丞斐起了作弄之心，笑道：“在下与冯侍郎是没法相比的，兄台想必也听过，冯侍郎有三绝吧？”\n",
      "冯侍郎有三绝？禇明锦尚未听说过，睁大眼看冯丞斐。\n",
      "“冯侍郎有三绝，眼睛能摄魂夺魄，微笑间倾国倾城，妙手绘丹青绝笔。”冯丞斐朝禇明锦招了招手，倾身凑到禇明锦耳边，低声道：“其实，听说，冯侍郎还有一绝，床技无人能敌！”\n",
      "温热清新的气息在她耳边吹着，低沉的声音带着魅惑人的绵醇，柔软的一物从耳垂擦过，带起酥-麻往身体里流窜，禇明锦下意识地后退，眼睛一眨不眨地看向冯丞斐。\n",
      "冯丞斐的眼珠子黑得纯粹，好像深沉的光芒四射的黑曜石，稍不自觉便会被吸进去，鼻梁挺直，肌肤不是特别白皙，温润细腻宛如玉石，却又比玉石温暖柔软。\n",
      "四目相对，片刻后，禇明锦笑了起来，调皮地凑到冯丞斐耳边，压低声音道：“李兄，冯侍郎纵有四绝，却不及李兄一绝。”禇明锦略顿了顿，往冯丞斐耳洞里哈气，忍住笑，加重了语气道：“李兄的口技，相信是天上人间绝无仅有的。”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[0.4655, 0.1617, 0.0430, 0.0399, 0.0305]]),\n",
       "indices=tensor([[2769, 1372, 6760,  671, 7309]]))"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[0.6350, 0.1693, 0.0324, 0.0295, 0.0211]]),\n",
       "indices=tensor([[2769, 1372, 6760,  671, 7309]]))"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[0.4127, 0.1103, 0.0789, 0.0718, 0.0514]]),\n",
       "indices=tensor([[1372, 2769, 6760,  671, 7309]]))"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[0.4746, 0.1268, 0.0907, 0.0826, 0.0591]]),\n",
       "indices=tensor([[1372, 2769, 6760,  671, 7309]]))"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[0.5136, 0.1373, 0.0982, 0.0894, 0.0639]]),\n",
       "indices=tensor([[1372, 2769, 6760,  671, 7309]]))"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = results['tr-xl-zh36l']['logits']\n",
    "i = 27\n",
    "logits = logits[i: i + 1] \n",
    "logits.softmax(-1).topk(5)\n",
    "logits = logits / 0.8\n",
    "logits.softmax(-1).topk(5)\n",
    "\n",
    "a = torch.ones(1, logits.size(1))\n",
    "a[0, 2769] *= 1.2\n",
    "logits = logits / a\n",
    "logits.softmax(-1).topk(5)\n",
    "\n",
    "logits = top_k_logits(logits, 10)\n",
    "logits.softmax(-1).topk(5)\n",
    "logits = top_p_logits(logits, 0.9)\n",
    "logits.softmax(-1).topk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'明月几时有？把酒问青天。\\n不知'"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "model = models['tr-xl-zh24l'][0]\n",
    "model.device = device\n",
    "_ = model.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr-xl-zh24l 371\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑\"无聊老头\"大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "<doc>\n",
      "novelname:\n",
      "qidiannovelcategories:完本,签约,vip\n",
      "qidiannovelauthorcategories:%s\n",
      "qidiannovelscore:9.5\n",
      "qidiannovelrecommendtime:57周\n",
      "前言\n",
      "感谢大家来看我的新书，我会努力更新的，请大家支持我！\n",
      "第一章开场（1）\n",
      ".开场结束.外面。\n",
      "\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑\"无聊老头\"大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "<doc>\n",
      "novelname:\n",
      "qidiannovelcategories:完本,签约,vip\n",
      "qidiannovelauthorcategories:%s\n",
      "qidiannovelscore:9.5\n",
      "qidiannovelrecommendtime:57周\n",
      "前言\n",
      "感谢大家来看我的新书，我会努力更新的，请大家支持我！\n",
      "第一章开场（1）\n",
      "花絮如梦！\n",
      "我已经\n",
      "\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑\"无聊老头\"大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "<doc>\n",
      "novelname:\n",
      "qidiannovelcategories:完本,签约,vip\n",
      "qidiannovelauthorcategories:%s\n",
      "qidiannovelscore:9.5\n",
      "qidiannovelrecommendtime:57周\n",
      "前言\n",
      "感谢大家来看我的新书，我会努力更新的，请大家支持我！\n",
      "第一章开场（1）的微博求关注，微信公\n",
      "\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑\"无聊老头\"大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "<doc>\n",
      "novelname:\n",
      "qidiannovelcategories:完本,签约,vip\n",
      "qidiannovelauthorcategories:%s\n",
      "qidiannovelscore:9.5\n",
      "qidiannovelrecommendtime:57周\n",
      "前言\n",
      "感谢大家来看我的新书，我会努力更新的，请大家支持我！\n",
      "第一章开场（1）&lt;height:36px1&\n",
      "\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑\"无聊老头\"大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "<doc>\n",
      "novelname:\n",
      "qidiannovelcategories:完本,签约,vip\n",
      "qidiannovelauthorcategories:%s\n",
      "qidiannovelscore:9.5\n",
      "qidiannovelrecommendtime:57周\n",
      "前言\n",
      "感谢大家来看我的新书，我会努力更新的，请大家支持我！\n",
      "第一章开场（1）\n",
      "太阳升起来，这一天\n",
      "\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑\"无聊老头\"大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "<doc>\n",
      "novelname:\n",
      "qidiannovelcategories:完本,签约,vip\n",
      "qidiannovelauthorcategories:%s\n",
      "qidiannovelscore:9.5\n",
      "qidiannovelrecommendtime:57周\n",
      "前言\n",
      "感谢大家来看我的新书，我会努力更新的，请大家支持我！\n",
      "第一章开场（1）字数一千字正文2百\n",
      "\n",
      "\n",
      "tr-xl-zh36l 300\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑“无聊老头”大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "[unused11]novelname:\n",
      "novelcategory:\n",
      "novelwords:556k\n",
      "novelstatus:连载中\n",
      "第1章网虫追妻记\n",
      "z国首都\n",
      "\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑“无聊老头”大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "[unused11]novelname:\n",
      "novelcategory:\n",
      "novelwords:556k\n",
      "novelstatus:连载中\n",
      "第1章青铜岛（2）\n",
      "从红海\n",
      "\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑“无聊老头”大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "[unused11]novelname:\n",
      "novelcategory:\n",
      "novelwords:556k\n",
      "novelstatus:连载中\n",
      "第1章好人坏人(4)\n",
      "楔子\n",
      "\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑“无聊老头”大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "[unused11]novelname:\n",
      "novelcategory:\n",
      "novelwords:556k\n",
      "novelstatus:连载中\n",
      "第1章连载\n",
      "无心再恋爱\n",
      "末\n",
      "\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑“无聊老头”大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "[unused11]novelname:\n",
      "novelcategory:\n",
      "novelwords:556k\n",
      "novelstatus:连载中\n",
      "第1章\n",
      "田妙花猛的从睡梦中\n",
      "\n",
      "完结感言\n",
      "本书在这里说明一下\n",
      "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
      "这里也要感谢作者编辑“无聊老头”大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
      "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
      "各位朋友，来日再见！\n",
      "[unused11]novelname:\n",
      "novelcategory:\n",
      "novelwords:556k\n",
      "novelstatus:连载中\n",
      "第1章\n",
      "飞贼兰蔻忽闪着卷曲\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, (model, tokenizer) in models.items():\n",
    "    if is_zh and 'zh' not in model_name: continue\n",
    "    _prompt = padding_texts[model_name] #% (title, category)\n",
    "    _text = _prompt #+ text[:15]\n",
    "    input_ids = torch.LongTensor([convert_text_to_ids(tokenizer, _text)])\n",
    "    if 'tr-xl' in model_name: input_ids = input_ids.t()\n",
    "    reply = sample_sequence(infer(model), tokenizer, 10, input_ids.to(model.device), temperature=[1], top_k=[0], top_p=0.9, repeat=3, punishRate=1.2)\n",
    "    print(model_name, len(convert_text_to_ids(tokenizer, _text)))\n",
    "    for i in range(len(reply)):\n",
    "        print(tokenizer.convert_ids_to_text(reply[i]).replace('[unused10]', '\\n').replace('##', ''))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11566, 9360, 9502, 11689, 8472, 10869, 10935, 10939]"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[11566, 9360, 9502, 11689, 8472]"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_text_to_ids('qidiannovelcategories')\n",
    "tokenizer.convert_text_to_ids('qidiannovel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_text = \"\"\"完结感言\n",
    "本书在这里说明一下\n",
    "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
    "这里也要感谢作者编辑\\\"无聊老头\\\"大叔，他对这部小说给予了很多指导，让我有了灵感和动力>。当然这本书也是因为他给我的灵感才有的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能>在这里有这样的名字和地位。\n",
    "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
    "各位朋友，来日再见！\n",
    "<doc>\n",
    "Novelname:\n",
    "qidiannovelcategories:完本,签约,vip\n",
    "qidiannovelauthorcategories:\n",
    "qidiannovelscore:9.5\n",
    "qidiannovelrecommendtime:57周\n",
    "前言\n",
    "感谢大家来看我的新书，我会努力更新的，请大家支持我！\n",
    "第一章 开场（1）\n",
    "\"\"\"\n",
    "\n",
    "padding_texts = {}\n",
    "padding_texts['tr-xl-zh24l'] = \"\"\"完结感言\n",
    "本书在这里说明一下\n",
    "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
    "这里也要感谢作者编辑\\\"无聊老头\\\"大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
    "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
    "各位朋友，来日再见！\n",
    "<doc>\n",
    "Novelname:\n",
    "qidiannovelcategories:完本,签约,vip\n",
    "qidiannovelauthorcategories:%s\n",
    "qidiannovelscore:9.5\n",
    "qidiannovelrecommendtime:57周\n",
    "前言\n",
    "感谢大家来看我的新书，我会努力更新的，请大家支持我！\n",
    "第一章 开场（1）\n",
    "\"\"\"\n",
    "padding_texts['tr-xl-zh36l'] = \"\"\"完结感言\n",
    "本书在这里说明一下\n",
    "在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\n",
    "这里也要感谢作者编辑“无聊老头”大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\n",
    "感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\n",
    "各位朋友，来日再见！\n",
    "<eod>novelname:\n",
    "novelcategory:\n",
    "novelwords:556k\n",
    "novelstatus:连载中\n",
    "第1章\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tr-xl-zh24l': '完结感言\\n本书在这里说明一下\\n在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\\n这里也要感谢作者编辑\"无聊老头\"大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\\n感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\\n各位朋友，来日再见！\\n<doc>\\nNovelname:\\nqidiannovelcategories:完本,签约,vip\\nqidiannovelauthorcategories:%s\\nqidiannovelscore:9.5\\nqidiannovelrecommendtime:57周\\n前言\\n感谢大家来看我的新书，我会努力更新的，请大家支持我！\\n第一章 开场（1）\\n',\n",
       " 'tr-xl-zh36l': '完结感言\\n本书在这里说明一下\\n在这里要说的是，本书的前后两部分，第一部分《天价女友》，是一个非常精彩的故事，它的构思、设定都非常独特，我觉得我是在这部书里受益匪浅，也非常喜欢它，所以想写这样一部故事。\\n这里也要感谢作者编辑“无聊老头”大叔，他对这部小说给予了很多指导，让我有了写作的动力。当然这本书也是因为他给我的灵感，否则我也没有机会创造出这么一个世界，也不能写出这么一个精彩的故事，更不可能成为作家，也不可能在这里有这样的名字和地位。\\n感谢你们，也感谢这部书的每一个读者朋友，是你们支持我，才有今天的我。\\n各位朋友，来日再见！\\n<eod>novelname:\\nnovelcategory:\\nnovelwords:556k\\nnovelstatus:连载中\\n第1章\\n'}"
      ]
     },
     "execution_count": 1006,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(main_input, mems, sample_n):\n",
    "    query_len, batch = main_input.size()\n",
    "    assert batch == 1, str(batch)\n",
    "    if batch != sample_n:\n",
    "        main_input = main_input.expand(query_len, sample_n)\n",
    "        def expand(m):\n",
    "            return m.expand(m.size(0), sample_n, m.size(2))\n",
    "        mems = tuple(expand(i) if type(i) not in [tuple, list] else (expand(i[0]), expand(i[1])) for i in mems)\n",
    "    return main_input, mems\n",
    "\n",
    "def sample_sequence(infer_func, tokenizer, length, text_ids=None,\n",
    "                    temperature=[1], temperature_lens=[1024], top_k=[0], top_k_lens=[1024], \n",
    "                    top_p=0, punishRate=1.2, device='cuda', sample=True,\n",
    "                    tgt_len=512, repeat=3, logger=None, debug=False):\n",
    "    output = text_ids\n",
    "    unk = tokenizer.unk()\n",
    "    mems = tuple()\n",
    "    input_size = text_ids.size(0)\n",
    "    if input_size > tgt_len:\n",
    "        chunk_input = torch.split(text_ids, tgt_len, dim=0)\n",
    "        text_ids = chunk_input[-1]\n",
    "        with torch.no_grad():\n",
    "            for input_ in chunk_input[:-1]:\n",
    "                ret = infer_func(input_, *mems)\n",
    "                mems = ret[1:]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        cur_temperature = temperature[0]\n",
    "        cur_temperature_lens = temperature_lens[0]\n",
    "        cur_index = 0\n",
    "\n",
    "        top_k_index = 0\n",
    "        cur_top_k = top_k[0]\n",
    "        cur_top_k_lens = top_k_lens[0]\n",
    "\n",
    "        binputs, bmems = sample_batch(text_ids, mems, repeat) # binputs.size: qlen, batch_size\n",
    "        penalized_so_fars = [[] for i in range(repeat)]  # XD [list(tokenizer.convert_text_to_ids('-1')) for i in range(repeat)]\n",
    "        output = output.expand(-1, repeat) # XD output.repeat(1, repeat)\n",
    "\n",
    "        if debug == True:\n",
    "            # Set the random seed manually for reproducibility.\n",
    "            np.random.seed(0)\n",
    "            torch.manual_seed(0)\n",
    "            random.seed(0)\n",
    "            torch.cuda.manual_seed(0)\n",
    "            torch.cuda.manual_seed_all(0)\n",
    "\n",
    "        for i in range(length):\n",
    "            ret = infer_func(binputs, *bmems)\n",
    "            logits, bmems = ret[0], ret[1:]\n",
    "\n",
    "            if i >= cur_temperature_lens and cur_index < len(temperature_lens) - 1:\n",
    "                cur_index += 1\n",
    "                cur_temperature = temperature[cur_index]\n",
    "                cur_temperature_lens = temperature_lens[cur_index]\n",
    "\n",
    "            logits = logits[-1, :, :] / cur_temperature if i < cur_temperature_lens else logits[-1, :, :]\n",
    "            logits[:, unk] = -float(\"inf\") # size: batch, vocab_size\n",
    "            if punishRate != 1.0:\n",
    "                for b_ind in range(repeat):\n",
    "                    if i == 0:\n",
    "                        pre_tokens = output[:, b_ind].tolist()\n",
    "                        for pre_token in pre_tokens:\n",
    "                            if pre_token not in penalized_so_fars[b_ind]:\n",
    "                                penalized_so_fars[b_ind].append(pre_token)\n",
    "                        logits[b_ind, penalized_so_fars[b_ind]] /= punishRate\n",
    "                    else:\n",
    "                        pre_tokens = output[-1:, b_ind].tolist()\n",
    "                        for pre_token in pre_tokens:\n",
    "                            if pre_token not in penalized_so_fars[b_ind]:\n",
    "                                penalized_so_fars[b_ind].append(pre_token)\n",
    "                        logits[b_ind, penalized_so_fars[b_ind]] /= punishRate\n",
    "\n",
    "            if i >= cur_top_k_lens and top_k_index < len(top_k) - 1:\n",
    "                top_k_index += 1\n",
    "                cur_top_k = top_k[top_k_index]\n",
    "                cur_top_k_lens = top_k_lens[top_k_index]\n",
    "            logits = top_k_logits(logits, k=cur_top_k) if i < cur_top_k_lens else top_k_logits(logits, k=1)\n",
    "            if top_p > 0:\n",
    "                logits = top_p_logits(logits, top_p, device=output.device)\n",
    "            log_probs = F.softmax(logits, dim=-1)\n",
    "            if sample:\n",
    "                prev = torch.multinomial(log_probs, num_samples=1)\n",
    "#                 print(log_probs, log_probs.size())\n",
    "#                 print(prev, prev.size())\n",
    "            else:\n",
    "                _, prev = torch.topk(log_probs, k=1, dim=-1)\n",
    "            binputs = prev.T\n",
    "            output = torch.cat((output, prev.T), dim=0)\n",
    "        result = [output[:, b_ind].tolist() for b_ind in range(repeat)]\n",
    "    return result\n",
    "\n",
    "def top_p_logits(logits, top_p, threshold=-float('Inf'), filter_value=-float(\"inf\"), device=None):\n",
    "    assert top_p > 0\n",
    "    # Compute cumulative probabilities of sorted tokens\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "    cumulative_probabilities = torch.cumsum(\n",
    "        F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "    # Remove tokens with cumulative probability above the threshold\n",
    "    sorted_indices_to_remove = cumulative_probabilities > top_p\n",
    "    # Shift the indices to the right to keep also the first token above the threshold\n",
    "    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :\n",
    "                                                                 -1].clone()\n",
    "    sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "    batch, vlen = logits.size()\n",
    "    dim_shift = torch.arange(0, batch * vlen, vlen).unsqueeze(1).to(device)\n",
    "    shift_sorted_indices = sorted_indices + dim_shift\n",
    "\n",
    "    # Back to unsorted indices and set them to -infinity\n",
    "    indices_to_remove = shift_sorted_indices[sorted_indices_to_remove]\n",
    "    logits = logits.view(-1)\n",
    "    logits[indices_to_remove] = filter_value\n",
    "    logits = logits.view(batch, vlen)\n",
    "\n",
    "    indices_to_remove = logits < threshold\n",
    "    logits[indices_to_remove] = filter_value\n",
    "    return logits\n",
    "\n",
    "def top_k_logits(logits, k):\n",
    "    if k == 0:\n",
    "        return logits\n",
    "    else:\n",
    "        values = torch.topk(logits, k)[0]\n",
    "        batch_mins = values[:, -1].view(-1, 1).expand_as(logits)\n",
    "        return torch.where(logits < batch_mins, torch.ones_like(logits) * -1e10, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.h = []\n",
    "with torch.no_grad():\n",
    "    outputs = infer(model)(input_ids.t().to(model.device), *tuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, tensor(5.5987), tensor(7.6025)),\n",
       " (1, tensor(10.2144), tensor(5.7188)),\n",
       " (2, tensor(14.6231), tensor(8.1893)),\n",
       " (3, tensor(21.4703), tensor(7.4709)),\n",
       " (4, tensor(27.7487), tensor(6.4097)),\n",
       " (5, tensor(32.8273), tensor(4.8736)),\n",
       " (6, tensor(35.6842), tensor(5.7815)),\n",
       " (7, tensor(39.4510), tensor(7.1989)),\n",
       " (8, tensor(44.4999), tensor(8.8033)),\n",
       " (9, tensor(50.7340), tensor(7.2952)),\n",
       " (10, tensor(55.4423), tensor(7.9693)),\n",
       " (11, tensor(61.0670), tensor(6.7234)),\n",
       " (12, tensor(64.6895), tensor(7.1054)),\n",
       " (13, tensor(68.1650), tensor(7.0033)),\n",
       " (14, tensor(71.3439), tensor(8.0297)),\n",
       " (15, tensor(75.5502), tensor(7.7979)),\n",
       " (16, tensor(79.1198), tensor(8.3848)),\n",
       " (17, tensor(82.9650), tensor(8.8104)),\n",
       " (18, tensor(87.1567), tensor(8.9794)),\n",
       " (19, tensor(90.9538), tensor(10.2715)),\n",
       " (20, tensor(96.1590), tensor(12.2447)),\n",
       " (21, tensor(101.4405), tensor(14.7695)),\n",
       " (22, tensor(107.2525), tensor(16.8721)),\n",
       " (23, tensor(114.7952), tensor(19.2625)),\n",
       " (24, tensor(124.3836), tensor(18.6267)),\n",
       " (25, tensor(134.4390), tensor(21.6349)),\n",
       " (26, tensor(146.7338), tensor(32.8655)),\n",
       " (27, tensor(162.3308), tensor(89.0248)),\n",
       " (28, tensor(210.1942), tensor(151.4546)),\n",
       " (29, tensor(331.1592), tensor(133.4239)),\n",
       " (30, tensor(453.0885), tensor(439.7865)),\n",
       " (31, tensor(872.8109), tensor(119.9196))]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = model.h\n",
    "[(i, h[i].std(), (h[i + 1] - h[i]).std()) for i in range(len(h) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids.to(model.device), output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, tensor(0.0380), tensor(0.5697)),\n",
       " (1, tensor(0.5732), tensor(0.5271)),\n",
       " (2, tensor(1.0049), tensor(0.4064)),\n",
       " (3, tensor(1.3114), tensor(0.3322)),\n",
       " (4, tensor(1.5061), tensor(0.3446)),\n",
       " (5, tensor(1.6678), tensor(0.3630)),\n",
       " (6, tensor(1.8270), tensor(0.3725)),\n",
       " (7, tensor(1.9951), tensor(0.5527)),\n",
       " (8, tensor(2.2182), tensor(0.7076)),\n",
       " (9, tensor(2.5876), tensor(0.6395)),\n",
       " (10, tensor(2.9889), tensor(0.5948)),\n",
       " (11, tensor(3.3889), tensor(0.5656)),\n",
       " (12, tensor(3.7718), tensor(0.5275)),\n",
       " (13, tensor(4.1098), tensor(0.4977)),\n",
       " (14, tensor(4.3973), tensor(0.5121)),\n",
       " (15, tensor(4.6723), tensor(0.4920)),\n",
       " (16, tensor(4.9094), tensor(0.4900)),\n",
       " (17, tensor(5.1064), tensor(0.5056)),\n",
       " (18, tensor(5.2823), tensor(0.5331)),\n",
       " (19, tensor(5.4394), tensor(0.5673)),\n",
       " (20, tensor(5.5810), tensor(0.5723)),\n",
       " (21, tensor(5.7075), tensor(0.5937)),\n",
       " (22, tensor(5.8304), tensor(0.6449)),\n",
       " (23, tensor(5.9800), tensor(0.6563)),\n",
       " (24, tensor(6.1246), tensor(0.7027)),\n",
       " (25, tensor(6.2951), tensor(0.7422)),\n",
       " (26, tensor(6.4853), tensor(0.7824)),\n",
       " (27, tensor(6.6987), tensor(0.8212)),\n",
       " (28, tensor(6.9397), tensor(0.9118)),\n",
       " (29, tensor(7.2397), tensor(0.9675)),\n",
       " (30, tensor(7.5901), tensor(0.9806)),\n",
       " (31, tensor(7.9546), tensor(1.0979)),\n",
       " (32, tensor(8.4184), tensor(1.2165)),\n",
       " (33, tensor(8.9805), tensor(1.3253)),\n",
       " (34, tensor(9.6592), tensor(1.4853)),\n",
       " (35, tensor(10.4951), tensor(1.6307)),\n",
       " (36, tensor(11.4530), tensor(1.6605)),\n",
       " (37, tensor(12.5014), tensor(1.8264)),\n",
       " (38, tensor(13.7129), tensor(1.8641)),\n",
       " (39, tensor(14.9738), tensor(2.0047)),\n",
       " (40, tensor(16.4006), tensor(2.0995)),\n",
       " (41, tensor(17.9080), tensor(2.2261)),\n",
       " (42, tensor(19.5418), tensor(2.3539)),\n",
       " (43, tensor(21.2459), tensor(2.4879)),\n",
       " (44, tensor(22.9823), tensor(3.1982)),\n",
       " (45, tensor(24.8811), tensor(4.3503)),\n",
       " (46, tensor(26.9484), tensor(3.6658)),\n",
       " (47, tensor(28.4784), tensor(28.1606))]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = outputs.hidden_states\n",
    "[(i, h[i].std(), (h[i + 1] - h[i]).std()) for i in range(len(h) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, tensor(0.0747), tensor(7.3432)),\n",
       " (1, tensor(7.3467), tensor(1.9436)),\n",
       " (2, tensor(9.1519), tensor(1.3266)),\n",
       " (3, tensor(9.9043), tensor(8.8011)),\n",
       " (4, tensor(14.3849), tensor(0.7851)),\n",
       " (5, tensor(14.3645), tensor(0.9697)),\n",
       " (6, tensor(14.4759), tensor(1.2821)),\n",
       " (7, tensor(15.1120), tensor(3.6007)),\n",
       " (8, tensor(15.8244), tensor(1.9169)),\n",
       " (9, tensor(16.9650), tensor(1.5871)),\n",
       " (10, tensor(17.5919), tensor(2.1751)),\n",
       " (11, tensor(18.9304), tensor(1.3076)),\n",
       " (12, tensor(19.0266), tensor(1.5120)),\n",
       " (13, tensor(19.7175), tensor(1.7031)),\n",
       " (14, tensor(20.5265), tensor(2.3869)),\n",
       " (15, tensor(21.9366), tensor(2.5495)),\n",
       " (16, tensor(23.2286), tensor(2.2050)),\n",
       " (17, tensor(24.5118), tensor(3.1435)),\n",
       " (18, tensor(26.1887), tensor(3.2419)),\n",
       " (19, tensor(28.4994), tensor(2.5456)),\n",
       " (20, tensor(28.9179), tensor(2.2949)),\n",
       " (21, tensor(29.8167), tensor(3.8301)),\n",
       " (22, tensor(28.4710), tensor(8.3605)),\n",
       " (23, tensor(23.3440), tensor(22.9552))]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = outputs.hidden_states\n",
    "[(i, h[i].std(), (h[i + 1] - h[i]).std()) for i in range(len(h) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filepaths = [\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_hyy/6425-插翅难飞-阿陶陶',\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_hyy/113689-不二之臣-不止是颗菜',\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_hyy/9744-操练吧，教官！-浅问',\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_hyy/117096-表小姐-吱吱',\n",
    "    '/elderberry_shared/69shuba/20210403_69shu_novel_dev1/24523-等你仰望-易修罗',\n",
    "    '/elderberry_shared/69shuba/20210403_69shu_novel_dev1/13012-重生之诱君欢-似是故人来',\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_hyy/16811-盛世之初-梦见稻谷',\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_hyy/31403-沉香如屑-苏寞',\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_hyy/35358-穿越豪门贵妇-仓央央仓',\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_hyy/18204-逆袭之好孕人生[反重生]-盈澈逝雪',\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_hyy/7092-好色婶子-耕田的牛',\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_dev1/64241-撒旦的挚爱逃妻-简简',\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_hyy/55925-总裁，夫人又胎动了-贝小爱',\n",
    "    '/elderberry_shared/69shuba/20210330_69shu_novel_hyy/6428-读者和主角绝逼是真爱-颓',\n",
    "#     '/nas/xd/data/novels/bl_rel_examples/营业悖论.txt',\n",
    "#     '/nas/xd/data/novels/bl_rel_examples/【BL】[现代都市]《针锋对决》作者：水千丞.txt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“We’ve got a problem. And since it may affect your arrival on Daa’Very, Captain Picard felt you should know about it.”\n",
      "\n",
      "At the mention of his homeworld, Morgen’s attention turned up a notch. “I’m listening,” he said.\n",
      "\n",
      "“The Enterprise has run into a subspace phenomenon,” Riker explained. “Something we’ve never encountered before.”\n",
      "\n",
      "“Has it thrown us off course?” the Daa’Vit asked. The first officer shook his head. “No. Our course is\n",
      "\n",
      "unchanged. But the phenomenon has got us traveling at warp factor nine point nine five.”\n",
      "\n",
      "Morgen’s forehead ridged over. “What?”\n",
      "\n",
      "Riker nodded. “I know how it sounds, sir. But it’s the truth.” The Daa’Vit gestured to one of the chairs. “Sit, Commander. Please.”\n",
      "\n",
      "The human conformed to the request. Morgen sat across from him on a rather queer-looking couch-a stone-and-moss affair which had come from ship’s stores. “Now,” the Daa’Vit told him, “say that again.” Riker spread his hands. He went over the whole business, leaving nothing out. After all, it was Morgen’s right to know-not only as the next ruler of his people, but as a captain in Starfleet. And his initial surprise notwithstanding, the Daa’Vit seemed to take it in stride.\n",
      "\n",
      "“You know,” he told Riker, “we had our share of close calls on the Excalibur. Maybe more than our share. Somehow, we always seemed to get out of them.” He smiled as he remembered, the surliness brought on by his confinement forgotten. “After a while, you develop a belief that there’s no problem you can’t solve—no trap from which you can’t devise an escape.” He looked meaningfully at his guest. “Do you know what I mean?” The first officer nodded. “Yes, sir. I do.”\n",
      "\n",
      "“Some might call that kind of confidence a trap in and of itself. And I suppose it could be. But more often, I think it’s an asset. Because if you really believe you’re going to upset the odds, you generally will.” Morgen ran his palm over a clump of moss on the couch, studied it. “I really believe we’re going to get out of this, Riker.” He raised his head, fixing the human with his yellow eyes. “How about you?”\n",
      "\n",
      "“And that,” said Troi, “is our predicament as I understand it.” The rec cabin was empty but for the six of them—Troi herself, Ben Zoma, Cadwallader, Joseph, Greyhorse, and Asmund. The ship’s counselor looked from face to face. “Questions?” “I take it Simenon is already involved in solving the problem,” said Greyhorse, his voice implying criticism of the idea—which was usually the case when he was talking about the Gnalish. “That is correct,” Troi told him. “He is working closely with Geordi La Forge.”\n",
      "\n",
      "The doctor added, “Much to Commander La Forge’s delight, no doubt.” That drew a murmur of laughter; even the empath had to chuckle. Only Asmund, who sat in the back of the room apart from the others, seemed less than entertained by the remark. “And Morgen?” asked Cadwallader.\n",
      "\n",
      "“Commander Riker is discussing this with him separately. After all, there are political ramifications to his late arrival which will have to be dealt with.”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 2048)\n",
       "    (wpe): Embedding(2048, 2048)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoLocalSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = models['EleutherAI/gpt-neo-2.7B'][0].to('cuda:2')\n",
    "_ = models['EleutherAI/gpt-neo-1.3B'][0].to('cuda:1')\n",
    "_ = models['gpt2-xl'][0].to('cuda:0')\n",
    "_ = models['Transformer-XL-1.1B'][0].to('cuda:1')\n",
    "models['Transformer-XL-1.1B'][0].device = torch.device('cuda:1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
