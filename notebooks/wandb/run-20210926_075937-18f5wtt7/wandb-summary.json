{
    "_timestamp": 1632643542.5174541,
    "train/global_step": 16,
    "train/learning_rate": 0.001,
    "_step": 8,
    "train/epoch": 4.0,
    "_runtime": 384.5627362728119,
    "train/loss": 0.9004,
    "eval/runtime": 1.7052,
    "eval/samples_per_second": 37.532,
    "eval/loss": 0.950279951095581,
    "train/train_runtime": 22.0279,
    "train/total_flos": 213809957437440.0,
    "train/train_samples_per_second": 0.726,
    "graph_0": {
        "_type": "graph",
        "format": "torch",
        "nodes": [
            {
                "name": "transformer",
                "id": 140199275915536,
                "class_name": "GPTNeoModel(\n  (wte): WrappedEmbedding(\n    (prompt_embedding): Embedding(10000, 2560)\n  )\n  (wpe): Embedding(2048, 2560)\n  (drop): Dropout(p=0, inplace=False)\n  (h): ModuleList(\n    (0): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (1): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (2): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (3): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (4): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (5): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (6): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (7): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (8): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (9): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (10): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (11): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (12): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (13): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (14): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (15): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (16): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (17): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (18): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (19): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (20): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (21): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (22): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (23): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (24): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (25): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (26): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (27): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (28): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (29): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (30): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n    (31): GPTNeoBlock(\n      (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (attn): GPTNeoAttention(\n        (attention): GPTNeoLocalSelfAttention(\n          (attn_dropout): Dropout(p=0, inplace=False)\n          (resid_dropout): Dropout(p=0, inplace=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n        )\n      )\n      (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      (mlp): GPTNeoMLP(\n        (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n        (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n        (dropout): Dropout(p=0, inplace=False)\n      )\n    )\n  )\n  (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n)",
                "parameters": [
                    [
                        "wte.prompt_embedding.weight",
                        [
                            10000,
                            2560
                        ]
                    ],
                    [
                        "wpe.weight",
                        [
                            2048,
                            2560
                        ]
                    ],
                    [
                        "h.0.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.0.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.0.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.0.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.0.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.0.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.0.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.0.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.0.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.0.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.0.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.0.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.0.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.1.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.1.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.1.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.1.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.1.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.1.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.1.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.1.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.1.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.1.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.1.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.1.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.1.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.2.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.2.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.2.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.2.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.2.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.2.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.2.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.2.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.2.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.2.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.2.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.2.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.2.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.3.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.3.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.3.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.3.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.3.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.3.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.3.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.3.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.3.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.3.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.3.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.3.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.3.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.4.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.4.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.4.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.4.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.4.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.4.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.4.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.4.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.4.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.4.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.4.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.4.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.4.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.5.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.5.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.5.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.5.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.5.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.5.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.5.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.5.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.5.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.5.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.5.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.5.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.5.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.6.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.6.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.6.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.6.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.6.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.6.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.6.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.6.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.6.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.6.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.6.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.6.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.6.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.7.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.7.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.7.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.7.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.7.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.7.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.7.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.7.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.7.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.7.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.7.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.7.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.7.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.8.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.8.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.8.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.8.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.8.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.8.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.8.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.8.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.8.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.8.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.8.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.8.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.8.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.9.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.9.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.9.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.9.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.9.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.9.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.9.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.9.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.9.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.9.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.9.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.9.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.9.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.10.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.10.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.10.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.10.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.10.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.10.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.10.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.10.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.10.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.10.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.10.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.10.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.10.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.11.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.11.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.11.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.11.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.11.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.11.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.11.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.11.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.11.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.11.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.11.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.11.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.11.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.12.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.12.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.12.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.12.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.12.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.12.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.12.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.12.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.12.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.12.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.12.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.12.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.12.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.13.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.13.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.13.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.13.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.13.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.13.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.13.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.13.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.13.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.13.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.13.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.13.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.13.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.14.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.14.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.14.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.14.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.14.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.14.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.14.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.14.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.14.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.14.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.14.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.14.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.14.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.15.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.15.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.15.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.15.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.15.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.15.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.15.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.15.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.15.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.15.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.15.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.15.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.15.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.16.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.16.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.16.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.16.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.16.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.16.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.16.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.16.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.16.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.16.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.16.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.16.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.16.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.17.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.17.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.17.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.17.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.17.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.17.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.17.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.17.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.17.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.17.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.17.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.17.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.17.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.18.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.18.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.18.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.18.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.18.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.18.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.18.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.18.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.18.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.18.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.18.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.18.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.18.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.19.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.19.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.19.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.19.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.19.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.19.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.19.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.19.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.19.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.19.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.19.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.19.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.19.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.20.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.20.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.20.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.20.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.20.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.20.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.20.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.20.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.20.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.20.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.20.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.20.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.20.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.21.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.21.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.21.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.21.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.21.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.21.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.21.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.21.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.21.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.21.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.21.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.21.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.21.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.22.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.22.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.22.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.22.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.22.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.22.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.22.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.22.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.22.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.22.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.22.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.22.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.22.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.23.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.23.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.23.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.23.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.23.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.23.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.23.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.23.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.23.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.23.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.23.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.23.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.23.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.24.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.24.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.24.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.24.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.24.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.24.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.24.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.24.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.24.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.24.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.24.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.24.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.24.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.25.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.25.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.25.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.25.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.25.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.25.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.25.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.25.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.25.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.25.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.25.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.25.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.25.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.26.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.26.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.26.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.26.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.26.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.26.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.26.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.26.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.26.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.26.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.26.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.26.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.26.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.27.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.27.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.27.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.27.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.27.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.27.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.27.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.27.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.27.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.27.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.27.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.27.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.27.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.28.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.28.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.28.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.28.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.28.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.28.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.28.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.28.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.28.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.28.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.28.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.28.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.28.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.29.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.29.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.29.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.29.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.29.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.29.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.29.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.29.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.29.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.29.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.29.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.29.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.29.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.30.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.30.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.30.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.30.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.30.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.30.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.30.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.30.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.30.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.30.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.30.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.30.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.30.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.31.ln_1.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.31.ln_1.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.31.attn.attention.k_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.31.attn.attention.v_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.31.attn.attention.q_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.31.attn.attention.out_proj.weight",
                        [
                            2560,
                            2560
                        ]
                    ],
                    [
                        "h.31.attn.attention.out_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.31.ln_2.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.31.ln_2.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "h.31.mlp.c_fc.weight",
                        [
                            10240,
                            2560
                        ]
                    ],
                    [
                        "h.31.mlp.c_fc.bias",
                        [
                            10240
                        ]
                    ],
                    [
                        "h.31.mlp.c_proj.weight",
                        [
                            2560,
                            10240
                        ]
                    ],
                    [
                        "h.31.mlp.c_proj.bias",
                        [
                            2560
                        ]
                    ],
                    [
                        "ln_f.weight",
                        [
                            2560
                        ]
                    ],
                    [
                        "ln_f.bias",
                        [
                            2560
                        ]
                    ]
                ],
                "output_shape": [
                    [
                        [
                            [
                                0
                            ],
                            [
                                0
                            ],
                            [
                                0
                            ],
                            [
                                0
                            ],
                            [
                                0
                            ],
                            [
                                0
                            ],
                            [
                                0
                            ],
                            [
                                0
                            ],
                            0,
                            [
                                0
                            ],
                            [
                                0
                            ],
                            0,
                            0,
                            0,
                            0,
                            0,
                            0
                        ],
                        [
                            [
                                0
                            ],
                            0,
                            0,
                            0,
                            0,
                            [
                                0
                            ],
                            0,
                            [
                                0
                            ],
                            0,
                            [
                                0
                            ],
                            0,
                            0,
                            [
                                0
                            ],
                            0,
                            0
                        ]
                    ]
                ],
                "num_parameters": [
                    25600000,
                    5242880,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560,
                    6553600,
                    6553600,
                    6553600,
                    6553600,
                    2560,
                    2560,
                    2560,
                    26214400,
                    10240,
                    26214400,
                    2560,
                    2560,
                    2560
                ]
            },
            {
                "name": "lm_head",
                "id": 140199275916112,
                "class_name": "Linear(in_features=2560, out_features=50257, bias=False)",
                "parameters": [
                    [
                        "weight",
                        [
                            50257,
                            2560
                        ]
                    ]
                ],
                "output_shape": [
                    [
                        16,
                        52,
                        50257
                    ]
                ],
                "num_parameters": [
                    128657920
                ]
            }
        ],
        "edges": []
    }
}
