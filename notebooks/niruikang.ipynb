{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95be2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9551c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file_utils.py: default_cache_path = /home/xd/.cache/huggingface/transformers\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForMaskedLM, RobertaTokenizer, GPT2LMHeadModel, GPT2Tokenizer, GPTNeoForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "db3fa297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 940,   10,  940,   28, 1238, 1367,   10,  940,   28]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "296b6a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer._convert_id_to_token(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "779144b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  16,   10,   16,   28,   17,  220,  198,  362,   10,   22,   28,   24,\n",
       "          220,  198,  513,   10,   18,   28,   21,  220,  198,  604,   10,   20,\n",
       "           28,   24,  220,  198,  513,   10,   22,   28,  940,  220,  198,  362,\n",
       "           10,   23,   28, 1065]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0c9ad6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "#prompt = \"In a shocking finding, scientists discovered a herd of unicorns living in a remote, \" \\\n",
    "#          \"previously unexplored valley, in the Andes Mountains. Even more surprising to the \" \\\n",
    "#          \"researchers was the fact that the unicorns spoke perfect English.\"\n",
    "prompt = \"1+1=2 \\n 2+7=9 \\n 3+3=6 \\n 4+5=9 \\n 4+7=11 \\n 2+5=\"\n",
    "input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.8, max_length=40)\n",
    "gen_text = tokenizer1.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1d7e1a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'EleutherAI has been launched, bringing a new level of personalised communications, collaboration across the industry and access to a unique data set.\\n\\ne-EUI has gone live today and provides real-time information on a growing number of businesses'}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator(\"EleutherAI has\", do_sample=True, min_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3535e3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/config.json\n",
      "In cached_path: output_path = /home/xd/.cache/huggingface/transformers/gpt-neo-2.7B-config.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/pytorch_model.bin\n",
      "In cached_path: output_path = /home/xd/.cache/huggingface/transformers/0839a11efa893f2a554f8f540f904b0db0e5320a2b1612eb02c3fd25471c189a.a144c17634fa6a7823e398888396dd623e204dce9e33c3175afabfbf24bd8f56\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/vocab.json\n",
      "In cached_path: output_path = /home/xd/.cache/huggingface/transformers/d4455fdc7c8e2bcf94a0bfe134b748a93c37ecadb7b8f6b0eb508ffdd433a61e.a1b97b074a5ac71fad0544c8abc1b3581803d73832476184bde6cff06a67b6bb\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/merges.txt\n",
      "In cached_path: output_path = /home/xd/.cache/huggingface/transformers/5660be25091706bde0cfb60f17ae72c7a2aa40223d68954d4d8ffd1fc6995643.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/added_tokens.json\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/special_tokens_map.json\n",
      "In cached_path: output_path = /home/xd/.cache/huggingface/transformers/953b5ce47652cf8b6e945b3570bfa7621164c337e05419b954dbe0a4d16a7480.3ae9ae72462581d20e36bc528e9c47bb30cd671bb21add40ca0b24a0be9fac22\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/tokenizer_config.json\n",
      "In cached_path: output_path = /home/xd/.cache/huggingface/transformers/57ccc3b8af045ea106fffa36bcc8b764e9702b5f4c1f7b3aad70ccfcaa931221.c31b6b7d3225be0c43bc0f8e5d84d03a8b49fdb6b9f6009bbfff1f9cc5ec18bc\n",
      "In cached_path: url_or_filename = https://huggingface.co/EleutherAI/gpt-neo-2.7B/resolve/main/tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "model1 = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")\n",
    "tokenizer1 = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5c77df76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1=2 \\n 2+7=9 \\n 3+3=6 \\n 4+5=9 \\n 4+7=11 \\n 2+5=3'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "77950073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'EleutherAI has been on the market for nearly a decade and is a powerful digital editor that produces the most advanced video and audio editing technology the industry has ever seen. It delivers a world class editing suite that includes, amongst others, 3D Pro'}]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"EleutherAI has\", do_sample=True, min_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ba2e8d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Money is made by those who can see it from\\nthe point of view of the general interest\\n\\nFriday, November 28, 2019\\n\\nA New World Order: A New World Order in 2020\\n\\nNow that the globalist elite and their'}]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Money is\", do_sample=True, min_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5978d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7a4239c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f6b6c8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5691, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "91188f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  4.9714,  -0.4495,  -4.9218,  ..., -11.8880,  -9.5686,  -3.0024],\n",
       "         [ -4.2398,  -7.8103,  -9.7348,  ..., -13.4145, -14.4087,  -9.4264],\n",
       "         [ -5.0132,  -8.4638, -10.0772,  ..., -10.3600, -12.6557, -10.2641],\n",
       "         [  0.8371,  -3.4739,  -7.0565,  ..., -11.1889,  -7.6853,  -5.4216],\n",
       "         [ -7.4059,  -6.9669,  -9.3173,  ..., -17.2867, -11.8878,  -9.2022],\n",
       "         [ -2.5484,  -6.7806, -10.7850,  ..., -20.9872, -16.2743,  -9.2439]]],\n",
       "       grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5194fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1,2,3,4,5,6]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c6673032",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f7ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e80c23b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "012f4235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer._convert_id_to_token(74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "02eae341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def greet(name): \n",
      "        print(\"Hello\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "A function to greet user. Given a user name it should say hello\n",
    "\n",
    "def greet(name): \n",
    "\n",
    "ANSWER:\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "start = input_ids.size(1)\n",
    "\n",
    "out = model.generate(input_ids, do_sample=True,\n",
    "                     max_length=50, num_beams=2, \n",
    "\n",
    "                     early_stopping=True, eos_token_id=tokenizer.eos_token_id,c )\n",
    "\n",
    "print(tokenizer.decode(out[0][start:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "8534dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"China =>  Chine \" \\\n",
    "        \" America => Amérique \" \\\n",
    "        \" Japan =>\"\n",
    "input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.8, max_length=40)\n",
    "gen_text = tokenizer1.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7928fc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China =>  Chine  America => Amérique  Japan => Japon  Mexico => México  Spain => España  France => France  Italy => Italia  Portugal =>'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a6fa9681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"1 + 1 => 2 \\n 2 + 2 => 4 \\n 3 + 5 =>8 \\n 9 + 3 =>\"\n",
    "        \n",
    "input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=26)\n",
    "gen_text = tokenizer1.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "5e9e5003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 + 1 => 2 \\n 2 + 2 => 4 \\n 3 + 5 =>8 \\n 9 + 3 => 12'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "7fdbff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 37, but ``max_length`` is set to 10.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"3 beads make => 1 rope , 6 beads make => 2 rope \" \\\n",
    "        \"3 beads make => 1 rope , 30 beads make => 10 rope\" \\\n",
    "        \"3 beads make => 1 rope , 27 beads make =>\"\n",
    "input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "gen_tokens = model1.generate(input_ids, do_sample=True, temperature=1, max_length=10)\n",
    "gen_text = tokenizer1.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "4b16b8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 beads make => 1 rope, 6 beads make => 2 rope 3 beads make => 1 rope, 30 beads make => 10 rope3 beads make => 1 rope, 27 beads make => 10 rope\\n\\nThe number of beads in a rope is the number of beads in the rope divided by the number of beads in the rope.\\n\\nThe number of beads in a rope is the number of beads in the rope divided by the number of beads in the rope.\\n\\nThe number of beads in'"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "id": "4f206f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 120, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1 2 4 6 3 How many numbers are greater than 3? 2\\n2 5 1 3 How many numbers are greater than 3? 1\\n8 6 4 2 1 How many numbers are greater than 3? 3\\n1 3 5 6 7 How many numbers are greater than 3? 3\\n6 7 8 5 2 1 How many numbers are greater than 3? 4\\n6 4 2 7 0 2 How many numbers are greater than 3? 3\\n6 1 0 2 1 1 How many numbers are greater than 3? 1\\n7 0 3 2 1 How many numbers are greater than 3? 1'"
      ]
     },
     "execution_count": 1112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt = \"3 beads make 3 / 3 = 1 rope \" \\\n",
    "#         \"6 beads make 6 / 3 = 2 rope\" \\\n",
    "#         \"9 beads make 9 / 3 = 3 rope\" \\\n",
    "#         \"12 beads make 12 / 3 = 4 rope\" \\\n",
    "#         \"21 beads make\"\n",
    "input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=30)\n",
    "gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "id": "c8c7a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = '''A F D , A F D H -> H\n",
    "# D G S R , D G E S R -> E\n",
    "# I T U D , I Y T U D ->'''\n",
    "# prompt = '''A B , A F E , B S F , A T U B -> 3\n",
    "#          A B , T K A B , P B L E S , S G H -> 1\n",
    "#          A B , S T B , P T L A S , U T S A B -> 3\n",
    "#          A B , T K Q B , P B L A S , S R T Y -> 2\n",
    "#          A B , T A Q B , P B L T S , S R T Y -> 1\n",
    "#          A B , S T B , P T L A B S , U T S T B -> 2\n",
    "#          A B , S B , P T S , U T S A Y B -> 3\n",
    "#          A B , T R G F J , P A B L , S G G F H -> 2\n",
    "#          A B , T P Q B , P B K A , S R T M -> 2\n",
    "#          A B , A F U T E , B S F G , F T R A U B -> 3\n",
    "#          A B , S T Y B , P T S , A S Y B -> 3\n",
    "#          A B , T A B Q , P A S E , S R P Y ->'''\n",
    "# prompt = '''A D G S What is the third letter? G\n",
    "# I G C S R What is the third letter? C\n",
    "# R U K H T What is the third letter? K\n",
    "# W I P K S What is the third letter? P\n",
    "# Y A W R S What is the third letter? W\n",
    "# B K D X V What is the third letter? D\n",
    "# M L O A Q What is the third letter? O\n",
    "# I J X L A What is the third letter? X\n",
    "# M L U T S What is the third letter? U\n",
    "# Q R G X R What is the third letter? G\n",
    "# W X A Y T What is the third letter? A\n",
    "# M N B V C What is the third letter? B\n",
    "# U I O A S What is the third letter? O\n",
    "# P W R A Q What is the third letter?'''\n",
    "prompt = '''1 2 4 6 3 How many numbers are greater than 3? 2\n",
    "2 5 1 3 How many numbers are greater than 3? 1\n",
    "8 6 4 2 1 How many numbers are greater than 3? 3\n",
    "1 3 5 6 7 How many numbers are greater than 3? 3\n",
    "6 7 8 5 2 1 How many numbers are greater than 3? 4\n",
    "6 4 2 7 0 2 How many numbers are greater than 3? 3\n",
    "6 1 0 2 1 1 How many numbers are greater than 3? 1\n",
    "7 0 3 2 1 How many numbers are greater than 3? 1\n",
    "7 5 3 2 1 How many numbers are greater than 3?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "id": "7b853b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = '''A A A , B B B Are they equal in number? YES\n",
    "# A A , B B B Are they equal in number? NO\n",
    "# A A A , B Are they equal in number? NO\n",
    "# A A , B B Are they equal in number? YES\n",
    "# A A A A , B Are they equal in number? NO\n",
    "# E E E , G G Are they equal in number? NO\n",
    "# F F F , B B B Are they equal in number? YES\n",
    "# R R R , I I I Are they equal in number?'''\n",
    "# prompt = '''A A A B B What is the largest number of letters? A\n",
    "# A A B C C C What is the largest number of letters? C\n",
    "# A B B C What is the largest number of letters? B\n",
    "# A B A C C C What is the largest number of letters? C\n",
    "# B B A C C A A G What is the largest number of letters?'''\n",
    "# prompt = '''Which letter is more than F\n",
    "# F F , A B B B -> B\n",
    "# F F , A A C C C -> C\n",
    "# F F , B B B A A C -> B\n",
    "# F F , A A A D C -> A\n",
    "# F , A A B D -> A\n",
    "# F F F , D S A B S S S A D ->'''\n",
    "# # prompt = '''F F , A B B Which number of characters is the same as F? B\n",
    "# F F , A A C C C Which number of characters is the same as F? A\n",
    "# F F , B B B A A C Which number of characters is the same as F? A\n",
    "# F F , A A A D C C Which number of characters is the same as F? C\n",
    "# F , A A B D D Which number of characters is the same as F? B\n",
    "# F F F , D S A B D D S S A D Which number of characters is the same as F? S\n",
    "# F , D D A S S Which number of characters is the same as F? A\n",
    "# F , S A P A P Which number of characters is the same as F? S\n",
    "# F F F , A A D R E A C Which number of characters is the same as F? A\n",
    "# F , A C C C A J G G Which number of characters is the same as F? J\n",
    "# F F, A C C C A A J G G Which number of characters is the same as F?'''\n",
    "# prompt = '''Which one is more?\n",
    "# A B C B , A B -> 1\n",
    "# A C D , B C A D -> 2\n",
    "# A B C C A , A S -> 1\n",
    "# B A , A -> 1\n",
    "# C , A B ->'''\n",
    "# prompt = '''Reverse numbers\n",
    "# 1 2 3 4 5 6 -> 6 5 4 3 2 1\n",
    "# 1 2 3 -> 3 2 1\n",
    "# 1 2 3 4-> 4 3 2 1\n",
    "# 1 3 4 2 -> 2 4 3 1\n",
    "# 1 4 3 -> 3 4 1\n",
    "# 1 5 4 ->'''\n",
    "# prompt = '''Sort\n",
    "# 1 2 4 3 6 5 -> 1 2 3 4 5 6\n",
    "# 1 3 2 -> 1 2 3\n",
    "# 1 4 3 2 5 ->'''\n",
    "# prompt = '''A C B C how many Cs are there? 2\n",
    "# A C B C C how many Cs are there? 3\n",
    "# A C D S how many Cs are there? 1\n",
    "# A C E C C how many Cs are there? 3\n",
    "# A E C C how many Cs are there? 2\n",
    "# A C D C R T A S how many Cs are there? 2\n",
    "# Q C D C C E W C how many Cs are there? 4\n",
    "# E F C S G C W C how many Cs are there? 3\n",
    "# A C D C A E C C how many Cs are there? 4\n",
    "# A W C R S F how many Cs are there? 1\n",
    "# A C B C C A C E how many Cs are there?'''\n",
    "# prompt = '''0 1 2 What is the positional relationship between 0 and 1? left\n",
    "# 1 0 2 What is the positional relationship between 0 and 1? right\n",
    "# 1 2 3 0 What is the positional relationship between 0 and 1? left\n",
    "# 2 0 1 3 What is the positional relationship between 0 and 1? left\n",
    "# 0 2 1 3 What is the positional relationship between 0 and 1? left\n",
    "# 0 9 1 2 What is the positional relationship between 0 and 1? left\n",
    "# 2 1 3 4 0 What is the positional relationship between 0 and 1? right\n",
    "# 2 3 1 4 0 What is the positional relationship between 0 and 1? right\n",
    "# 4 0 5 8 1 What is the positional relationship between 0 and 1?'''\n",
    "# prompt = '''F D S G J What is the location of S? 3\n",
    "# S G D A G What is the location of S? 1\n",
    "# K S A E T What is the location of S? 2\n",
    "# L G R E S What is the location of S? 5\n",
    "# P O A S R What is the location of S? 4\n",
    "# T A F S G What is the location of S? 4\n",
    "# T S D F A What is the location of S? 2\n",
    "# R A S G D What is the location of S? 3\n",
    "# L A Y S W What is the location of S? 4\n",
    "# O C H R Q S What is the location of S? 6\n",
    "# G S N E V D What is the location of S? 2\n",
    "# O C H G S N E What is the location of S?'''\n",
    "# prompt = '''F D S G J What's on the right of S? G\n",
    "# S R D A G What's on the right of S? R\n",
    "# K S A E T What's on the right of S? A\n",
    "# L G R E S H What's on the right of S? H\n",
    "# P O A S R What's on the right of S? R\n",
    "# T A S W G What's on the right of S? W\n",
    "# T S D F A What's on the right of S? D\n",
    "# R A S G D H What's on the right of S? G\n",
    "# S L Y A W What's on the right of S? L\n",
    "# O S C H R Q F J What's on the right of S? C\n",
    "# S L N E V D What's on the right of S?'''\n",
    "# prompt = '''A B S G E What are the second to fourth letters? B S G\n",
    "# A E T W Q What are the second to fourth letters? E T W\n",
    "# K H A F S What are the second to fourth letters? H A F\n",
    "# U Y E A S F What are the second to fourth letters? Y E A\n",
    "# T S R W A What are the second to fourth letters? S R W\n",
    "# I T S A E What are the second to fourth letters? T S A\n",
    "# Y I O A W What are the second to fourth letters?'''\n",
    "# prompt = '''A B G S E What is the letter between G and E? S\n",
    "# A G T E Q What is the letter between G and E? T\n",
    "# K G A F E What is the letter between G and E? A F\n",
    "# G Y S E S F What is the letter between G and E? Y S\n",
    "# G S R E A What is the letter between G and E? S R\n",
    "# I G S A E What is the letter between G and E?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "id": "bcd8a80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 4 6 3 How many numbers are greater than 3? 2\n",
      "2 5 1 3 How many numbers are greater than 3? 1\n",
      "8 6 4 2 1 How many numbers are greater than 3? 3\n",
      "1 3 5 6 7 How many numbers are greater than 3? 3\n",
      "6 7 8 5 2 1 How many numbers are greater than 3? 4\n",
      "6 4 2 7 0 2 How many numbers are greater than 3? 3\n",
      "6 1 0 2 1 1 How many numbers are greater than 3? 1\n",
      "7 0 3 2 1 How many numbers are greater than 3? 1\n",
      "7 5 3 2 1 How many numbers are greater than 3?\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "id": "f173f549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# openai.api_key = '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'\n",
    "openai.api_key = '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'\n",
    "\n",
    "response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a60d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56a0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43768453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f9156d4",
   "metadata": {},
   "source": [
    "# 测试代码！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "56833146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0fe245",
   "metadata": {},
   "source": [
    "#  输出下面两个图中，数量多的那一个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2132,
   "id": "ba7ea8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "    data = np.random.randint(1,5,[1,2])\n",
    "    while(1):\n",
    "        if(data[0][0] == data[0][1]):\n",
    "            data = np.random.randint(1,5,[1,2])\n",
    "        else:\n",
    "            break\n",
    "    n1 = data[0][0] #size of sample\n",
    "    elements = set([\"E\", \"A\", \"M\", \"D\", \"G\"])\n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    \n",
    "    n2 = data[0][1] #size of sample\n",
    "    random_pop2 = [element for i in range(n2) for element in random.sample(elements, 1)]\n",
    "    for i in range(n1):    \n",
    "        list1.append(random_pop1[i]) \n",
    "    list1.append(\"|\")\n",
    "    for i in range(n2):    \n",
    "        list1.append(random_pop2[i]) \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Are the equal in number?\")\n",
    "    \n",
    "    if(data[0][0] > data[0][1]):\n",
    "        list1.append(\"1\")\n",
    "    else:\n",
    "        list1.append(\"2\")\n",
    "    return(list1)\n",
    "\n",
    "def create(n):\n",
    "    list2 = []\n",
    "    function()\n",
    "    \n",
    "    for i in range(1,n,1):\n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "        \n",
    "    list1=[]\n",
    "    data = np.random.randint(1,5,[1,2])\n",
    "    while(1):\n",
    "        if(data[0][0] == data[0][1]):\n",
    "            data = np.random.randint(1,5,[1,2])\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    global n1 , n2\n",
    "    n1 = data[0][0] #size of sample\n",
    "    elements = set([\"E\", \"A\", \"M\", \"D\", \"G\"])\n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    \n",
    "   \n",
    "    n2 = data[0][1] #size of sample\n",
    "    random_pop2 = [element for i in range(n2) for element in random.sample(elements, 1)]\n",
    "    for i in range(n1):    \n",
    "        list1.append(random_pop1[i]) \n",
    "    list1.append(\"|\")\n",
    "    for i in range(n2):    \n",
    "        list1.append(random_pop2[i]) \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Are the equal in number?\")\n",
    "    list2.append(\"\\n\")\n",
    "    list2.extend(list1)\n",
    "    \n",
    "    str = \" \"\n",
    "    prompt = str.join(list2)\n",
    "    return(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2128,
   "id": "03f2513f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'E', 'M', '|', 'A', '.', 'Are the equal in number?', '1']"
      ]
     },
     "execution_count": 2128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2129,
   "id": "ef0c46f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " A | G D A M . Are the equal in number? 2 \n",
      " A G E G | M . Are the equal in number?\n"
     ]
    }
   ],
   "source": [
    "print(create(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2130,
   "id": "609097ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 31, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 48, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 58, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 80, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 98, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 112, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 126, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 140, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 158, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 177, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 192, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 209, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 223, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 237, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 256, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 263, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 283, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 310, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 323, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 328, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 45, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 59, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 81, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 90, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 115, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 126, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 145, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 159, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 167, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 191, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 202, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 219, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 240, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 254, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 273, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 288, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 297, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 319, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 333, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 32, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 49, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 62, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 77, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 97, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 106, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 130, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 142, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 161, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 173, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 196, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 207, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 218, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 240, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 256, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 270, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 277, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 300, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 324, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 347, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 30, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 48, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 61, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 80, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 93, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 108, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 119, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 142, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 154, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 177, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 185, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 205, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 221, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 244, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 258, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 263, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 285, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 310, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 309, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 322, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 50, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 63, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 79, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 98, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 115, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 126, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 144, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 157, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 170, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 189, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 208, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 222, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 226, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 251, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 276, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 278, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 301, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 325, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 328, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 31, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 48, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 61, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 82, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 90, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 112, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 122, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 140, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 156, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 167, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 196, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 208, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 219, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 240, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 247, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 269, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 283, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 300, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 323, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 330, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 43, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 61, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 81, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 90, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 120, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 127, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 136, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 151, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 178, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 193, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 205, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 214, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 229, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 257, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 269, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 290, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 306, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 317, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 333, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 31, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 48, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 62, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 76, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 96, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 108, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 132, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 137, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 166, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 185, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 194, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 203, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 217, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 234, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 257, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 269, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 281, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 308, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 327, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 328, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 31, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 44, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 62, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 79, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 91, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 103, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 124, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 143, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 163, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 173, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 187, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 201, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 219, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 240, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 252, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 264, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 288, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 312, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 318, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 341, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 31, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 48, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 59, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 77, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 96, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 104, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 124, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 138, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 161, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 185, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 182, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 210, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 224, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 237, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 252, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 271, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 285, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 300, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 319, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 332, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "992"
      ]
     },
     "execution_count": 2130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 2130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=30)\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        x = gen_text[number-1]\n",
    "        \n",
    "        if(n1 > n2):\n",
    "            ans = \"1\"\n",
    "        else:\n",
    "            ans = \"2\"\n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "#        print(ans,x)\n",
    "\n",
    "fo = open(\"foo.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2131,
   "id": "4e6bf9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " M | G E . Are the equal in number? 2 \n",
      " E D D A | A A . Are the equal in number? 1 \n",
      " M | D M A M . Are the equal in number? 2 \n",
      " D D | M G E G . Are the equal in number? 2 \n",
      " D | A G M . Are the equal in number? 2 \n",
      " M E | A . Are the equal in number? 1 \n",
      " G A D | A . Are the equal in number? 1 \n",
      " A | D D . Are the equal in number? 2 \n",
      " E | G A . Are the equal in number? 2 \n",
      " M G D | A A A G . Are the equal in number? 2 \n",
      " D M G G | A A . Are the equal in number? 1 \n",
      " D D | G . Are the equal in number? 1 \n",
      " A D D | A A . Are the equal in number? 1 \n",
      " A A | A D M A . Are the equal in number? 2 \n",
      " A | A M E A . Are the equal in number? 2 \n",
      " G G | E D G M . Are the equal in number? 2 \n",
      " A G G G | D . Are the equal in number? 1 \n",
      " A G D G | E M D . Are the equal in number? 1 \n",
      " D D M | E . Are the equal in number? 1 \n",
      " G E M G | A . Are the equal in number? 1 \n",
      " E G D | A M M M . Are the equal in number?\n",
      " Correct: [4. 5. 9. 5. 7. 8. 9. 6. 4. 8. 8. 6. 8. 6. 7. 6. 6. 4. 6. 7.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "id": "fdfada33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 432, 4)"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd2c632daf0>"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 431.5, 287.5, -0.5)"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "lena = mpimg.imread('temp.png')\n",
    "lena.shape\n",
    "plt.imshow(lena)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2133,
   "id": "7a2ca0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986"
      ]
     },
     "execution_count": 2133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 2133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAASWklEQVR4nO3df5Dc933X8eerckVn0pA46ChB0kVKEQUBpTGHHGgJGeIE2WakQkNHGn7YNK0mQ1XSphSUSUfjEf84yZDOlBFQtfU0ZJrKbqDlwBeU0IZhYOogJXWcyKrsi1AriTR2EpPAdKij9s0f+1Vnu97Tffe0e3f69PmY2bnv5/t9737f+n6/+9Le93u7m6pCktSmr9voBiRJs2PIS1LDDHlJapghL0kNM+QlqWF3bNSKt23bVrt27dqo1UvSbemTn/zkF6tqrm/9hoX8rl27OHfu3EatXpJuS0l+fZJ6T9dIUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhvUK+ST7k1xMspzk2Jjl80k+nuRXkzyV5L7ptypJmtSqIZ9kC3ASuBfYCxxOsnek7EeBx6rqdcAh4F9Ou1FJ0uT6vJLfByxX1aWqehE4DRwcqSngD3fTrwD+1/RalCStVZ93vG4HrgyNrwJ3j9Q8BHw0yQ8ALwPuGfdASY4ARwDm5+cn7VW3YNexxyeqv/zw/U2s+1bcrn1vpD+Ix9mk653muvuY1oXXw8DPVNUO4D7gg0le8thVdaqqFqpqYW6u90cvSJLWqE/IXwN2Do13dPOGvQ14DKCqfgX4BmDbNBqUJK1dn5A/C+xJsjvJVgYXVhdHan4DeBNAkj/NIOSfn2ajkqTJrRryVXUdOAqcAS4w+Cua80lOJDnQlf0w8H1JPg38HPBg+Q3hkrThen3UcFUtAUsj844PTT8NfPt0W5Mk3Srf8SpJDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJalivkE+yP8nFJMtJjo1Z/mNJnuxuzyT531PvVJI0sVW/GSrJFuAk8GbgKnA2yWL3bVAAVNUPDdX/APC6GfQqSZpQn1fy+4DlqrpUVS8Cp4GDN6k/zOB7XiVJG6xPyG8HrgyNr3bzXiLJa4DdwC/femuSpFvV64u8J3AI+HBV/c64hUmOAEcA5ufn17ySXccen/g+lx++f83r0+TbfLNs79u1b2la+rySvwbsHBrv6OaNc4ibnKqpqlNVtVBVC3Nzc/27lCStSZ+QPwvsSbI7yVYGQb44WpTkTwF3Ar8y3RYlSWu1ashX1XXgKHAGuAA8VlXnk5xIcmCo9BBwuqpqNq1KkibV65x8VS0BSyPzjo+MH5peW5KkafAdr5LUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktSwXiGfZH+Si0mWkxxboea7kzyd5HySD023TUnSWqz69X9JtgAngTcDV4GzSRar6umhmj3Au4Bvr6oXkvzRWTUsSeqvzyv5fcByVV2qqheB08DBkZrvA05W1QsAVfXcdNuUJK1Fny/y3g5cGRpfBe4eqfmTAEn+O7AFeKiq/tPoAyU5AhwBmJ+fX0u/G27Xsccnqr/88P1rvu+t3n/4vlpfG7mvPU40bFoXXu8A9gBvBA4DP5nklaNFVXWqqhaqamFubm5Kq5YkraRPyF8Ddg6Nd3Tzhl0FFqvqa1X1P4FnGIS+JGkD9Qn5s8CeJLuTbAUOAYsjNb/I4FU8SbYxOH1zaXptSpLWYtWQr6rrwFHgDHABeKyqzic5keRAV3YG+FKSp4GPAz9SVV+aVdOSpH76XHilqpaApZF5x4emC3hnd5MkbRK+41WSGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIa1ivkk+xPcjHJcpJjY5Y/mOT5JE92t++dfquSpEmt+vV/SbYAJ4E3A1eBs0kWq+rpkdJHq+roDHqUJK1Rn1fy+4DlqrpUVS8Cp4GDs21LkjQNfb7IeztwZWh8Fbh7TN13JXkD8AzwQ1V1ZbQgyRHgCMD8/Pzk3UqaqV3HHp/4Ppcfvn8GnayvSf/dt9O/eVoXXv8DsKuqvhX4GPCBcUVVdaqqFqpqYW5ubkqrliStpE/IXwN2Do13dPN+T1V9qap+uxv+FPAXptOeJOlW9An5s8CeJLuTbAUOAYvDBUlePTQ8AFyYXouSpLVa9Zx8VV1PchQ4A2wBHqmq80lOAOeqahH4R0kOANeBLwMPzrBnSVJPfS68UlVLwNLIvOND0+8C3jXd1iRJt8p3vEpSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDeoV8kv1JLiZZTnLsJnXflaSSLEyvRUnSWq0a8km2ACeBe4G9wOEke8fUvRx4B/CJaTcpSVqbPq/k9wHLVXWpql4ETgMHx9T9M+A9wP+bYn+SpFvQ54u8twNXhsZXgbuHC5LcBeysqseT/MhKD5TkCHAEYH5+fvJup2TXsccnqr/88P0z6kSrmXRfgfvrduW+no1bvvCa5OuA9wM/vFptVZ2qqoWqWpibm7vVVUuSVtEn5K8BO4fGO7p5N7wc+LPAf0lyGXg9sOjFV0naeH1C/iywJ8nuJFuBQ8DijYVV9ZWq2lZVu6pqF/AEcKCqzs2kY0lSb6uGfFVdB44CZ4ALwGNVdT7JiSQHZt2gJGnt+lx4paqWgKWRecdXqH3jrbclSZoG3/EqSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDesV8kn2J7mYZDnJsTHL357kM0meTPLfkuydfquSpEmtGvJJtgAngXuBvcDhMSH+oar6c1X1bcB7gfdPu1FJ0uT6vJLfByxX1aWqehE4DRwcLqiqrw4NXwbU9FqUJK1Vny/y3g5cGRpfBe4eLUry/cA7ga3AXxv3QEmOAEcA5ufnJ+1VkjShqV14raqTVfXNwD8FfnSFmlNVtVBVC3Nzc9NatSRpBX1C/hqwc2i8o5u3ktPAd95CT5KkKekT8meBPUl2J9kKHAIWhwuS7Bka3g88O70WJUlrteo5+aq6nuQocAbYAjxSVeeTnADOVdUicDTJPcDXgBeAB2bZtCSpnz4XXqmqJWBpZN7xoel3TLkvSdIU+I5XSWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJalivkE+yP8nFJMtJjo1Z/s4kTyd5KskvJXnN9FuVJE1q1ZBPsgU4CdwL7AUOJ9k7UvarwEJVfSvwYeC9025UkjS5Pq/k9wHLVXWpql4ETgMHhwuq6uNV9Vvd8Algx3TblCStRZ+Q3w5cGRpf7eat5G3AR8YtSHIkybkk555//vn+XUqS1mSqF16T/F1gAXjfuOVVdaqqFqpqYW5ubpqrliSNcUePmmvAzqHxjm7e75PkHuDdwF+tqt+eTnuSpFvR55X8WWBPkt1JtgKHgMXhgiSvA34COFBVz02/TUnSWqwa8lV1HTgKnAEuAI9V1fkkJ5Ic6MreB3wj8PNJnkyyuMLDSZLWUZ/TNVTVErA0Mu/40PQ9U+5LkjQFvuNVkhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGtYr5JPsT3IxyXKSY2OWvyHJp5JcT/LW6bcpSVqLVUM+yRbgJHAvsBc4nGTvSNlvAA8CH5p2g5KktevzHa/7gOWqugSQ5DRwEHj6RkFVXe6W/e4MepQkrVGf0zXbgStD46vdvIklOZLkXJJzzz///FoeQpI0gXW98FpVp6pqoaoW5ubm1nPVkvQHUp+QvwbsHBrv6OZJkja5PiF/FtiTZHeSrcAhYHG2bUmSpmHVkK+q68BR4AxwAXisqs4nOZHkAECSv5jkKvC3gZ9Icn6WTUuS+unz1zVU1RKwNDLv+ND0WQancSRJm4jveJWkhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SG9Qr5JPuTXEyynOTYmOV/KMmj3fJPJNk19U4lSRNbNeSTbAFOAvcCe4HDSfaOlL0NeKGq/gTwY8B7pt2oJGlyfV7J7wOWq+pSVb0InAYOjtQcBD7QTX8YeFOSTK9NSdJapKpuXpC8FdhfVd/bjf8ecHdVHR2q+WxXc7Ubf66r+eLIYx0BjnTDbwEuTusf0tkGfHHVqo2xWXvbrH3B5u1ts/YFm7c3+5rcSr29pqrm+j7IHdPrZ3VVdQo4NavHT3KuqhZm9fi3YrP2tln7gs3b22btCzZvb/Y1uWn11ud0zTVg59B4RzdvbE2SO4BXAF+61eYkSbemT8ifBfYk2Z1kK3AIWBypWQQe6KbfCvxyrXYeSJI0c6uerqmq60mOAmeALcAjVXU+yQngXFUtAj8NfDDJMvBlBv8RbISZnQqags3a22btCzZvb5u1L9i8vdnX5KbS26oXXiVJty/f8SpJDTPkJalht2XIb9aPWUiyM8nHkzyd5HySd4ypeWOSryR5srsdX6feLif5TLfOc2OWJ8mPd9vsqSR3rVNf3zK0LZ5M8tUkPzhSsy7bLMkjSZ7r3vdxY96rknwsybPdzztXuO8DXc2zSR4YVzOD3t6X5Ne6/fULSV65wn1vuu9n0NdDSa4N7a/7VrjvTZ/HM+jr0aGeLid5coX7zmx7dY8/NidmdqxV1W11Y3Dx93PAa4GtwKeBvSM1/xD41930IeDRdert1cBd3fTLgWfG9PZG4D9uwHa7DGy7yfL7gI8AAV4PfGKD9u1vMnizx7pvM+ANwF3AZ4fmvRc41k0fA94z5n6vAi51P+/spu9ch97eAtzRTb9nXG999v0M+noI+Mc99vVNn8fT7mtk+T8Hjq/39uoef2xOzOpYux1fyW/aj1moqs9X1ae66f8DXAC2z3q9U3IQ+Dc18ATwyiSvXuce3gR8rqp+fZ3XC0BV/VcGfx02bPhY+gDwnWPu+teBj1XVl6vqBeBjwP5Z91ZVH62q693wCQbvYVlXK2yzPvo8j2fSV5cF3w383LTWN4mb5MRMjrXbMeS3A1eGxld5aZD+Xk33JPgK8EfWpbtOd4rodcAnxiz+S0k+neQjSf7MOrVUwEeTfDKDj5cY1We7ztohVn7ibcQ2A/imqvp8N/2bwDeNqdkM2+57GPwmNs5q+34WjnankR5Z4bTDRm6zvwJ8oaqeXWH5um2vkZyYybF2O4b8ppfkG4F/C/xgVX11ZPGnGJyO+PPAvwB+cZ3a+o6quovBp4l+f5I3rNN6e8ngjXYHgJ8fs3ijttnvU4Pflzfd3xwneTdwHfjZFUrWe9//K+CbgW8DPs/g1Mhmcpibv4pfl+11s5yY5rF2O4b8pv6YhSRfz2DH/WxV/bvR5VX11ar6v930EvD1SbbNuq+qutb9fA74BQa/Lg/rs11n6V7gU1X1hdEFG7XNOl+4cdqq+/ncmJoN23ZJHgT+BvB3umB4iR77fqqq6gtV9TtV9bvAT66wvg3ZZl0e/C3g0ZVq1mN7rZATMznWbseQ37Qfs9Cd6/tp4EJVvX+Fmj924/pAkn0M9sFM/wNK8rIkL78xzeCC3WdHyhaBv5+B1wNfGfrVcT2s+OpqI7bZkOFj6QHg34+pOQO8Jcmd3amJt3TzZirJfuCfAAeq6rdWqOmz76fd1/C1nL+5wvr6PI9n4R7g16r7xNxR67G9bpITsznWZnUFeZY3Bn8J8gyDq/Pv7uadYHCwA3wDg1/7l4H/Abx2nfr6Dga/Yj0FPNnd7gPeDry9qzkKnGfw1wRPAH95Hfp6bbe+T3frvrHNhvsKgy+H+RzwGWBhHffnyxiE9iuG5q37NmPwn8znga8xONf5NgbXcn4JeBb4z8CrutoF4KeG7vs93fG2DPyDdeptmcH52RvH2o2/KPvjwNLN9v2M+/pgdww9xSC4Xj3aVzd+yfN4ln1183/mxnE1VLtu26tbx0o5MZNjzY81kKSG3Y6nayRJPRnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWH/H/z5CK63JmqPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "\n",
    "        #print(response.choices[0].text)\n",
    "        #number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            else:\n",
    "                x = response.choices[0].text[i]\n",
    "        \n",
    "        if(n1 > n2):\n",
    "            ans = \"1\"\n",
    "        else:\n",
    "            ans = \"2\"\n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "#        print(ans,x)\n",
    "\n",
    "fo = open(\"foo_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2014,
   "id": "cc6dbfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " G M G G | E D . Which one is more? 1 \n",
      " M E A M | D E D . Which one is more? 1 \n",
      " D M E A | G D . Which one is more? 1 \n",
      " D D M | M . Which one is more? 1 \n",
      " M A | M . Which one is more? 1 \n",
      " A G | G D D E . Which one is more? 2 \n",
      " G D G A | M D . Which one is more? 1 \n",
      " E | D E A . Which one is more? 2 \n",
      " M D E D | D A . Which one is more? 1 \n",
      " D M E E | A D . Which one is more? 1 \n",
      " G | G D A . Which one is more? 2 \n",
      " G M M | A D M G . Which one is more? 2 \n",
      " D E | M E D M . Which one is more? 2 \n",
      " A A E | M M D A . Which one is more? 2 \n",
      " E G | A A M D . Which one is more? 2 \n",
      " D | M D . Which one is more? 2 \n",
      " M G | G M D M . Which one is more? 2 \n",
      " M A | E . Which one is more? 1 \n",
      " D A D D | A D D . Which one is more? 1 \n",
      " D E G | E M . Which one is more? 1 \n",
      " D A D | G G . Which one is more?\n",
      " Correct: [3. 5. 6. 8. 6. 7. 8. 4. 7. 7. 9. 5. 8. 6. 8. 8. 9. 5. 6. 7.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2134,
   "id": "3c4625c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " M E | E M M E . Are the equal in number? 2 \n",
      " M M | M E A A . Are the equal in number? 2 \n",
      " E | G A . Are the equal in number? 2 \n",
      " M E | M E D E . Are the equal in number? 2 \n",
      " E G E M | G . Are the equal in number? 1 \n",
      " G A | A . Are the equal in number? 1 \n",
      " D E | G M G E . Are the equal in number? 2 \n",
      " M E A | D E M E . Are the equal in number? 2 \n",
      " M A D M | D G . Are the equal in number? 1 \n",
      " D D | D . Are the equal in number? 1 \n",
      " M M | D A E . Are the equal in number? 2 \n",
      " E E | D A M . Are the equal in number? 2 \n",
      " E | D D . Are the equal in number? 2 \n",
      " G G A | E . Are the equal in number? 1 \n",
      " D E G | D . Are the equal in number? 1 \n",
      " M | A D A A . Are the equal in number? 2 \n",
      " E E | D E G E . Are the equal in number? 2 \n",
      " A G | G M G . Are the equal in number? 2 \n",
      " D E D M | G G . Are the equal in number? 1 \n",
      " A | G D . Are the equal in number? 2 \n",
      " D | M M . Are the equal in number?\n",
      " Correct: [7. 4. 6. 6. 6. 8. 7. 8. 4. 7. 8. 6. 6. 6. 5. 8. 4. 8. 5. 8.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "4b6dd932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " D | M D A D . Which one is more? 2 \n",
      " M G | D . Which one is more? 1 \n",
      " G G A G | E E . Which one is more? 1 \n",
      " G G D E | A D . Which one is more?\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "f6e9305a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "32391d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(response.choices[0].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd624d",
   "metadata": {},
   "source": [
    "# 2.1、判断数量是否相等："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "1619b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "    data = np.random.randint(1,5,[1,2])\n",
    "    n1 = data[0][0] #size of sample\n",
    "    elements = set([\"E\", \"A\", \"M\", \"D\", \"G\"])\n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    \n",
    "    n2 = data[0][1] #size of sample\n",
    "    random_pop2 = [element for i in range(n2) for element in random.sample(elements, 1)]\n",
    "    for i in range(n1):    \n",
    "        list1.append(random_pop1[i]) \n",
    "    list1.append(\"|\")\n",
    "    for i in range(n2):    \n",
    "        list1.append(random_pop2[i]) \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Are they equal in number?\")\n",
    "    if(data[0][0] == data[0][1]):\n",
    "        list1.append(\"Yes\")\n",
    "    else:\n",
    "        list1.append(\"No\")\n",
    "    return(list1)\n",
    "\n",
    "def create(n):\n",
    "    list2 = []\n",
    "    function()\n",
    "    \n",
    "    for i in range(1,n,1):\n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "        \n",
    "    list1=[]\n",
    "    data = np.random.randint(1,5,[1,2])\n",
    "    global n1 , n2\n",
    "    n1 = data[0][0] #size of sample\n",
    "    elements = set([\"E\", \"A\", \"M\", \"D\", \"G\"])\n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    \n",
    "   \n",
    "    n2 = data[0][1] #size of sample\n",
    "    random_pop2 = [element for i in range(n2) for element in random.sample(elements, 1)]\n",
    "    for i in range(n1):    \n",
    "        list1.append(random_pop1[i]) \n",
    "    list1.append(\"|\")\n",
    "    for i in range(n2):    \n",
    "        list1.append(random_pop2[i]) \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Are they equal in number?\")\n",
    "    list2.append(\"\\n\")\n",
    "    list2.extend(list1)\n",
    "    \n",
    "    str = \" \"\n",
    "    prompt = str.join(list2)\n",
    "    return(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "7371bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " D D M | A A G M . Are they equal in number? No \n",
      " A E G E | M . Are they equal in number? No \n",
      " A A E D | D . Are they equal in number? No \n",
      " M G M | D E E . Are they equal in number? Yes \n",
      " M | M E . Are they equal in number? No \n",
      " A E | D D D . Are they equal in number? No \n",
      " M M A | G . Are they equal in number? No \n",
      " D G | E A . Are they equal in number? Yes \n",
      " D E E | M E G M . Are they equal in number? No \n",
      " G E A M | M G . Are they equal in number?\n"
     ]
    }
   ],
   "source": [
    "print(create(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "7e4015b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 33, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 43, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 57, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 74, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 96, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 114, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 121, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 137, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 154, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 181, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 195, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 206, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 226, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 236, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 260, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 269, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 290, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 305, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 317, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 332, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 30, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 42, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 62, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 79, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 95, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 116, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 126, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 141, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 157, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 170, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 186, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 201, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 222, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 235, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 240, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 276, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 285, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 305, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 317, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 341, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 31, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 48, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 77, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 94, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 101, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 126, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 142, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 149, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 174, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 182, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 194, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 218, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 230, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 250, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 276, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 287, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 303, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 329, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 346, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 33, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 42, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 58, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 80, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 96, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 106, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 128, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 143, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 149, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 184, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 192, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 209, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 219, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 237, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 256, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 283, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 293, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 300, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 308, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 348, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 33, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 45, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 58, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 77, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 98, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 111, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 120, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 156, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 155, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 171, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 197, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 200, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 212, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 226, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 254, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 272, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 276, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 304, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 313, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 329, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 47, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 79, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 95, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 118, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 129, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 141, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 151, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 173, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 178, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 205, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 227, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 247, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 257, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 272, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 297, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 306, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 317, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 333, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 47, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 60, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 76, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 95, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 109, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 132, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 139, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 163, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 167, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 188, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 203, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 218, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 246, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 249, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 267, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 282, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 295, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 331, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 318, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 31, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 47, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 60, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 81, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 93, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 102, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 134, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 136, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 152, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 176, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 189, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 207, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 219, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 231, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 261, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 266, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 294, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 310, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 300, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 344, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 47, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 60, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 76, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 96, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 111, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 134, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 142, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 160, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 176, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 184, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 201, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 214, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 235, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 250, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 267, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 288, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 293, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 322, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 326, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 31, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 50, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 78, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 96, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 106, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 115, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 150, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 158, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 179, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 197, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 204, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 226, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 246, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 264, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 276, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 285, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 312, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 311, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 327, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1026"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=30)\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        if(len(gen_text) > number+1):\n",
    "            x = gen_text[number-1]+gen_text[number]+gen_text[number+1]\n",
    "        else:\n",
    "            x = gen_text[number-1]+gen_text[number]\n",
    "        if(n1 == n2):\n",
    "            ans = \"Yes\"  \n",
    "        else:\n",
    "            ans = \"No\"\n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "#        print(ans,x)\n",
    "\n",
    "fo = open(\"foo1.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "7c67acea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " M D | M . Are they equal in number? No \n",
      " M M D | M D . Are they equal in number? No \n",
      " E E M | E M E M . Are they equal in number? No \n",
      " D E D | A G D . Are they equal in number? Yes \n",
      " E | E D D . Are they equal in number? No \n",
      " A D D | D A . Are they equal in number? No \n",
      " E G M | E . Are they equal in number? No \n",
      " E D | M A M . Are they equal in number? No \n",
      " E G D | G A A . Are they equal in number? Yes \n",
      " D | G M D E . Are they equal in number? No \n",
      " A G E M | G . Are they equal in number? No \n",
      " G | G A . Are they equal in number? No \n",
      " M M | A . Are they equal in number? No \n",
      " G | G D . Are they equal in number? No \n",
      " E G D | E G . Are they equal in number? No \n",
      " M G | A G A . Are they equal in number? No \n",
      " A | E . Are they equal in number? Yes \n",
      " G G | D G E G . Are they equal in number? No \n",
      " E E D G | D . Are they equal in number? No \n",
      " G D | G E D . Are they equal in number? No \n",
      " E A G | A G D . Are they equal in number?\n",
      " Correct: [4. 4. 6. 4. 6. 8. 5. 7. 6. 6. 6. 6. 5. 6. 7. 8. 7. 6. 6. 6.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo1.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "8eb51b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = \"\"\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x += response.choices[0].text[i]\n",
    "                \n",
    "        if(n1 == n2):\n",
    "            ans = \"Yes\"  #     'Y','e','s'\n",
    "        else:\n",
    "            ans = \"No\"\n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "#        print(ans,x)\n",
    "        x = \"\"\n",
    "    \n",
    "fo = open(\"foo1_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp1_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "28847caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " M D M G | G . Are they equal in number? No \n",
      " A | E G G E . Are they equal in number? No \n",
      " A | M . Are they equal in number? Yes \n",
      " D | G M M . Are they equal in number? No \n",
      " G G M G | M G A G . Are they equal in number? Yes \n",
      " D M M M | E G A G . Are they equal in number? Yes \n",
      " E A | M E G M . Are they equal in number? No \n",
      " M | E A D . Are they equal in number? No \n",
      " G G | G M E . Are they equal in number? No \n",
      " D | G M M . Are they equal in number? No \n",
      " A | A M A M . Are they equal in number? No \n",
      " A | G A . Are they equal in number? No \n",
      " A G | A D A D . Are they equal in number? No \n",
      " G | E M . Are they equal in number? No \n",
      " D G | M A . Are they equal in number? Yes \n",
      " M D G | A D M . Are they equal in number? Yes \n",
      " D | E . Are they equal in number? Yes \n",
      " M G D | G E M . Are they equal in number? Yes \n",
      " E M | G . Are they equal in number? No \n",
      " E | E A A E . Are they equal in number? No \n",
      " E M D M | A M . Are they equal in number?\n",
      " Correct: [4. 4. 5. 8. 5. 4. 6. 6. 9. 8. 6. 7. 7. 9. 6. 8. 9. 5. 5. 7.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo1_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abb131e",
   "metadata": {},
   "source": [
    "# 4.   请说出下面那种物品的个数最多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "id": "d6b3a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "    global count \n",
    "    count = np.zeros(5)\n",
    "    data = np.random.randint(6,10,[1,1])\n",
    "    global n1\n",
    "    n1 = data[0][0] #size of sample\n",
    "    elements = set([\"E\", \"A\", \"M\", \"D\", \"G\"])\n",
    "    global listc\n",
    "    listc = [\"A\", \"D\", \"E\", \"G\", \"M\"] #元组位序\n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    \n",
    "    for i in range(n1):    \n",
    "        list1.append(random_pop1[i]) \n",
    "        \n",
    "    \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Which letter has the largest number?\")\n",
    "    \n",
    "    for i in range(n1):\n",
    "        if(list1[i] ==  \"A\"):\n",
    "            count[0] += 1\n",
    "        elif(list1[i] == \"D\"):\n",
    "            count[1] += 1\n",
    "        elif(list1[i] == \"E\"):\n",
    "            count[2] += 1\n",
    "        elif(list1[i] == \"G\"):\n",
    "            count[3] += 1\n",
    "        else:\n",
    "            count[4] += 1\n",
    "    \n",
    "    maxn = 0\n",
    "    max = count[0]\n",
    "    \n",
    "    for i in range(5):    \n",
    "        if(count[i] > max):\n",
    "            max = count[i] #最大值\n",
    "            maxn = i #最大值位置\n",
    "    \n",
    "    for i in range(5):\n",
    "        count[i] = 0\n",
    "    \n",
    "    list1.append(listc[maxn])\n",
    "#     print(list1)\n",
    "    return list1\n",
    "\n",
    "def create(n):\n",
    "    list2 = []\n",
    "    function()\n",
    "    \n",
    "    for i in range(1,n,1):\n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "     \n",
    "    list1=[]\n",
    "    data = np.random.randint(6,10,[1,1])\n",
    "    \n",
    "    n1 = data[0][0] #size of sample\n",
    "    elements = set([\"E\", \"A\", \"M\", \"D\", \"G\"])\n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    for i in range(n1):    \n",
    "        list1.append(random_pop1[i]) \n",
    "        \n",
    "    for i in range(n1):\n",
    "        if(list1[i] ==  \"A\"):\n",
    "            count[0] += 1\n",
    "        elif(list1[i] == \"D\"):\n",
    "            count[1] += 1\n",
    "        elif(list1[i] == \"E\"):\n",
    "            count[2] += 1\n",
    "        elif(list1[i] == \"G\"):\n",
    "            count[3] += 1\n",
    "        else:\n",
    "            count[4] += 1\n",
    "    \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Which letter has the largest number?\")\n",
    "    list2.append(\"\\n\")\n",
    "    list2.extend(list1)\n",
    "    \n",
    "    str = \" \"\n",
    "    prompt = str.join(list2)\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "f59d2378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " D G A E E D D G . Which letter has the largest number? D \n",
      " G D E A E G M A D . Which letter has the largest number? A \n",
      " E E A D D M . Which letter has the largest number?\n"
     ]
    }
   ],
   "source": [
    "print(create(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "id": "63efd2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 35, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 52, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 73, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 94, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 106, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 129, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 146, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 166, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 185, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 202, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 221, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 241, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 256, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 275, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 301, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 316, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 331, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 347, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 366, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 386, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 34, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 55, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 75, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 90, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 107, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 130, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 146, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 163, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 182, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 209, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 221, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 243, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 250, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 269, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 296, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 312, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 323, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 356, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 373, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 387, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 34, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 52, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 75, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 89, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 111, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 126, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 152, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 162, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 176, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 201, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 220, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 231, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 254, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 277, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 293, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 314, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 330, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 347, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 359, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 387, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 34, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 51, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 70, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 88, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 109, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 130, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 149, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 168, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 181, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 203, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 218, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 246, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 253, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 275, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 291, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 309, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 334, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 354, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 370, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 395, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 36, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 52, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 72, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 92, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 114, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 124, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 151, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 159, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 184, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 204, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 221, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 239, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 254, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 274, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 299, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 311, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 329, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 341, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 360, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 387, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 37, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 53, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 70, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 95, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 109, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 128, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 141, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 160, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 181, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 205, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 219, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 241, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 258, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 278, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 294, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 311, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 339, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 349, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 366, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 402, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 34, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 52, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 72, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 92, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 112, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 132, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 146, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 164, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 183, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 203, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 216, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 241, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 258, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 277, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 297, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 308, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 335, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 349, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 364, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 385, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 33, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 56, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 71, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 94, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 106, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 130, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 144, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 163, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 188, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 198, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 218, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 229, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 257, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 271, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 295, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 313, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 328, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 354, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 368, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 379, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 34, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 53, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 73, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 96, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 112, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 127, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 147, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 166, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 185, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 197, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 216, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 236, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 261, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 279, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 291, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 314, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 325, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 360, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 372, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 386, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 38, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 53, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 71, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 92, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 106, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 133, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 151, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 168, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 178, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 203, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 221, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 243, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 259, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 285, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 291, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 318, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 332, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 349, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 371, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 385, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1308"
      ]
     },
     "execution_count": 975,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 975,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=30)\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        x = gen_text[number-1]\n",
    "\n",
    "        for j in range(0,5,1):\n",
    "#             print(max1,count[j])\n",
    "            if(count[j] > max1):\n",
    "                max1 = count[j] #最大值\n",
    "                maxn = j #最大值位置\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "       \n",
    "        ans = listc[maxn]\n",
    "        \n",
    "            \n",
    "        maxn = 0\n",
    "        max1 = 0        \n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "    \n",
    "fo = open(\"foo2.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "6ac93236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " D E A D A A D M D . Which letter has the largest number? D \n",
      " M G A M D D . Which letter has the largest number? D \n",
      " E D D A E G M . Which letter has the largest number? D \n",
      " E E G G M M D G . Which letter has the largest number? G \n",
      " D A M M G G . Which letter has the largest number? G \n",
      " D G A D A A . Which letter has the largest number? A \n",
      " G D E E D E M E D . Which letter has the largest number? E \n",
      " G E A A E A E . Which letter has the largest number? A \n",
      " G A A M G A A G . Which letter has the largest number? A \n",
      " E G M G A M . Which letter has the largest number? G \n",
      " D A M M G E G G . Which letter has the largest number? G \n",
      " A M G G G D . Which letter has the largest number? G \n",
      " A D D A E M . Which letter has the largest number? A \n",
      " A G M A M D A . Which letter has the largest number? A \n",
      " M M E M A A G D D . Which letter has the largest number? M \n",
      " G E G A D A M D G . Which letter has the largest number? G \n",
      " D D A A M G M A . Which letter has the largest number? A \n",
      " G E E M A D A A . Which letter has the largest number? A \n",
      " G A G M M G G . Which letter has the largest number? G \n",
      " A D G G A G A G . Which letter has the largest number? G \n",
      " E M A M G M G G . Which letter has the largest number?\n",
      " Correct: [3. 3. 5. 5. 3. 4. 2. 4. 5. 4. 6. 6. 6. 5. 8. 6. 3. 6. 8. 7.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo2.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "21b1f57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 981,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 981,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "x = \"\"\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x = response.choices[0].text[i]\n",
    "\n",
    "        for j in range(0,5,1):\n",
    "#             print(max1,count[j])\n",
    "            if(count[j] > max1):\n",
    "                max1 = count[j] #最大值\n",
    "                maxn = j #最大值位置\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "       \n",
    "        ans = listc[maxn]\n",
    "        \n",
    "            \n",
    "        maxn = 0\n",
    "        max1 = 0        \n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "  \n",
    "\n",
    "     \n",
    "fo = open(\"foo2_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp2_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "66e38baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " M D G M G M A M E . Which letter has the largest number? M \n",
      " E E E D A M . Which letter has the largest number? E \n",
      " A G A E A D G G G . Which letter has the largest number? G \n",
      " M E A M M A A M . Which letter has the largest number? M \n",
      " M M E A E M D G A . Which letter has the largest number? M \n",
      " A E D M D G D . Which letter has the largest number? D \n",
      " G E G D M D D . Which letter has the largest number? D \n",
      " E E M G D M G D . Which letter has the largest number? D \n",
      " M A E A M A . Which letter has the largest number? A \n",
      " G M G D G G E A M . Which letter has the largest number? G \n",
      " M M G G M E M G A . Which letter has the largest number? M \n",
      " D A G D G G A . Which letter has the largest number? G \n",
      " D E E M E E A E D . Which letter has the largest number? E \n",
      " G D G G G D G . Which letter has the largest number? G \n",
      " D M D M A D G G E . Which letter has the largest number? D \n",
      " G A M G M A M D . Which letter has the largest number? M \n",
      " D A M A G M M D . Which letter has the largest number? M \n",
      " A G A E E E M . Which letter has the largest number? E \n",
      " D D M G G D D G . Which letter has the largest number? D \n",
      " M E M E G E M M A . Which letter has the largest number? M \n",
      " G E G M E A A G . Which letter has the largest number?\n",
      " Correct: [ 4.  5.  6.  5.  2.  8.  7.  7.  7.  5.  6.  4.  3.  7.  7.  8. 10.  6.\n",
      "  7.  8.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo2_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2ed5f",
   "metadata": {},
   "source": [
    "# 5.   请把大于14的数输出：find (> val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2036,
   "id": "533ac793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): \n",
    "    list1 = []\n",
    "    global count \n",
    "    count = np.zeros(5)\n",
    "    data = np.random.randint(6,10,1)\n",
    "    \n",
    "    global n1\n",
    "    n1 = data[0]#size of sample\n",
    "\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    ans = []\n",
    "    for i in range(n1): \n",
    "        list1.append(np.random.randint(9,13,1))\n",
    "        \n",
    "    for i in range(n1): \n",
    "#         print(list1[i])\n",
    "        list2.append(list1[i][0])\n",
    "    \n",
    "    data1 = np.random.randint(15,20,1)\n",
    "    list2.append(data1[0])\n",
    "    #list2存放了随机生成的数据\n",
    "    random.shuffle(list2)\n",
    "    Tr = 0\n",
    "    Fa = 0\n",
    "    \n",
    "    list2.append(\".\")\n",
    "    list2.append(\"Which numbers are greater than 14?\")\n",
    "    \n",
    "    \n",
    "    for i in range(n1+1):\n",
    "        if(int(list2[i]) >  14 ):\n",
    "            ans.append(list2[i])\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    ans1 = list(set(ans))\n",
    "    ans1.sort()\n",
    "    list2.extend(ans1)\n",
    "    return list2\n",
    "\n",
    "def create(n):\n",
    "    \n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "    list4 = []\n",
    "    for i in range(1,n,1): \n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "       \n",
    "        \n",
    "    list2.append(\"\\n\")\n",
    "    \n",
    "    \n",
    "    #生成测试用例\n",
    "    data = np.random.randint(6,10,1)\n",
    "    \n",
    "    global ans \n",
    "    ans = \"\"\n",
    "    n1 = data[0] #size of sample\n",
    "    \n",
    "    for i in range(n1):\n",
    "        data1 = np.random.randint(9,13,1)\n",
    "        list1.append(data1[0]) #生成随机数\n",
    "        \n",
    "    data1 = np.random.randint(15,20,1)\n",
    "    list1.append(data1[0])\n",
    "    #list2存放了随机生成的数据\n",
    "    random.shuffle(list1)    \n",
    "    \n",
    "    list3.extend(list1)\n",
    "    \n",
    "    for i in range(n1+1):\n",
    "        if(int(list3[i]) >  14 ):\n",
    "            ans = list3[i]\n",
    "            \n",
    "    \n",
    "    list2.extend(list3)\n",
    "    \n",
    "    \n",
    "    list2.append(\".\")\n",
    "    list2.append(\"Which numbers are greater than 14?\")\n",
    "    \n",
    "    for i in range(len(list2)):\n",
    "        list4.append(str(list2[i]))\n",
    "    \n",
    "    \n",
    "    prompt = \" \".join(list4)\n",
    "    \n",
    "    return(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2038,
   "id": "d1f3a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "\n",
      " 10 12 12 10 16 12 9 10 12 12 . Which numbers are greater than 14? 16 \n",
      " 10 10 10 18 12 9 9 10 10 . Which numbers are greater than 14? 18 \n",
      " 10 11 11 15 9 9 12 9 . Which numbers are greater than 14?\n"
     ]
    }
   ],
   "source": [
    "print(ans)\n",
    "print(create(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2051,
   "id": "75e778c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "17\n",
      "16\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1486"
      ]
     },
     "execution_count": 2051,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 2051,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数,最小值为3\n",
    "# n = int(input()) #测试几次，最小值为2\n",
    "Count = 10\n",
    "\n",
    "x = \"\"\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        \n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=(num*23))\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        #模型输出\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        for i in range(number-1,len(gen_text)-1):\n",
    "            if(gen_text[i] == \"\\n\"):\n",
    "                break\n",
    "            elif(gen_text[i] == ' '):\n",
    "                pass\n",
    "            else:\n",
    "                x += gen_text[i]\n",
    "            \n",
    "#         n = 0\n",
    "        \n",
    "#         for i in range(0,len(x)-1,2):\n",
    "               \n",
    "#             n = int(x[i])*10 + int(x[i+1])\n",
    "            \n",
    "#             x1.append(n)\n",
    "        \n",
    "#         x2 = list(set(x1))\n",
    "#         x2.sort()\n",
    "        \n",
    "#         ans1 = list(set(ans))\n",
    "#         ans1.sort()\n",
    "        \n",
    "        print(ans)\n",
    "        print(x)\n",
    "        \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "        x = \"\"\n",
    "#         x.clear()\n",
    "#         x1.clear()\n",
    "#         x2.clear()\n",
    "#         ans.clear()\n",
    "#         ans1.clear()\n",
    "        \n",
    "fo = open(\"foo3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2052,
   "id": "03d4c435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " 12 11 10 12 9 18 9 11 11 10 . Which numbers are greater than 14? 18 \n",
      " 9 10 9 12 10 10 9 18 10 . Which numbers are greater than 14? 18 \n",
      " 12 10 12 12 10 12 9 11 18 9 . Which numbers are greater than 14? 18 \n",
      " 9 10 16 12 12 10 10 12 . Which numbers are greater than 14? 16 \n",
      " 12 11 12 11 16 10 9 11 . Which numbers are greater than 14? 16 \n",
      " 10 10 11 10 16 12 10 12 . Which numbers are greater than 14? 16 \n",
      " 11 9 12 11 12 15 9 . Which numbers are greater than 14? 15 \n",
      " 12 9 10 16 11 10 10 12 . Which numbers are greater than 14? 16 \n",
      " 10 12 12 11 11 11 10 18 9 9 . Which numbers are greater than 14? 18 \n",
      " 9 11 19 9 9 11 12 10 9 11 . Which numbers are greater than 14? 19 \n",
      " 9 11 12 16 10 9 9 . Which numbers are greater than 14? 16 \n",
      " 12 11 11 9 19 9 12 12 9 10 . Which numbers are greater than 14? 19 \n",
      " 10 11 9 9 11 10 18 . Which numbers are greater than 14? 18 \n",
      " 12 9 17 11 9 11 11 9 11 12 . Which numbers are greater than 14? 17 \n",
      " 12 11 10 10 12 16 9 12 9 . Which numbers are greater than 14? 16 \n",
      " 12 9 11 9 18 10 11 . Which numbers are greater than 14? 18 \n",
      " 9 17 10 9 12 9 11 . Which numbers are greater than 14? 17 \n",
      " 11 9 9 10 10 9 16 11 10 12 . Which numbers are greater than 14? 16 \n",
      " 9 10 12 11 15 9 10 10 11 . Which numbers are greater than 14? 15 \n",
      " 10 10 11 10 10 11 17 . Which numbers are greater than 14? 17 \n",
      " 11 9 11 16 10 12 9 . Which numbers are greater than 14?\n",
      " Correct: [ 4.  2.  5.  7.  7.  8.  9.  9.  9.  7.  6.  8.  9. 10. 10.  9.  8.  9.\n",
      "  9. 10.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2049,
   "id": "0a1d63ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1495"
      ]
     },
     "execution_count": 2049,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 2049,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数,最小值为3\n",
    "# n = int(input()) #测试几次，最小值为2\n",
    "Count = 10\n",
    "\n",
    "x = \"\"\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        \n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=2)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x += response.choices[0].text[i]\n",
    "            \n",
    "        \n",
    "            \n",
    "#         print(ans)\n",
    "#         print(x)\n",
    "        \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "        x = \"\"\n",
    "        \n",
    "fo = open(\"foo3_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp3_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2050,
   "id": "b7acc21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " 18 11 11 10 9 10 12 9 11 9 . Which numbers are greater than 14? 18 \n",
      " 11 16 12 12 9 11 12 . Which numbers are greater than 14? 16 \n",
      " 9 11 16 9 11 9 10 . Which numbers are greater than 14? 16 \n",
      " 10 9 11 11 12 9 10 18 12 . Which numbers are greater than 14? 18 \n",
      " 12 11 10 16 12 11 9 10 12 . Which numbers are greater than 14? 16 \n",
      " 12 12 11 11 10 11 12 11 17 9 . Which numbers are greater than 14? 17 \n",
      " 10 17 12 12 9 12 12 11 9 . Which numbers are greater than 14? 17 \n",
      " 11 11 12 9 10 18 9 11 12 11 . Which numbers are greater than 14? 18 \n",
      " 10 12 10 9 15 12 10 . Which numbers are greater than 14? 15 \n",
      " 11 11 9 11 11 15 11 . Which numbers are greater than 14? 15 \n",
      " 12 10 12 18 11 12 12 11 11 11 . Which numbers are greater than 14? 18 \n",
      " 10 9 9 12 12 19 12 10 10 . Which numbers are greater than 14? 19 \n",
      " 12 10 10 12 18 10 9 . Which numbers are greater than 14? 18 \n",
      " 10 11 18 11 9 10 10 9 . Which numbers are greater than 14? 18 \n",
      " 10 11 18 9 12 12 11 10 . Which numbers are greater than 14? 18 \n",
      " 9 9 12 11 11 16 12 . Which numbers are greater than 14? 16 \n",
      " 18 12 12 11 10 12 12 10 10 . Which numbers are greater than 14? 18 \n",
      " 10 12 9 9 18 9 9 10 . Which numbers are greater than 14? 18 \n",
      " 15 11 10 12 11 9 12 11 . Which numbers are greater than 14? 15 \n",
      " 9 9 10 10 19 12 11 9 12 11 . Which numbers are greater than 14? 19 \n",
      " 11 15 12 9 10 11 10 12 10 . Which numbers are greater than 14?\n",
      " Correct: [ 1.  4.  7.  8.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
      " 10. 10.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo3_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "1278866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 16, 13, 15, 13]\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3024f",
   "metadata": {},
   "source": [
    "# 大于14的数有多少个（find (> val)和count的组合）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "id": "0cde462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "    global count \n",
    "    count = np.zeros(5)\n",
    "    data = np.random.randint(6,10,1)\n",
    "    global n1\n",
    "    n1 = data[0]#size of sample\n",
    "    \n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    ans = 0\n",
    "    for i in range(n1): \n",
    "        list1.append(np.random.randint(10,18,1))\n",
    "        \n",
    "    for i in range(n1): \n",
    "#         print(list1[i])\n",
    "        list2.append(list1[i][0])\n",
    "    #list2存放了随机生成的数据\n",
    "   \n",
    "    Tr = 0\n",
    "    Fa = 0\n",
    "    \n",
    "    list2.append(\".\")\n",
    "    list2.append(\"How many numbers are greater than 14?\")\n",
    "\n",
    "    \n",
    "    for i in range(n1):\n",
    "        if(int(list2[i]) >  14 ):\n",
    "            \n",
    "            ans += 1\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "    list2.append(ans)\n",
    "    return list2\n",
    "\n",
    "def create(n):\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "    list4 = []\n",
    "    for i in range(1,n,1): \n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "       \n",
    "        \n",
    "    list2.append(\"\\n\")\n",
    "    \n",
    "    #生成测试用例\n",
    "    data = np.random.randint(6,10,1)\n",
    "    global n1\n",
    "    global ans \n",
    "    ans = 0\n",
    "    n1 = data[0] #size of sample\n",
    "    for i in range(n1): \n",
    "        list1.append(np.random.randint(10,18,1)) #生成随机数\n",
    "        \n",
    "    \n",
    "    for i in range(n1): \n",
    "#         print(list1[i])\n",
    "        list3.append(list1[i][0])\n",
    "    \n",
    "    for i in range(n1):\n",
    "        if(int(list3[i]) >  14 ):\n",
    "            \n",
    "            ans += 1\n",
    "            \n",
    "        else:\n",
    "            pass   \n",
    "    \n",
    "    list2.extend(list3)\n",
    "    \n",
    "    \n",
    "    list2.append(\".\")\n",
    "    list2.append(\"How many numbers are greater than 14?\")\n",
    "    \n",
    "    for i in range(len(list2)):\n",
    "        list4.append(str(list2[i]))\n",
    "    \n",
    "    \n",
    "    prompt = \" \".join(list4)\n",
    "    \n",
    "    return(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "id": "15d9c069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 36, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 58, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 76, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 96, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 114, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 138, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 148, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 173, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 193, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 211, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 229, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 258, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 267, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 298, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 313, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 328, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 347, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 371, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 382, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 404, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 38, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 57, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 73, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 92, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 111, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 136, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 154, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 173, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 198, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 212, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 229, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 245, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 278, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 286, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 311, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 329, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 346, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 367, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 389, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 405, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 37, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 57, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 78, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 98, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 112, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 133, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 156, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 173, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 189, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 216, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 233, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 254, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 277, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 288, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 314, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 340, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 352, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 372, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 387, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 415, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 35, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 55, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 74, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 94, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 118, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 135, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 153, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 178, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 185, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 215, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 227, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 250, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 271, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 295, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 312, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 333, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 349, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 374, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 391, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 407, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 38, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 59, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 75, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 93, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 113, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 133, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 150, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 177, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 190, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 217, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 229, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 252, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 274, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 292, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 303, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 329, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 348, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 369, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 387, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 409, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 37, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 58, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 76, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 97, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 117, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 136, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 152, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 172, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 200, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 209, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 230, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 252, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 265, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 296, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 316, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 334, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 347, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 371, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 396, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 410, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 37, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 58, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 72, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 95, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 109, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 136, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 155, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 176, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 197, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 215, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 231, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 255, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 277, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 288, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 305, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 329, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 342, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 373, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 394, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 405, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 39, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 55, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 78, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 99, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 116, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 130, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 155, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 171, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 191, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 218, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 233, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 243, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 272, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 288, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 313, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 327, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 348, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 375, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 397, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 413, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 38, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 57, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 75, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 96, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 117, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 135, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 157, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 178, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 192, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 209, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 236, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 250, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 268, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 297, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 302, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 320, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 351, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 366, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 384, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 401, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 37, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 54, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 77, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 95, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 117, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 133, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 151, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 173, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 191, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 212, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 232, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 251, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 273, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 285, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 311, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 327, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 351, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 365, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 392, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 409, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1494"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数,最小值为3\n",
    "# n = int(input()) #测试几次，最小值为2\n",
    "Count = 10\n",
    "\n",
    "x = \"\"\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        \n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=30)\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        #模型输出\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        x = int(gen_text[number-1])\n",
    "        \n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "        print(x)\n",
    "        print(ans)\n",
    "        \n",
    "fo = open(\"foo4.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp4.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "id": "0c56fcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " 10 10 14 12 10 13 12 13 . How many numbers are greater than 14? 0 \n",
      " 11 16 14 15 12 11 . How many numbers are greater than 14? 2 \n",
      " 10 15 17 16 11 16 16 10 16 . How many numbers are greater than 14? 6 \n",
      " 16 10 11 17 12 15 12 16 10 . How many numbers are greater than 14? 4 \n",
      " 11 13 10 15 16 14 15 . How many numbers are greater than 14? 3 \n",
      " 16 10 16 15 11 10 10 . How many numbers are greater than 14? 3 \n",
      " 15 10 11 11 14 12 15 . How many numbers are greater than 14? 2 \n",
      " 14 11 12 13 11 17 13 . How many numbers are greater than 14? 1 \n",
      " 14 17 16 17 14 11 12 15 . How many numbers are greater than 14? 4 \n",
      " 14 16 16 12 17 14 10 12 . How many numbers are greater than 14? 3 \n",
      " 15 15 14 13 13 12 11 . How many numbers are greater than 14? 2 \n",
      " 14 14 16 14 12 13 . How many numbers are greater than 14? 1 \n",
      " 13 11 14 11 15 11 16 16 . How many numbers are greater than 14? 3 \n",
      " 16 13 10 12 16 17 14 17 17 . How many numbers are greater than 14? 5 \n",
      " 15 13 13 16 11 14 10 12 . How many numbers are greater than 14? 2 \n",
      " 17 15 15 10 13 15 13 11 10 . How many numbers are greater than 14? 4 \n",
      " 12 10 14 12 13 17 10 10 12 . How many numbers are greater than 14? 1 \n",
      " 15 16 11 12 14 11 10 11 . How many numbers are greater than 14? 2 \n",
      " 13 16 16 14 15 14 . How many numbers are greater than 14? 3 \n",
      " 15 16 11 16 11 11 15 . How many numbers are greater than 14? 4 \n",
      " 13 13 17 11 11 17 . How many numbers are greater than 14?\n",
      " Correct: [0. 1. 3. 2. 1. 1. 3. 1. 3. 2. 2. 5. 4. 3. 2. 3. 4. 4. 3. 4.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo4.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "id": "c4e2045c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n",
      "4 2\n",
      "0 1\n",
      "1 4\n",
      "1 4\n",
      "2 2\n",
      "4 0\n",
      "3 3\n",
      "1 2\n",
      "2 3\n",
      "3 5\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 3\n",
      "3 5\n",
      "3 4\n",
      "3 2\n",
      "3 3\n",
      "2 5\n",
      "3 2\n",
      "4 3\n",
      "1 1\n",
      "2 4\n",
      "2 2\n",
      "3 3\n",
      "4 7\n",
      "2 2\n",
      "2 4\n",
      "2 4\n",
      "2 5\n",
      "2 2\n",
      "2 1\n",
      "1 5\n",
      "1 1\n",
      "3 3\n",
      "2 4\n",
      "3 3\n",
      "3 3\n",
      "2 1\n",
      "2 3\n",
      "3 3\n",
      "3 3\n",
      "1 4\n",
      "3 1\n",
      "3 3\n",
      "3 4\n",
      "2 1\n",
      "3 1\n",
      "3 2\n",
      "1 3\n",
      "2 1\n",
      "3 3\n",
      "3 2\n",
      "2 4\n",
      "2 3\n",
      "3 2\n",
      "2 1\n",
      "1 1\n",
      "3 3\n",
      "3 4\n",
      "6 2\n",
      "2 1\n",
      "1 1\n",
      "2 1\n",
      "3 2\n",
      "1 2\n",
      "3 1\n",
      "3 1\n",
      "3 1\n",
      "4 5\n",
      "2 3\n",
      "4 4\n",
      "1 3\n",
      "3 3\n",
      "1 1\n",
      "1 0\n",
      "3 1\n",
      "1 3\n",
      "2 2\n",
      "3 5\n",
      "2 6\n",
      "3 3\n",
      "5 3\n",
      "1 2\n",
      "3 3\n",
      "1 1\n",
      "2 5\n",
      "3 2\n",
      "2 3\n",
      "2 2\n",
      "1 3\n",
      "2 2\n",
      "3 3\n",
      "3 5\n",
      "3 1\n",
      "2 4\n",
      "3 5\n",
      "4 3\n",
      "1 2\n",
      "2 4\n",
      "3 1\n",
      "3 1\n",
      "2 3\n",
      "2 1\n",
      "3 3\n",
      "3 4\n",
      "1 2\n",
      "4 3\n",
      "1 2\n",
      "2 3\n",
      "1 4\n",
      "2 3\n",
      "2 3\n",
      "2 5\n",
      "3 2\n",
      "2 2\n",
      "2 2\n",
      "2 6\n",
      "2 4\n",
      "4 0\n",
      "4 1\n",
      "2 3\n",
      "2 3\n",
      "2 1\n",
      "6 2\n",
      "4 4\n",
      "1 3\n",
      "3 3\n",
      "1 4\n",
      "2 2\n",
      "2 2\n",
      "3 4\n",
      "1 2\n",
      "2 3\n",
      "2 2\n",
      "2 2\n",
      "2 1\n",
      "2 3\n",
      "1 1\n",
      "2 5\n",
      "3 4\n",
      "3 2\n",
      "2 6\n",
      "2 2\n",
      "5 2\n",
      "2 3\n",
      "6 5\n",
      "3 3\n",
      "3 3\n",
      "2 2\n",
      "2 1\n",
      "4 3\n",
      "3 5\n",
      "4 3\n",
      "4 5\n",
      "1 2\n",
      "4 7\n",
      "2 2\n",
      "3 3\n",
      "4 3\n",
      "2 1\n",
      "2 4\n",
      "2 6\n",
      "1 2\n",
      "1 3\n",
      "2 2\n",
      "3 3\n",
      "2 3\n",
      "3 3\n",
      "2 5\n",
      "2 2\n",
      "1 2\n",
      "2 5\n",
      "3 2\n",
      "4 1\n",
      "2 1\n",
      "3 3\n",
      "1 2\n",
      "1 1\n",
      "4 4\n",
      "2 2\n",
      "4 1\n",
      "3 2\n",
      "3 3\n",
      "2 2\n",
      "2 2\n",
      "3 2\n",
      "2 5\n",
      "2 5\n",
      "3 4\n",
      "1 1\n",
      "3 3\n",
      "1 0\n",
      "2 3\n",
      "2 2\n",
      "2 3\n",
      "1 1\n",
      "3 4\n",
      "3 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1491"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数,最小值为3\n",
    "# n = int(input()) #测试几次，最小值为2\n",
    "Count = 10\n",
    "\n",
    "x = \"\"\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        \n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x = int(response.choices[0].text[i])\n",
    "        \n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "        print(x,ans)\n",
    "        \n",
    "fo = open(\"foo4_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp4_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "id": "f1fd254b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "id": "71698450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af2e2e",
   "metadata": {},
   "source": [
    "# 哪个字母比F多?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2135,
   "id": "a1eba9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "   \n",
    "    ans = []\n",
    "     \n",
    "    count = np.zeros(4)\n",
    "    data = np.random.randint(2,4,1)\n",
    "    n1 = data[0]\n",
    "    data1 = np.random.randint(1,n1,3)\n",
    "    data2 = np.random.randint(n1,6,1)\n",
    "    data3 = np.random.randint(0,4,1)\n",
    "    elements = set([\"E\", \"A\", \"D\", \"G\"])\n",
    "    global listc\n",
    "    listc = [\"A\", \"D\", \"E\", \"G\"] #元组位序\n",
    "    t = 0\n",
    "    \n",
    "            \n",
    "    for i in range(n1): \n",
    "        list1.append(\"F\")\n",
    "    \n",
    "    list1.append(\"|\")\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        if(i == data3[0]):\n",
    "            for j in range(data2[0]):\n",
    "                list2.append(listc[data3[0]])\n",
    "        else:\n",
    "            for f in range(data1[t]):\n",
    "                list2.append(listc[t])\n",
    "            t += 1\n",
    "\n",
    "            \n",
    "    list2.sort()\n",
    "    \n",
    "    list3 = \"\".join(list2)        \n",
    "    list4 = list(list3)\n",
    "    list1.extend(list4)\n",
    "    \n",
    "    ans = listc[data3[0]]\n",
    "    \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Which words are more than F?\")\n",
    "   \n",
    "    list1.extend(ans)\n",
    "    for i in range(0,4):\n",
    "        count[i] = 0\n",
    "    return list1\n",
    "\n",
    "def create(n):\n",
    "    list2 = [] #最终的集合\n",
    "    count = np.zeros(5)\n",
    "    function()\n",
    "    global ans\n",
    "    ans = []\n",
    "    for i in range(1,n,1):\n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "     \n",
    "    list1 = []\n",
    "    list3 = []\n",
    "    list4 = []\n",
    "    list5 = []\n",
    "    data = np.random.randint(2,4,1)\n",
    "    n1 = data[0]\n",
    "    data1 = np.random.randint(1,n1,3)\n",
    "    data2 = np.random.randint(n1,6,1)\n",
    "    data3 = np.random.randint(0,4,1)\n",
    "     #size of sample\n",
    "    n2 = data1[0]\n",
    "    \n",
    "    elements = set([\"E\", \"A\", \"D\", \"G\"])\n",
    "    t = 0\n",
    "    \n",
    "            \n",
    "    for i in range(n1): \n",
    "        list1.append(\"F\")\n",
    "    \n",
    "    list1.append(\"|\")\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        if(i == data3[0]):\n",
    "            for j in range(data2[0]):\n",
    "                list3.append(listc[data3[0]])\n",
    "        else:\n",
    "            for f in range(data1[t]):\n",
    "                list3.append(listc[t])\n",
    "            t += 1\n",
    "            \n",
    "            \n",
    "    list3.sort()\n",
    "    list4 = \"\".join(list3)\n",
    "    list5 = list(list4)\n",
    "  \n",
    "    ans = listc[data3[0]]\n",
    "    list1.extend(list5)\n",
    "    \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Which words are more than F?\")\n",
    "    list2.append(\"\\n\")\n",
    "    list2.extend(list1)\n",
    "    \n",
    "    str = \" \"\n",
    "    prompt = str.join(list2)\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2136,
   "id": "b545c3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " F F | A D E E E E E . Which words are more than F? E \n",
      " F F | A D E E E E . Which words are more than F? E \n",
      " F F | A D D D D D D E . Which words are more than F?\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "print(create(3))\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2126,
   "id": "9bd292de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G G\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2126-690458b9b6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mgen_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mgen_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1004\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   1526\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1116\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    996\u001b[0m                 )\n\u001b[1;32m    997\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    999\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     ):\n\u001b[0;32m--> 600\u001b[0;31m         outputs = self.attention(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mpast_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'k_hidden_states'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_value_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_value_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m  \u001b[0;31m# XD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = \"\"\n",
    "list1 = []\n",
    "list2 = []\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=(num*33))\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        x = \"\"\n",
    "        \n",
    "        for i in range(number-1,len(gen_text)+1):\n",
    "            if(i >= len(gen_text)):\n",
    "                break\n",
    "            elif(gen_text[i] == \"\\n\"):\n",
    "                break\n",
    "            elif(gen_text[i] == \" \"):\n",
    "                pass\n",
    "            else:\n",
    "                x += gen_text[i]\n",
    "                \n",
    "\n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "        print(ans,x)\n",
    "        x =\"\"\n",
    "        \n",
    "fo = open(\"foo5.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp5.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"foo5.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "id": "ec22bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " F F F | A A A A A D D D D E E E G G G. Which words are more than F? A D \n",
      " F F | A A A D D E E E E E G G G G G G. Which words are more than F? A E G \n",
      " F F F | A A D D D D D D E E E E G G. Which words are more than F? D E \n",
      " F | A A A D D D D D D E E E E E G G G G. Which words are more than F? A D E G \n",
      " F F | A A A A D D D D E G G G G G. Which words are more than F? A D G \n",
      " F | A A A A D D D D D E E E E E G G G. Which words are more than F? A D E G \n",
      " F F | A A A A D D D D E E G G G G G. Which words are more than F? A D G \n",
      " F | A A A A A A A D D D E E E E E G G G G. Which words are more than F? A D E G \n",
      " F | A A A A A A D D D D E E E E G. Which words are more than F? A D E \n",
      " F F | A A A A D D E E E E G G G. Which words are more than F? A E G \n",
      " F F F | A A A A E E E E E E E G G G. Which words are more than F? A E \n",
      " F | A A A D D D E E E E E E E G G G G G G. Which words are more than F? A D E G \n",
      " F F F | A A A A A D D D D E E E E E E E G G. Which words are more than F? A D E \n",
      " F F | A A A A A D D D D E E E G G. Which words are more than F? A D E \n",
      " F F | A A A A D D E E E E G G G. Which words are more than F? A E G \n",
      " F F F | A A A A A A D D D E E E E E G G G G. Which words are more than F? A E G \n",
      " F F | A A A D D D D E E E G G G. Which words are more than F? A D E G \n",
      " F F F | A A A A D D D D D E E E E G G G G G. Which words are more than F? A D E G \n",
      " F | A A A D D D D D E E G G G. Which words are more than F? A D E G \n",
      " F | A A A D D D E E E E E E G G G G. Which words are more than F? A D E G \n",
      " F F | A A A A A A A A A D D D D D D E E G. Which words are more than F? A D E G \n",
      " F F | A A A A A A A A A A A A A A A A A A\n"
     ]
    }
   ],
   "source": [
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2140,
   "id": "baf87c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E F\n",
      "G G\n",
      "D D\n",
      "A A\n",
      "A A\n",
      "D D\n",
      "D D\n",
      "A E\n",
      "A A\n",
      "D E\n",
      "G G\n",
      "E E\n",
      "E E\n",
      "E E\n",
      "G G\n",
      "G G\n",
      "G G\n",
      "A A\n",
      "E E\n",
      "G G\n",
      "E EEEE\n",
      "D D\n",
      "E E\n",
      "A A\n",
      "D D\n",
      "D D\n",
      "G G\n",
      "E E\n",
      "E E\n",
      "D D\n",
      "E E\n",
      "G G\n",
      "D D\n",
      "G G\n",
      "E E\n",
      "G G\n",
      "D D\n",
      "D D\n",
      "G G\n",
      "E E\n",
      "D G\n",
      "G G\n",
      "G G\n",
      "E E\n",
      "E E\n",
      "E E\n",
      "G G\n",
      "A A\n",
      "D D\n",
      "G G\n",
      "G G\n",
      "D D\n",
      "D E\n",
      "D D\n",
      "D D\n",
      "E E\n",
      "A A\n",
      "A A\n",
      "A A\n",
      "A A\n",
      "A A\n",
      "A A\n",
      "G G\n",
      "D E\n",
      "A E\n",
      "D E\n",
      "D D\n",
      "D D\n",
      "E E\n",
      "A A\n",
      "A A\n",
      "E E\n",
      "A D\n",
      "G G\n",
      "G G\n",
      "D D\n",
      "G G\n",
      "D D\n",
      "E E\n",
      "G G\n",
      "D A\n",
      "A G\n",
      "E E\n",
      "E E\n",
      "A A\n",
      "D E\n",
      "D D\n",
      "A E\n",
      "D D\n",
      "G G\n",
      "A A\n",
      "G G\n",
      "A A\n",
      "E E\n",
      "D D\n",
      "D D\n",
      "G G\n",
      "E E\n",
      "G G\n",
      "E E\n",
      "G A\n",
      "G D\n",
      "E E\n",
      "E E\n",
      "D D\n",
      "G G\n",
      "A A\n",
      "G D\n",
      "G G\n",
      "E E\n",
      "A A\n",
      "D D\n",
      "E E\n",
      "D D\n",
      "G G\n",
      "G G\n",
      "E E\n",
      "A A\n",
      "D D\n",
      "G G\n",
      "D E\n",
      "E E\n",
      "D E\n",
      "E E\n",
      "D D\n",
      "E E\n",
      "D D\n",
      "D D\n",
      "A A\n",
      "G G\n",
      "G G\n",
      "D D\n",
      "A A\n",
      "E E\n",
      "G G\n",
      "A A\n",
      "A A\n",
      "A A\n",
      "G G\n",
      "G G\n",
      "E D\n",
      "G D\n",
      "E E\n",
      "E E\n",
      "A A\n",
      "G G\n",
      "G G\n",
      "G G\n",
      "G G\n",
      "G G\n",
      "E E\n",
      "G G\n",
      "E E\n",
      "A A\n",
      "A A\n",
      "G G\n",
      "A A\n",
      "A A\n",
      "E E\n",
      "A A\n",
      "A D\n",
      "A A\n",
      "D A\n",
      "D D\n",
      "A A\n",
      "G G\n",
      "A A\n",
      "D D\n",
      "D D\n",
      "A A\n",
      "G G\n",
      "G G\n",
      "A A\n",
      "D D\n",
      "E E\n",
      "E E\n",
      "G G\n",
      "A A\n",
      "E E\n",
      "A D\n",
      "A GFF|\n",
      "A A\n",
      "A D\n",
      "E E\n",
      "E E\n",
      "D D\n",
      "A A\n",
      "D D\n",
      "A A\n",
      "E E\n",
      "E E\n",
      "A A\n",
      "G G\n",
      "D D\n",
      "A E\n",
      "D D\n",
      "G G\n",
      "A A\n",
      "E E\n",
      "D D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1303"
      ]
     },
     "execution_count": 2140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 2140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = []\n",
    "list1 = []\n",
    "list2 = []\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "        x = \"\"\n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=4)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x += response.choices[0].text[i]\n",
    "                \n",
    "        \n",
    "#         list1 = \"\".join(x)\n",
    "#         list2 = list(list1)\n",
    "#         x = list2         \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "        print(ans,x)\n",
    "        x = \"\"\n",
    "        ans=\"\"\n",
    "        \n",
    "fo = open(\"foo5_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp5_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2141,
   "id": "c9505e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " F F | A D E E E E E . Which words are more than F? E \n",
      " F F | A A A A A D E . Which words are more than F? A \n",
      " F F | A A A A D E . Which words are more than F? A \n",
      " F F | A A A A D E . Which words are more than F? A \n",
      " F F | A D E E E . Which words are more than F? E \n",
      " F F F | A A D D D D D D E . Which words are more than F? D \n",
      " F F F | A A D D E E E E . Which words are more than F? E \n",
      " F F | A D E G G G . Which words are more than F? G \n",
      " F F | A D D D E . Which words are more than F? D \n",
      " F F | A D E G G G G . Which words are more than F? G \n",
      " F F | A D D D D D D E . Which words are more than F? D \n",
      " F F F | A A D E E E E E . Which words are more than F? E \n",
      " F F F | A A D D E E G G G G . Which words are more than F? G \n",
      " F F | A D E G G G . Which words are more than F? G \n",
      " F F F | A A D D E E G G G G . Which words are more than F? G \n",
      " F F | A D D D E . Which words are more than F? D \n",
      " F F F | A A D D E E E E E . Which words are more than F? E \n",
      " F F F | A A D E E G G G G . Which words are more than F? G \n",
      " F F F | A A A A D D E E . Which words are more than F? A \n",
      " F F F | A A A A A A A D E . Which words are more than F? A \n",
      " F F | A D D D D D E . Which words are more than F?\n",
      " Correct: [ 1.  7.  7.  9.  9.  8. 10.  7. 10.  9. 10. 10.  8. 10.  9. 10. 10. 10.\n",
      " 10.  9.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo5_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "041d9a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " F F | A A A A D D E E G G G G G G G G G . Which words are more than F? A G \n",
      " F F | A A A D D D E G G G . Which words are more than F?\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "bc64c3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " F F | A A A A D D E E G G G G G G G G G. Which words are more than F? A G \n",
      " F F | A A A D D D E G G G. Which words are more than F? A G \n",
      " F F | A A A D D E E G G\n"
     ]
    }
   ],
   "source": [
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72ed4b",
   "metadata": {},
   "source": [
    "# 哪个字母和F一样多?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "id": "f40e5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "   \n",
    "    ans = \"\"\n",
    "     \n",
    "    count = np.zeros(4)\n",
    "    data = np.random.randint(2,4,1)\n",
    "#     data1 = np.random.randint(12,20,1)\n",
    "    n1 = data[0] #size of sample\n",
    "    if(n1 == 2):\n",
    "        n2 = 3\n",
    "    else:\n",
    "        n2 = 5\n",
    "#     n2 = data1[0]\n",
    "    elements = set([\"E\", \"A\", \"D\", \"G\"])\n",
    "    global listc,lista\n",
    "    listc = [\"A\", \"D\", \"E\", \"G\"] #元组位序\n",
    "    lista = [\"R\", \"T\", \"K\", \"P\", \"U\"]\n",
    "    random_pop1 = [element for i in range(n2) for element in random.sample(elements, 1)]\n",
    "    random_pop2 = [element for i in range(1,2) for element in random.sample(lista, 1)]\n",
    "    for i in range(n1): \n",
    "        list1.append(\"F\")\n",
    "    \n",
    "    list1.append(\"|\")\n",
    "    \n",
    "    for i in range(n2):\n",
    "        list2.append(random_pop1[i]) \n",
    "    \n",
    "    for i in range(n2):\n",
    "        if(list2[i] ==  \"A\"):\n",
    "            count[0] += 1\n",
    "        elif(list2[i] == \"D\"):\n",
    "            count[1] += 1\n",
    "        elif(list2[i] == \"E\"):\n",
    "            count[2] += 1\n",
    "        else:\n",
    "            count[3] += 1\n",
    "            \n",
    "    \n",
    "    flag = 0\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        if(count[i] == n1):\n",
    "            ans = listc[i]\n",
    "            flag = 1\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    if(flag == 0):\n",
    "        for i in range(n1):\n",
    "            list2.append(random_pop2[0])\n",
    "        ans = random_pop2[0]\n",
    "        \n",
    "    \n",
    "    list2.sort()\n",
    "    list3 = \"\".join(list2)        \n",
    "    list4 = list(list3)\n",
    "    \n",
    "    list1.extend(list4)\n",
    "    \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Which character has the same number as F?\")\n",
    "    flag = 0\n",
    "    list1.extend(ans)\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        count[i] = 0\n",
    "    flag = 0\n",
    "    return list1\n",
    "\n",
    "def create(n):\n",
    "    list2 = [] #最终的集合\n",
    "    count = np.zeros(4)\n",
    "    function()\n",
    "    global ans\n",
    "    ans = \"\"\n",
    "    for i in range(1,n,1):\n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "     \n",
    "    list1 = []\n",
    "    list3 = []\n",
    "    list4 = []\n",
    "    list5 = []\n",
    "    data = np.random.randint(2,4,1)\n",
    "#     data1 = np.random.randint(9,12,1)\n",
    "    n1 = data[0] #size of sample\n",
    "    if(n1 == 2):\n",
    "        n2 = 3\n",
    "    else:\n",
    "        n2 = 5\n",
    "#     n2 = data1[0]\n",
    "    \n",
    "    elements = set([\"E\", \"A\", \"D\", \"G\"])\n",
    "    random_pop1 = [element for i in range(n2) for element in random.sample(elements, 1)]\n",
    "    random_pop2 = [element for i in range(1,2) for element in random.sample(lista, 1)]\n",
    "    for i in range(n1): \n",
    "        list1.append(\"F\")\n",
    "    \n",
    "    list1.append(\"|\")\n",
    "    \n",
    "    for i in range(n2):\n",
    "        list3.append(random_pop1[i]) \n",
    "        \n",
    "    for i in range(n2):\n",
    "        if(list3[i] ==  \"A\"):\n",
    "            count[0] += 1\n",
    "        elif(list3[i] == \"D\"):\n",
    "            count[1] += 1\n",
    "        elif(list3[i] == \"E\"):\n",
    "            count[2] += 1\n",
    "        else:\n",
    "            count[3] += 1\n",
    "    flag = 0\n",
    "  \n",
    "    for i in range(0,4):\n",
    "        if(count[i] == n1):\n",
    "            ans=listc[i]\n",
    "            flag = 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    if(flag == 0):\n",
    "        for i in range(n1):\n",
    "            list3.append(random_pop2[0])\n",
    "        ans = random_pop2[0]\n",
    "        \n",
    "    list3.sort()\n",
    "    list4 = \"\".join(list3)\n",
    "    list5 = list(list4)\n",
    "    list1.extend(list5)\n",
    "    \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Which character has the same number as F?\")\n",
    "    list2.append(\"\\n\")\n",
    "    list2.extend(list1)\n",
    "    flag = 0\n",
    "    str = \" \"\n",
    "    prompt = str.join(list2)\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "id": "e88e9f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " F F F | D D E E G P P P . Which character has the same number as F? P \n",
      " F F | A A G . Which character has the same number as F? A \n",
      " F F F | D E E E G . Which character has the same number as F? E \n",
      " F F | D E G U U . Which character has the same number as F? U \n",
      " F F | D D G . Which character has the same number as F? D \n",
      " F F F | A A D E G P P P . Which character has the same number as F? P \n",
      " F F F | A D D D G . Which character has the same number as F? D \n",
      " F F | D D E . Which character has the same number as F? D \n",
      " F F | D E G T T . Which character has the same number as F? T \n",
      " F F F | A D D E E K K K . Which character has the same number as F? K \n",
      " F F | A A E . Which character has the same number as F? A \n",
      " F F | A D G K K . Which character has the same number as F? K \n",
      " F F F | A D E G G T T T . Which character has the same number as F? T \n",
      " F F | A A D . Which character has the same number as F? A \n",
      " F F F | A A D D E T T T . Which character has the same number as F?\n",
      "T\n"
     ]
    }
   ],
   "source": [
    "print(create(15))\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "id": "c16f61e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 42, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 66, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 79, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 113, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 123, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 147, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 183, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 191, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 209, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 239, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 262, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 276, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 288, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 314, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 335, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 366, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 397, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 411, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 421, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 463, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 45, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 60, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 82, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 103, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 123, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 146, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 163, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 199, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 221, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 229, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 264, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 263, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 299, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 329, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 330, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 374, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 393, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 394, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 429, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 468, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 42, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 63, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 80, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 111, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 132, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 146, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 167, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 181, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 231, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 224, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 264, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 293, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 296, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 322, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 364, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 366, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 397, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 410, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 442, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 488, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 48, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 61, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 88, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 106, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 132, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 157, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 167, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 193, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 222, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 243, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 250, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 294, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 309, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 333, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 340, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 365, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 380, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 406, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 447, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 454, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 44, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 60, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 80, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 107, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 132, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 155, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 175, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 196, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 207, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 231, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 260, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 283, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 285, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 314, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 339, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 379, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 400, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 414, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 439, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 457, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 39, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 67, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 86, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 114, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 135, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 163, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 169, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 198, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 203, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 248, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 255, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 281, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 309, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 329, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 338, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 378, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 384, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 419, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 429, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 450, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 44, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 60, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 86, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 115, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 132, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 150, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 169, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 201, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 226, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 244, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 252, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 270, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 319, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 324, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 350, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 369, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 393, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 437, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 433, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 454, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 41, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 58, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 90, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 107, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 138, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 155, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 173, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 184, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 215, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 239, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 261, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 274, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 310, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 322, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 350, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 358, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 381, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 432, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 428, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 451, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 44, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 63, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 78, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 107, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 132, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 157, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 171, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 192, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 228, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 242, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 256, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 277, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 298, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 311, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 353, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 382, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 387, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 428, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 424, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 448, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 39, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 69, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 82, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 105, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 142, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 154, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 175, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 201, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 220, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 231, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 268, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 290, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 308, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 334, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 349, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 362, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 402, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 432, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 432, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 442, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 1225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = \"\"\n",
    "list1 = []\n",
    "list2 = []\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=30)\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(number-1,len(gen_text)+1):\n",
    "            if(i >= len(gen_text)):\n",
    "                break\n",
    "            elif(gen_text[i] == \"\\n\"):\n",
    "                break\n",
    "            elif(gen_text[i] == \" \"):\n",
    "                pass\n",
    "            else:\n",
    "                x = gen_text[i]\n",
    "                \n",
    "       \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "fo = open(\"foo6.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp6.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "id": "bd339b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " F F | E E G . Which character has the same number as F? E \n",
      " F F | A A E . Which character has the same number as F? A \n",
      " F F F | A D E E E . Which character has the same number as F? E \n",
      " F F F | A A A G G . Which character has the same number as F? A \n",
      " F F F | A D E E E . Which character has the same number as F? E \n",
      " F F F | A D E G G K K K . Which character has the same number as F? K \n",
      " F F F | D D E E G P P P . Which character has the same number as F? P \n",
      " F F | A D D . Which character has the same number as F? D \n",
      " F F | D E G T T . Which character has the same number as F? T \n",
      " F F | D D G . Which character has the same number as F? D \n",
      " F F F | D D E E E . Which character has the same number as F? E \n",
      " F F | E E G . Which character has the same number as F? E \n",
      " F F | D G G . Which character has the same number as F? G \n",
      " F F | A E G K K . Which character has the same number as F? K \n",
      " F F F | A D G G G . Which character has the same number as F? G \n",
      " F F | E G G . Which character has the same number as F? G \n",
      " F F | A E G K K . Which character has the same number as F? K \n",
      " F F F | A A E E G K K K . Which character has the same number as F? K \n",
      " F F F | A A D D E P P P . Which character has the same number as F? P \n",
      " F F | E E G . Which character has the same number as F? E \n",
      " F F | E G G . Which character has the same number as F?\n",
      " Correct: [ 1.  4.  7.  9. 10.  8.  8.  6.  9.  7.  7.  9.  8.  5.  9.  7.  7.  8.\n",
      " 10.  9.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo6.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "id": "791599a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = \"\"\n",
    "list1 = []\n",
    "list2 = []\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    \n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x = response.choices[0].text[i]\n",
    "                \n",
    "#         x.sort()  \n",
    "#         list1 = \"\".join(x)\n",
    "#         list2 = list(list1)       \n",
    "#         x = list2\n",
    "        \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "            \n",
    "        \n",
    "#         x.clear()\n",
    "#         ans.clear()\n",
    "        \n",
    "        \n",
    "fo = open(\"foo6_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp6_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "id": "5c42bb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " F F | D D E . Which character has the same number as F? D \n",
      " F F | A A E . Which character has the same number as F?\n",
      " Correct: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo6_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "id": "a870cedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    }
   ],
   "source": [
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d217fb0",
   "metadata": {},
   "source": [
    "# count particular（find (== val)和count的组合）: 需要测试数数的基础版本 AAA ->3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "id": "35f17e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "   \n",
    "    ans = []\n",
    "    count = np.zeros(4)\n",
    "    data = np.random.randint(3,10,1)\n",
    "    n1 = data[0] #size of sample\n",
    "    \n",
    "    elements = set([\"E\", \"A\", \"D\", \"G\"])\n",
    "    global listc\n",
    "    listc = [\"A\", \"D\", \"E\", \"G\"] #元组位序\n",
    "    random_pop1 = [element for i in range(1,2) for element in random.sample(elements, 1)]\n",
    "\n",
    "    for i in range(n1):\n",
    "        list1.append(random_pop1[0]) \n",
    "    \n",
    "    ans = str(n1)\n",
    "    \n",
    "    \n",
    "    list1.append(\".\")\n",
    "#     list1.append(\"how many %ss are there?\" %random_pop1[0])\n",
    "    list1.append(\"how many characters are there?\")\n",
    "    list1.append(ans)\n",
    "\n",
    "    return list1\n",
    "\n",
    "def create(n):\n",
    "    list2 = [] #最终的集合\n",
    "    count = np.zeros(5)\n",
    "    function()\n",
    "    global ans\n",
    "    ans = \"\"\n",
    "    for i in range(1,n,1):\n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "     \n",
    "    list1 = []\n",
    "    \n",
    "    data = np.random.randint(3,10,1)\n",
    "    \n",
    "    n1 = data[0] #size of sample\n",
    "    \n",
    "    \n",
    "    elements = set([\"E\", \"A\", \"D\", \"G\"])\n",
    "    random_pop1 = [element for i in range(1,2) for element in random.sample(elements, 1)]\n",
    "    for i in range(n1): \n",
    "        list1.append(random_pop1[0])\n",
    "    \n",
    "    ans = str(n1)\n",
    "    \n",
    "    list1.append(\".\")\n",
    "#     list1.append(\"how many %ss are there?\" %random_pop1[0])\n",
    "    list1.append(\"how many characters are there?\")\n",
    "    list2.append(\"\\n\")\n",
    "    list2.extend(list1)\n",
    "\n",
    "    prompt = \" \".join(list2)\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "id": "34cd5c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " D D D D D . how many characters are there? 5 \n",
      " G G G G G G G G . how many characters are there? 8 \n",
      " E E E E E . how many characters are there?\n"
     ]
    }
   ],
   "source": [
    "print(create(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "id": "9b8593e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 30, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 45, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 67, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 73, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 81, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 108, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 133, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 142, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 154, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 166, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 190, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 209, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 233, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 247, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 253, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 280, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 295, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 302, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 309, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 338, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 33, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 40, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 60, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 75, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 89, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 113, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 122, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 148, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 159, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 171, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 187, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 215, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 218, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 239, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 236, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 268, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 302, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 299, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 323, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 340, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 50, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 57, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 83, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 94, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 108, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 128, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 135, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 161, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 185, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 205, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 215, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 214, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 243, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 247, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 265, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 281, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 301, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 320, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 337, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 35, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 51, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 68, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 82, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 95, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 112, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 125, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 140, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 155, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 181, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 186, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 196, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 223, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 236, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 258, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 268, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 272, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 297, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 331, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 327, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 47, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 67, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 73, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 96, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 98, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 108, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 140, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 156, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 180, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 199, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 205, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 225, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 234, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 260, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 275, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 294, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 317, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 314, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 334, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 52, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 68, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 70, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 95, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 108, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 129, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 146, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 154, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 176, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 194, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 200, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 227, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 229, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 251, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 273, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 295, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 301, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 332, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 348, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 30, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 44, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 66, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 78, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 104, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 111, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 129, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 147, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 153, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 175, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 175, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 202, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 231, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 222, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 260, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 265, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 291, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 297, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 324, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 331, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 32, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 45, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 61, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 74, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 93, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 117, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 130, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 146, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 163, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 179, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 185, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 202, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 226, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 235, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 252, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 278, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 287, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 293, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 323, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 328, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 33, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 50, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 56, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 71, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 98, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 120, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 121, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 141, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 146, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 179, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 184, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 194, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 219, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 239, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 251, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 276, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 282, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 300, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 307, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 322, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 30, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 46, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 67, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 73, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 83, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 111, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 122, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 143, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 175, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 175, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 195, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 202, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 220, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 225, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 252, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 269, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 292, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 294, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 314, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 318, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1090"
      ]
     },
     "execution_count": 1238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数,最小值为3\n",
    "# n = int(input()) #测试几次，最小值为2\n",
    "Count = 10\n",
    "\n",
    "x = \"\"\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        \n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=30)\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        #模型输出\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        x = gen_text[number-1]\n",
    "        \n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "\n",
    "        \n",
    "    \n",
    "fo = open(\"foo7.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp7.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "id": "da95be4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " D D D D D D . how many characters are there? 6 \n",
      " G G G G G . how many characters are there? 5 \n",
      " E E E E E . how many characters are there? 5 \n",
      " D D D D D . how many characters are there? 5 \n",
      " D D D D D D . how many characters are there? 6 \n",
      " A A A A A A A . how many characters are there? 7 \n",
      " G G G G G . how many characters are there? 5 \n",
      " G G G G . how many characters are there? 4 \n",
      " A A A A A . how many characters are there? 5 \n",
      " D D D . how many characters are there? 3 \n",
      " D D D D . how many characters are there? 4 \n",
      " E E E E E E . how many characters are there? 6 \n",
      " G G G G G G G G G . how many characters are there? 9 \n",
      " G G G . how many characters are there? 3 \n",
      " E E E E E E E E E . how many characters are there? 9 \n",
      " A A A A . how many characters are there? 4 \n",
      " D D D D . how many characters are there? 4 \n",
      " G G G G G G . how many characters are there? 6 \n",
      " A A A A . how many characters are there? 4 \n",
      " D D D . how many characters are there? 3 \n",
      " G G G G G G G . how many characters are there?\n",
      " Correct: [0. 0. 1. 3. 1. 3. 4. 2. 1. 1. 5. 3. 5. 2. 3. 6. 1. 3. 3. 4.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo7.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "id": "1da829b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n",
      "3 3\n",
      "8 9\n",
      "5 5\n",
      "4 4\n",
      "4 5\n",
      "6 7\n",
      "4 5\n",
      "5 5\n",
      "8 9\n",
      "6 6\n",
      "6 7\n",
      "6 7\n",
      "8 8\n",
      "5 5\n",
      "6 6\n",
      "8 9\n",
      "4 5\n",
      "7 8\n",
      "4 4\n",
      "6 5\n",
      "6 5\n",
      "7 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n",
      "5 7\n",
      "4 3\n",
      "8 9\n",
      "3 4\n",
      "5 4\n",
      "6 7\n",
      "6 7\n",
      "7 7\n",
      "6 6\n",
      "3 3\n",
      "9 9\n",
      "7 8\n",
      "3 3\n",
      "5 5\n",
      "5 5\n",
      "4 3\n",
      "5 5\n",
      "1 6\n",
      "6 6\n",
      "3 3\n",
      "5 6\n",
      "8 9\n",
      "4 5\n",
      "3 3\n",
      "3 3\n",
      "6 6\n",
      "6 5\n",
      "5 5\n",
      "6 6\n",
      "4 4\n",
      "5 6\n",
      "8 9\n",
      "4 4\n",
      "9 9\n",
      "0 9\n",
      "4 7\n",
      "4 9\n",
      "4 3\n",
      "4 6\n",
      "5 5\n",
      "3 3\n",
      "7 9\n",
      "5 5\n",
      "5 5\n",
      "6 6\n",
      "4 3\n",
      "4 4\n",
      "4 4\n",
      "6 6\n",
      "3 3\n",
      "7 7\n",
      "4 5\n",
      "3 3\n",
      "4 4\n",
      "7 7\n",
      "7 6\n",
      "9 6\n",
      "3 3\n",
      "5 6\n",
      "3 3\n",
      "3 3\n",
      "4 4\n",
      "7 8\n",
      "6 6\n",
      "7 8\n",
      "9 9\n",
      "6 8\n",
      "0 9\n",
      "5 5\n",
      "6 6\n",
      "3 3\n",
      "4 4\n",
      "8 8\n",
      "9 9\n",
      "8 3\n",
      "7 8\n",
      "7 6\n",
      "3 4\n",
      "4 6\n",
      "4 7\n",
      "5 5\n",
      "7 7\n",
      "4 3\n",
      "8 8\n",
      "7 6\n",
      "4 4\n",
      "7 8\n",
      "8 8\n",
      "6 7\n",
      "0 9\n",
      "8 9\n",
      "9 9\n",
      "6 7\n",
      "9 9\n",
      "0 6\n",
      "8 8\n",
      "3 3\n",
      "6 6\n",
      "5 5\n",
      "4 4\n",
      "4 5\n",
      "3 3\n",
      "7 8\n",
      "5 8\n",
      "8 8\n",
      "7 9\n",
      "4 3\n",
      "3 3\n",
      "6 7\n",
      "8 9\n",
      "7 8\n",
      "3 3\n",
      "7 7\n",
      "4 3\n",
      "4 4\n",
      "9 8\n",
      "5 6\n",
      "6 7\n",
      "9 9\n",
      "4 7\n",
      "6 6\n",
      "8 8\n",
      "4 4\n",
      "9 9\n",
      "4 4\n",
      "4 4\n",
      "4 4\n",
      "7 8\n",
      "7 7\n",
      "4 3\n",
      "6 6\n",
      "3 3\n",
      "8 8\n",
      "6 6\n",
      "0 9\n",
      "4 7\n",
      "3 3\n",
      "4 7\n",
      "5 5\n",
      "3 3\n",
      "3 3\n",
      "4 5\n",
      "5 5\n",
      "0 9\n",
      "5 6\n",
      "7 8\n",
      "8 8\n",
      "6 6\n",
      "8 9\n",
      "8 8\n",
      "3 3\n",
      "7 8\n",
      "5 7\n",
      "5 6\n",
      "8 3\n",
      "4 7\n",
      "2 3\n",
      "6 7\n",
      "5 4\n",
      "7 8\n",
      "4 3\n",
      "2 3\n",
      "6 8\n",
      "6 6\n",
      "8 8\n",
      "7 7\n",
      "5 5\n",
      "8 8\n",
      "7 8\n",
      "4 4\n",
      "8 9\n",
      "6 6\n",
      "5 6\n",
      "5 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1116"
      ]
     },
     "execution_count": 1241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数,最小值为3\n",
    "# n = int(input()) #测试几次，最小值为2\n",
    "Count = 10\n",
    "\n",
    "x = \"\"\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        \n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x = response.choices[0].text[i]\n",
    "        \n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "        print(x,ans)\n",
    "        \n",
    "    \n",
    "fo = open(\"foo7_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp7_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "65851f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "eccbdc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(Count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd1b690",
   "metadata": {},
   "source": [
    "# 请找出下列数组中，0与1的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "id": "e5a7aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "    global count \n",
    "    count = np.zeros(5)\n",
    "    data = np.random.randint(6,10,1)\n",
    "    global n1\n",
    "    n1 = data[0]#size of sample\n",
    "    \n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    \n",
    "    data1 = np.random.randint(0,6,2) #生成0与1的位置 data1[0]是0的位置，data1[1]是1的位置\n",
    "    while(1):\n",
    "        if(data1[0] == data1[1]):\n",
    "            data1 = np.random.randint(0,6,2)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    for i in range(n1): \n",
    "        if(i == data1[0]):\n",
    "            list1.append(np.array([0]))\n",
    "        elif(i == data1[1]):\n",
    "            list1.append(np.array([1]))\n",
    "        else:\n",
    "            list1.append(np.random.randint(2,7,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(n1): \n",
    "\n",
    "        list2.append(list1[i][0])   \n",
    "        \n",
    "    \n",
    "    \n",
    "    list2.append(\".\")\n",
    "    list2.append(\"What is the positional relationship between 0 and 1?\")\n",
    "\n",
    "    if(data1[0] > data1[1]):\n",
    "        list2.append(\"Right\")\n",
    "    else:\n",
    "        list2.append(\"Left\")\n",
    "        \n",
    "    return list2\n",
    "\n",
    "def create(n):\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "    list4 = []\n",
    "    for i in range(1,n,1): \n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "       \n",
    "        \n",
    "    list2.append(\"\\n\")\n",
    "    \n",
    "    #生成测试用例\n",
    "    data = np.random.randint(6,10,1)\n",
    "    global n1\n",
    "    global ans \n",
    "    n1 = data[0] #size of sample\n",
    "    data1 = np.random.randint(0,6,2) #生成0与1的位置 data1[0]是0的位置，data1[1]是1的位置\n",
    "    while(1):\n",
    "        if(data1[0] == data1[1]):\n",
    "            data1 = np.random.randint(0,6,2)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    for i in range(n1): \n",
    "        if(i == data1[0]):\n",
    "            list1.append(np.array([0]))\n",
    "        elif(i == data1[1]):\n",
    "            list1.append(np.array([1]))\n",
    "        else:\n",
    "            list1.append(np.random.randint(2,7,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(n1): \n",
    "\n",
    "        list3.append(list1[i][0])   \n",
    "        \n",
    "    \n",
    "    \n",
    "    list3.append(\".\")\n",
    "    list3.append(\"What is the positional relationship between 0 and 1?\")\n",
    "              \n",
    "\n",
    "    list2.extend(list3)\n",
    "    \n",
    "    if(data1[0] > data1[1]):\n",
    "        ans = \"Right\"\n",
    "    else:\n",
    "        ans = \"Left\"\n",
    "        \n",
    "   \n",
    "    for i in range(len(list2)):\n",
    "        list4.append(str(list2[i]))\n",
    "    \n",
    "    \n",
    "    prompt = \" \".join(list4)\n",
    "    \n",
    "    return(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "id": "71f5ab22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 1248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "id": "c98fe760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Left\n",
      "Right Left\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1710"
      ]
     },
     "execution_count": 1253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数,最小值为3\n",
    "# n = int(input()) #测试几次，最小值为2\n",
    "Count = 10\n",
    "\n",
    "\n",
    "x = \"\"\n",
    "x1 = []\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        \n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=(num*25))\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        #模型输出\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        for i in range(number-1,len(gen_text)):\n",
    "            if(i+1 >= len(gen_text)):\n",
    "                break\n",
    "            elif(gen_text[i+1] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x += gen_text[i]\n",
    "                \n",
    "                \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "        print(x,ans)\n",
    "        \n",
    "        x = \"\"\n",
    "    \n",
    "fo = open(\"foo8.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp8.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "id": "bc55c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Right\n",
      "Right Left\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Right Left\n",
      "Right Right\n",
      "Left Right\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Right Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Right\n",
      "Left Right\n",
      "Right Right\n",
      "Left Left\n",
      "Left Right\n",
      "Right Right\n",
      "Left Right\n",
      "Right Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Right Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Right Left\n",
      "Right Right\n",
      "Left Left\n",
      "Left Right\n",
      "Right Right\n",
      "Right Right\n",
      "Left Left\n",
      "Left Left\n",
      "Right Right\n",
      "Right Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Right Left\n",
      "Right Left\n",
      "Left Right\n",
      "Right Right\n",
      "Left Right\n",
      "Right Right\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Right Right\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Left Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Right Right\n",
      "Left Right\n",
      "Left Left\n",
      "Right Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Right Right\n",
      "Right Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Right Right\n",
      "Right Right\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Right Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Right Left\n",
      "Right Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Right Left\n",
      "Left Right\n",
      "Right Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Right Right\n",
      "Right Right\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Right Right\n",
      "Left Right\n",
      "Right Right\n",
      "Right Right\n",
      "Left Left\n",
      "Right Left\n",
      "Right Left\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Right\n",
      "Left Left\n",
      "Right Right\n",
      "Left Left\n",
      "Right Left\n",
      "Left Right\n",
      "Right Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Right\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Left Right\n",
      "Left Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Left\n",
      "Left Right\n",
      "Right Right\n",
      "Left Left\n",
      "Left Right\n",
      "Left Left\n",
      "Right Right\n",
      "Left Left\n",
      "Left Left\n",
      "Left Left\n",
      "Right Right\n",
      "Left Left\n",
      "Right Left\n",
      "Left Left\n",
      "Left Right\n",
      "Right Left\n",
      "Right Right\n",
      "Left Left\n",
      "Left Left\n",
      "Right Left\n",
      "Left Right\n",
      "Left Right\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1723"
      ]
     },
     "execution_count": 1255,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1255,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数,最小值为3\n",
    "# n = int(input()) #测试几次，最小值为2\n",
    "Count = 10\n",
    "\n",
    "\n",
    "x = \"\"\n",
    "x1 = []\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        \n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x += response.choices[0].text[i]\n",
    "                \n",
    "                \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "        print(x,ans)\n",
    "        \n",
    "        x = \"\"\n",
    "    \n",
    "fo = open(\"foo8_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp8_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f246abb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 4 3 1 3 0 4 . What is the positional relationship between 0 and 1? Right \n",
      " 2 3 0 5 1 6 2 4 . What is the positional relationship between 0 and 1?\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "39b7fcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2 0 1 6 2 6 5. What is the positional relationship between 0 and 1? Left \n",
      " 2 1 5 6 4 0. What is the positional relationship between 0 and 1? Right \n",
      " 2 1 5 6 4 0. What\n"
     ]
    }
   ],
   "source": [
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8533d53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "99b14c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e8591",
   "metadata": {},
   "source": [
    "# 找出第n个人的名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "id": "8a9d26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "    global count \n",
    "    count = np.zeros(5)\n",
    "    data = np.random.randint(6,10,[1,1])\n",
    "    global n1\n",
    "    n1 = data[0][0] #size of sample\n",
    "    elements = string.ascii_uppercase\n",
    "    \n",
    "    ans = \"\"\n",
    "    \n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    \n",
    "    for i in range(n1):    \n",
    "        list1.append(random_pop1[i]) \n",
    "        \n",
    "    ans = list1[2]\n",
    "    \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"What is the third letter?\")\n",
    "    \n",
    "    list1.append(ans)\n",
    "#     print(list1)\n",
    "    return list1\n",
    "\n",
    "def create(n):\n",
    "    list2 = []\n",
    "    function()\n",
    "    global ans\n",
    "    ans = \"\"\n",
    "    for i in range(1,n,1):\n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "     \n",
    "    list1=[]\n",
    "    data = np.random.randint(6,10,[1,1])\n",
    "    \n",
    "    n1 = data[0][0] #size of sample\n",
    "    elements = string.ascii_uppercase\n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    for i in range(n1):    \n",
    "        list1.append(random_pop1[i]) \n",
    "        \n",
    "    ans = list1[2]\n",
    "    \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"What is the third letter?\")\n",
    "    \n",
    "    list2.append(\"\\n\")\n",
    "    list2.extend(list1)\n",
    "    \n",
    "    str = \" \"\n",
    "    prompt = str.join(list2)\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "id": "a8c3bbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 34, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 52, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 72, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 80, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 104, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 123, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 140, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 154, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 180, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 188, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 197, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 223, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 245, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 259, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 282, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 290, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 310, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 324, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 350, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 367, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 35, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 52, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 64, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 84, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 107, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 116, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 138, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 151, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 171, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 196, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 212, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 221, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 246, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 265, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 281, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 293, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 308, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 327, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 341, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 365, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 32, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 55, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 68, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 88, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 103, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 115, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 141, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 156, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 174, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 187, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 212, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 228, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 249, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 252, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 276, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 299, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 310, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 338, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 353, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 368, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 32, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 51, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 63, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 86, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 104, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 118, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 142, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 149, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 174, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 192, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 209, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 219, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 239, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 266, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 280, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 299, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 306, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 325, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 353, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 373, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 35, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 49, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 68, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 84, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 103, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 120, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 139, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 159, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 174, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 187, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 210, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 224, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 250, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 263, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 284, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 287, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 321, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 337, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 351, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 371, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 30, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 51, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 68, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 87, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 107, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 124, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 136, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 151, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 174, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 190, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 207, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 222, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 245, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 265, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 280, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 289, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 311, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 336, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 350, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 358, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 33, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 52, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 67, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 89, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 103, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 119, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 144, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 151, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 175, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 189, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 210, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 223, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 247, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 269, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 274, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 299, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 314, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 328, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 348, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 373, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 34, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 52, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 67, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 85, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 104, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 118, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 135, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 155, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 170, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 193, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 209, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 227, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 241, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 258, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 277, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 296, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 305, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 331, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 356, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 366, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 34, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 48, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 70, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 88, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 108, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 118, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 132, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 159, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 167, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 191, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 212, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 229, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 244, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 260, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 278, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 300, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 312, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 325, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 347, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 361, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 31, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 52, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 68, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 86, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 105, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 117, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 131, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 152, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 166, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 196, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 215, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 221, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 239, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 257, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 271, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 289, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 318, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 331, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 345, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 362, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1073"
      ]
     },
     "execution_count": 1462,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1462,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAARTUlEQVR4nO3dfYxdeV3H8ffHlmoCRBZ3VGw7tGDVVEVZxy4+IVHALmtaFTTd+LAo2hCpovhUgmlI/WfBiImmUapsRAJ2V3wa3WJBwRiNiy24PHSX7g612DbI8rCCxshS/frHPTXXy0znzPTemTs/3q/kZs7D957znXPO/fTMOffepqqQJLXp89a7AUnS5BjyktQwQ16SGmbIS1LDDHlJatjm9VrxjTfeWDt27Fiv1UvShvSud73rY1U107d+3UJ+x44dnDlzZr1WL0kbUpIPraTeyzWS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYb1CPsneJOeSLCQ5vMj8X09yX/d4MMm/jb1TSdKKLfs++SSbgGPAc4BLwOkk81V1/9WaqvrZofqfAp4+gV4lSSvU50x+D7BQVeer6lHgBLD/GvW3AX8wjuYkSdenzydetwIXh8YvATcvVpjkycBO4O1LzD8IHASYnZ1dUaOSpt+Ow/esqP7CHbdOqBNdNe4brweAN1fVfy82s6qOV9VcVc3NzPT+6gVJ0ir1CfnLwPah8W3dtMUcwEs1kjQ1+oT8aWBXkp1JtjAI8vnRoiRfBdwA/MN4W5QkrdayIV9VV4BDwCngAeDuqjqb5GiSfUOlB4AT5f8MLklTo9dXDVfVSeDkyLQjI+OvHF9bkqRx8BOvktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqWK+QT7I3ybkkC0kOL1HzA0nuT3I2yZvG26YkaTU2L1eQZBNwDHgOcAk4nWS+qu4fqtkFvBz4lqp6JMkXT6phSVJ/fc7k9wALVXW+qh4FTgD7R2p+AjhWVY8AVNXD421TkrQay57JA1uBi0Pjl4CbR2q+AiDJ3wObgFdW1V+OLijJQeAgwOzs7Gr63dB2HL5nxc+5cMetE+hEfax0f03LvtqofV+v6/m9W95m47rxuhnYBTwLuA34nSRPGC2qquNVNVdVczMzM2NatSRpKX1C/jKwfWh8Wzdt2CVgvqo+U1X/DDzIIPQlSeuoT8ifBnYl2ZlkC3AAmB+p+VMGZ/EkuZHB5Zvz42tTkrQay4Z8VV0BDgGngAeAu6vqbJKjSfZ1ZaeAjye5H3gH8AtV9fFJNS1J6qfPjVeq6iRwcmTakaHhAl7WPSRJU8JPvEpSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1rFfIJ9mb5FyShSSHF5n/wiQfTXJf9/jx8bcqSVqpzcsVJNkEHAOeA1wCTieZr6r7R0rvqqpDE+hRkrRKfc7k9wALVXW+qh4FTgD7J9uWJGkclj2TB7YCF4fGLwE3L1L3/CTPBB4EfraqLo4WJDkIHASYnZ1debfakHYcvmdF9RfuuHXDr3ul6x3nujeqjbrNpr3vcd14/XNgR1U9DXgb8PrFiqrqeFXNVdXczMzMmFYtSVpKn5C/DGwfGt/WTfs/VfXxqvp0N/q7wDeMpz1J0vXoE/KngV1JdibZAhwA5ocLkjxpaHQf8MD4WpQkrday1+Sr6kqSQ8ApYBNwZ1WdTXIUOFNV88BPJ9kHXAE+Abxwgj1Lknrqc+OVqjoJnByZdmRo+OXAy8fbmiTpevmJV0lqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNaxXyCfZm+RckoUkh69R9/wklWRufC1KklZr2ZBPsgk4BtwC7AZuS7J7kbrHAy8F3jnuJiVJq9PnTH4PsFBV56vqUeAEsH+Rul8BXgX81xj7kyRdh809arYCF4fGLwE3DxckuQnYXlX3JPmFpRaU5CBwEGB2dnbl3U6BHYfvWVH9hTtudd3aMFa6n8F9Pe2u+8Zrks8DXgP83HK1VXW8quaqam5mZuZ6Vy1JWkafkL8MbB8a39ZNu+rxwNcAf5PkAvAMYN6br5K0/vqE/GlgV5KdSbYAB4D5qzOr6pNVdWNV7aiqHcC9wL6qOjORjiVJvS0b8lV1BTgEnAIeAO6uqrNJjibZN+kGJUmr1+fGK1V1Ejg5Mu3IErXPuv62JEnj4CdeJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhrWK+ST7E1yLslCksOLzH9xkvcluS/J3yXZPf5WJUkrtWzIJ9kEHANuAXYDty0S4m+qqq+tqq8HXg28ZtyNSpJWrs+Z/B5goarOV9WjwAlg/3BBVX1qaPSxQI2vRUnSam3uUbMVuDg0fgm4ebQoyUuAlwFbgO9YbEFJDgIHAWZnZ1faqz4H7Th8z4qfc+GOWyfQydpa6e/dwu+syRjbjdeqOlZVTwV+CfjlJWqOV9VcVc3NzMyMa9WSpCX0CfnLwPah8W3dtKWcAL7nOnqSJI1Jn5A/DexKsjPJFuAAMD9ckGTX0OitwEPja1GStFrLXpOvqitJDgGngE3AnVV1NslR4ExVzQOHkjwb+AzwCHD7JJuWJPXT58YrVXUSODky7cjQ8EvH3JckaQz8xKskNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhrWK+ST7E1yLslCksOLzH9ZkvuTvDfJXyd58vhblSSt1LIhn2QTcAy4BdgN3JZk90jZPwFzVfU04M3Aq8fdqCRp5fqcye8BFqrqfFU9CpwA9g8XVNU7quo/u9F7gW3jbVOStBp9Qn4rcHFo/FI3bSkvAt5yPU1JksZj8zgXluSHgDng25eYfxA4CDA7OzvOVa/IjsP3rKj+wh23TqiTtfO5+DtL6ncmfxnYPjS+rZv2/yR5NvAKYF9VfXqxBVXV8aqaq6q5mZmZ1fQrSVqBPiF/GtiVZGeSLcABYH64IMnTgdcyCPiHx9+mJGk1lg35qroCHAJOAQ8Ad1fV2SRHk+zryn4VeBzwh0nuSzK/xOIkSWuo1zX5qjoJnByZdmRo+Nlj7kuSNAZ+4lWSGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYb1CPsneJOeSLCQ5vMj8ZyZ5d5IrSV4w/jYlSauxbMgn2QQcA24BdgO3Jdk9UvYvwAuBN427QUnS6m3uUbMHWKiq8wBJTgD7gfuvFlTVhW7e/0ygR0nSKvW5XLMVuDg0fqmbtmJJDiY5k+TMRz/60dUsQpK0Amt647WqjlfVXFXNzczMrOWqJelzUp+QvwxsHxrf1k2TJE25PiF/GtiVZGeSLcABYH6ybUmSxmHZkK+qK8Ah4BTwAHB3VZ1NcjTJPoAk35jkEvD9wGuTnJ1k05Kkfvq8u4aqOgmcHJl2ZGj4NIPLOJKkKeInXiWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIa1ivkk+xNci7JQpLDi8z//CR3dfPfmWTH2DuVJK3YsiGfZBNwDLgF2A3clmT3SNmLgEeq6suBXwdeNe5GJUkr1+dMfg+wUFXnq+pR4ASwf6RmP/D6bvjNwHcmyfjalCStRqrq2gXJC4C9VfXj3fgPAzdX1aGhmvd3NZe68Q92NR8bWdZB4GA3+pXAuXH9Ip0bgY8tW7U+prW3ae0Lpre3ae0Lprc3+1q5pXp7clXN9F3I5vH1s7yqOg4cn9Tyk5ypqrlJLf96TGtv09oXTG9v09oXTG9v9rVy4+qtz+Way8D2ofFt3bRFa5JsBr4Q+Pj1NidJuj59Qv40sCvJziRbgAPA/EjNPHB7N/wC4O213HUgSdLELXu5pqquJDkEnAI2AXdW1dkkR4EzVTUPvA54Q5IF4BMM/iFYDxO7FDQG09rbtPYF09vbtPYF09ubfa3cWHpb9sarJGnj8hOvktQwQ16SGrYhQ35av2YhyfYk70hyf5KzSV66SM2zknwyyX3d48ga9XYhyfu6dZ5ZZH6S/Ea3zd6b5KY16usrh7bFfUk+leRnRmrWZJsluTPJw93nPq5Oe2KStyV5qPt5wxLPvb2reSjJ7YvVTKC3X03ygW5//UmSJyzx3Gvu+wn09cokl4f21/OWeO41X8cT6OuuoZ4uJLlviedObHt1y180JyZ2rFXVhnowuPn7QeApwBbgPcDukZqfBH67Gz4A3LVGvT0JuKkbfjzw4CK9PQv4i3XYbheAG68x/3nAW4AAzwDeuU779l8ZfNhjzbcZ8EzgJuD9Q9NeDRzuhg8Dr1rkeU8Eznc/b+iGb1iD3p4LbO6GX7VYb332/QT6eiXw8z329TVfx+Pua2T+rwFH1np7dctfNCcmdaxtxDP5qf2ahar6cFW9uxv+d+ABYOuk1zsm+4Hfr4F7gSckedIa9/CdwAer6kNrvF4AqupvGbw7bNjwsfR64HsWeep3AW+rqk9U1SPA24C9k+6tqt5aVVe60XsZfIZlTS2xzfro8zqeSF9dFvwA8AfjWt9KXCMnJnKsbcSQ3wpcHBq/xGcH6f/VdC+CTwJftCbddbpLRE8H3rnI7G9K8p4kb0ny1WvUUgFvTfKuDL5eYlSf7TppB1j6hbce2wzgS6rqw93wvwJfskjNNGy7H2Pwl9hiltv3k3Cou4x05xKXHdZzm30b8JGqemiJ+Wu2vUZyYiLH2kYM+amX5HHAHwE/U1WfGpn9bgaXI74O+E3gT9eorW+tqpsYfJvoS5I8c43W20sGH7TbB/zhIrPXa5v9PzX4e3nq3nOc5BXAFeCNS5Ss9b7/LeCpwNcDH2ZwaWSa3Ma1z+LXZHtdKyfGeaxtxJCf6q9ZSPIYBjvujVX1x6Pzq+pTVfUf3fBJ4DFJbpx0X1V1ufv5MPAnDP5cHtZnu07SLcC7q+ojozPWa5t1PnL1slX38+FFatZt2yV5IfDdwA92wfBZeuz7saqqj1TVf1fV/wC/s8T61mWbdXnwfcBdS9WsxfZaIicmcqxtxJCf2q9Z6K71vQ54oKpes0TNl169P5BkD4N9MNF/gJI8Nsnjrw4zuGH3/pGyeeBHMvAM4JNDfzquhSXPrtZjmw0ZPpZuB/5skZpTwHOT3NBdmnhuN22ikuwFfhHYV1X/uURNn30/7r6G7+V87xLr6/M6noRnAx+o7htzR63F9rpGTkzmWJvUHeRJPhi8E+RBBnfnX9FNO8rgYAf4AgZ/9i8A/wg8ZY36+lYGf2K9F7ivezwPeDHw4q7mEHCWwbsJ7gW+eQ36ekq3vvd06766zYb7CoP/HOaDwPuAuTXcn49lENpfODRtzbcZg39kPgx8hsG1zhcxuJfz18BDwF8BT+xq54DfHXruj3XH2wLwo2vU2wKD67NXj7Wr7yj7MuDktfb9hPt6Q3cMvZdBcD1ptK9u/LNex5Psq5v+e1ePq6HaNdte3TqWyomJHGt+rYEkNWwjXq6RJPVkyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SG/S+aj6wWDpA8hwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=30)\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        x = gen_text[number-1]\n",
    "        \n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "   \n",
    "\n",
    "     \n",
    "fo = open(\"foo9.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp9.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "id": "bbe07fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " S S L M X R N Z . What is the third letter? L \n",
      " I P L S K T . What is the third letter? L \n",
      " X U H Z D Z . What is the third letter? H \n",
      " W E D G Z T S R K . What is the third letter? D \n",
      " L O H R Z X Z E T . What is the third letter? H \n",
      " Z O R P E Q C . What is the third letter? R \n",
      " T S I I A M B V . What is the third letter? I \n",
      " X N I O B J Y V S . What is the third letter? I \n",
      " G P M L S A E . What is the third letter? M \n",
      " R W J A Y E N F C . What is the third letter? J \n",
      " V P E V R W U I . What is the third letter? E \n",
      " V N G P M Y . What is the third letter? G \n",
      " H Z G X J P D . What is the third letter? G \n",
      " L Q T T N X R . What is the third letter? T \n",
      " C Z R E V Z . What is the third letter? R \n",
      " U L X J H O . What is the third letter? X \n",
      " R I C F O W F . What is the third letter? C \n",
      " G H W K I D U Q S . What is the third letter? W \n",
      " C Q B R Z I P . What is the third letter? B \n",
      " D Z C C V A . What is the third letter? C \n",
      " X M F K N O L . What is the third letter?\n",
      " Correct: [0. 2. 4. 6. 4. 2. 4. 5. 3. 5. 6. 5. 3. 6. 4. 7. 5. 6. 6. 5.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo9.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "id": "07b9f719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077"
      ]
     },
     "execution_count": 1261,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1261,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQg0lEQVR4nO3df6zdd13H8efLlmoCCwx7xbn2cgdWkqoI89qh4lzkhx0zLQqSLv7YBGyINIIoWoJpSP1ng4iJplEKLCIBu4GCV1csEzFGk812cwy60e2uFttmbDKWTUNkVN7+cb4lh8u5vefennPv7YfnI7m53x/vc77v+/l+z6vf+/3ec5qqQpLUpu9Y6QYkSeNjyEtSwwx5SWqYIS9JDTPkJalha1dqw+vXr6+pqamV2rwkXZDuvPPOL1XVxLD1KxbyU1NTHDlyZKU2L0kXpCRfWEy9l2skqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSw4YK+SRbkxxLMptk9zw1r0lyb5KjST482jYlSUux4N/JJ1kD7ANeBpwCDieZqap7+2o2AW8DfrKqHkvyPeNqWJI0vGHO5LcAs1V1vKqeBA4A2+fU/Dqwr6oeA6iqR0bbpiRpKYZ5x+ulwMm++VPAFXNqfgAgyb8Ca4B3VNXfz32iJDuBnQCTk5NL6VdalKndty6q/sQN14ypkwvDYscLvnnMHO/VZ1Q3XtcCm4CrgGuB9yZ5xtyiqtpfVdNVNT0xMfRHL0iSlmiYkD8NbOyb39At63cKmKmqr1XVfwD30wt9SdIKGibkDwObklyWZB2wA5iZU/NxemfxJFlP7/LN8dG1KUlaigVDvqrOALuAQ8B9wC1VdTTJ3iTburJDwKNJ7gU+Dby1qh4dV9OSpOEM9VHDVXUQODhn2Z6+6QLe0n1JklYJ3/EqSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0bKuSTbE1yLMlskt0D1l+f5L+S3N19vX70rUqSFmvtQgVJ1gD7gJcBp4DDSWaq6t45pTdX1a4x9ChJWqJhzuS3ALNVdbyqngQOANvH25YkaRQWPJMHLgVO9s2fAq4YUPeqJFcC9wO/VVUn5xYk2QnsBJicnFx8txe4qd23LvoxJ264ZgydLK/F/twt/MzSajGqG69/C0xV1fOB24APDCqqqv1VNV1V0xMTEyPatCRpPsOE/GlgY9/8hm7ZN1TVo1X11W72fcCPjqY9SdL5GCbkDwObklyWZB2wA5jpL0hySd/sNuC+0bUoSVqqBa/JV9WZJLuAQ8Aa4KaqOppkL3CkqmaA30yyDTgDfBm4fow9S5KGNMyNV6rqIHBwzrI9fdNvA9422tYkSefLd7xKUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlq2FAhn2RrkmNJZpPsPkfdq5JUkunRtShJWqoFQz7JGmAfcDWwGbg2yeYBdRcBbwLuGHWTkqSlGeZMfgswW1XHq+pJ4ACwfUDdHwA3Av87wv4kSedh7RA1lwIn++ZPAVf0FyS5HNhYVbcmeet8T5RkJ7ATYHJycvHdfpub2n3roupP3HDNmDqRRm+xxzeM7hg/n9fWSvY9jPO+8ZrkO4B3A7+9UG1V7a+q6aqanpiYON9NS5IWMEzInwY29s1v6JaddRHwQ8A/JTkBvAiY8earJK28YUL+MLApyWVJ1gE7gJmzK6vq8apaX1VTVTUF3A5sq6ojY+lYkjS0BUO+qs4Au4BDwH3ALVV1NMneJNvG3aAkaemGufFKVR0EDs5Ztmee2qvOvy1J0ij4jldJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJathQIZ9ka5JjSWaT7B6w/g1JPpvk7iT/kmTz6FuVJC3WgiGfZA2wD7ga2AxcOyDEP1xVP1xVLwDeCbx71I1KkhZvmDP5LcBsVR2vqieBA8D2/oKqeqJv9qlAja5FSdJSrR2i5lLgZN/8KeCKuUVJ3gi8BVgH/MygJ0qyE9gJMDk5udhev2Fq962LfsyJG65Z8va0+DEf1Xiv5L4+n5/5fPteqfG+kDlmg43sxmtV7auq5wK/B/z+PDX7q2q6qqYnJiZGtWlJ0jyGCfnTwMa++Q3dsvkcAF55Hj1JkkZkmJA/DGxKclmSdcAOYKa/IMmmvtlrgAdG16IkaakWvCZfVWeS7AIOAWuAm6rqaJK9wJGqmgF2JXkp8DXgMeC6cTYtSRrOMDdeqaqDwME5y/b0Tb9pxH1JkkbAd7xKUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlq2FAhn2RrkmNJZpPsHrD+LUnuTXJPkk8lefboW5UkLdaCIZ9kDbAPuBrYDFybZPOcsn8Hpqvq+cBHgXeOulFJ0uINcya/BZitquNV9SRwANjeX1BVn66qr3SztwMbRtumJGkp1g5Rcylwsm/+FHDFOepfB3xi0IokO4GdAJOTk0O2qFGY2n3roupP3HDNmDrRuLmv1W+kN16T/DIwDbxr0Pqq2l9V01U1PTExMcpNS5IGGOZM/jSwsW9+Q7fsmyR5KfB24Ker6qujaU+SdD6GOZM/DGxKclmSdcAOYKa/IMkLgfcA26rqkdG3KUlaigVDvqrOALuAQ8B9wC1VdTTJ3iTburJ3AU8DPpLk7iQz8zydJGkZDXO5hqo6CBycs2xP3/RLR9yXJGkEfMerJDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDVsqJBPsjXJsSSzSXYPWH9lkruSnEny6tG3KUlaigVDPskaYB9wNbAZuDbJ5jll/wlcD3x41A1KkpZu7RA1W4DZqjoOkOQAsB2492xBVZ3o1n19DD1KkpZomJC/FDjZN38KuGIpG0uyE9gJMDk5uZSnGImp3bcuqv7EDdeM5LGStNyW9cZrVe2vqumqmp6YmFjOTUvSt6VhQv40sLFvfkO3TJK0yg0T8oeBTUkuS7IO2AHMjLctSdIoLBjyVXUG2AUcAu4Dbqmqo0n2JtkGkOTHkpwCfhF4T5Kj42xakjScYW68UlUHgYNzlu3pmz5M7zKOJGkV8R2vktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGjZUyCfZmuRYktkkuwes/84kN3fr70gyNfJOJUmLtmDIJ1kD7AOuBjYD1ybZPKfsdcBjVfX9wB8BN466UUnS4g1zJr8FmK2q41X1JHAA2D6nZjvwgW76o8BLkmR0bUqSliJVde6C5NXA1qp6fTf/K8AVVbWrr+ZzXc2pbv7BruZLc55rJ7Czm30ecGxUP0hnPfClBatWxmrtbbX2Bau3t9XaF6ze3uxr8ebr7dlVNTHsk6wdXT8Lq6r9wP5xPX+SI1U1Pa7nPx+rtbfV2hes3t5Wa1+wenuzr8UbVW/DXK45DWzsm9/QLRtYk2Qt8HTg0fNtTpJ0foYJ+cPApiSXJVkH7ABm5tTMANd1068G/rEWug4kSRq7BS/XVNWZJLuAQ8Aa4KaqOppkL3CkqmaA9wMfTDILfJnePwQrYWyXgkZgtfa2WvuC1dvbau0LVm9v9rV4I+ltwRuvkqQLl+94laSGGfKS1LALMuRX68csJNmY5NNJ7k1yNMmbBtRcleTxJHd3X3uWqbcTST7bbfPIgPVJ8sfdmN2T5PJl6ut5fWNxd5Inkrx5Ts2yjFmSm5I80r3v4+yyZya5LckD3feL53nsdV3NA0muG1Qzht7eleTz3f76WJJnzPPYc+77MfT1jiSn+/bXK+Z57Dlfx2Po6+a+nk4kuXuex45tvLrnH5gTYzvWquqC+qJ38/dB4DnAOuAzwOY5Nb8B/Fk3vQO4eZl6uwS4vJu+CLh/QG9XAX+3AuN2Alh/jvWvAD4BBHgRcMcK7dsv0nuzx7KPGXAlcDnwub5l7wR2d9O7gRsHPO6ZwPHu+8Xd9MXL0NvLgbXd9I2Dehtm34+hr3cAvzPEvj7n63jUfc1Z/4fAnuUer+75B+bEuI61C/FMftV+zEJVPVRVd3XT/w3cB1w67u2OyHbgL6rnduAZSS5Z5h5eAjxYVV9Y5u0CUFX/TO+vw/r1H0sfAF454KE/C9xWVV+uqseA24Ct4+6tqj5ZVWe62dvpvYdlWc0zZsMY5nU8lr66LHgN8Jej2t5inCMnxnKsXYghfylwsm/+FN8apN+o6V4EjwPfvSzddbpLRC8E7hiw+seTfCbJJ5L84DK1VMAnk9yZ3sdLzDXMuI7bDuZ/4a3EmAE8q6oe6qa/CDxrQM1qGLvX0vtNbJCF9v047OouI900z2WHlRyznwIerqoH5lm/bOM1JyfGcqxdiCG/6iV5GvBXwJur6ok5q++idzniR4A/AT6+TG29uKoup/dpom9McuUybXco6b3RbhvwkQGrV2rMvkn1fl9edX9znOTtwBngQ/OULPe+/1PgucALgIfoXRpZTa7l3GfxyzJe58qJUR5rF2LIr+qPWUjyFHo77kNV9ddz11fVE1X1P930QeApSdaPu6+qOt19fwT4GL1fl/sNM67jdDVwV1U9PHfFSo1Z5+Gzl626748MqFmxsUtyPfBzwC91wfAthtj3I1VVD1fV/1XV14H3zrO9FRmzLg9+Abh5vprlGK95cmIsx9qFGPKr9mMWumt97wfuq6p3z1PzvWfvDyTZQm8fjPUfoCRPTXLR2Wl6N+w+N6dsBvjV9LwIeLzvV8flMO/Z1UqMWZ/+Y+k64G8G1BwCXp7k4u7SxMu7ZWOVZCvwu8C2qvrKPDXD7PtR99V/L+fn59neMK/jcXgp8PnqPjF3ruUYr3PkxHiOtXHdQR7nF72/BLmf3t35t3fL9tI72AG+i96v/bPAvwHPWaa+XkzvV6x7gLu7r1cAbwDe0NXsAo7S+2uC24GfWIa+ntNt7zPdts+OWX9fofefwzwIfBaYXsb9+VR6of30vmXLPmb0/pF5CPgavWudr6N3L+dTwAPAPwDP7Gqngff1Pfa13fE2C/zaMvU2S+/67Nlj7exflH0fcPBc+37MfX2wO4buoRdcl8ztq5v/ltfxOPvqlv/52eOqr3bZxqvbxnw5MZZjzY81kKSGXYiXayRJQzLkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsP+H8RaWhdardh6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x = response.choices[0].text[i]\n",
    "        \n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "   \n",
    "\n",
    "     \n",
    "fo = open(\"foo9_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp9_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "id": "e7ab1843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " G G D D A M A . What is the third letter? D \n",
      " E E D E G M M . What is the third letter? D \n",
      " D G G M D G E E A . What is the third letter? G \n",
      " G A A M A G . What is the third letter? A \n",
      " D G A D A E . What is the third letter? A \n",
      " M M A A A A . What is the third letter? A \n",
      " A G A D G A D G E . What is the third letter? A \n",
      " M D M D D M D A . What is the third letter? M \n",
      " E D D G E G D . What is the third letter? D \n",
      " A E A M A E M A M . What is the third letter? A \n",
      " D D D M A G M . What is the third letter? D \n",
      " G G A M A A E . What is the third letter? A \n",
      " M M M G D G M . What is the third letter? M \n",
      " M D E D A M E . What is the third letter? E \n",
      " D D M D A D . What is the third letter? M \n",
      " E M A E A A . What is the third letter? A \n",
      " M M G M D A M . What is the third letter? G \n",
      " A G E A E G M A . What is the third letter? E \n",
      " E G A E A D E G G . What is the third letter? A \n",
      " G A E G M E G E G . What is the third letter? E \n",
      " E E D A M M E D E . What is the third letter?\n",
      " Correct: [3. 1. 1. 5. 4. 2. 3. 5. 3. 6. 3. 3. 3. 2. 6. 6. 4. 3. 4. 4.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo9_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "86d0adc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "[1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "print(T)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17be2677",
   "metadata": {},
   "source": [
    "# F是第几个字母？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1975,
   "id": "db8ddd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "ans = [\"First\",\"Second\",\"Third\",\"Fourth\",\"Fifth\",\"Sixth\",\"Seventh\",\"Eighth\",\"Ninth\"]\n",
    "voc = string.ascii_uppercase.replace('F','')\n",
    "\n",
    "\n",
    "def make_examples(n_examples, vocab=voc):  # 很多题目可以共用代码框架\n",
    "    examples = []\n",
    "    \n",
    "    for _ in range(n_examples):\n",
    "        input_len = random.randint(5, 7)\n",
    "        F = [\"F\"]\n",
    "#         print(input_len)\n",
    "        a = random.sample(vocab, input_len)\n",
    "#         print(a)\n",
    "        loc = random.randint(1, input_len)\n",
    "        a.insert(loc, F[0])\n",
    "        examples.append([a, ans[loc]])\n",
    "        \n",
    "    print(examples)\n",
    "    return examples\n",
    "\n",
    "def example2str(example): \n",
    "    a,ans = example\n",
    "    return '%s. What is the location of F? %s' % (' '.join(a), ''.join(ans))\n",
    "\n",
    "def exampleans(example): \n",
    "    global ans\n",
    "    a,ans = example\n",
    "    return '%s. What is the location of F?' % (' '.join(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1976,
   "id": "27d084cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['S', 'Z', 'R', 'F', 'I', 'N'], 'Fourth']]\n",
      "[[['J', 'I', 'O', 'R', 'Z', 'L', 'F'], 'Seventh']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "143\n",
      "[[['G', 'Y', 'H', 'C', 'N', 'J', 'F'], 'h'], [['V', 'N', 'X', 'L', 'E', 'F'], 't']]\n",
      "[[['I', 'T', 'H', 'V', 'U', 'F'], 't']]\n",
      "125\n",
      "259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 1976,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1976,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = \"\"\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(1,21,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        text = '\\n'.join(example2str(e) for e in make_examples(num))  \n",
    "        text += '\\n'\n",
    "        text += '\\n'.join(exampleans(e) for e in make_examples(1)) \n",
    "        input_ids = tokenizer1(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=(num*50))\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = int(len(text)- num + 2)\n",
    "        \n",
    "        \n",
    "        for i in range(number-1,len(gen_text)):\n",
    "            if(i+1 >= len(gen_text)):\n",
    "                break\n",
    "            elif(gen_text[i+1] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x += gen_text[i]\n",
    "                \n",
    "                \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-1] += 1\n",
    "        else:\n",
    "            F[num-1] += 1\n",
    "        \n",
    "        print(len(text))\n",
    "        print(len(gen_text))\n",
    "        x = \"\"\n",
    "        \n",
    "fo = open(\"foo10.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp10.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "id": "b2c3a67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " G M A M A M D D F . What is the location of F? Ninth \n",
      " A M G F M M G D M . What is the location of F? Fourth \n",
      " A D F G M D D . What is the location of F? Third \n",
      " D A A M F A M . What is the location of F? Fifth \n",
      " G F A D D G . What is the location of F? Second \n",
      " G D G F E E . What is the location of F? Fourth \n",
      " E D G F E A . What is the location of F? Fourth \n",
      " G M F A M A A G A . What is the location of F? Third \n",
      " A E G M F D . What is the location of F? Fifth \n",
      " M E G F G A . What is the location of F? Fourth \n",
      " D F G E G E M . What is the location of F? Second \n",
      " A G G D M D M F G . What is the location of F? Eighth \n",
      " A E M F A D D . What is the location of F? Fourth \n",
      " G F G M G D A D . What is the location of F? Second \n",
      " E F D M M E A D D . What is the location of F? Second \n",
      " M A M F M D M D . What is the location of F? Fourth \n",
      " G F M E A A D G . What is the location of F? Second \n",
      " E E A D A A F M . What is the location of F? Seventh \n",
      " M E E A F G . What is the location of F? Fifth \n",
      " A D D A F A . What is the location of F? Fifth \n",
      " A F D A E E E . What is the location of F?\n",
      " Correct: [0. 1. 1. 0. 0. 2. 1. 1. 0. 2. 4. 1. 0. 2. 0. 2. 2. 3. 1. 2.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo10.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2075,
   "id": "2d58d112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 2075,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAU70lEQVR4nO3dfZBd9X3f8fcnIsIztuOIsJM4ekDCkTOR6xaYjUibmHpqHoTJSLTFjWjTyg0dDS2aOkPTRh5nsEcez4A9dTvtKDVqranjhgpsmnaniFGIH9LJZMBaMAZLjsIiEyMNMYrFQDt2AMG3f9yjzOWyqz27e+/umvN+zezsOb/z+93zveee+9mz59yHVBWSpG75kaUuQJK0+Ax/Seogw1+SOsjwl6QOMvwlqYPOW+oCBl144YW1fv36pS5Dkn6oPPzww39RVWNt+y+78F+/fj2Tk5NLXYYk/VBJ8mdz6e9pH0nqIMNfkjrI8JekDjL8JamDDH9J6iDDX5I6qFX4J9mS5FiSqSS7z9Hv7yepJON9bR9uxh1Lcs0wipYkLcysr/NPsgLYC1wFnAAOJ5moqqMD/d4KfAh4qK9tE7AdeBfw08AfJHlnVb0yvLsgSZqrNkf+m4GpqjpeVS8BB4Bt0/T7OHAH8Jd9bduAA1X1YlV9G5hqbk+StITavMN3NfB03/wJ4PL+DkkuA9ZW1X1J/vXA2AcHxq4eXEGSncBOgHXr1rWrXJJGbP3u++Y85qnbrxtBJcO34Au+SX4E+DTwr+Z7G1W1r6rGq2p8bKz1R1NIkuapzZH/SWBt3/yapu2stwJ/DfhqEoCfAiaSbG0xVpK0BNoc+R8GNibZkGQlvQu4E2cXVtXzVXVhVa2vqvX0TvNsrarJpt/2JOcn2QBsBL429HshSZqTWY/8q+pMkl3AIWAFsL+qjiTZA0xW1cQ5xh5Jcg9wFDgD3OIrfSRp6bX6SOeqOggcHGi7bYa+7x2Y/wTwiXnWJ0kaAd/hK0kdZPhLUgcZ/pLUQYa/JHWQ4S9JHWT4S1IHGf6S1EGGvyR1kOEvSR1k+EtSBxn+ktRBhr8kdZDhL0kdZPhLUgcZ/pLUQYa/JHVQq/BPsiXJsSRTSXZPs/zmJI8neTTJHyXZ1LSvT/KDpv3RJJ8Z9h2QJM3drN/klWQFsBe4CjgBHE4yUVVH+7rdVVWfafpvBT4NbGmWPVlVlwy1aknSgrQ58t8MTFXV8ap6CTgAbOvvUFUv9M2+GajhlShJGrY24b8aeLpv/kTT9hpJbknyJPBJ4F/2LdqQ5OtJ/jDJexZUrSRpKIZ2wbeq9lbVO4DfBH6raX4GWFdVlwK3Ancl+bHBsUl2JplMMnnq1KlhlSRJmkGb8D8JrO2bX9O0zeQAcD1AVb1YVd9rph8GngTeOTigqvZV1XhVjY+NjbUsXZI0X23C/zCwMcmGJCuB7cBEf4ckG/tmrwOeaNrHmgvGJLkY2AgcH0bhkqT5m/XVPlV1Jsku4BCwAthfVUeS7AEmq2oC2JXkSuBl4DlgRzP8CmBPkpeBV4Gbq+r0KO6IJKm9WcMfoKoOAgcH2m7rm/7QDOPuBe5dSIGSpOHzHb6S1EGGvyR1kOEvSR1k+EtSBxn+ktRBhr8kdZDhL0kdZPhLUgcZ/pLUQYa/JHWQ4S9JHWT4S1IHGf6S1EGGvyR1kOEvSR1k+EtSBxn+ktRBrcI/yZYkx5JMJdk9zfKbkzye5NEkf5RkU9+yDzfjjiW5ZpjFS5LmZ9bwb76AfS9wLbAJuLE/3Bt3VdW7q+oS4JPAp5uxm+h94fu7gC3Ab5/9QndJ0tJpc+S/GZiqquNV9RJwANjW36GqXuibfTNQzfQ24EBVvVhV3wammtuTJC2hNl/gvhp4um/+BHD5YKcktwC3AiuBv9M39sGBsaunGbsT2Amwbt26NnWrz/rd982p/1O3XzeiSiT1W87PzaFd8K2qvVX1DuA3gd+a49h9VTVeVeNjY2PDKkmSNIM24X8SWNs3v6Zpm8kB4Pp5jpUkLYI24X8Y2JhkQ5KV9C7gTvR3SLKxb/Y64IlmegLYnuT8JBuAjcDXFl62JGkhZj3nX1VnkuwCDgErgP1VdSTJHmCyqiaAXUmuBF4GngN2NGOPJLkHOAqcAW6pqldGdF8kSS21ueBLVR0EDg603dY3/aFzjP0E8In5FihJGj7f4StJHWT4S1IHGf6S1EGGvyR1kOEvSR1k+EtSBxn+ktRBhr8kdZDhL0kdZPhLUgcZ/pLUQYa/JHWQ4S9JHWT4S1IHGf6S1EGGvyR1kOEvSR3UKvyTbElyLMlUkt3TLL81ydEkjyX5UpKL+pa9kuTR5mdicKwkafHN+jWOSVYAe4GrgBPA4SQTVXW0r9vXgfGq+n6Sfw58EviVZtkPquqS4ZYtSVqINkf+m4GpqjpeVS8BB4Bt/R2q6itV9f1m9kFgzXDLlCQNU5vwXw083Td/ommbyU3A/X3zb0oymeTBJNdPNyDJzqbP5KlTp1qUJElaiFlP+8xFkl8FxoG/3dd8UVWdTHIx8OUkj1fVk/3jqmofsA9gfHy8hlmTJOn12hz5nwTW9s2vadpeI8mVwEeArVX14tn2qjrZ/D4OfBW4dAH1SpKGoE34HwY2JtmQZCWwHXjNq3aSXArcSS/4n+1rX5Xk/Gb6QuAXgf4LxZKkJTDraZ+qOpNkF3AIWAHsr6ojSfYAk1U1AXwKeAvwhSQA36mqrcDPAXcmeZXeH5rbB14lJElaAq3O+VfVQeDgQNttfdNXzjDuj4F3L6RASdLw+Q5fSeogw1+SOsjwl6QOMvwlqYMMf0nqIMNfkjrI8JekDjL8JamDDH9J6iDDX5I6yPCXpA4y/CWpgwx/Seogw1+SOsjwl6QOMvwlqYMMf0nqoFbhn2RLkmNJppLsnmb5rUmOJnksyZeSXNS3bEeSJ5qfHcMsXpI0P7OGf5IVwF7gWmATcGOSTQPdvg6MV9VfB74IfLIZewHwUeByYDPw0SSrhle+JGk+2hz5bwamqup4Vb0EHAC29Xeoqq9U1feb2QeBNc30NcADVXW6qp4DHgC2DKd0SdJ8tfkC99XA033zJ+gdyc/kJuD+c4xdPTggyU5gJ8C6detalDQa63ffN6f+T91+3bzHDo5fSot5v5fLfdbcLeVj7X42fEO94JvkV4Fx4FNzGVdV+6pqvKrGx8bGhlmSJGkabcL/JLC2b35N0/YaSa4EPgJsraoX5zJWkrS42oT/YWBjkg1JVgLbgYn+DkkuBe6kF/zP9i06BFydZFVzoffqpk2StIRmPedfVWeS7KIX2iuA/VV1JMkeYLKqJuid5nkL8IUkAN+pqq1VdTrJx+n9AQHYU1WnR3JPJEmttbngS1UdBA4OtN3WN33lOcbuB/bPt0BJ0vD5Dl9J6iDDX5I6yPCXpA4y/CWpgwx/Seogw1+SOsjwl6QOMvwlqYMMf0nqIMNfkjrI8JekDjL8JamDDH9J6iDDX5I6yPCXpA4y/CWpgwx/SeqgVuGfZEuSY0mmkuyeZvkVSR5JcibJDQPLXknyaPMzMThWkrT4Zv0axyQrgL3AVcAJ4HCSiao62tftO8AHgd+Y5iZ+UFWXLLxUSdKwtPkO383AVFUdB0hyANgG/FX4V9VTzbJXR1CjJGnI2pz2WQ083Td/omlr601JJpM8mOT66Tok2dn0mTx16tQcblqSNB+LccH3oqoaB/4h8O+TvGOwQ1Xtq6rxqhofGxtbhJIkqdvahP9JYG3f/JqmrZWqOtn8Pg58Fbh0DvVJkkagTfgfBjYm2ZBkJbAdaPWqnSSrkpzfTF8I/CJ91wokSUtj1vCvqjPALuAQ8C3gnqo6kmRPkq0ASX4+yQngA8CdSY40w38OmEzyDeArwO0DrxKSJC2BNq/2oaoOAgcH2m7rmz5M73TQ4Lg/Bt69wBolSUPmO3wlqYMMf0nqIMNfkjrI8JekDjL8JamDDH9J6iDDX5I6yPCXpA4y/CWpgwx/Seogw1+SOsjwl6QOMvwlqYMMf0nqIMNfkjrI8JekDjL8JamDWoV/ki1JjiWZSrJ7muVXJHkkyZkkNwws25HkieZnx7AKlyTN36zhn2QFsBe4FtgE3Jhk00C37wAfBO4aGHsB8FHgcmAz8NEkqxZetiRpIdoc+W8GpqrqeFW9BBwAtvV3qKqnquox4NWBsdcAD1TV6ap6DngA2DKEuiVJC9DmC9xXA0/3zZ+gdyTfxnRjVw92SrIT2Amwbt26ljc9vfW775tT/6duv25B69MPp4XsJ3MdOzheWg6WxQXfqtpXVeNVNT42NrbU5UjSG16b8D8JrO2bX9O0tbGQsZKkEWkT/oeBjUk2JFkJbAcmWt7+IeDqJKuaC71XN22SpCU0a/hX1RlgF73Q/hZwT1UdSbInyVaAJD+f5ATwAeDOJEeasaeBj9P7A3IY2NO0SZKWUJsLvlTVQeDgQNttfdOH6Z3SmW7sfmD/AmqUJA3ZsrjgK0laXIa/JHWQ4S9JHWT4S1IHGf6S1EGGvyR1kOEvSR1k+EtSBxn+ktRBhr8kdZDhL0kdZPhLUgcZ/pLUQYa/JHWQ4S9JHWT4S1IHGf6S1EGtwj/JliTHkkwl2T3N8vOT3N0sfyjJ+qZ9fZIfJHm0+fnMkOuXJM3DrF/jmGQFsBe4CjgBHE4yUVVH+7rdBDxXVT+TZDtwB/ArzbInq+qS4ZYtSVqINkf+m4GpqjpeVS8BB4BtA322AZ9rpr8IvC9JhlemJGmY2oT/auDpvvkTTdu0farqDPA88BPNsg1Jvp7kD5O8Z7oVJNmZZDLJ5KlTp+Z0ByRJczfqC77PAOuq6lLgVuCuJD822Kmq9lXVeFWNj42NjbgkSVKb8D8JrO2bX9O0TdsnyXnA24DvVdWLVfU9gKp6GHgSeOdCi5YkLUyb8D8MbEyyIclKYDswMdBnAtjRTN8AfLmqKslYc8GYJBcDG4HjwyldkjRfs77ap6rOJNkFHAJWAPur6kiSPcBkVU0AnwU+n2QKOE3vDwTAFcCeJC8DrwI3V9XpUdwRSVJ7s4Y/QFUdBA4OtN3WN/2XwAemGXcvcO8Ca5QkDZnv8JWkDjL8JamDDH9J6iDDX5I6yPCXpA4y/CWpgwx/Seogw1+SOsjwl6QOMvwlqYMMf0nqIMNfkjrI8JekDjL8JamDDH9J6iDDX5I6yPCXpA5qFf5JtiQ5lmQqye5plp+f5O5m+UNJ1vct+3DTfizJNUOsXZI0T7OGf/MF7HuBa4FNwI1JNg10uwl4rqp+Bvh3wB3N2E30vs/3XcAW4LfPfqG7JGnptDny3wxMVdXxqnoJOABsG+izDfhcM/1F4H1J0rQfqKoXq+rbwFRze5KkJZSqOneH5AZgS1X9s2b+HwOXV9Wuvj7fbPqcaOafBC4HPgY8WFX/rWn/LHB/VX1xYB07gZ3N7M8CxxZ+117nQuAvRnC7C7Vc64LlW9tyrQuWb23WNXfLtbaZ6rqoqsba3sh5w6tn/qpqH7BvlOtIMllV46Ncx3ws17pg+da2XOuC5Vubdc3dcq1tWHW1Oe1zEljbN7+maZu2T5LzgLcB32s5VpK0yNqE/2FgY5INSVbSu4A7MdBnAtjRTN8AfLl655MmgO3Nq4E2ABuBrw2ndEnSfM162qeqziTZBRwCVgD7q+pIkj3AZFVNAJ8FPp9kCjhN7w8ETb97gKPAGeCWqnplRPdlNiM9rbQAy7UuWL61Lde6YPnWZl1zt1xrG0pds17wlSS98fgOX0nqIMNfkjroDRf+C/koihHWtDbJV5IcTXIkyYem6fPeJM8nebT5uW3UdfWt+6kkjzfrnZxmeZL8h2abPZbkskWo6Wf7tsWjSV5I8usDfRZtmyXZn+TZ5j0tZ9suSPJAkiea36tmGLuj6fNEkh3T9RlyXZ9K8ifNY/V7SX58hrHnfNxHUNfHkpzse7zeP8PYcz6HR1Tb3X11PZXk0RnGjnKbTZsTI9vPquoN80PvgvSTwMXASuAbwKaBPv8C+EwzvR24exHqejtwWTP9VuBPp6nrvcD/XqLt9hRw4TmWvx+4HwjwC8BDS/C4/jm9N7EsyTYDrgAuA77Z1/ZJYHczvRu4Y5pxFwDHm9+rmulVI67rauC8ZvqO6epq87iPoK6PAb/R4rE+53N4FLUNLP+3wG1LsM2mzYlR7WdvtCP/hXwUxchU1TNV9Ugz/X+BbwGrR7nOIdsG/E71PAj8eJK3L+L63wc8WVV/tojrfI2q+j/0XsnWr39f+hxw/TRDrwEeqKrTVfUc8AC9z7kaWV1V9ftVdaaZfZDe+2sW1Qzbq402z+GR1dZkwT8A/vsw19nGOXJiJPvZGy38VwNP982f4PUh+1d9mifI88BPLEp1QHOa6VLgoWkW/80k30hyf5J3LVZNQAG/n+Th9D5qY1Cb7TpK25n5ybhU2wzgJ6vqmWb6z4GfnKbPUm+7X6P3X9t0ZnvcR2FXczpq/wynL5Z6e70H+G5VPTHD8kXZZgM5MZL97I0W/stakrcA9wK/XlUvDCx+hN5pjb8B/Efgfy5iab9UVZfR++TWW5JcsYjrPqf03li4FfjCNIuXcpu9RvX+915Wr5tO8hF676/53Rm6LPbj/p+AdwCXAM/QO72y3NzIuY/6R77NzpUTw9zP3mjhv5CPohipJD9K7wH93ar6H4PLq+qFqvp/zfRB4EeTXDjqupr1nWx+Pwv8Hq//5NWl/JiOa4FHquq7gwuWcps1vnv29Ffz+9lp+izJtkvyQeCXgX/UBMbrtHjch6qqvltVr1TVq8B/nmF9S7avNXnw94C7Z+oz6m02Q06MZD97o4X/Qj6KYmSa84ifBb5VVZ+eoc9Pnb32kGQzvcdmMf4ovTnJW89O07tY+M2BbhPAP0nPLwDP9/0bOmozHokt1Tbr078v7QD+1zR9DgFXJ1nVnOa4umkbmSRbgH8DbK2q78/Qp83jPuy6+q8T/d0Z1tfmOTwqVwJ/Us2nEw8a9TY7R06MZj8bxVXrpfyh98qUP6X3ioGPNG176D0RAN5E7xTCFL3PGbp4EWr6JXr/qj0GPNr8vB+4Gbi56bMLOELv1Q0PAn9rkbbXxc06v9Gs/+w2668t9L7Q50ngcWB8kWp7M70wf1tf25JsM3p/gJ4BXqZ3PvUmeteKvgQ8AfwBcEHTdxz4L31jf63Z36aAf7oIdU3RO/97dl87++q2nwYOnutxH3Fdn2/2n8foBdrbB+tq5l/3HB51bU37fz27b/X1XcxtNlNOjGQ/8+MdJKmD3minfSRJLRj+ktRBhr8kdZDhL0kdZPhLUgcZ/pLUQYa/JHXQ/wcr82ZEeahpCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = np.zeros(20)\n",
    "T = [1, 2, 2, 0, 3, 2, 2, 0, 0, 1, 1, 0, 0, 0, 2, 0, 2, 0, 4, 3]\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/10\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "id": "f7fbf107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " G Y F A K E O P R . What is the location of F? Seventh \n",
      " K F Q K Y O V J G . What is the location of F? Second \n",
      " R M V F O S . What is the location of F? Fourth \n",
      " I R N R F G . What is the location of F? Third \n",
      " W F P I N I L W . What is the location of F? Eighth \n",
      " L D H F K E X . What is the location of F? Third \n",
      " H T F Z N S . What is the location of F? Third \n",
      " J C D E O C F . What is the location of F? Seventh \n",
      " A Y P Y F W S G Y . What is the location of F? Fifth \n",
      " K N G W C V F C . What is the location of F? Second \n",
      " N F H L O U . What is the location of F? Second \n",
      " W Q T P F S . What is the location of F? Sixth \n",
      " U D N Z O F S Y B . What is the location of F? Sixth \n",
      " B F M P I B L . What is the location of F? Second \n",
      " P F L G G E G D . What is the location of F? Second \n",
      " Z D B F Z R R . What is the location of F? Fourth \n",
      " S B W J L F . What is the location of F? Sixth \n",
      " D F J H W R I M F . What is the location of F? Seventh \n",
      " Z H Y I D D P F . What is the location of F? Eighth \n",
      " R F L M T N . What is the location of F? Sixth \n",
      " L F D Q K V D . What is the location of F?\n",
      " Correct: [1. 2. 2. 0. 3. 2. 2. 0. 0. 1. 1. 0. 0. 0. 2. 0. 2. 0. 4. 3.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo10.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "id": "bb56a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fourth Third\n",
      "Third Fourth\n",
      "Third Fourth\n",
      "Eighth Third\n",
      "Third Second\n",
      "Third Fourth\n",
      "Third Third\n",
      "Seventh Second\n",
      "Third Second\n",
      "Third Fifth\n",
      "Fourth Fourth\n",
      "Third Third\n",
      "Second Third\n",
      "Fifth Seventh\n",
      "Third Fourth\n",
      "Third First\n",
      "Third Seventh\n",
      "Third Third\n",
      "Third Third\n",
      "Third Fourth\n",
      "Fourth Fifth\n",
      "Third Fifth\n",
      "Third First\n",
      "Fourth Fifth\n",
      "Third First\n",
      "Second Third\n",
      "Third Third\n",
      "Second Third\n",
      "Third Second\n",
      "Third Third\n",
      "Third Fourth\n",
      "Third Fifth\n",
      "Third Second\n",
      "Third Sixth\n",
      "Second Seventh\n",
      "Sixth Sixth\n",
      "Third Fifth\n",
      "Third Fifth\n",
      "Third Fifth\n",
      "Third Sixth\n",
      "Eighth Seventh\n",
      " Fourth\n",
      "Fourth Fifth\n",
      "Third Fifth\n",
      "Third First\n",
      "Third Third\n",
      "Eighth Fifth\n",
      "Third Eighth\n",
      "Fourth Second\n",
      "Third First\n",
      "Third Fifth\n",
      "Third Sixth\n",
      "Second First\n",
      "Third Fourth\n",
      "Third Seventh\n",
      "Third First\n",
      "Third Fifth\n",
      "Third Second\n",
      "Third Fourth\n",
      "Third Sixth\n",
      "Fourth First\n",
      "Second Fifth\n",
      "Tenth Fourth\n",
      "Third Second\n",
      "Third First\n",
      "Third Fifth\n",
      "Third Second\n",
      "Third Fifth\n",
      "Third Fifth\n",
      "Third Third\n",
      "Third Second\n",
      "Third Fourth\n",
      "Third Fifth\n",
      "Third Seventh\n",
      "Third Fifth\n",
      "Third Seventh\n",
      "Seventh Second\n",
      "Fifth Fourth\n",
      "Second Second\n",
      "Third Second\n",
      "Seventh Fourth\n",
      "Third Third\n",
      "Second Second\n",
      "First Fourth\n",
      "Third First\n",
      "Second Second\n",
      "Third Fifth\n",
      "Third Second\n",
      "Second Second\n",
      "Third Fifth\n",
      "Third Sixth\n",
      "Third Third\n",
      "Third Fifth\n",
      "Third Second\n",
      "Third Third\n",
      "Third Fifth\n",
      "Third Third\n",
      "Third Seventh\n",
      "Fifth Second\n",
      "Third Second\n",
      "Third Third\n",
      "Fourth Fifth\n",
      "Fourth Third\n",
      "Seventh Fifth\n",
      "Third Third\n",
      "Eighth Eighth\n",
      "Third Third\n",
      "Fourth Seventh\n",
      "Third Third\n",
      "Second Sixth\n",
      "Seventh Fourth\n",
      "Sixth Fourth\n",
      "Third Second\n",
      "Third Fifth\n",
      "Third Fifth\n",
      "Third First\n",
      "Third Second\n",
      "Second Fifth\n",
      "Third Fifth\n",
      "Third Third\n",
      "Third Third\n",
      "Fourth Second\n",
      "Third First\n",
      "Third Fourth\n",
      "Third Second\n",
      "Third Third\n",
      "Third Fourth\n",
      "Third First\n",
      "Sixth Fifth\n",
      "Third Fifth\n",
      "Third Fifth\n",
      "Third First\n",
      "Third Fifth\n",
      "Third Fourth\n",
      "Third Fifth\n",
      "Third Sixth\n",
      "Third Third\n",
      "Third First\n",
      "Third First\n",
      "Second Second\n",
      "Eighth Fourth\n",
      "Fourth Fifth\n",
      "Fourth Fourth\n",
      "Fourth First\n",
      "Fourth Sixth\n",
      "Third Third\n",
      "First Second\n",
      "Third Seventh\n",
      "Third Fifth\n",
      "Second Third\n",
      "Third Third\n",
      "Third Fifth\n",
      "Third Second\n",
      "Third Third\n",
      "Third Seventh\n",
      "Third Seventh\n",
      "Third Second\n",
      "Sixth Fourth\n",
      "Third Fifth\n",
      "Third Second\n",
      "Seventh Third\n",
      "Third Sixth\n",
      "Fourth Third\n",
      "Fourth First\n",
      "Fifth Fifth\n",
      "First Second\n",
      "Third Second\n",
      "Third Fourth\n",
      "Eighth Third\n",
      "Third Fourth\n",
      "Third First\n",
      "Third First\n",
      "Third Fifth\n",
      "Third Eighth\n",
      "Third Second\n",
      "Third Third\n",
      "Seventh Sixth\n",
      "Second Sixth\n",
      "Third Third\n",
      "Third Sixth\n",
      "Eighth First\n",
      "Fourth Fifth\n",
      "Third Fifth\n",
      "Third Fourth\n",
      "Third Third\n",
      "Second Fifth\n",
      "Second Fourth\n",
      "Third Fourth\n",
      "Third Third\n",
      "Sixth Seventh\n",
      "Third Third\n",
      "Third Second\n",
      "Third Fifth\n",
      "Third First\n",
      "Third Second\n",
      "Third Fourth\n",
      "Fourth Fifth\n",
      "Third Third\n",
      "Third Sixth\n",
      "Third Third\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1195"
      ]
     },
     "execution_count": 1312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1312,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = \"\"\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x += response.choices[0].text[i]\n",
    "                \n",
    "                \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        \n",
    "        print(x,ans)\n",
    "        x = \"\"\n",
    "        \n",
    "fo = open(\"foo10_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp10_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "id": "b8d72a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " M A A E D F E . What is the location of F? Sixth \n",
      " D D M A E F A A E . What is the location of F? Sixth \n",
      " D F A E D E G E E . What is the location of F? Second \n",
      " D G E A F E . What is the location of F? Fifth \n",
      " M G E M M F M E E . What is the location of F? Sixth \n",
      " G G M G F M E M D . What is the location of F? Fifth \n",
      " M A G F G A . What is the location of F? Fourth \n",
      " M E E F D E . What is the location of F? Fourth \n",
      " A A F E A A G D . What is the location of F? Third \n",
      " A F A D E M E G . What is the location of F? Second \n",
      " D F D D A G . What is the location of F? Second \n",
      " M E A E F A . What is the location of F? Fifth \n",
      " E D F D G M . What is the location of F? Third \n",
      " M M A F M D D . What is the location of F? Fourth \n",
      " D F E D A E E M A . What is the location of F? Second \n",
      " G D D G E A M F . What is the location of F? Eighth \n",
      " D M F M G D A . What is the location of F? Third \n",
      " G E M D G E D F A . What is the location of F? Eighth \n",
      " E E G D F A A G A . What is the location of F? Fifth \n",
      " M A D A E E F . What is the location of F? Seventh \n",
      " E G E F G A D D . What is the location of F?\n",
      " Correct: [2. 1. 2. 0. 3. 5. 3. 0. 3. 2. 3. 2. 0. 1. 1. 2. 2. 2. 3. 3.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo10_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca44e4",
   "metadata": {},
   "source": [
    "# 紧挨F的左/右边是？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e324c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "    global count \n",
    "    count = np.zeros(5)\n",
    "    data = np.random.randint(6,10,1)\n",
    "    data1 = np.random.randint(1,data-1,1)\n",
    "    global n1\n",
    "    n1 = data[0] #size of sample\n",
    "    elements = string.ascii_uppercase\n",
    "    ans = \"\"\n",
    "    flag = 0\n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    \n",
    "    for i in range(n1-1):\n",
    "        if(random_pop1[i] == \"F\"):\n",
    "            flag = 1\n",
    "        else:\n",
    "            pass\n",
    "    if(flag == 1):\n",
    "        for i in range(n1): \n",
    "             list1.append(random_pop1[i])\n",
    "    else:\n",
    "        for i in range(n1): \n",
    "            if(i == data1):\n",
    "                list1.append(\"F\")\n",
    "            else:\n",
    "                list1.append(random_pop1[i]) \n",
    "        \n",
    "    ans = list1[data1[0]+1]\n",
    "    \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Which one is on the right of F?\")\n",
    "    \n",
    "    list1.append(ans)\n",
    "#     print(list1)\n",
    "    return list1\n",
    "\n",
    "def create(n):\n",
    "    list2 = []\n",
    "    function()\n",
    "    global ans\n",
    "    ans = \"\"\n",
    "    for i in range(1,n,1):\n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "    flag = 0\n",
    "    list1=[]\n",
    "    data = np.random.randint(6,10,1)\n",
    "    data1 = np.random.randint(1,data-1,1)\n",
    "    n1 = data[0]#size of sample\n",
    "    elements = string.ascii_uppercase\n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    for i in range(n1-1):\n",
    "        if(random_pop1[i] == \"F\"):\n",
    "            flag = 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    if(flag == 1):\n",
    "        for i in range(n1): \n",
    "             list1.append(random_pop1[i])\n",
    "    else:\n",
    "        for i in range(n1): \n",
    "            if(i == data1):\n",
    "                list1.append(\"F\")\n",
    "            else:\n",
    "                list1.append(random_pop1[i]) \n",
    "        \n",
    "    ans = list1[data1[0]+1]\n",
    "    \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"Which one is on the right of F?\")\n",
    "    \n",
    "    list2.append(\"\\n\")\n",
    "    list2.extend(list1)\n",
    "    \n",
    "    str = \" \"\n",
    "    prompt = str.join(list2)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2076,
   "id": "a5e8de30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " A A F D A M S A . Which one is on the right of F? D \n",
      " E M F G S S S . Which one is on the right of F? G \n",
      " A A M A M F E A . Which one is on the right of F? E \n",
      " D F A E D M G . Which one is on the right of F? A \n",
      " G M E M A D F E A . Which one is on the right of F? E \n",
      " M D F A A A . Which one is on the right of F? A \n",
      " A D D F E G S G D . Which one is on the right of F? E \n",
      " M D F M M G A E . Which one is on the right of F? M \n",
      " S F G D D G M G . Which one is on the right of F? G \n",
      " S D M G A S F D M . Which one is on the right of F? D \n",
      " G D F E A D D S G . Which one is on the right of F? E \n",
      " D F G S G M S A A . Which one is on the right of F? G \n",
      " G E M S D D F M G . Which one is on the right of F? M \n",
      " M A G G M D F M . Which one is on the right of F? M \n",
      " A S E E F M E M A . Which one is on the right of F? M \n",
      " M A F M A S M . Which one is on the right of F? M \n",
      " D M E M M F S E . Which one is on the right of F? S \n",
      " A A F D A E . Which one is on the right of F? D \n",
      " G E D D S D F E . Which one is on the right of F? E \n",
      " G S D D M F S D . Which one is on the right of F? S \n",
      " A M G F G E A D E . Which one is on the right of F?\n",
      " Correct: [2. 1. 4. 6. 3. 4. 4. 2. 7. 4. 5. 4. 3. 3. 6. 5. 4. 6. 2. 4.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo11.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "id": "2daaf2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 41, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 57, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 82, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 100, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 118, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 142, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 160, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 180, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 201, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 224, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 244, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 267, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 277, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 301, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 331, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 352, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 359, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 389, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 408, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 427, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 36, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 61, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 78, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 102, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 125, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 137, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 166, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 179, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 205, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 224, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 244, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 265, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 290, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 312, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 327, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 356, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 364, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 394, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 401, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 430, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 38, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 62, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 79, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 97, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 123, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 137, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 160, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 186, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 202, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 223, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 242, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 261, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 284, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 305, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 332, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 348, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 365, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 393, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 402, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 422, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 37, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 61, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 77, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 103, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 118, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 135, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 167, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 185, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 200, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 227, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 248, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 264, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 281, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 311, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 320, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 343, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 362, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 386, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 409, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 421, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 39, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 61, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 85, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 104, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 125, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 141, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 164, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 183, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 201, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 227, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 243, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 261, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 282, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 315, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 325, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 354, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 367, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 385, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 406, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 426, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 37, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 58, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 77, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 101, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 120, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 146, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 163, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 182, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 200, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 226, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 239, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 261, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 281, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 308, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 333, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 353, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 364, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 388, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 403, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 422, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 40, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 63, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 78, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 100, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 124, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 147, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 162, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 184, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 204, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 228, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 243, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 261, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 283, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 306, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 322, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 346, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 371, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 384, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 400, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 428, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 41, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 56, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 78, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 98, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 117, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 142, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 165, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 182, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 209, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 229, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 243, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 265, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 284, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 299, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 317, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 348, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 369, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 381, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 408, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 429, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 39, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 60, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 80, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 104, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 121, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 146, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 159, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 182, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 199, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 225, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 249, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 260, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 287, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 305, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 323, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 348, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 372, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 384, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 402, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 417, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 36, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 61, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 79, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 96, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 121, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 144, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 157, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 182, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 202, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 222, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 246, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 260, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 287, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 305, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 323, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 350, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 373, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 391, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 405, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 440, but ``max_length`` is set to 30.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1229"
      ]
     },
     "execution_count": 1272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAARW0lEQVR4nO3dfYxdeV3H8ffHlmoCRBZ3RGw7TMGKqYqwjl18QiIPdlnTqiDpxodFwIZIlQefhmAaUv9ZIEKiaZQCG5GI3RUFR7dYEDBG42ILLg/dpbtDrbYNsgIraIgsxa9/3FNzudzp3JneOw8/3q9kMud3zvfe8+05537mzDlzb1NVSJLa9HVr3YAkaXIMeUlqmCEvSQ0z5CWpYYa8JDVs81qt+Nprr62ZmZm1Wr0kbUgf/OAHP11VU6PWr1nIz8zMcOrUqbVavSRtSEn+dTn1Xq6RpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDRsp5JPsSXImyUKSuSHLX5/kru7r3iT/OfZOJUnLtuTfySfZBBwBngFcAE4mma+quy/XVNXL+up/GXjSBHqVJC3TKGfyu4GFqjpbVQ8Cx4B9V6i/CfiTcTQnSbo6o7zjdStwvm98Abh+WGGSxwA7gPctsvwAcABgenp6WY3qa9PM3B3Lfsy5W26cQCfSxjTuG6/7gbdX1ZeHLayqo1U1W1WzU1Mjf/SCJGmFRgn5i8D2vvG2bt4w+/FSjSStG6OE/ElgZ5IdSbbQC/L5waIk3wFcA/zjeFuUJK3UkiFfVZeAg8AJ4B7g9qo6neRwkr19pfuBY+X/DC5J68ZIHzVcVceB4wPzDg2MXzW+tiRJ4+A7XiWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1LCRQj7JniRnkiwkmVuk5rlJ7k5yOsnbxtumJGklNi9VkGQTcAR4BnABOJlkvqru7qvZCbwC+MGqeiDJN0+qYUnS6EY5k98NLFTV2ap6EDgG7Buo+UXgSFU9AFBV94+3TUnSSix5Jg9sBc73jS8A1w/UfDtAkn8ANgGvqqq/HnyiJAeAAwDT09Mr6XdDm5m7Y9mPOXfLjRPoRBpuIx+jy+19vfQ9aeO68boZ2Ak8FbgJeGOSRwwWVdXRqpqtqtmpqakxrVqStJhRQv4isL1vvK2b1+8CMF9VX6qqfwHupRf6kqQ1NErInwR2JtmRZAuwH5gfqHknvbN4klxL7/LN2fG1KUlaiSVDvqouAQeBE8A9wO1VdTrJ4SR7u7ITwGeS3A28H/j1qvrMpJqWJI1mlBuvVNVx4PjAvEN90wW8vPuSJK0TvuNVkhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWEjhXySPUnOJFlIMjdk+fOS/EeSu7qvF46/VUnScm1eqiDJJuAI8AzgAnAyyXxV3T1QeltVHZxAj5KkFRrlTH43sFBVZ6vqQeAYsG+ybUmSxmHJM3lgK3C+b3wBuH5I3bOTPAW4F3hZVZ0fLEhyADgAMD09vfxupVU0M3fHsurP3XLjhDrZONxm68+4brz+JTBTVU8A3gO8ZVhRVR2tqtmqmp2amhrTqiVJixkl5C8C2/vG27p5/6+qPlNVX+yGbwK+dzztSZKuxighfxLYmWRHki3AfmC+vyDJo/uGe4F7xteiJGmllrwmX1WXkhwETgCbgFur6nSSw8CpqpoHfiXJXuAS8FngeRPsWZI0olFuvFJVx4HjA/MO9U2/AnjFeFuTJF0t3/EqSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGjRTySfYkOZNkIcncFeqenaSSzI6vRUnSSi0Z8kk2AUeAG4BdwE1Jdg2pezjwEuAD425SkrQyo5zJ7wYWqupsVT0IHAP2Dan7beDVwP+MsT9J0lXYPELNVuB83/gCcH1/QZLrgO1VdUeSX1/siZIcAA4ATE9PL7/bdWBm7o5l1Z+75cYJdbI8V9v31+q/e7XWO851b1QbdZut976v+sZrkq8DXgf86lK1VXW0qmaranZqaupqVy1JWsIoIX8R2N433tbNu+zhwHcBf5vkHPBkYN6br5K09kYJ+ZPAziQ7kmwB9gPzlxdW1eeq6tqqmqmqGeBOYG9VnZpIx5KkkS0Z8lV1CTgInADuAW6vqtNJDifZO+kGJUkrN8qNV6rqOHB8YN6hRWqfevVtSZLGwXe8SlLDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDVspJBPsifJmSQLSeaGLH9Rko8muSvJ3yfZNf5WJUnLtWTIJ9kEHAFuAHYBNw0J8bdV1XdX1ROB1wCvG3ejkqTlG+VMfjewUFVnq+pB4Biwr7+gqj7fN3woUONrUZK0UptHqNkKnO8bXwCuHyxK8mLg5cAW4EeHPVGSA8ABgOnp6eX2+jVvZu6OZdWfu+XGCXWiSbuafe1xon5ju/FaVUeq6nHAbwK/tUjN0aqararZqampca1akrSIUUL+IrC9b7ytm7eYY8BPXEVPkqQxGSXkTwI7k+xIsgXYD8z3FyTZ2Te8EbhvfC1KklZqyWvyVXUpyUHgBLAJuLWqTic5DJyqqnngYJKnA18CHgBunmTTkqTRjHLjlao6DhwfmHeob/olY+5LkjQGvuNVkhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNGynkk+xJcibJQpK5IctfnuTuJB9J8t4kjxl/q5Kk5Voy5JNsAo4ANwC7gJuS7Boo+2dgtqqeALwdeM24G5UkLd8oZ/K7gYWqOltVDwLHgH39BVX1/qr6Qje8E9g23jYlSSsxSshvBc73jS908xbzAuBdV9OUJGk8No/zyZL8LDAL/Mgiyw8ABwCmp6dXvJ6ZuTuW/Zhzt9y44vXp6ix3f7mvtNpaPkZHOZO/CGzvG2/r5n2FJE8HXgnsraovDnuiqjpaVbNVNTs1NbWSfiVJyzBKyJ8EdibZkWQLsB+Y7y9I8iTgDfQC/v7xtylJWoklQ76qLgEHgRPAPcDtVXU6yeEke7uy1wIPA/40yV1J5hd5OknSKhrpmnxVHQeOD8w71Df99DH3JUkaA9/xKkkNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktSwkUI+yZ4kZ5IsJJkbsvwpST6U5FKS54y/TUnSSiwZ8kk2AUeAG4BdwE1Jdg2U/RvwPOBt425QkrRym0eo2Q0sVNVZgCTHgH3A3ZcLqupct+x/J9CjJGmFRgn5rcD5vvEF4PqVrCzJAeAAwPT09EqeYixm5u5YVv25W26cUCeSNFmreuO1qo5W1WxVzU5NTa3mqiXpa9IoIX8R2N433tbNkyStc6OE/ElgZ5IdSbYA+4H5ybYlSRqHJUO+qi4BB4ETwD3A7VV1OsnhJHsBknxfkgvATwNvSHJ6kk1LkkYzyo1Xquo4cHxg3qG+6ZP0LuNIktYR3/EqSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1LCRQj7JniRnkiwkmRuy/OuT3NYt/0CSmbF3KklatiVDPskm4AhwA7ALuCnJroGyFwAPVNW3Aa8HXj3uRiVJyzfKmfxuYKGqzlbVg8AxYN9AzT7gLd3024GnJcn42pQkrUSq6soFyXOAPVX1wm78c8D1VXWwr+ZjXc2FbvyJrubTA891ADjQDR8PnBnXP6RzLfDpJavWxnrtbb32Beu3t/XaF6zf3uxr+Rbr7TFVNTXqk2weXz9Lq6qjwNFJPX+SU1U1O6nnvxrrtbf12hes397Wa1+wfnuzr+UbV2+jXK65CGzvG2/r5g2tSbIZ+EbgM1fbnCTp6owS8ieBnUl2JNkC7AfmB2rmgZu76ecA76ulrgNJkiZuycs1VXUpyUHgBLAJuLWqTic5DJyqqnngzcBbkywAn6X3g2AtTOxS0Bis197Wa1+wfntbr33B+u3NvpZvLL0teeNVkrRx+Y5XSWqYIS9JDduQIb9eP2YhyfYk709yd5LTSV4ypOapST6X5K7u69Aq9XYuyUe7dZ4asjxJfrfbZh9Jct0q9fX4vm1xV5LPJ3npQM2qbLMktya5v3vfx+V5j0zyniT3dd+vWeSxN3c19yW5eVjNBHp7bZKPd/vrHUkeschjr7jvJ9DXq5Jc7Ntfz1rksVd8HU+gr9v6ejqX5K5FHjux7dU9/9CcmNixVlUb6ovezd9PAI8FtgAfBnYN1PwS8Afd9H7gtlXq7dHAdd30w4F7h/T2VOCv1mC7nQOuvcLyZwHvAgI8GfjAGu3bf6f3Zo9V32bAU4DrgI/1zXsNMNdNzwGvHvK4RwJnu+/XdNPXrEJvzwQ2d9OvHtbbKPt+An29Cvi1Efb1FV/H4+5rYPnvAIdWe3t1zz80JyZ1rG3EM/l1+zELVfXJqvpQN/1fwD3A1kmvd0z2AX9UPXcCj0jy6FXu4WnAJ6rqX1d5vQBU1d/R++uwfv3H0luAnxjy0B8D3lNVn62qB4D3AHsm3VtVvbuqLnXDO+m9h2VVLbLNRjHK63gifXVZ8FzgT8a1vuW4Qk5M5FjbiCG/FTjfN77AVwfp/9d0L4LPAd+0Kt11uktETwI+MGTx9yf5cJJ3JfnOVWqpgHcn+WB6Hy8xaJTtOmn7WfyFtxbbDOBRVfXJbvrfgUcNqVkP2+759H4TG2apfT8JB7vLSLcuctlhLbfZDwOfqqr7Flm+attrICcmcqxtxJBf95I8DPgz4KVV9fmBxR+idznie4DfA965Sm39UFVdR+/TRF+c5CmrtN6RpPdGu73Anw5ZvFbb7CtU7/fldfc3x0leCVwC/niRktXe978PPA54IvBJepdG1pObuPJZ/KpsryvlxDiPtY0Y8uv6YxaSPITejvvjqvrzweVV9fmq+u9u+jjwkCTXTrqvqrrYfb8feAe9X5f7jbJdJ+kG4ENV9anBBWu1zTqfunzZqvt+/5CaNdt2SZ4H/DjwM10wfJUR9v1YVdWnqurLVfW/wBsXWd+abLMuD34KuG2xmtXYXovkxESOtY0Y8uv2Yxa6a31vBu6pqtctUvMtl+8PJNlNbx9M9AdQkocmefjlaXo37D42UDYP/Hx6ngx8ru9Xx9Ww6NnVWmyzPv3H0s3AXwypOQE8M8k13aWJZ3bzJirJHuA3gL1V9YVFakbZ9+Puq/9ezk8usr5RXseT8HTg49V9Yu6g1dheV8iJyRxrk7qDPMkven8Jci+9u/Ov7OYdpnewA3wDvV/7F4B/Ah67Sn39EL1fsT4C3NV9PQt4EfCiruYgcJreXxPcCfzAKvT12G59H+7WfXmb9fcVev85zCeAjwKzq7g/H0ovtL+xb96qbzN6P2Q+CXyJ3rXOF9C7l/Ne4D7gb4BHdrWzwJv6Hvv87nhbAH5hlXpboHd99vKxdvkvyr4VOH6lfT/hvt7aHUMfoRdcjx7sqxt/1et4kn118//w8nHVV7tq26tbx2I5MZFjzY81kKSGbcTLNZKkERnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWH/B4Y+q5WwBDevAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=30)\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        x = gen_text[number-1]\n",
    "        \n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "            \n",
    "     \n",
    "    \n",
    "fo = open(\"foo11.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp11.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "id": "a82a3a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1211"
      ]
     },
     "execution_count": 1275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x = response.choices[0].text[i]\n",
    "        \n",
    "        if(x == ans):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "            \n",
    "     \n",
    "    \n",
    "fo = open(\"foo11_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp11_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2061,
   "id": "d314ca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " A A F D A M S A . Which one is on the right of F? D \n",
      " E M F G S S S . Which one is on the right of F? G \n",
      " A A M A M F E A . Which one is on the right of F? E \n",
      " D F A E D M G . Which one is on the right of F? A \n",
      " G M E M A D F E A . Which one is on the right of F? E \n",
      " M D F A A A . Which one is on the right of F? A \n",
      " A D D F E G S G D . Which one is on the right of F? E \n",
      " M D F M M G A E . Which one is on the right of F? M \n",
      " S F G D D G M G . Which one is on the right of F? G \n",
      " S D M G A S F D M . Which one is on the right of F? D \n",
      " G D F E A D D S G . Which one is on the right of F? E \n",
      " D F G S G M S A A . Which one is on the right of F? G \n",
      " G E M S D D F M G . Which one is on the right of F? M \n",
      " M A G G M D F M . Which one is on the right of F? M \n",
      " A S E E F M E M A . Which one is on the right of F? M \n",
      " M A F M A S M . Which one is on the right of F? M \n",
      " D M E M M F S E . Which one is on the right of F? S \n",
      " A A F D A E . Which one is on the right of F? D \n",
      " G E D D S D F E . Which one is on the right of F? E \n",
      " G S D D M F S D . Which one is on the right of F? S \n",
      " A M G F G E A D E . Which one is on the right of F?\n",
      " Correct: [2. 1. 4. 6. 3. 4. 4. 2. 7. 4. 5. 4. 3. 3. 6. 5. 4. 6. 2. 4.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo11.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "id": "a648171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " M E G F E A E A G . Which one is on the right of F? E \n",
      " A S M F M M M . Which one is on the right of F? M \n",
      " M M D A F S G S D . Which one is on the right of F? S \n",
      " D F G D A G M D . Which one is on the right of F? G \n",
      " A G E M G F E G . Which one is on the right of F? E \n",
      " M M A G F S . Which one is on the right of F? S \n",
      " E S S E D S F G . Which one is on the right of F? G \n",
      " G E M D E F M D . Which one is on the right of F? M \n",
      " S S M F S M M . Which one is on the right of F? S \n",
      " D A E E D S F G . Which one is on the right of F? G \n",
      " S M G E M F A . Which one is on the right of F? A \n",
      " G M E G M E A F M . Which one is on the right of F? M \n",
      " A D G F M D . Which one is on the right of F? M \n",
      " G F E S S A . Which one is on the right of F? E \n",
      " G E F G E G A E G . Which one is on the right of F? G \n",
      " D F S S E S . Which one is on the right of F? S \n",
      " E S D D G F G D . Which one is on the right of F? G \n",
      " A F E E G E D S S . Which one is on the right of F? E \n",
      " A F E M E E . Which one is on the right of F? E \n",
      " M A G G F G M D . Which one is on the right of F? G \n",
      " D M M E D A F M . Which one is on the right of F?\n",
      " Correct: [3. 2. 6. 2. 4. 5. 6. 3. 6. 4. 5. 2. 5. 6. 2. 7. 5. 3. 2. 5.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo11_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "879a2c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14. 12. 11. 11.  9. 10. 11. 13. 10. 10.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5bef5b",
   "metadata": {},
   "source": [
    "# F和O之间的是？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "id": "221535c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "    global count \n",
    "    count = np.zeros(5)\n",
    "    data = np.random.randint(7,10,1)\n",
    "    data1 = np.random.randint(1,data-1,2)\n",
    "    while(1):\n",
    "        if(data1[0] == data1[1]):\n",
    "            data1 = np.random.randint(1,data,2)\n",
    "\n",
    "        elif(abs(data1[0]-data1[1] != 2)):\n",
    "            data1 = np.random.randint(1,data,2)\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    global n1\n",
    "    n1 = data[0] #size of sample\n",
    "    elements = string.ascii_uppercase\n",
    "    ans = []\n",
    "    flag = 0\n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    while(1):\n",
    "        for i in range(n1):\n",
    "            if(random_pop1[i] == \"F\" or random_pop1[i] == \"O\"):\n",
    "                random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "                flag = 1\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        if(flag == 0):\n",
    "            break\n",
    "        flag = 0\n",
    "    \n",
    "    \n",
    "    for i in range(n1):  \n",
    "        if(data1[0] < data1[1]):\n",
    "            if(i == data1[0]):\n",
    "                list1.append(\"F\")\n",
    "            elif(i == data1[1]):\n",
    "                list1.append(\"O\")\n",
    "            else:\n",
    "                list1.append(random_pop1[i]) \n",
    "        else:\n",
    "            if(i == data1[0]):\n",
    "                list1.append(\"O\")\n",
    "            elif(i == data1[1]):\n",
    "                list1.append(\"F\")\n",
    "            else:\n",
    "                list1.append(random_pop1[i])\n",
    "    \n",
    "    \n",
    "    if(data1[0] > data1[1]):     \n",
    "        n = data1[1]+1\n",
    "        ans.append(list1[n])\n",
    "            \n",
    "    else:\n",
    "        n = data1[0]+1\n",
    "        ans.append(list1[n])\n",
    "            \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"What is the letter between F and O?\")\n",
    "    \n",
    "    list1.extend(ans)\n",
    "#     print(list1)\n",
    "    ans.clear()\n",
    "    return list1\n",
    "\n",
    "\n",
    "def create(n):\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    \n",
    "    for i in range(1,n,1): \n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "       \n",
    "        \n",
    "    list2.append(\"\\n\")\n",
    "    flag =0\n",
    "    #生成测试用例\n",
    "    data = np.random.randint(7,10,1)\n",
    "    global n1\n",
    "    global ans \n",
    "    n1 = data[0] #size of sample\n",
    "    data1 = np.random.randint(0,data-1,2) #生成0与1的位置 data1[0]是0的位置，data1[1]是1的位置\n",
    "    while(1):\n",
    "        if(data1[0] == data1[1]):\n",
    "            data1 = np.random.randint(1,data,2)\n",
    "\n",
    "        elif(abs(data1[0]-data1[1] != 2)):\n",
    "            data1 = np.random.randint(1,data,2)\n",
    "\n",
    "        else:\n",
    "            break\n",
    "   \n",
    "    elements = string.ascii_uppercase\n",
    "    ans = []\n",
    "    \n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    while(1):\n",
    "        for i in range(n1):\n",
    "            if(random_pop1 == \"F\" or random_pop1 == \"O\"):\n",
    "                random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "                flag = 1\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        if(flag == 0):\n",
    "            break\n",
    "        flag = 0\n",
    "        \n",
    "    for i in range(n1):  \n",
    "        if(data1[0] < data1[1]):\n",
    "            if(i == data1[0]):\n",
    "                list1.append(\"F\")\n",
    "            elif(i == data1[1]):\n",
    "                list1.append(\"O\")\n",
    "            else:\n",
    "                list1.append(random_pop1[i]) \n",
    "        else:\n",
    "            if(i == data1[0]):\n",
    "                list1.append(\"O\")\n",
    "            elif(i == data1[1]):\n",
    "                list1.append(\"F\")\n",
    "            else:\n",
    "                list1.append(random_pop1[i])\n",
    "    \n",
    "    list2.extend(list1)\n",
    "    \n",
    "    if(data1[0] > data1[1]):     \n",
    "        n = data1[1]+1\n",
    "        ans.append(list1[n])\n",
    "            \n",
    "    else:\n",
    "        n = data1[0]+1\n",
    "        ans.append(list1[n])\n",
    "            \n",
    "    list2.append(\".\")\n",
    "    list2.append(\"What is the letter between F and O?\")\n",
    "    \n",
    "    \n",
    "    prompt = \" \".join(list2)\n",
    "    list2.clear()\n",
    "    return(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1547,
   "id": "945022f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " P S V F Q O P S P . What is the letter between F and O? Q \n",
      " P D F H O H Y . What is the letter between F and O? H \n",
      " Q Q W V L F Z O . What is the letter between F and O? Z \n",
      " Y F B O W V K T X . What is the letter between F and O? B \n",
      " E H W Q U F L O R . What is the letter between F and O? L \n",
      " V F Z O P N Z . What is the letter between F and O? Z \n",
      " S F A O A Q J I . What is the letter between F and O? A \n",
      " S G T G F I O . What is the letter between F and O? I \n",
      " W E X Z F U O . What is the letter between F and O? U \n",
      " D Q F Z O H G M S . What is the letter between F and O? Z \n",
      " B Y W T I F T O . What is the letter between F and O? T \n",
      " Z M H I F G O . What is the letter between F and O? G \n",
      " E S U F G O A B . What is the letter between F and O? G \n",
      " K Y F D O Y V . What is the letter between F and O? D \n",
      " P N F B O Y W X Y . What is the letter between F and O? B \n",
      " I A F Y O C A Y K . What is the letter between F and O?\n",
      "['Y']\n"
     ]
    }
   ],
   "source": [
    "print(create(16))\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "id": "f5714609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X']\n",
      "['G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J']\n",
      "['J']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R']\n",
      "['G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L']\n",
      "['M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T']\n",
      "['T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R']\n",
      "['Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F']\n",
      "['V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F']\n",
      "['V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K']\n",
      "['K']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F']\n",
      "['F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I']\n",
      "['I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P']\n",
      "['Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I']\n",
      "['I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z']\n",
      "['K']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L']\n",
      "['Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J']\n",
      "['B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y']\n",
      "['Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K']\n",
      "['K']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F']\n",
      "['H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C']\n",
      "['P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X']\n",
      "['Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K']\n",
      "['Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O']\n",
      "['L']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S']\n",
      "['G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J']\n",
      "['L']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['L']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T']\n",
      "['T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S']\n",
      "['B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N']\n",
      "['V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R']\n",
      "['S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K']\n",
      "['U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R']\n",
      "['Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J']\n",
      "['Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F']\n",
      "['D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I']\n",
      "['N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V']\n",
      "['C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C']\n",
      "['I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y']\n",
      "['Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K']\n",
      "['K']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S']\n",
      "['B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "['M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T']\n",
      "['M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D']\n",
      "['D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P']\n",
      "['K']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I']\n",
      "['I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X']\n",
      "['X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N']\n",
      "['M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J']\n",
      "['L']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D']\n",
      "['K']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n",
      "['C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L']\n",
      "['L']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n",
      "['B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D']\n",
      "['D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D']\n",
      "['D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N']\n",
      "['S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "['M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E']\n",
      "['C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K']\n",
      "['X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y']\n",
      "['Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['L']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "['M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n",
      "['P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U']\n",
      "['I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W']\n",
      "['U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U']\n",
      "['U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C']\n",
      "['C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K']\n",
      "['H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C']\n",
      "['C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R']\n",
      "['G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D']\n",
      "['D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "['H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T']\n",
      "['X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C']\n",
      "['H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V']\n",
      "['S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y']\n",
      "['T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K']\n",
      "['K']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "['C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V']\n",
      "['V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "['M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P']\n",
      "['G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P']\n",
      "['B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W']\n",
      "['G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C']\n",
      "['B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C']\n",
      "['X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T']\n",
      "['S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L']\n",
      "['C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R']\n",
      "['N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X']\n",
      "['Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n",
      "['N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L']\n",
      "['D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n",
      "['D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E']\n",
      "['P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V']\n",
      "['C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U']\n",
      "['G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z']\n",
      "['S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V']\n",
      "['D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X']\n",
      "['X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P']\n",
      "['T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "['L']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X']\n",
      "['X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P']\n",
      "['X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q']\n",
      "['Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X']\n",
      "['U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S']\n",
      "['S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I']\n",
      "['S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N']\n",
      "['N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n",
      "['B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y']\n",
      "['C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K']\n",
      "['E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X']\n",
      "['X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O']\n",
      "['A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T']\n",
      "['T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D']\n",
      "['Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P']\n",
      "['H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V']\n",
      "['W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S']\n",
      "['F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H']\n",
      "['X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W']\n",
      "['R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n",
      "['J']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V']\n",
      "['Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G']\n",
      "['Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "['J']\n",
      "['V']\n",
      "['M']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1317"
      ]
     },
     "execution_count": 1548,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1548,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = \"\"\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=(num*22))\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        x = []\n",
    "        \n",
    "        for i in range(number-1,len(gen_text)):\n",
    "            if(i+1 >= len(gen_text)):\n",
    "                break\n",
    "            elif(gen_text[i] == \"\\n\"):\n",
    "                break\n",
    "            elif(gen_text[i] == \" \"):\n",
    "                pass\n",
    "            else:\n",
    "                x.append(gen_text[i])\n",
    "                \n",
    "                \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        print(ans)\n",
    "        print(x)\n",
    "        x = []\n",
    "        ans.clear()\n",
    "        \n",
    "fo = open(\"foo12_1.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp12_1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "id": "1d76f57b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " D D E F D O G A . What are the letters between F and O? D \n",
      " D G F A O G G D . What are the letters between F and O? A \n",
      " A F E O G A G G . What are the letters between F and O? E \n",
      " A D S A D F D O S . What are the letters between F and O? D \n",
      " D G S F E O G G . What are the letters between F and O? E \n",
      " E D G F S O S G M . What are the letters between F and O? S \n",
      " A A G F S O E G M . What are the letters between F and O? S \n",
      " E F G O D G S . What are the letters between F and O? G \n",
      " M E A F E O S . What are the letters between F and O? E \n",
      " A M D F A O A D . What are the letters between F and O? A \n",
      " M A F A O E S . What are the letters between F and O? A \n",
      " D G G D F D O . What are the letters between F and O? D \n",
      " G A F D O S M M A . What are the letters between F and O? D \n",
      " M M S S D E F A O . What are the letters between F and O? A \n",
      " A A E F A O A S . What are the letters between F and O? A \n",
      " E M G F D O M . What are the letters between F and O? D \n",
      " A E D F G O D G . What are the letters between F and O? G \n",
      " D M M A M F E O . What are the letters between F and O? E \n",
      " M G A D F G O . What are the letters between F and O? G \n",
      " G A M A F G O S A . What are the letters between F and O? G \n",
      " M A A A F S O E S . What are the letters between F and O?\n",
      " Correct: [2. 1. 5. 5. 2. 2. 2. 5. 2. 4. 5. 2. 4. 4. 3. 5. 5. 3. 3. 5.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo12.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1549,
   "id": "3eec3ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " V W F T O G J . What is the letter between F and O? T \n",
      " H Q B S F H O . What is the letter between F and O? H \n",
      " V U W F A O G . What is the letter between F and O? A \n",
      " N Z L F N O J E . What is the letter between F and O? N \n",
      " N M F W O J X . What is the letter between F and O? W \n",
      " U K I F K O S N U . What is the letter between F and O? K \n",
      " I M D T M K F P O . What is the letter between F and O? P \n",
      " G F K O L C E L H . What is the letter between F and O? K \n",
      " C F Y O J I U . What is the letter between F and O? Y \n",
      " Q L F D O T Z G . What is the letter between F and O? D \n",
      " R K C F W O I . What is the letter between F and O? W \n",
      " U Z U L F K O I . What is the letter between F and O? K \n",
      " T F U O I A G P Z . What is the letter between F and O? U \n",
      " S Y S R F K O Z B . What is the letter between F and O? K \n",
      " M F A O I E H G P . What is the letter between F and O? A \n",
      " U X J X I F W O . What is the letter between F and O? W \n",
      " K V B Q P Y F C O . What is the letter between F and O? C \n",
      " S P F J O W K G Q . What is the letter between F and O? J \n",
      " Z F L O E H B K K . What is the letter between F and O? L \n",
      " J I F M O U R . What is the letter between F and O? M \n",
      " F V O Z D M U U L . What is the letter between F and O?\n",
      " Correct: [1. 0. 0. 4. 6. 5. 2. 0. 4. 3. 3. 3. 1. 3. 3. 1. 3. 3. 4. 2.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo12_1.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "id": "39a318a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M']\n",
      "['M']\n",
      "['G']\n",
      "['S']\n",
      "['D']\n",
      "['G']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['S']\n",
      "['G']\n",
      "['D']\n",
      "['M']\n",
      "['S']\n",
      "['S']\n",
      "['S']\n",
      "['G']\n",
      "['A']\n",
      "['S']\n",
      "['S']\n",
      "['M']\n",
      "['S']\n",
      "['G']\n",
      "['G']\n",
      "['D']\n",
      "['G']\n",
      "['D']\n",
      "['D']\n",
      "['G']\n",
      "['G']\n",
      "['S']\n",
      "['S']\n",
      "['D']\n",
      "['D']\n",
      "['M']\n",
      "['M']\n",
      "['G']\n",
      "['D']\n",
      "['E']\n",
      "['G']\n",
      "['M']\n",
      "['O']\n",
      "['M']\n",
      "['O']\n",
      "['M']\n",
      "['O']\n",
      "['M']\n",
      "['A']\n",
      "['E']\n",
      "['E']\n",
      "['D']\n",
      "['D']\n",
      "['G']\n",
      "['G']\n",
      "['D']\n",
      "['E']\n",
      "['S']\n",
      "['S']\n",
      "['S']\n",
      "['S']\n",
      "['A']\n",
      "['A']\n",
      "['M']\n",
      "['M']\n",
      "['S']\n",
      "['S']\n",
      "['G']\n",
      "['G']\n",
      "['A']\n",
      "['G']\n",
      "['D']\n",
      "['A']\n",
      "['G']\n",
      "['G']\n",
      "['S']\n",
      "['S']\n",
      "['D']\n",
      "['D']\n",
      "['A']\n",
      "['S']\n",
      "['E']\n",
      "['E']\n",
      "['A']\n",
      "['O']\n",
      "['G']\n",
      "['S']\n",
      "['G']\n",
      "['F']\n",
      "['D']\n",
      "['O']\n",
      "['S']\n",
      "['E']\n",
      "['E']\n",
      "['S']\n",
      "['M']\n",
      "['D']\n",
      "['M']\n",
      "['S']\n",
      "['M']\n",
      "['M']\n",
      "['G']\n",
      "['G']\n",
      "['G']\n",
      "['A']\n",
      "['D']\n",
      "['A']\n",
      "['S']\n",
      "['G']\n",
      "['A']\n",
      "['S']\n",
      "['A']\n",
      "['E']\n",
      "['E']\n",
      "['E']\n",
      "['D']\n",
      "['D']\n",
      "['D']\n",
      "['M']\n",
      "['S']\n",
      "['O']\n",
      "['A']\n",
      "['A']\n",
      "['E']\n",
      "['E']\n",
      "['M']\n",
      "['E']\n",
      "['E']\n",
      "['M']\n",
      "['S']\n",
      "['A']\n",
      "['E']\n",
      "['A']\n",
      "['G']\n",
      "['G']\n",
      "['S']\n",
      "['S']\n",
      "['M']\n",
      "['G']\n",
      "['S']\n",
      "['D']\n",
      "['S']\n",
      "['S']\n",
      "['E']\n",
      "['E']\n",
      "['E']\n",
      "['G']\n",
      "['M']\n",
      "['G']\n",
      "['G']\n",
      "['D']\n",
      "['E']\n",
      "['E']\n",
      "['S']\n",
      "['S']\n",
      "['M']\n",
      "['G']\n",
      "['D']\n",
      "['E']\n",
      "['M']\n",
      "['D']\n",
      "['G']\n",
      "['O']\n",
      "['S']\n",
      "['O']\n",
      "['G']\n",
      "['O']\n",
      "['D']\n",
      "['G']\n",
      "['A']\n",
      "['A']\n",
      "['M']\n",
      "['G']\n",
      "['D']\n",
      "['M']\n",
      "['A']\n",
      "['E']\n",
      "['E']\n",
      "['G']\n",
      "['G']\n",
      "['M']\n",
      "['S']\n",
      "['S']\n",
      "['S']\n",
      "['S']\n",
      "['A']\n",
      "['D']\n",
      "['M']\n",
      "['E']\n",
      "['S']\n",
      "['S']\n",
      "['E']\n",
      "['E']\n",
      "['G']\n",
      "['E']\n",
      "['M']\n",
      "['M']\n",
      "['E']\n",
      "['M']\n",
      "['G']\n",
      "['O']\n",
      "['S']\n",
      "['M']\n",
      "['S']\n",
      "['G']\n",
      "['E']\n",
      "['A']\n",
      "['A']\n",
      "['G']\n",
      "['M']\n",
      "['G']\n",
      "['D']\n",
      "['G']\n",
      "['S']\n",
      "['A']\n",
      "['G']\n",
      "['G']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['D']\n",
      "['S']\n",
      "['G']\n",
      "['M']\n",
      "['M']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['G']\n",
      "['G']\n",
      "['D']\n",
      "['D']\n",
      "['E']\n",
      "['E']\n",
      "['M']\n",
      "['S']\n",
      "['A']\n",
      "['E']\n",
      "['D']\n",
      "['O']\n",
      "['D']\n",
      "['G']\n",
      "['E']\n",
      "['S']\n",
      "['E']\n",
      "['S']\n",
      "['A']\n",
      "['A']\n",
      "['M']\n",
      "['D']\n",
      "['E']\n",
      "['G']\n",
      "['E']\n",
      "['E']\n",
      "['E']\n",
      "['E']\n",
      "['D']\n",
      "['M']\n",
      "['G']\n",
      "['D']\n",
      "['S']\n",
      "['G']\n",
      "['E']\n",
      "['G']\n",
      "['G']\n",
      "['G']\n",
      "['A']\n",
      "['S']\n",
      "['D']\n",
      "['S']\n",
      "['G']\n",
      "['D']\n",
      "['E']\n",
      "['G']\n",
      "['G']\n",
      "['E']\n",
      "['S']\n",
      "['D']\n",
      "['A']\n",
      "['E']\n",
      "['G']\n",
      "['O']\n",
      "['S']\n",
      "['S']\n",
      "['E']\n",
      "['G']\n",
      "['A']\n",
      "['G']\n",
      "['D']\n",
      "['D']\n",
      "['S']\n",
      "['S']\n",
      "['S']\n",
      "['M']\n",
      "['M']\n",
      "['A']\n",
      "['G']\n",
      "['O']\n",
      "['G']\n",
      "['E']\n",
      "['E']\n",
      "['E']\n",
      "['A']\n",
      "['A']\n",
      "['M']\n",
      "['M']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['M']\n",
      "['M']\n",
      "['G']\n",
      "['M']\n",
      "['E']\n",
      "['G']\n",
      "['D']\n",
      "['O']\n",
      "['S']\n",
      "['M']\n",
      "['S']\n",
      "['E']\n",
      "['E']\n",
      "['S']\n",
      "['A']\n",
      "['G']\n",
      "['S']\n",
      "['S']\n",
      "['G']\n",
      "['D']\n",
      "['G']\n",
      "['A']\n",
      "['A']\n",
      "['A']\n",
      "['D']\n",
      "['E']\n",
      "['G']\n",
      "['G']\n",
      "['D']\n",
      "['E']\n",
      "['M']\n",
      "['M']\n",
      "['A']\n",
      "['G']\n",
      "['S']\n",
      "['E']\n",
      "['S']\n",
      "['S']\n",
      "['A']\n",
      "['D']\n",
      "['A']\n",
      "['A']\n",
      "['M']\n",
      "['G']\n",
      "['G']\n",
      "['S']\n",
      "['G']\n",
      "['D']\n",
      "['E']\n",
      "['A']\n",
      "['D']\n",
      "['M']\n",
      "['D']\n",
      "['A']\n",
      "['S']\n",
      "['F']\n",
      "['D']\n",
      "['O']\n",
      "['S']\n",
      "['D']\n",
      "['S']\n",
      "['A']\n",
      "['D']\n",
      "['S']\n",
      "['S']\n",
      "['E']\n",
      "['A']\n",
      "['M']\n",
      "['S']\n",
      "['S']\n",
      "['G']\n",
      "['G']\n",
      "['S']\n",
      "['S']\n",
      "['A']\n",
      "['G']\n",
      "['G']\n",
      "['G']\n",
      "['E']\n",
      "['G']\n",
      "['S']\n",
      "['M']\n",
      "['E']\n",
      "['E']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1361"
      ]
     },
     "execution_count": 1295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = \"\"\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "        \n",
    "        x = []\n",
    "        \n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x.append(response.choices[0].text[i]) \n",
    "                \n",
    "                \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "        print(ans)\n",
    "        print(x)\n",
    "        x = []\n",
    "        ans.clear()\n",
    "        \n",
    "fo = open(\"foo12_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp12_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab45b94",
   "metadata": {},
   "source": [
    "# 第2个到第4个字母是？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "id": "34e69b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(): #生成随机字符串，并进行长度比较\n",
    "    list1 = []\n",
    "    global count \n",
    "    count = np.zeros(5)\n",
    "    data = np.random.randint(7,10,1)\n",
    "    data1 = np.random.randint(1,data,2)\n",
    "\n",
    "    \n",
    "    global n1\n",
    "    n1 = data[0] #size of sample\n",
    "    elements = string.ascii_uppercase\n",
    "    ans = []\n",
    "    \n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    \n",
    "    for i in range(n1):  \n",
    "        \n",
    "        list1.append(random_pop1[i])\n",
    "    \n",
    "      \n",
    "    for i in range(1,4):\n",
    "        \n",
    "        ans.append(list1[i])\n",
    "            \n",
    "    \n",
    "            \n",
    "    list1.append(\".\")\n",
    "    list1.append(\"What are the second to fourth letters?\")\n",
    "    \n",
    "    list1.extend(ans)\n",
    "#     print(list1)\n",
    "    return list1\n",
    "\n",
    "\n",
    "def create(n):\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    \n",
    "    for i in range(1,n,1): \n",
    "        list2.append(\"\\n\")\n",
    "        list2.extend(function())\n",
    "       \n",
    "        \n",
    "    list2.append(\"\\n\")\n",
    "    \n",
    "    #生成测试用例\n",
    "    data = np.random.randint(7,10,1)\n",
    "    global n1\n",
    "    global ans \n",
    "    n1 = data[0] #size of sample\n",
    "    data1 = np.random.randint(0,data,2) #生成0与1的位置 data1[0]是0的位置，data1[1]是1的位置\n",
    "\n",
    "   \n",
    "    elements = string.ascii_uppercase\n",
    "    ans = []\n",
    "    \n",
    "    random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "    \n",
    "    for i in range(n1):  \n",
    "        \n",
    "        list1.append(random_pop1[i])\n",
    "    \n",
    "    list2.extend(list1)\n",
    "     \n",
    "    for i in range(1,4):\n",
    "        ans.append(list1[i])\n",
    "            \n",
    "            \n",
    "    list2.append(\".\")\n",
    "    list2.append(\"What are the second to fourth letters?\")\n",
    "    \n",
    "    \n",
    "    prompt = \" \".join(list2)\n",
    "    \n",
    "    return(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "id": "66581d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n E N K U Y J M G U . What are the second to fourth letters? N K U \\n G T G V P T T Q S . What are the second to fourth letters? T G V \\n Q X Q H T J K A . What are the second to fourth letters? X Q H \\n H C G E M L T V . What are the second to fourth letters? C G E \\n I G X Y Z D D F . What are the second to fourth letters? G X Y \\n Z K R J C F Y R . What are the second to fourth letters? K R J \\n P V H V R W Y J . What are the second to fourth letters? V H V \\n Z F M B H R P V M . What are the second to fourth letters? F M B \\n D B T I T W O . What are the second to fourth letters? B T I \\n Q I D W B R X I . What are the second to fourth letters? I D W \\n Y Y J Z C L M . What are the second to fourth letters? Y J Z \\n Y K O U S K X Z . What are the second to fourth letters? K O U \\n P Y Z Y X B W P . What are the second to fourth letters? Y Z Y \\n G Q Y T H Y L V Q . What are the second to fourth letters? Q Y T \\n W H D Y U Y D G R . What are the second to fourth letters?'"
      ]
     },
     "execution_count": 1469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "id": "d5463322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y', 'V', 'C']\n",
      "['C', 'Y', 'V', 'C', 'M', 'U', 'W', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'N', 'X']\n",
      "['S', 'P', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'I', 'I']\n",
      "['M', 'I', 'I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'B', 'Z']\n",
      "['W', 'G', 'B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'X', 'G']\n",
      "['J', 'X', 'X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'W', 'L']\n",
      "['J', 'W', 'L']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'S', 'U']\n",
      "['M', 'B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'L', 'H']\n",
      "['F', 'L', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'B', 'Y']\n",
      "['D', 'B', 'Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'N', 'Q']\n",
      "['Q', 'P', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'P', 'B']\n",
      "['L', 'P', 'B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', 'F', 'W']\n",
      "['G', 'V', 'F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'P', 'P']\n",
      "['T', 'P', 'P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U', 'R', 'V']\n",
      "['S', 'U', 'R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'F', 'D']\n",
      "['W', 'N', 'F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'Q', 'K']\n",
      "['Z', 'Q', 'K']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'F', 'T']\n",
      "['C', 'F', 'T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'W', 'Z']\n",
      "['I', 'W', 'Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'Q', 'D']\n",
      "['B', 'Q', 'D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'T', 'M']\n",
      "['O', 'T', 'M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'B', 'K']\n",
      "['W', 'P', 'B', 'K', 'K', 'M', 'J', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'M', 'P']\n",
      "['L', 'M', 'P', 'G', 'C', 'Q', 'S', 'P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H', 'A', 'R']\n",
      "['H', 'A', 'R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'X', 'C']\n",
      "['B', 'X', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'K']\n",
      "['A', 'B', 'K']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'R', 'A']\n",
      "['Z', 'N', 'R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'N', 'W']\n",
      "['M', 'N', 'W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'I']\n",
      "['O', 'I', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'C', 'P']\n",
      "['M', 'C', 'P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'U', 'A']\n",
      "['W', 'U', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'Q', 'X']\n",
      "['J', 'Q', 'X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', 'J', 'T']\n",
      "['V', 'J', 'T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'H', 'H']\n",
      "['S', 'H', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'E', 'B']\n",
      "['G', 'E', 'B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'Q', 'U']\n",
      "['N', 'B', 'Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'U', 'A']\n",
      "['J', 'U', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U', 'E', 'G']\n",
      "['U', 'E', 'G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'Y', 'N']\n",
      "['P', 'Y', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'E', 'T']\n",
      "['W', 'E', 'T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'X', 'I']\n",
      "['J', 'X', 'I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'E']\n",
      "['C', 'V', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'S', 'G']\n",
      "['T', 'S', 'G', 'M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'U', 'Y']\n",
      "['W', 'J', 'U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'H', 'Z']\n",
      "['B', 'H', 'Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'A', 'G']\n",
      "['A', 'G', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U', 'O', 'S']\n",
      "['S', 'U', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'R', 'D']\n",
      "['V', 'M', 'R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', 'I', 'W']\n",
      "['V', 'I', 'W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Q', 'S']\n",
      "['M', 'X', 'Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H', 'Y', 'X']\n",
      "['H', 'Y', 'X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'O', 'A']\n",
      "['W', 'O', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'Z', 'Q']\n",
      "['T', 'Z', 'Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H', 'O', 'L']\n",
      "['H', 'O', 'L']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'W', 'R']\n",
      "['Z', 'W', 'R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'I', 'R']\n",
      "['M', 'I', 'R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'C', 'M']\n",
      "['C', 'D', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'J', 'A']\n",
      "['Z', 'J', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'P', 'P']\n",
      "['B', 'P', 'P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'H', 'C']\n",
      "['G', 'H', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'L', 'D']\n",
      "['L', 'D', 'W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'J', 'O']\n",
      "['Z', 'X', 'J', 'O', 'O', 'K', 'J', 'M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'O', 'O']\n",
      "['V', 'E', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'X', 'S']\n",
      "['Y', 'T', 'X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', 'M', 'Y']\n",
      "['K', 'M', 'Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'Z', 'V']\n",
      "['F', 'Z', 'V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'A', 'C']\n",
      "['R', 'A', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'H', 'F']\n",
      "['Z', 'H', 'F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U', 'F', 'D']\n",
      "['R', 'U', 'F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H', 'H', 'S']\n",
      "['S', 'H', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'Q', 'P']\n",
      "['I', 'Q', 'P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', 'Z', 'S']\n",
      "['K', 'K', 'Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'D', 'I']\n",
      "['W', 'D', 'I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'G', 'N']\n",
      "['A', 'G', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', 'W', 'F']\n",
      "['W', 'F', 'D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', 'Z', 'O']\n",
      "['V', 'Z', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'Z', 'T']\n",
      "['M', 'Z', 'T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', 'D', 'V']\n",
      "['V', 'D', 'V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'E', 'T']\n",
      "['J', 'C', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'Q', 'I']\n",
      "['J', 'Q', 'I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'V', 'Z']\n",
      "['E', 'V', 'Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'O', 'B']\n",
      "['R', 'P', 'O', 'B', 'E', 'G', 'U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'J', 'H']\n",
      "['O', 'Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'J', 'O']\n",
      "['T', 'J', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'R', 'O']\n",
      "['T', 'T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'Q', 'X']\n",
      "['O', 'Q', 'X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'F', 'N']\n",
      "['E', 'E', 'F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'F', 'L']\n",
      "['E', 'F', 'L']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H', 'Q', 'K']\n",
      "['H', 'Q', 'K']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'K', 'B']\n",
      "['J', 'K', 'B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Q', 'I']\n",
      "['T', 'A', 'Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'X', 'S']\n",
      "['A', 'X', 'S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y', 'S', 'R']\n",
      "['S', 'R', 'S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'B', 'F']\n",
      "['F', 'J', 'B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'M', 'P']\n",
      "['J', 'M', 'P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'W', 'W']\n",
      "['W', 'W', 'W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'I', 'O']\n",
      "['D', 'I', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'I', 'T']\n",
      "['M', 'C', 'I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q', 'L', 'O']\n",
      "['Q', 'L', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'T', 'E']\n",
      "['T', 'E', 'T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'K', 'E']\n",
      "['I', 'I', 'K']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'T', 'Q']\n",
      "['Q', 'O', 'T', 'Q', 'A', 'B', 'C', 'Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'T', 'W']\n",
      "['J', 'J', 'T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q', 'F', 'Z']\n",
      "['Q', 'F', 'Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'O', 'E']\n",
      "['O', 'P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'S', 'C']\n",
      "['A', 'S', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'U', 'B']\n",
      "['O', 'U', 'B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U', 'O', 'V']\n",
      "['G', 'U', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'W', 'C']\n",
      "['H', 'D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q', 'N', 'R']\n",
      "['Q', 'N', 'R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'B', 'N']\n",
      "['I', 'B', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'H', 'N']\n",
      "['P', 'H', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y', 'I', 'O']\n",
      "['Y', 'I', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'N', 'A']\n",
      "['V', 'E', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'D', 'N']\n",
      "['X', 'D', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'P', 'I']\n",
      "['E', 'P', 'I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U', 'M', 'X']\n",
      "['T', 'U', 'M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'X', 'I']\n",
      "['X', 'I', 'S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'O', 'C']\n",
      "['M', 'O', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', 'X', 'M']\n",
      "['V', 'X', 'M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'A']\n",
      "['C', 'C', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'W', 'R']\n",
      "['X', 'R', 'W', 'R', 'U', 'X', 'B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H', 'N', 'Z']\n",
      "['H', 'N', 'Z']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'B', 'M']\n",
      "['D', 'B', 'M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'E', 'L']\n",
      "['E', 'I', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'A', 'I']\n",
      "['M', 'A', 'I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'W', 'O']\n",
      "['T', 'W', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'G', 'U']\n",
      "['M', 'B', 'G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', 'J', 'Q']\n",
      "['V', 'J', 'Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'Q', 'Y']\n",
      "['H', 'N', 'Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'E', 'R']\n",
      "['P', 'E', 'R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'P', 'C']\n",
      "['F', 'P', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'J', 'V']\n",
      "['J', 'J', 'V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'O', 'S']\n",
      "['Z', 'O', 'S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'U', 'W']\n",
      "['J', 'U', 'W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'Q', 'L']\n",
      "['N', 'Q', 'L']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U', 'D', 'H']\n",
      "['N', 'U', 'D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'P', 'X']\n",
      "['R', 'E', 'P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'X', 'E']\n",
      "['L', 'X', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'H', 'Z']\n",
      "['T', 'D', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'D', 'Y']\n",
      "['S', 'J', 'D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'U', 'N']\n",
      "['D', 'Q', 'U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'T', 'D']\n",
      "['B', 'T', 'D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'Y', 'S']\n",
      "['L', 'Y', 'S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y', 'Z', 'Z']\n",
      "['Z', 'F', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'A', 'E']\n",
      "['Z', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'D', 'Y']\n",
      "['F', 'P', 'D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'D', 'C']\n",
      "['V', 'E', 'D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'P', 'U']\n",
      "['F', 'P', 'U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'G', 'B']\n",
      "['W', 'A', 'G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'X', 'R']\n",
      "['E', 'N', 'X']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'V', 'H']\n",
      "['A', 'V', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'Z', 'R']\n",
      "['I', 'Z', 'R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'D', 'Y']\n",
      "['F', 'D', 'Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', 'I', 'Y']\n",
      "['V', 'I', 'Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'G', 'V']\n",
      "['O', 'G', 'V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'R', 'I']\n",
      "['R', 'R', 'I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'E', 'V']\n",
      "['E', 'V', 'N']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U', 'H', 'C']\n",
      "['C', 'U', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'F', 'C']\n",
      "['M', 'D', 'F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'L', 'E']\n",
      "['Z', 'L', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'Z', 'A']\n",
      "['I', 'S', 'Z', 'A', 'S', 'F', 'P', 'W']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'G', 'Y']\n",
      "['T', 'S', 'G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V', 'G', 'V']\n",
      "['V', 'G', 'V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'I', 'E']\n",
      "['I', 'F', 'I']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H', 'M', 'Q']\n",
      "['H', 'M', 'Q']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'U', 'C']\n",
      "['J', 'U', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'D', 'D']\n",
      "['Z', 'D', 'D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', 'T', 'F']\n",
      "['K', 'T', 'F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'I', 'D']\n",
      "['J', 'I', 'D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'W', 'V']\n",
      "['F', 'W', 'V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'F', 'A']\n",
      "['I', 'F', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'O', 'Y']\n",
      "['X', 'O', 'Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'H', 'S']\n",
      "['H', 'S', 'R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'D', 'V']\n",
      "['N', 'D', 'V']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'F', 'Q']\n",
      "['F', 'Q', 'G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'T', 'A']\n",
      "['E', 'T', 'A']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'G', 'J']\n",
      "['X', 'G', 'J']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'E', 'P']\n",
      "['Z', 'E', 'P']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'W', 'G']\n",
      "['W', 'W', 'G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 'F', 'A']\n",
      "['M', 'M', 'F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'L', 'F']\n",
      "['A', 'R', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S', 'X', 'Q']\n",
      "['T', 'S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'N', 'Q']\n",
      "['B', 'T']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K', 'I', 'C']\n",
      "['K', 'I', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'O', 'W']\n",
      "['U', 'L', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'O', 'Y']\n",
      "['T', 'O', 'Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'C', 'W']\n",
      "['M', 'D', 'C']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'I', 'U']\n",
      "['R', 'I', 'U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'F', 'F']\n",
      "['V', 'E', 'F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z', 'Q', 'G']\n",
      "['Z', 'Q', 'G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'L', 'U']\n",
      "['L', 'L', 'U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'Y', 'V']\n",
      "['L', 'E', 'Y']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'F']\n",
      "['W', 'X', 'F']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q', 'L', 'H']\n",
      "['Q', 'L', 'H']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'M', 'M']\n",
      "['P', 'M', 'M']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'D', 'J']\n",
      "['B', 'D', 'J']\n",
      "['P', 'Q', 'Y']\n",
      "['P', 'Q', 'Y']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1448"
      ]
     },
     "execution_count": 1460,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1460,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = \"\"\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=(num*25))\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = int(len(prompt)- num + 2)\n",
    "        \n",
    "        x = []\n",
    "        \n",
    "        for i in range(number-1,len(gen_text)):\n",
    "            if(i+1 >= len(gen_text)):\n",
    "                break\n",
    "            elif(gen_text[i] == \"\\n\"):\n",
    "                break\n",
    "            elif(gen_text[i] == \" \"):\n",
    "                pass\n",
    "            else:\n",
    "                x.append(gen_text[i])\n",
    "                \n",
    "                \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "            \n",
    "        print(ans)\n",
    "        print(x)\n",
    "        ans.clear()\n",
    "        x = []\n",
    "    \n",
    "fo = open(\"foo13.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp13.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2055,
   "id": "da19047e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " E W O G C R E F G . What are the second to fourth letters? W O G \n",
      " G Z M L H E W O . What are the second to fourth letters? Z M L \n",
      " H X L T Y Z K . What are the second to fourth letters? X L T \n",
      " L W B F G M F . What are the second to fourth letters? W B F \n",
      " F M Z Y B U E A . What are the second to fourth letters? M Z Y \n",
      " O W G P D E X . What are the second to fourth letters? W G P \n",
      " N S I H F B R W Y . What are the second to fourth letters? S I H \n",
      " H K G H Y C H . What are the second to fourth letters? K G H \n",
      " B D C Z Q Q P . What are the second to fourth letters? D C Z \n",
      " T W A R I B M . What are the second to fourth letters? W A R \n",
      " E U X O Y C K . What are the second to fourth letters? U X O \n",
      " W J F Q H X G A T . What are the second to fourth letters? J F Q \n",
      " M Q W K Z A N . What are the second to fourth letters? Q W K \n",
      " K F G F U X D G E . What are the second to fourth letters? F G F \n",
      " E B L Y R J U G G . What are the second to fourth letters? B L Y \n",
      " R F Z O E I L W . What are the second to fourth letters? F Z O \n",
      " P I G H P M W . What are the second to fourth letters? I G H \n",
      " D H X B Y J T Y . What are the second to fourth letters? H X B \n",
      " S B F R A K Q B . What are the second to fourth letters? B F R \n",
      " W W V C R H J O . What are the second to fourth letters? W V C \n",
      " L P Q Y P Y H R O . What are the second to fourth letters?\n",
      " Correct: [0. 2. 7. 4. 6. 6. 4. 7. 5. 7. 9. 6. 7. 8. 7. 6. 5. 8. 7. 6.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo13.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "id": "c87fd051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'H', 'J']\n",
      "['J', 'G', 'S', 'R']\n",
      "['W', 'L', 'A']\n",
      "['A', 'W', 'L']\n",
      "['T', 'U', 'U']\n",
      "['U', 'U', 'J']\n",
      "['L', 'K', 'G']\n",
      "['K', 'L']\n",
      "['W', 'E', 'Q']\n",
      "['W', 'E', 'Q']\n",
      "['C', 'C', 'K']\n",
      "['C', 'C', 'K']\n",
      "['U', 'W', 'B']\n",
      "['W', 'B']\n",
      "['H', 'B', 'B']\n",
      "['H', 'B', 'B']\n",
      "['H', 'U', 'O']\n",
      "['H', 'U', 'O']\n",
      "['L', 'T', 'C']\n",
      "['V', 'L', 'T']\n",
      "['N', 'P', 'O']\n",
      "['N', 'P', 'O']\n",
      "['X', 'U', 'N']\n",
      "['X', 'U', 'N']\n",
      "['E', 'F', 'I']\n",
      "['N', 'E', 'F']\n",
      "['D', 'D', 'E']\n",
      "['D', 'E', 'J']\n",
      "['F', 'C', 'Y']\n",
      "['V', 'F', 'C']\n",
      "['P', 'Z', 'Z']\n",
      "['R', 'P']\n",
      "['U', 'O', 'X']\n",
      "['U', 'O', 'X']\n",
      "['F', 'G', 'X']\n",
      "['F', 'G', 'X']\n",
      "['R', 'L', 'D']\n",
      "['L', 'D', 'C']\n",
      "['I', 'V', 'P']\n",
      "['I', 'V', 'P']\n",
      "['U', 'T', 'J']\n",
      "['J', 'P', 'I']\n",
      "['S', 'Z', 'M']\n",
      "['V', 'S', 'Z']\n",
      "['L', 'K', 'J']\n",
      "['Q', 'L', 'K']\n",
      "['I', 'G', 'L']\n",
      "['S', 'I', 'G']\n",
      "['V', 'J', 'X']\n",
      "['D', 'V']\n",
      "['X', 'C', 'G']\n",
      "['X', 'C', 'G']\n",
      "['T', 'X', 'M']\n",
      "['T', 'X']\n",
      "['X', 'P', 'E']\n",
      "['X', 'P', 'E']\n",
      "['V', 'C', 'T']\n",
      "['V', 'C', 'T']\n",
      "['H', 'M', 'V']\n",
      "['H', 'M', 'V']\n",
      "['B', 'X', 'P']\n",
      "['B', 'X', 'P']\n",
      "['K', 'I', 'T']\n",
      "['K', 'I', 'T']\n",
      "['E', 'M', 'E']\n",
      "['E', 'V', 'H']\n",
      "['C', 'K', 'S']\n",
      "['C', 'K', 'S']\n",
      "['P', 'H', 'X']\n",
      "['H', 'X', 'X']\n",
      "['Y', 'Y', 'O']\n",
      "['Y', 'Y', 'O']\n",
      "['I', 'F', 'N']\n",
      "['I', 'F', 'N']\n",
      "['U', 'B', 'J']\n",
      "['C', 'U', 'B']\n",
      "['D', 'L', 'L']\n",
      "['V', 'D', 'L']\n",
      "['V', 'F', 'I']\n",
      "['V', 'F', 'I']\n",
      "['J', 'F', 'H']\n",
      "['J', 'F', 'H']\n",
      "['Z', 'Z', 'W']\n",
      "['E', 'Z', 'Z']\n",
      "['U', 'B', 'Q']\n",
      "['Q', 'A', 'X']\n",
      "['Z', 'X', 'E']\n",
      "['Z', 'X', 'E']\n",
      "['E', 'J', 'X']\n",
      "['W', 'E']\n",
      "['T', 'W', 'E']\n",
      "['D', 'T']\n",
      "['L', 'G', 'U']\n",
      "['A', 'L', 'G']\n",
      "['C', 'E', 'J']\n",
      "['C', 'E', 'J']\n",
      "['W', 'I', 'U']\n",
      "['U', 'W']\n",
      "['T', 'I', 'S']\n",
      "['T', 'I', 'S']\n",
      "['E', 'B', 'T']\n",
      "['E', 'B', 'T']\n",
      "['N', 'W', 'A']\n",
      "['N', 'W', 'A']\n",
      "['Y', 'L', 'Z']\n",
      "['Y', 'L', 'Z']\n",
      "['H', 'K', 'O']\n",
      "['H', 'K', 'O']\n",
      "['V', 'H', 'G']\n",
      "['H', 'V', 'H']\n",
      "['X', 'M', 'X']\n",
      "['V', 'X']\n",
      "['V', 'Q', 'D']\n",
      "['V', 'Q', 'D']\n",
      "['N', 'K', 'I']\n",
      "['N', 'K', 'I']\n",
      "['X', 'I', 'U']\n",
      "['X', 'I', 'U']\n",
      "['M', 'G', 'V']\n",
      "['M', 'G', 'V']\n",
      "['X', 'P', 'B']\n",
      "['D', 'X', 'P']\n",
      "['B', 'L', 'E']\n",
      "['J', 'B', 'L']\n",
      "['L', 'A', 'O']\n",
      "['U', 'L', 'A']\n",
      "['L', 'A', 'E']\n",
      "['J', 'L', 'A']\n",
      "['M', 'K', 'O']\n",
      "['Z', 'M', 'K']\n",
      "['A', 'E', 'N']\n",
      "['E', 'A', 'E']\n",
      "['H', 'U', 'A']\n",
      "['H', 'U', 'A']\n",
      "['X', 'T', 'I']\n",
      "['V', 'X', 'T']\n",
      "['M', 'Y', 'X']\n",
      "['M', 'Y', 'X']\n",
      "['G', 'E', 'O']\n",
      "['Z', 'G', 'E']\n",
      "['M', 'E', 'T']\n",
      "['Q', 'M', 'E']\n",
      "['W', 'O', 'F']\n",
      "['W', 'O', 'F']\n",
      "['T', 'D', 'J']\n",
      "['T', 'D', 'J']\n",
      "['W', 'B', 'P']\n",
      "['W', 'B', 'P']\n",
      "['U', 'A', 'Y']\n",
      "['U', 'U', 'A']\n",
      "['Q', 'F', 'A']\n",
      "['F', 'A', 'W']\n",
      "['M', 'U', 'M']\n",
      "['M', 'U', 'M']\n",
      "['F', 'F', 'L']\n",
      "['F', 'F', 'L']\n",
      "['D', 'Q', 'O']\n",
      "['D', 'Q', 'O']\n",
      "['Q', 'X', 'U']\n",
      "['Q', 'X', 'U']\n",
      "['N', 'X', 'I']\n",
      "['B', 'N', 'X', 'I', 'L']\n",
      "['Y', 'T', 'K']\n",
      "['Z', 'Y', 'T']\n",
      "['O', 'J', 'A']\n",
      "['O', 'J', 'A']\n",
      "['Y', 'F', 'L']\n",
      "['Y', 'F', 'L']\n",
      "['X', 'O', 'N']\n",
      "['X', 'O', 'N']\n",
      "['S', 'P', 'T']\n",
      "['S', 'P', 'T']\n",
      "['N', 'J', 'D']\n",
      "['G', 'N', 'J']\n",
      "['R', 'S', 'H']\n",
      "['Z', 'R', 'S']\n",
      "['Q', 'E', 'G']\n",
      "['Q', 'E', 'G']\n",
      "['Y', 'N', 'Z']\n",
      "['Y', 'N', 'Z']\n",
      "['L', 'I', 'T']\n",
      "['N', 'L']\n",
      "['B', 'L', 'K']\n",
      "['Y', 'B']\n",
      "['N', 'X', 'Z']\n",
      "['X', 'Z', 'J']\n",
      "['G', 'I', 'P']\n",
      "['F', 'G', 'I']\n",
      "['M', 'X', 'Y']\n",
      "['M', 'X', 'Y']\n",
      "['K', 'Y', 'S']\n",
      "['M', 'K', 'Y']\n",
      "['I', 'M', 'M']\n",
      "['I', 'M', 'M']\n",
      "['T', 'O', 'Q']\n",
      "['O', 'Q']\n",
      "['V', 'C', 'N']\n",
      "['K', 'V', 'C']\n",
      "['W', 'U', 'W']\n",
      "['W', 'U', 'W']\n",
      "['Z', 'V', 'R']\n",
      "['K', 'B', 'I', 'P', 'Z']\n",
      "['Z', 'O', 'G']\n",
      "['Z', 'O', 'G']\n",
      "['C', 'X', 'Z']\n",
      "['C', 'X']\n",
      "['S', 'R', 'A']\n",
      "['S', 'R', 'A']\n",
      "['F', 'E', 'W']\n",
      "['I', 'F', 'E']\n",
      "['K', 'O', 'L']\n",
      "['S', 'K', 'O']\n",
      "['Z', 'Z', 'Z']\n",
      "['Z', 'Z', 'Z']\n",
      "['D', 'Z', 'O']\n",
      "['W', 'D']\n",
      "['N', 'R', 'O']\n",
      "['K', 'N', 'R']\n",
      "['K', 'K', 'R']\n",
      "['K', 'K', 'R']\n",
      "['L', 'C', 'S']\n",
      "['U', 'L', 'C']\n",
      "['R', 'G', 'Z']\n",
      "['G', 'R', 'G']\n",
      "['J', 'R', 'C']\n",
      "['D', 'J', 'R']\n",
      "['W', 'P', 'M']\n",
      "['W', 'P', 'M']\n",
      "['X', 'K', 'I']\n",
      "['X', 'K', 'I']\n",
      "['B', 'R', 'C']\n",
      "['B', 'R', 'C']\n",
      "['V', 'T', 'Z']\n",
      "['V', 'T', 'Z']\n",
      "['A', 'H', 'B']\n",
      "['A', 'H', 'B']\n",
      "['M', 'G', 'O']\n",
      "['M', 'G', 'O']\n",
      "['J', 'F', 'S']\n",
      "['G', 'J', 'F']\n",
      "['K', 'G', 'C']\n",
      "['Z', 'X', 'J']\n",
      "['S', 'F', 'A']\n",
      "['S', 'F', 'A']\n",
      "['Y', 'B', 'Q']\n",
      "['B', 'Q']\n",
      "['A', 'J', 'S']\n",
      "['P', 'A', 'J']\n",
      "['B', 'J', 'J']\n",
      "['B', 'J', 'J']\n",
      "['T', 'N', 'Z']\n",
      "['T', 'N', 'Z']\n",
      "['U', 'R', 'K']\n",
      "['O', 'U', 'R']\n",
      "['L', 'N', 'L']\n",
      "['L', 'N', 'L']\n",
      "['N', 'U', 'E']\n",
      "['O', 'N']\n",
      "['O', 'Z', 'Q']\n",
      "['O', 'Z', 'Q']\n",
      "['K', 'D', 'V']\n",
      "['K', 'D', 'V']\n",
      "['U', 'R', 'S']\n",
      "['U', 'U', 'R']\n",
      "['R', 'W', 'A']\n",
      "['R', 'W', 'A']\n",
      "['B', 'X', 'N']\n",
      "['J', 'B']\n",
      "['P', 'E', 'F']\n",
      "['P', 'E', 'F']\n",
      "['B', 'U', 'N']\n",
      "['B', 'U', 'N']\n",
      "['A', 'E', 'G']\n",
      "['K', 'A', 'E']\n",
      "['Y', 'V', 'M']\n",
      "['Y', 'V', 'M']\n",
      "['M', 'W', 'W']\n",
      "['M', 'W', 'W']\n",
      "['S', 'H', 'V']\n",
      "['S', 'H', 'V']\n",
      "['Q', 'E', 'I']\n",
      "['A', 'Q', 'E', 'I', 'A']\n",
      "['P', 'A', 'B']\n",
      "['B', 'P']\n",
      "['P', 'H', 'W']\n",
      "['O', 'P']\n",
      "['E', 'I', 'F']\n",
      "['O', 'E', 'I']\n",
      "['P', 'O', 'N']\n",
      "['P', 'P', 'O']\n",
      "['E', 'B', 'I']\n",
      "['E', 'B', 'I']\n",
      "['E', 'N', 'A']\n",
      "['A', 'E']\n",
      "['Q', 'P', 'G']\n",
      "['Q', 'P', 'G']\n",
      "['O', 'L', 'D']\n",
      "['O', 'L', 'D']\n",
      "['U', 'B', 'S']\n",
      "['U', 'B', 'S']\n",
      "['A', 'L', 'Y']\n",
      "['A', 'L', 'Y']\n",
      "['J', 'U', 'A']\n",
      "['J', 'U', 'A']\n",
      "['B', 'L', 'D']\n",
      "['B', 'L', 'D']\n",
      "['C', 'E', 'I']\n",
      "['C', 'E', 'I']\n",
      "['K', 'I', 'M']\n",
      "['K', 'I', 'M']\n",
      "['I', 'L', 'L']\n",
      "['I', 'L', 'L']\n",
      "['S', 'T', 'L']\n",
      "['X', 'S']\n",
      "['W', 'E', 'Q']\n",
      "['W', 'E', 'Q']\n",
      "['N', 'Z', 'V']\n",
      "['N', 'Z', 'V']\n",
      "['N', 'O', 'Z']\n",
      "['N', 'O', 'Z']\n",
      "['Q', 'L', 'I']\n",
      "['D', 'Q', 'L', 'I', 'Z']\n",
      "['I', 'E', 'Q']\n",
      "['R', 'I', 'E']\n",
      "['D', 'K', 'V']\n",
      "['L', 'D', 'K']\n",
      "['U', 'V', 'T']\n",
      "['U', 'V', 'T']\n",
      "['A', 'G', 'O']\n",
      "['A', 'G', 'O']\n",
      "['Z', 'B', 'C']\n",
      "['K', 'Z']\n",
      "['Z', 'N', 'F']\n",
      "['Z', 'N', 'F']\n",
      "['D', 'S', 'R']\n",
      "['W', 'D']\n",
      "['C', 'E', 'F']\n",
      "['C', 'E', 'F']\n",
      "['L', 'N', 'K']\n",
      "['O', 'L', 'N']\n",
      "['B', 'N', 'D']\n",
      "['B', 'N', 'D']\n",
      "['Y', 'Y', 'X']\n",
      "['Y', 'Y', 'X']\n",
      "['J', 'I', 'D']\n",
      "['J', 'I', 'D']\n",
      "['L', 'O', 'U']\n",
      "['L', 'O', 'U']\n",
      "['Q', 'F', 'C']\n",
      "['Q', 'F', 'C']\n",
      "['J', 'X', 'J']\n",
      "['J', 'X', 'J']\n",
      "['P', 'N', 'N']\n",
      "['P', 'N', 'N']\n",
      "['G', 'K', 'Z']\n",
      "['G', 'K', 'Z']\n",
      "['W', 'O', 'Z']\n",
      "['W', 'O', 'Z']\n",
      "['S', 'I', 'M']\n",
      "['S', 'S', 'I']\n",
      "['G', 'E', 'K']\n",
      "['I', 'G', 'E', 'K', 'Y']\n",
      "['V', 'J', 'M']\n",
      "['V', 'J', 'M']\n",
      "['U', 'Y', 'I']\n",
      "['U', 'Y', 'I']\n",
      "['W', 'E', 'N']\n",
      "['W', 'E', 'N']\n",
      "['R', 'Z', 'V']\n",
      "['N', 'R', 'Z']\n",
      "['B', 'P', 'C']\n",
      "['C', 'B', 'P']\n",
      "['S', 'L', 'V']\n",
      "['S', 'L', 'V']\n",
      "['M', 'U', 'J']\n",
      "['Z', 'M', 'U']\n",
      "['I', 'F', 'E']\n",
      "['I', 'F', 'E']\n",
      "['X', 'Q', 'V']\n",
      "['X', 'Q', 'V']\n",
      "['H', 'T', 'Z']\n",
      "['H', 'T', 'Z']\n",
      "['M', 'Q', 'V']\n",
      "['M', 'Q', 'V']\n",
      "['L', 'C', 'U']\n",
      "['L', 'C', 'U']\n",
      "['W', 'Z', 'Z']\n",
      "['W', 'Z', 'Z']\n",
      "['L', 'U', 'K']\n",
      "['Z', 'L', 'U']\n",
      "['Q', 'J', 'C']\n",
      "['Q', 'J']\n",
      "['X', 'Q', 'J']\n",
      "['X', 'Q', 'J']\n",
      "['N', 'J', 'O']\n",
      "['N', 'J', 'O']\n",
      "['C', 'Y', 'K']\n",
      "['C', 'Y', 'K']\n",
      "['Y', 'F', 'A']\n",
      "['Y', 'F', 'A']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1456"
      ]
     },
     "execution_count": 1470,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1470,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = \"\"\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(2,22,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        prompt = create(num)\n",
    "        input_ids = tokenizer1(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        \n",
    "        x = []\n",
    "        \n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=prompt, temperature=0.1, max_tokens=5)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x.append(response.choices[0].text[i]) \n",
    "                \n",
    "                \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-2] += 1\n",
    "        else:\n",
    "            F[num-2] += 1\n",
    "            \n",
    "        print(ans)\n",
    "        print(x)\n",
    "        ans.clear()\n",
    "        x = []\n",
    "    \n",
    "fo = open(\"foo13_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(prompt,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp13_gpt3_2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "id": "416ecf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " E E S S A E M . What are the second to fourth letters? E S S \n",
      " G G E M E S D S S . What are the second to fourth letters? G E M \n",
      " M D D D E E D G M . What are the second to fourth letters? D D D \n",
      " A S E D E M G D S . What are the second to fourth letters? S E D \n",
      " S D S A M G S . What are the second to fourth letters? D S A \n",
      " E M M S S E E . What are the second to fourth letters? M M S \n",
      " D E D E A M G A . What are the second to fourth letters? E D E \n",
      " D M D G D A E . What are the second to fourth letters? M D G \n",
      " A S A A S D G . What are the second to fourth letters? S A A \n",
      " M G M S E A D . What are the second to fourth letters? G M S \n",
      " E S G S M D M D . What are the second to fourth letters? S G S \n",
      " S E S M S A A E . What are the second to fourth letters? E S M \n",
      " E A D D D S A E . What are the second to fourth letters? A D D \n",
      " E E G M G S E G G . What are the second to fourth letters? E G M \n",
      " A M E E M E E S . What are the second to fourth letters? M E E \n",
      " E S M A E E E A M . What are the second to fourth letters? S M A \n",
      " E M M D E M A D . What are the second to fourth letters? M M D \n",
      " M S M A A M A . What are the second to fourth letters? S M A \n",
      " G D D M D D A D . What are the second to fourth letters? D D M \n",
      " G S E A M A G M G . What are the second to fourth letters? S E A \n",
      " D S M S A D M A S . What are the second to fourth letters?\n",
      " Correct: [0. 2. 2. 2. 2. 9. 4. 4. 3. 5. 4. 6. 4. 6. 4. 5. 4. 6. 7. 5.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo13_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "id": "d01855ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " C H J W G A E K V . What are the second to fourth letters? H J W \n",
      " D B Z D Y V D . What are the second to fourth letters? B Z D \n",
      " O J T N P O P M D . What are the second to fourth letters? J T N \n",
      " V D P V P M C L A . What are the second to fourth letters? D P V \n",
      " D A V C A Z H E . What are the second to fourth letters? A V C \n",
      " S M B Q O X X M X . What are the second to fourth letters? M B Q \n",
      " A J V Y E D M . What are the second to fourth letters? J V Y \n",
      " E T B X K R R Z F . What are the second to fourth letters? T B X \n",
      " I Z U F R H D O . What are the second to fourth letters? Z U F \n",
      " Z T L P D E K O . What are the second to fourth letters? T L P \n",
      " O Y X P U L V . What are the second to fourth letters? Y X P \n",
      " R S R K M R U K . What are the second to fourth letters? S R K \n",
      " F B Y K K E V M . What are the second to fourth letters? B Y K \n",
      " Q G Q M K M M . What are the second to fourth letters? G Q M \n",
      " W H N N H Z C G . What are the second to fourth letters? H N N \n",
      " P X X B Q I G . What are the second to fourth letters? X X B \n",
      " A G A A Z K X . What are the second to fourth letters? G A A \n",
      " O J M F Q K F W . What are the second to fourth letters? J M F \n",
      " P P A N X Z X C . What are the second to fourth letters? P A N \n",
      " T P Z H O U G F O . What are the second to fourth letters? P Z H \n",
      " X Y F A E Z R I C . What are the second to fourth letters?\n",
      " Correct: [1. 3. 2. 5. 4. 5. 4. 5. 7. 7. 7. 7. 6. 7. 5. 5. 8. 8. 7. 8.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo13_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7615cf5",
   "metadata": {},
   "source": [
    "# 根据下面的图型，找到没有用到的材料：(其实是差集)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "id": "df6fc544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function(): #生成随机字符串，并进行长度比较\n",
    "#     list1 = []\n",
    "#     list2 = []\n",
    "#     ans = []\n",
    "#     data = np.random.randint(2,5,1) #第一个随机数是一号的长度，第二个是2号中随机数存放的位置，第三个是随机数是2号需要添加的随机数个数\n",
    "#     data1 = np.random.randint(1,data,1)\n",
    "#     data2 = np.random.randint(1,5,1)\n",
    "#     n1 = data[0] #size of sample\n",
    "#     elements = set([\"E\", \"A\", \"M\", \"D\", \"G\"])\n",
    "#     random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "#     j = 0\n",
    "#     t = \"\"\n",
    "#     n2 = data1[0] #size of sample\n",
    "#     n3 = data2[0]\n",
    "#     #print(n1,n2,n3)\n",
    "#     random_pop2 = [element for i in range(n3) for element in random.sample(elements, 1)]\n",
    "#     for i in range(n1):    \n",
    "#         list1.append(random_pop1[i]) \n",
    "    \n",
    "#     for i in range(n1+n3):  \n",
    "#         if(i == n2):\n",
    "# #             print(list2)\n",
    "#             list2.extend(random_pop2) \n",
    "#             ans.extend(random_pop2)\n",
    "# #           print(list2)\n",
    "#         else:\n",
    "#             list2.append(list1[j])\n",
    "#             j += 1\n",
    "#             if(j>=(len(list1))):\n",
    "#                 break\n",
    "#             else:\n",
    "#                 pass\n",
    "            \n",
    "#     j = 0\n",
    "#     list1.append(\"|\")\n",
    "#     list1.extend(list2)\n",
    "    \n",
    "#     list1.append(\".\")\n",
    "#     list1.append(\"What are the differences between them?\")\n",
    "    \n",
    "#     list1.extend(ans)\n",
    "#     ans = []\n",
    "#     return(list1)\n",
    "\n",
    "# def create(n):\n",
    "#     list1 = []\n",
    "#     list2 = []\n",
    "#     list3 = []\n",
    "#     list4 = []\n",
    "#     function()\n",
    "    \n",
    "#     for i in range(1,n,1):\n",
    "#         list2.append(\"\\n\")\n",
    "#         list2.extend(function())\n",
    "        \n",
    "#     global ans\n",
    "#     ans = []\n",
    "#     data = np.random.randint(2,5,1) #第一个随机数是一号的长度第三个是随机数是2号需要添加的随机数个数\n",
    "#     data1 = np.random.randint(1,data,1)#第二个是2号中随机数存放的位置\n",
    "#     data2 = np.random.randint(1,5,1)#第三个是随机数是2号需要添加的随机数个数\n",
    "#     n1 = data[0] #size of sample\n",
    "#     elements = set([\"E\", \"A\", \"M\", \"D\", \"G\"])\n",
    "#     random_pop1 = [element for i in range(n1) for element in random.sample(elements, 1)]\n",
    "#     j = 0\n",
    "#     t = \"\"\n",
    "#     n2 = data1[0] #size of sample\n",
    "#     n3 = data2[0]\n",
    "    \n",
    "#     random_pop2 = [element for i in range(n3) for element in random.sample(elements, 1)]\n",
    "#     for i in range(n1):    \n",
    "#         list3.append(random_pop1[i]) \n",
    "    \n",
    "#     for i in range(n1+n3):  \n",
    "#         if(i == n2):\n",
    "# #             print(list2)\n",
    "#             list4.extend(random_pop2) \n",
    "#             ans.extend(random_pop2)\n",
    "# #           print(list2)\n",
    "#         else:\n",
    "#             list4.append(list3[j])\n",
    "#             j += 1\n",
    "#             if(j>=(len(list3))):\n",
    "#                 break\n",
    "#             else:\n",
    "#                 pass\n",
    "            \n",
    "#     j = 0\n",
    "#     list3.append(\"|\")\n",
    "#     list3.extend(list4)\n",
    "    \n",
    "#     list3.append(\".\")\n",
    "#     list3.append(\"What are the differences between them?\")\n",
    "    \n",
    "#     list2.append(\"\\n\")\n",
    "#     list2.extend(list3)\n",
    "    \n",
    "#     str = \" \"\n",
    "#     prompt = str.join(list2)\n",
    "    \n",
    "#     return(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2142,
   "id": "eda8fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "def find_unused(a, b): return list(set(b) - set(a)) # 该题目专用\n",
    "global t\n",
    "\n",
    "def make_examples(transform_fn, n_examples, vocab=string.ascii_uppercase):  # 很多题目可以共用代码框架\n",
    "    examples = []\n",
    "    \n",
    "    for _ in range(n_examples):\n",
    "        \n",
    "        input_len = random.randint(3, 5)\n",
    "        \n",
    "        # 该题目专用部分\n",
    "        a = random.sample(vocab, input_len)\n",
    "        b = a.copy()\n",
    "        b.insert(random.randint(0, input_len), random.choice(list(set(vocab) - set(a))))\n",
    "        \n",
    "        examples.append([a, b, transform_fn(a, b)])\n",
    "    return examples\n",
    "\n",
    "def example2str(example):  # 很多任务可以共用\n",
    "    a, b, ans = example\n",
    "    \n",
    "    return '%s | %s -> %s' % (' '.join(a), ' '.join(b), ' '.join(ans))\n",
    "\n",
    "\n",
    "\n",
    "def exampleque(example):  # 很多任务可以共用\n",
    "    a, b, ans = example\n",
    "    global an\n",
    "    an = example[2]\n",
    "    return '%s | %s ->' % (' '.join(a), ' '.join(b))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847da4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 26, but ``max_length`` is set to 25.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(1,21,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        text = '\\n'.join(example2str(e) for e in make_examples(find_unused,num))  # 很多任务可以共用\n",
    "        text+='\\n'\n",
    "        text += '\\n'.join(exampleque(e) for e in make_examples(find_unused,1))\n",
    "        \n",
    "        input_ids = tokenizer1(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=(num*25))\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = int(len(text))\n",
    "        \n",
    "        x = []\n",
    "        \n",
    "        for i in range(number,len(gen_text)):\n",
    "            if(gen_text[i] == \"\\n\"):\n",
    "                break\n",
    "            elif(gen_text[i] == \" \"):\n",
    "                pass\n",
    "            else:\n",
    "                x.append(gen_text[i])\n",
    "                \n",
    "                \n",
    "        if(str(x) == str(an)):\n",
    "            T[num-1] += 1\n",
    "        else:\n",
    "            F[num-1] += 1\n",
    "            \n",
    "        \n",
    "#         print(\"len(gen_text)=\",ln(gen_text))\n",
    "#         print(\"len(text)=\",len(text))\n",
    "#         print(an)\n",
    "#         print(x)\n",
    "        text1 = text\n",
    "        text=\"\"\n",
    "    \n",
    "        x.clear()\n",
    "    \n",
    "fo = open(\"foo14.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(text1,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp14.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1429,
   "id": "89af0a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2067,
   "id": "fa10db9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: I B Z W U | I B Z O W U -> O\n",
      "D W H L | D W Y H L -> Y\n",
      "K A Z M W | K A N Z M W ->\n",
      " Correct: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo14.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2068,
   "id": "ead99c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 2068,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 2068,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(1,21,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        text = '\\n'.join(example2str(e) for e in make_examples(find_unused,num))  # 很多任务可以共用\n",
    "        text+='\\n'\n",
    "        text += '\\n'.join(exampleque(e) for e in make_examples(find_unused,1))\n",
    "        input_ids = tokenizer1(text, return_tensors=\"pt\").input_ids\n",
    "        \n",
    "        x = []\n",
    "        \n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=text, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x.append(response.choices[0].text[i]) \n",
    "                \n",
    "#         print(x)\n",
    "#         print(an)\n",
    "        if(str(x) == str(an)):\n",
    "            T[num-1] += 1\n",
    "        else:\n",
    "            F[num-1] += 1\n",
    "        text1 = text    \n",
    "        text=\"\"\n",
    "        an = \"\"\n",
    "        x.clear()\n",
    "        \n",
    "fo = open(\"foo14_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(text1,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp14_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2070,
   "id": "ea5484c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " Correct: [ 5.  5.  6.  7.  8.  9. 10.  8.  8.  9.  9.  6.  8. 10. 10.  9. 10. 10.\n",
      " 10. 10.]\n",
      " Total: 10\n",
      "R X M | R G X M -> G\n",
      "B C K G | L B C K G -> L\n",
      "C A Q U | Z C A Q U -> Z\n",
      "J D N H | J D F N H -> F\n",
      "D J M | D I J M -> I\n",
      "U I Y P | U K I Y P -> K\n",
      "N S H V | K N S H V -> K\n",
      "G O N M | G O Z N M -> Z\n",
      "U T Y | S U T Y -> S\n",
      "F N Z | F S N Z -> S\n",
      "J U L A Q | J U P L A Q -> P\n",
      "I D Q Y | I R D Q Y -> R\n",
      "E F T K | E F T K R -> R\n",
      "X U A | S X U A -> S\n",
      "D E C | D E Z C -> Z\n",
      "L S M T | H L S M T -> H\n",
      "C D V | C G D V -> G\n",
      "I X Z | A I X Z -> A\n",
      "Z R L P | Z R L P K -> K\n",
      "V M H Y D | B V M H Y D -> B\n",
      "C W M N | C W M T N ->\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo14_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2071,
   "id": "abec287b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 2071,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo = open(\"foo14_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(text1,str(T),Count))\n",
    "\n",
    "fo.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2072,
   "id": "53063de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: R X M | R G X M -> G\n",
      "B C K G | L B C K G -> L\n",
      "C A Q U | Z C A Q U -> Z\n",
      "J D N H | J D F N H -> F\n",
      "D J M | D I J M -> I\n",
      "U I Y P | U K I Y P -> K\n",
      "N S H V | K N S H V -> K\n",
      "G O N M | G O Z N M -> Z\n",
      "U T Y | S U T Y -> S\n",
      "F N Z | F S N Z -> S\n",
      "J U L A Q | J U P L A Q -> P\n",
      "I D Q Y | I R D Q Y -> R\n",
      "E F T K | E F T K R -> R\n",
      "X U A | S X U A -> S\n",
      "D E C | D E Z C -> Z\n",
      "L S M T | H L S M T -> H\n",
      "C D V | C G D V -> G\n",
      "I X Z | A I X Z -> A\n",
      "Z R L P | Z R L P K -> K\n",
      "V M H Y D | B V M H Y D -> B\n",
      "C W M N | C W M T N ->\n",
      " Correct: [ 5.  5.  6.  7.  8.  9. 10.  8.  8.  9.  9.  6.  8. 10. 10.  9. 10. 10.\n",
      " 10. 10.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo14_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be48e08a",
   "metadata": {},
   "source": [
    "# 下面哪个图形最牢固："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2003,
   "id": "f9b5bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "global t\n",
    "\n",
    "voc = string.ascii_uppercase.replace('A','')\n",
    "voca =voc.replace('B','')\n",
    "def make_examples( n_examples,vocab=voca):\n",
    "    examples = []\n",
    "    an = \"\"\n",
    "    for _ in range(n_examples): \n",
    "        input_len = np.random.randint(5, 7, 2)\n",
    "        an_len = np.random.randint(3,5,1)\n",
    "        loc = np.random.randint(2,3,1)\n",
    "        \n",
    "        a = random.sample(vocab, input_len[0])\n",
    "        b = random.sample(vocab, input_len[1])\n",
    "        c = random.sample(vocab, an_len[0])\n",
    "        c.append(\"A\")\n",
    "        c.append(\"B\")\n",
    "        random.shuffle(c)\n",
    "        abc = [a,b,c]\n",
    "        random.shuffle(abc)\n",
    "        for i in range(1,len(abc)+1): \n",
    "            if(abc[i-1] == c): \n",
    "                an=i\n",
    "        examples.append([abc[0], abc[1], abc[2], an])\n",
    "    return examples\n",
    "\n",
    "def example2str(example):  \n",
    "    a, b, c, an = example\n",
    "    return 'AB, 1)%s , 2)%s , 3)%s -> %s' % (' '.join(a), ' '.join(b), ' '.join(c), ' '.join(str(an)))\n",
    "\n",
    "def exampleque(example):   \n",
    "    a, b, c, an = example\n",
    "    global ans\n",
    "    ans = an\n",
    "    #print(ans)\n",
    "    return 'AB, 1)%s , 2)%s , 3)%s ->' % (' '.join(a), ' '.join(b), ' '.join(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2004,
   "id": "ade5ed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB, 1)Q X J O Z S , 2)L I C M K , 3)B M C A S -> 3\n",
      "AB, 1)H U Q L K W , 2)A B N O L , 3)P D J H X Y -> 2\n",
      "AB, 1)L W E B K A , 2)D K T G U , 3)Y N R O I -> 1\n",
      "AB, 1)C X G F S Y , 2)Y I N V P , 3)H Y A B U W -> 3\n",
      "AB, 1)A U W D B , 2)J D L M H , 3)F D U R N -> 1\n",
      "AB, 1)G R V T A B , 2)F U L R H , 3)Z F Q I C -> 1\n",
      "AB, 1)F N X Z K Y , 2)B H I M A K , 3)S J H V K ->\n"
     ]
    }
   ],
   "source": [
    "text = '\\n'.join(example2str(i) for i in make_examples(num))  # 很多任务可以共用\n",
    "text += '\\n'\n",
    "text += 'n'.join(exampleque(i) for i in make_examples(1))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2007,
   "id": "9a64127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 57, but ``max_length`` is set to 40.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 85, but ``max_length`` is set to 80.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 58, but ``max_length`` is set to 40.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 85, but ``max_length`` is set to 80.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 57, but ``max_length`` is set to 40.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 86, but ``max_length`` is set to 80.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2007-df1bdde95510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mgen_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mgen_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1004\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   1526\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1116\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    996\u001b[0m                 )\n\u001b[1;32m    997\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    999\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     ):\n\u001b[0;32m--> 600\u001b[0;31m         outputs = self.attention(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nas/xd/transformers/src/transformers/models/gpt_neo/modeling_gpt_neo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mpast_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'k_hidden_states'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_value_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_value_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m  \u001b[0;31m# XD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kf/miniconda3/envs/pytorch1.7.1/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "x = \"\"\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(1,21,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        text = '\\n'.join(example2str(i) for i in make_examples(num))  # 很多任务可以共用\n",
    "        text += '\\n'\n",
    "        text += 'n'.join(exampleque(i) for i in make_examples(1))\n",
    "        input_ids = tokenizer1(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        gen_tokens = model1.generate(input_ids, do_sample=True, temperature=0.1, max_length=(num*40))\n",
    "        gen_text = tokenizer1.batch_decode(gen_tokens)[0]\n",
    "        number = (len(text) - (2 * num) - 2)\n",
    "        \n",
    "        x = \"\"\n",
    "        \n",
    "        for i in range(number,len(gen_text)+1):\n",
    "            if(i+1 >= len(gen_text)):\n",
    "                break\n",
    "            elif(gen_text[i] == \"\\n\"):\n",
    "                break\n",
    "            elif(gen_text[i] == \" \"):\n",
    "                pass\n",
    "            else:\n",
    "                x = gen_text[i]\n",
    "                \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-1] += 1\n",
    "        else:\n",
    "            F[num-1] += 1\n",
    "        \n",
    "fo = open(\"foo15.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(text,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp15.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1897,
   "id": "c938d5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198"
      ]
     },
     "execution_count": 1897,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 1897,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQZ0lEQVR4nO3df6zdd13H8efLlmoCCwx7xdkfdGAlqYowrx0qzkUGdsy0KEi6+GMTsCHSCKJoCaYh9Z8NIiaaRimwiATsBgpeXbFMxBhNNtvNMehGt7tabJuxjbFsGiKj8vaP8y05XM7tPff2nPvj4/ORnNzvj/c53/f9fL/n1XO/33NOU1VIktr0HUvdgCRpfAx5SWqYIS9JDTPkJalhhrwkNWz1Um147dq1tWnTpqXavCStSHfeeeeXq2pi2PolC/lNmzZx9OjRpdq8JK1ISb44n3pP10hSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGDRXySbYlOZ5kOsmeWWpem+TeJMeSfGS0bUqSFmLO98knWQXsB14OnAaOJJmqqnv7ajYDbwd+sqoeT/I942pYkjS8YV7JbwWmq+pEVT0FHAR2zKj5dWB/VT0OUFWPjLZNSdJCDPOJ13XAqb7508DlM2p+ACDJvwKrgHdW1d/PfKAku4BdABs3blxIv9Ki2bTn1nnVn7zhmjF1Ii3cqC68rgY2A1cC1wLvS/KsmUVVdaCqJqtqcmJi6K9ekCQt0DAhfwbY0De/vlvW7zQwVVVfr6r/AO6nF/qSpCU0TMgfATYnuTTJGmAnMDWj5hP0XsWTZC290zcnRtemJGkh5gz5qjoL7AYOA/cBt1TVsST7kmzvyg4DjyW5F/gM8LaqemxcTUuShjPUVw1X1SHg0Ixle/umC3hrd5MkLRN+4lWSGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGjZUyCfZluR4kukkewasvz7Jo0nu7m5vGH2rkqT5Wj1XQZJVwH7g5cBp4EiSqaq6d0bpzVW1eww9SpIWaJhX8luB6ao6UVVPAQeBHeNtS5I0CnO+kgfWAaf65k8Dlw+oe3WSK4D7gd+qqlMzC5LsAnYBbNy4cf7dasls2nPrvOpP3nDNSO67Us33d4Y2fm8tP6O68Pq3wKaqeiFwG/DBQUVVdaCqJqtqcmJiYkSbliTNZpiQPwNs6Jtf3y37pqp6rKq+1s2+H/jR0bQnSboQw4T8EWBzkkuTrAF2AlP9BUku6ZvdDtw3uhYlSQs15zn5qjqbZDdwGFgF3FRVx5LsA45W1RTwm0m2A2eBrwDXj7FnSdKQhrnwSlUdAg7NWLa3b/rtwNtH25ok6UL5iVdJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNGyrkk2xLcjzJdJI956l7dZJKMjm6FiVJCzVnyCdZBewHrga2ANcm2TKg7iLgzcAdo25SkrQww7yS3wpMV9WJqnoKOAjsGFD3B8CNwP+MsD9J0gVYPUTNOuBU3/xp4PL+giSXARuq6tYkb5vtgZLsAnYBbNy4cf7drnCb9tw67/ucvOGaMXSyclzomM33/i2M94X8zks53iv1+bHc+77gC69JvgN4D/Dbc9VW1YGqmqyqyYmJiQvdtCRpDsOE/BlgQ9/8+m7ZORcBPwT8U5KTwEuAKS++StLSGybkjwCbk1yaZA2wE5g6t7KqnqiqtVW1qao2AbcD26vq6Fg6liQNbc6Qr6qzwG7gMHAfcEtVHUuyL8n2cTcoSVq4YS68UlWHgEMzlu2dpfbKC29LkjQKfuJVkhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekho2VMgn2ZbkeJLpJHsGrH9jks8luTvJvyTZMvpWJUnzNWfIJ1kF7AeuBrYA1w4I8Y9U1Q9X1YuAdwHvGXWjkqT5G+aV/FZguqpOVNVTwEFgR39BVT3ZN/t0oEbXoiRpoVYPUbMOONU3fxq4fGZRkjcBbwXWAD8z6IGS7AJ2AWzcuHG+vX7Tpj23zvs+J2+4ZsH3H9V9L9RK7VtaDB7jg43swmtV7a+q5wO/B/z+LDUHqmqyqiYnJiZGtWlJ0iyGCfkzwIa++fXdstkcBF51AT1JkkZkmJA/AmxOcmmSNcBOYKq/IMnmvtlrgAdG16IkaaHmPCdfVWeT7AYOA6uAm6rqWJJ9wNGqmgJ2J7kK+DrwOHDdOJuWJA1nmAuvVNUh4NCMZXv7pt884r4kSSPgJ14lqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1bKiQT7ItyfEk00n2DFj/1iT3JrknyaeTPHf0rUqS5mvOkE+yCtgPXA1sAa5NsmVG2b8Dk1X1QuBjwLtG3agkaf6GeSW/FZiuqhNV9RRwENjRX1BVn6mqr3aztwPrR9umJGkhVg9Rsw441Td/Grj8PPWvBz45aEWSXcAugI0bNw7ZoiSN16Y9t86r/uQN14ypk9Eb6YXXJL8MTALvHrS+qg5U1WRVTU5MTIxy05KkAYZ5JX8G2NA3v75b9i2SXAW8A/jpqvraaNqTJF2IYV7JHwE2J7k0yRpgJzDVX5DkxcB7ge1V9cjo25QkLcScIV9VZ4HdwGHgPuCWqjqWZF+S7V3Zu4FnAB9NcneSqVkeTpK0iIY5XUNVHQIOzVi2t2/6qhH3JUkaAT/xKkkNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNGyrkk2xLcjzJdJI9A9ZfkeSuJGeTvGb0bUqSFmLOkE+yCtgPXA1sAa5NsmVG2X8C1wMfGXWDkqSFWz1EzVZguqpOACQ5COwA7j1XUFUnu3XfGEOPkqQFGuZ0zTrgVN/86W7ZvCXZleRokqOPPvroQh5CkjQPi3rhtaoOVNVkVU1OTEws5qYl6f+lYUL+DLChb359t0yStMwNE/JHgM1JLk2yBtgJTI23LUnSKMwZ8lV1FtgNHAbuA26pqmNJ9iXZDpDkx5KcBn4ReG+SY+NsWpI0nGHeXUNVHQIOzVi2t2/6CL3TOJKkZcRPvEpSwwx5SWqYIS9JDTPkJalhhrwkNcyQl6SGGfKS1DBDXpIaZshLUsMMeUlqmCEvSQ0z5CWpYYa8JDXMkJekhhnyktQwQ16SGmbIS1LDDHlJapghL0kNM+QlqWGGvCQ1zJCXpIYZ8pLUMENekhpmyEtSwwx5SWrYUCGfZFuS40mmk+wZsP47k9zcrb8jyaaRdypJmrc5Qz7JKmA/cDWwBbg2yZYZZa8HHq+q7wf+CLhx1I1KkuZvmFfyW4HpqjpRVU8BB4EdM2p2AB/spj8GvCxJRtemJGkhUlXnL0heA2yrqjd0878CXF5Vu/tqPt/VnO7mH+xqvjzjsXYBu7rZFwDHR/WLdNYCX56zamks196Wa1+wfHtbrn3B8u3NvuZvtt6eW1UTwz7I6tH1M7eqOgAcGNfjJzlaVZPjevwLsVx7W659wfLtbbn2Bcu3N/uav1H1NszpmjPAhr759d2ygTVJVgPPBB670OYkSRdmmJA/AmxOcmmSNcBOYGpGzRRwXTf9GuAfa67zQJKksZvzdE1VnU2yGzgMrAJuqqpjSfYBR6tqCvgA8KEk08BX6P1DsBTGdipoBJZrb8u1L1i+vS3XvmD59mZf8zeS3ua88CpJWrn8xKskNcyQl6SGrciQX65fs5BkQ5LPJLk3ybEkbx5Qc2WSJ5Lc3d32LlJvJ5N8rtvm0QHrk+SPuzG7J8lli9TXC/rG4u4kTyZ5y4yaRRmzJDcleaT73Me5Zc9OcluSB7qfF89y3+u6mgeSXDeoZgy9vTvJF7r99fEkz5rlvufd92Po651JzvTtr1fOct/zPo/H0NfNfT2dTHL3LPcd23h1jz8wJ8Z2rFXVirrRu/j7IPA8YA3wWWDLjJrfAP6sm94J3LxIvV0CXNZNXwTcP6C3K4G/W4JxOwmsPc/6VwKfBAK8BLhjifbtl+h92GPRxwy4ArgM+HzfsncBe7rpPcCNA+73bOBE9/PibvriRejtFcDqbvrGQb0Ns+/H0Nc7gd8ZYl+f93k86r5mrP9DYO9ij1f3+ANzYlzH2kp8Jb9sv2ahqh6qqru66f8C7gPWjXu7I7ID+IvquR14VpJLFrmHlwEPVtUXF3m7AFTVP9N7d1i//mPpg8CrBtz1Z4HbquorVfU4cBuwbdy9VdWnqupsN3s7vc+wLKpZxmwYwzyPx9JXlwWvBf5yVNubj/PkxFiOtZUY8uuAU33zp/n2IP1mTfckeAL47kXprtOdInoxcMeA1T+e5LNJPpnkBxeppQI+leTO9L5eYqZhxnXcdjL7E28pxgzgOVX1UDf9JeA5A2qWw9i9jt5fYoPMte/HYXd3GummWU47LOWY/RTwcFU9MMv6RRuvGTkxlmNtJYb8spfkGcBfAW+pqidnrL6L3umIHwH+BPjEIrX10qq6jN63ib4pyRWLtN2hpPdBu+3ARwesXqox+xbV+3t52b3nOMk7gLPAh2cpWex9/6fA84EXAQ/ROzWynFzL+V/FL8p4nS8nRnmsrcSQX9Zfs5DkafR23Ier6q9nrq+qJ6vqv7vpQ8DTkqwdd19Vdab7+QjwcXp/LvcbZlzH6Wrgrqp6eOaKpRqzzsPnTlt1Px8ZULNkY5fkeuDngF/qguHbDLHvR6qqHq6q/62qbwDvm2V7SzJmXR78AnDzbDWLMV6z5MRYjrWVGPLL9msWunN9HwDuq6r3zFLzveeuDyTZSm8fjPUfoCRPT3LRuWl6F+w+P6NsCvjV9LwEeKLvT8fFMOurq6UYsz79x9J1wN8MqDkMvCLJxd2piVd0y8YqyTbgd4HtVfXVWWqG2fej7qv/Ws7Pz7K9YZ7H43AV8IXqvjF3psUYr/PkxHiOtXFdQR7njd47Qe6nd3X+Hd2yffQOdoDvovdn/zTwb8DzFqmvl9L7E+se4O7u9krgjcAbu5rdwDF67ya4HfiJRejred32Pttt+9yY9fcVev85zIPA54DJRdyfT6cX2s/sW7boY0bvH5mHgK/TO9f5enrXcj4NPAD8A/DsrnYSeH/ffV/XHW/TwK8tUm/T9M7PnjvWzr2j7PuAQ+fb92Pu60PdMXQPveC6ZGZf3fy3PY/H2Ve3/M/PHVd9tYs2Xt02ZsuJsRxrfq2BJDVsJZ6ukSQNyZCXpIYZ8pLUMENekhpmyEtSwwx5SWqYIS9JDfs/UkRamOvX4uoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = np.zeros(20)   #存储正确的情况\n",
    "F = np.zeros(20)   #存储错误的情况\n",
    "\n",
    "Count = 0  #样例总数\n",
    "# t = int(input()) #产生的上下文条数\n",
    "# n = int(input()) #测试几次\n",
    "Count = 10\n",
    "\n",
    "\n",
    "for i in range(1,11,1): #因为循环不计算右边界，所以如果要生成10个例子，需要写n = 11\n",
    "    for num in range(1,21,1): #这里从2开始，传到create函数中才会生成一个上下文，所以，要生成10个上下文，这里应该写12\n",
    "        text = '\\n'.join(example2str(i) for i in make_examples(num))  # 很多任务可以共用\n",
    "        text += '\\n'\n",
    "        text += 'n'.join(exampleque(i) for i in make_examples(1))\n",
    "        input_ids = tokenizer1(text, return_tensors=\"pt\").input_ids\n",
    "        \n",
    "        x = \"\"\n",
    "        \n",
    "        openai.api_key = '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'\n",
    "\n",
    "        response = openai.Completion.create(engine=\"davinci\", prompt=text, temperature=0.1, max_tokens=1)\n",
    "        \n",
    "        for i in range(0,len(response.choices[0].text)):\n",
    "            if(response.choices[0].text[i] == \" \"):\n",
    "                pass\n",
    "            elif(response.choices[0].text[i] == \"\\n\"):\n",
    "                break\n",
    "            else:\n",
    "                x=response.choices[0].text[i] \n",
    "                \n",
    "        if(str(x) == str(ans)):\n",
    "            T[num-1] += 1\n",
    "        else:\n",
    "            F[num-1] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "fo = open(\"foo15_gpt3.txt\", \"w\")\n",
    "fo.write(\"Test sample: %s\\n Correct: %s\\n Total: %s\" %(text,str(T),Count))\n",
    "# 关闭打开的文件\n",
    "fo.close()\n",
    "\n",
    "acc = np.zeros(20)\n",
    "for i in range(20):\n",
    "    acc[i] = T[i]/Count\n",
    "number = int(len(prompt)- num + 2)\n",
    "plt.bar(range(len(acc)), acc)\n",
    "plt.savefig(\"temp15_gpt3.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1899,
   "id": "2d854c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: AB, 1)H Q X M P C , 2)A B M T E , 3)C U J M E -> 2\n",
      "AB, 1)T H X Z R D , 2)Y F G N S Z , 3)M H A B V K -> 3\n",
      "AB, 1)P K U N F , 2)K A B L G I , 3)M R J O X V -> 2\n",
      "AB, 1)I S F Z U , 2)H C A B L D , 3)T R F X S Z -> 2\n",
      "AB, 1)Y K W G M L , 2)Y S J K T M , 3)W C A B V Z -> 3\n",
      "AB, 1)A B M W N V , 2)H S K Y C , 3)Y Z W I C J -> 1\n",
      "AB, 1)J Q P D K V , 2)J K D X Y , 3)K Q A B V M -> 3\n",
      "AB, 1)A B K H F T , 2)H X C M S G , 3)C D W G J E -> 1\n",
      "AB, 1)W A B T I L , 2)J Q N Y C K , 3)X M R N J -> 1\n",
      "AB, 1)G K J N T , 2)J S T F G E , 3)H C A B X Q -> 3\n",
      "AB, 1)R P M G O Z , 2)Q I Z V R , 3)U L A B G -> 3\n",
      "AB, 1)H A B D Y , 2)W O U F N G , 3)V Y X T J O -> 1\n",
      "AB, 1)A B D J R O , 2)F O G Q W , 3)P U S E Z R -> 1\n",
      "AB, 1)A B U Z C , 2)G T X K Z H , 3)H L G W S -> 1\n",
      "AB, 1)X Y E S T , 2)F O A B D , 3)G F Q J W M -> 2\n",
      "AB, 1)R K I H C , 2)M H G U Q S , 3)W A B O I -> 3\n",
      "AB, 1)J D A B W , 2)Q D V Y J E , 3)V T G D L -> 1\n",
      "AB, 1)L A B Q V I , 2)V X Z O D , 3)Y J S W Q Z -> 1\n",
      "AB, 1)F N J P W V , 2)Q R X E J I , 3)A B W K I G -> 3\n",
      "AB, 1)S N V C J , 2)M J A B D , 3)W Z R M V D -> 2\n",
      "AB, 1)W L E F Z , 2)M A B V C O , 3)J Z T C K ->\n",
      " Correct: [3. 3. 3. 4. 3. 3. 5. 5. 4. 4. 6. 5. 0. 4. 4. 4. 4. 3. 2. 4.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo15_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9026b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def find_unused(a, b): return list(set(b) - set(a)) # 该题目专用\n",
    "\n",
    "def make_examples(transform_fn, vocab=string.ascii_uppercase, n_examples=10):  # 很多题目可以共用代码框架\n",
    "    examples = []\n",
    "    for _ in range(n_examples):\n",
    "        input_len = random.randint(3, 5)\n",
    "        \n",
    "        # 该题目专用部分\n",
    "        a = random.sample(vocab, input_len)\n",
    "        b = a.copy()\n",
    "        b.insert(random.randint(0, input_len), random.choice(list(set(vocab) - set(a))))\n",
    "        \n",
    "        examples.append([a, b, transform_fn(a, b)])\n",
    "    return examples\n",
    "\n",
    "def example2str(example):  # 很多任务可以共用\n",
    "    a, b, ans = example\n",
    "    return '%s | %s -> %s' % (' '.join(a), ' '.join(b), ' '.join(ans))\n",
    "\n",
    "text = '\\n'.join(example2str(e) for e in make_examples(find_unused))  # 很多任务可以共用\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606fdad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def find_unused(a, b): return list(set(b) - set(a)) # 该题目专用\n",
    "\n",
    "def make_examples(transform_fn, vocab=string.ascii_uppercase, n_examples=10):  # 很多题目可以共用代码框架\n",
    "    examples = []\n",
    "    for _ in range(n_examples):\n",
    "        input_len = random.randint(3, 5)\n",
    "        \n",
    "        # 该题目专用部分\n",
    "        a = random.sample(vocab, input_len)\n",
    "        b = a.copy()\n",
    "        b.insert(random.randint(0, input_len), random.choice(list(set(vocab) - set(a))))\n",
    "        \n",
    "        examples.append([a, b, transform_fn(a, b)])\n",
    "    return examples\n",
    "\n",
    "def example2str(example):  # 很多任务可以共用\n",
    "    a, b, ans = example\n",
    "    return '%s | %s -> %s' % (' '.join(a), ' '.join(b), ' '.join(ans))\n",
    "\n",
    "text = '\\n'.join(example2str(e) for e in make_examples(find_unused))  # 很多任务可以共用\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1977,
   "id": "51dfee09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " M D M G | G . Are they equal in number? No \n",
      " A | E G G E . Are they equal in number? No \n",
      " A | M . Are they equal in number? Yes \n",
      " D | G M M . Are they equal in number? No \n",
      " G G M G | M G A G . Are they equal in number? Yes \n",
      " D M M M | E G A G . Are they equal in number? Yes \n",
      " E A | M E G M . Are they equal in number? No \n",
      " M | E A D . Are they equal in number? No \n",
      " G G | G M E . Are they equal in number? No \n",
      " D | G M M . Are they equal in number? No \n",
      " A | A M A M . Are they equal in number? No \n",
      " A | G A . Are they equal in number? No \n",
      " A G | A D A D . Are they equal in number? No \n",
      " G | E M . Are they equal in number? No \n",
      " D G | M A . Are they equal in number? Yes \n",
      " M D G | A D M . Are they equal in number? Yes \n",
      " D | E . Are they equal in number? Yes \n",
      " M G D | G E M . Are they equal in number? Yes \n",
      " E M | G . Are they equal in number? No \n",
      " E | E A A E . Are they equal in number? No \n",
      " E M D M | A M . Are they equal in number?\n",
      " Correct: [4. 4. 5. 8. 5. 4. 6. 6. 9. 8. 6. 7. 7. 9. 6. 8. 9. 5. 5. 7.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo1_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1978,
   "id": "a7d08658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " M D G M G M A M E . Which letter has the largest number? M \n",
      " E E E D A M . Which letter has the largest number? E \n",
      " A G A E A D G G G . Which letter has the largest number? G \n",
      " M E A M M A A M . Which letter has the largest number? M \n",
      " M M E A E M D G A . Which letter has the largest number? M \n",
      " A E D M D G D . Which letter has the largest number? D \n",
      " G E G D M D D . Which letter has the largest number? D \n",
      " E E M G D M G D . Which letter has the largest number? D \n",
      " M A E A M A . Which letter has the largest number? A \n",
      " G M G D G G E A M . Which letter has the largest number? G \n",
      " M M G G M E M G A . Which letter has the largest number? M \n",
      " D A G D G G A . Which letter has the largest number? G \n",
      " D E E M E E A E D . Which letter has the largest number? E \n",
      " G D G G G D G . Which letter has the largest number? G \n",
      " D M D M A D G G E . Which letter has the largest number? D \n",
      " G A M G M A M D . Which letter has the largest number? M \n",
      " D A M A G M M D . Which letter has the largest number? M \n",
      " A G A E E E M . Which letter has the largest number? E \n",
      " D D M G G D D G . Which letter has the largest number? D \n",
      " M E M E G E M M A . Which letter has the largest number? M \n",
      " G E G M E A A G . Which letter has the largest number?\n",
      " Correct: [ 4.  5.  6.  5.  2.  8.  7.  7.  7.  5.  6.  4.  3.  7.  7.  8. 10.  6.\n",
      "  7.  8.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo2_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"foo3_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1980,
   "id": "0c1916db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " 17 15 12 15 12 13 17 . How many numbers are greater than 14? 4 \n",
      " 12 11 17 10 13 10 . How many numbers are greater than 14? 1 \n",
      " 17 14 11 17 16 17 16 13 10 . How many numbers are greater than 14? 5 \n",
      " 14 10 14 15 16 15 15 . How many numbers are greater than 14? 4 \n",
      " 14 13 12 11 10 12 11 14 17 . How many numbers are greater than 14? 1 \n",
      " 11 17 10 17 16 17 17 13 13 . How many numbers are greater than 14? 5 \n",
      " 17 11 11 15 14 11 . How many numbers are greater than 14? 2 \n",
      " 10 16 11 11 14 16 . How many numbers are greater than 14? 2 \n",
      " 13 14 11 13 17 14 11 16 13 . How many numbers are greater than 14? 2 \n",
      " 10 17 13 17 16 15 17 16 17 . How many numbers are greater than 14? 7 \n",
      " 12 13 13 15 15 11 16 . How many numbers are greater than 14? 3 \n",
      " 10 16 16 10 10 12 17 . How many numbers are greater than 14? 3 \n",
      " 16 11 14 17 10 12 14 17 . How many numbers are greater than 14? 3 \n",
      " 13 17 10 11 12 11 14 12 . How many numbers are greater than 14? 1 \n",
      " 11 16 11 11 16 13 12 11 16 . How many numbers are greater than 14? 3 \n",
      " 16 17 15 17 17 11 15 . How many numbers are greater than 14? 6 \n",
      " 12 11 12 10 15 16 . How many numbers are greater than 14? 2 \n",
      " 17 10 16 17 17 16 17 10 16 . How many numbers are greater than 14? 7 \n",
      " 13 17 11 13 17 10 12 . How many numbers are greater than 14? 2 \n",
      " 17 10 11 12 13 14 14 . How many numbers are greater than 14? 1 \n",
      " 16 15 16 14 14 11 . How many numbers are greater than 14?\n",
      " Correct: [1. 2. 3. 1. 3. 6. 4. 3. 2. 2. 3. 5. 5. 2. 3. 4. 2. 4. 4. 6.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo4_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1981,
   "id": "d0932582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " F | A D D D D D D E E E E G G . Which words are more than F? D E G \n",
      " F F | A A A A A A D D D E E E G G . Which words are more than F? A D E \n",
      " F F | A A A A A A D E E E G G G G G G . Which words are more than F? A E G \n",
      " F | A A A A A D D D D D E E E G G G . Which words are more than F? A D E G \n",
      " F | A A A D D D D D D E E E G G . Which words are more than F? A D E G \n",
      " F F F | A A A D D D E E E E E E E G G G . Which words are more than F? E \n",
      " F | A A A A D D D D D D E E E G . Which words are more than F? A D E \n",
      " F F F | A A D D D D D E E E E E E G G G . Which words are more than F? D E \n",
      " F F | A A A A A D D D D D E E E E G G . Which words are more than F? A D E \n",
      " F F | A A A A D D D D E G G G G G G . Which words are more than F? A D G \n",
      " F | D D D D E E E E G G G G G . Which words are more than F? D E G \n",
      " F | A A E E E E E G G G G G G G . Which words are more than F? A E G \n",
      " F | A A A A D D D E G G G G G . Which words are more than F? A D G \n",
      " F F | A A A A D E E E E E E G G G . Which words are more than F? A E G \n",
      " F | A A A A D D E E E G G G G . Which words are more than F? A D E G \n",
      " F F | A A A D D D D D E G G G G . Which words are more than F? A D G \n",
      " F | A A A A A A A A D D G G G G . Which words are more than F? A D G \n",
      " F | A A A A A D D E E G G G G . Which words are more than F? A D E G \n",
      " F F F | A A A D D D D D D E E G G G G G . Which words are more than F? D G \n",
      " F F F | A A A A A A A A D D D G G . Which words are more than F? A \n",
      " F | A A A D D D D E E E G G G . Which words are more than F?\n",
      " Correct: [2. 3. 4. 2. 2. 1. 2. 5. 1. 5. 1. 2. 3. 2. 2. 4. 2. 6. 8. 2.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo5_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)      #测试只限制一个时，准确率是否会上升\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1982,
   "id": "aa0dcb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " F F | A E G U U . Which character has the same number as F? U \n",
      " F F | A E G K K . Which character has the same number as F? K \n",
      " F F | D D E . Which character has the same number as F? D \n",
      " F F F | A A A D E . Which character has the same number as F? A \n",
      " F F | A A D . Which character has the same number as F? A \n",
      " F F F | A A D G G P P P . Which character has the same number as F? P \n",
      " F F F | A A D D G R R R . Which character has the same number as F? R \n",
      " F F F | D D D D E U U U . Which character has the same number as F? U \n",
      " F F | D E G K K . Which character has the same number as F? K \n",
      " F F F | A D E E G R R R . Which character has the same number as F? R \n",
      " F F | A D E T T . Which character has the same number as F? T \n",
      " F F F | A D D D G . Which character has the same number as F? D \n",
      " F F | A A D . Which character has the same number as F? A \n",
      " F F | E E G . Which character has the same number as F? E \n",
      " F F F | A A E E G R R R . Which character has the same number as F? R \n",
      " F F F | D G G G G K K K . Which character has the same number as F? K \n",
      " F F | A A E . Which character has the same number as F? A \n",
      " F F | A D E K K . Which character has the same number as F? K \n",
      " F F | A D G K K . Which character has the same number as F? K \n",
      " F F F | D D E G G P P P . Which character has the same number as F? P \n",
      " F F F | A E E E G . Which character has the same number as F?\n",
      " Correct: [ 0.  9.  9.  6. 10.  8.  6. 10.  7.  9.  9. 10.  9.  9. 10.  8.  9.  8.\n",
      "  9.  8.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo6_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1983,
   "id": "a112122e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " D D D D . how many characters are there? 4 \n",
      " D D D D D D D D D . how many characters are there? 9 \n",
      " G G G G . how many characters are there? 4 \n",
      " E E E E . how many characters are there? 4 \n",
      " G G G G G G G G G . how many characters are there? 9 \n",
      " A A A A A A . how many characters are there? 6 \n",
      " A A A A A A A . how many characters are there? 7 \n",
      " A A A A . how many characters are there? 4 \n",
      " A A A A A . how many characters are there? 5 \n",
      " A A A A A A A A A . how many characters are there? 9 \n",
      " A A A A A A A A . how many characters are there? 8 \n",
      " E E E . how many characters are there? 3 \n",
      " G G G . how many characters are there? 3 \n",
      " G G G G G G G G G . how many characters are there? 9 \n",
      " A A A A A A A A A . how many characters are there? 9 \n",
      " D D D . how many characters are there? 3 \n",
      " A A A A . how many characters are there? 4 \n",
      " E E E . how many characters are there? 3 \n",
      " D D D D D D . how many characters are there? 6 \n",
      " D D D D D D D D . how many characters are there? 8 \n",
      " G G G G G G . how many characters are there?\n",
      " Correct: [4. 2. 3. 3. 5. 5. 5. 4. 4. 6. 6. 5. 4. 8. 6. 7. 5. 5. 6. 7.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo7_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1984,
   "id": "747b99dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " 3 4 0 5 1 6 5 3 2 . What is the positional relationship between 0 and 1? Left \n",
      " 5 1 0 3 3 5 . What is the positional relationship between 0 and 1? Right \n",
      " 4 1 6 0 2 3 6 3 . What is the positional relationship between 0 and 1? Right \n",
      " 3 6 5 1 6 0 6 6 5 . What is the positional relationship between 0 and 1? Right \n",
      " 6 4 3 6 1 0 4 3 . What is the positional relationship between 0 and 1? Right \n",
      " 5 6 0 3 1 3 . What is the positional relationship between 0 and 1? Left \n",
      " 5 5 1 3 0 3 3 6 . What is the positional relationship between 0 and 1? Right \n",
      " 2 3 0 3 4 1 . What is the positional relationship between 0 and 1? Left \n",
      " 0 4 3 5 1 4 6 . What is the positional relationship between 0 and 1? Left \n",
      " 3 1 5 4 0 5 6 3 5 . What is the positional relationship between 0 and 1? Right \n",
      " 3 0 5 3 5 1 3 4 . What is the positional relationship between 0 and 1? Left \n",
      " 5 5 0 5 1 5 . What is the positional relationship between 0 and 1? Left \n",
      " 4 0 3 1 4 6 4 6 . What is the positional relationship between 0 and 1? Left \n",
      " 0 3 1 5 5 6 . What is the positional relationship between 0 and 1? Left \n",
      " 1 3 3 0 2 2 . What is the positional relationship between 0 and 1? Right \n",
      " 6 5 6 0 4 1 4 6 2 . What is the positional relationship between 0 and 1? Left \n",
      " 2 0 1 4 4 6 4 3 3 . What is the positional relationship between 0 and 1? Left \n",
      " 1 2 0 5 5 5 2 . What is the positional relationship between 0 and 1? Right \n",
      " 4 3 1 2 0 4 3 5 4 . What is the positional relationship between 0 and 1? Right \n",
      " 0 5 6 3 1 5 2 2 . What is the positional relationship between 0 and 1? Left \n",
      " 3 3 5 1 0 3 2 2 6 . What is the positional relationship between 0 and 1?\n",
      " Correct: [5. 5. 5. 6. 6. 5. 7. 6. 8. 4. 5. 3. 8. 5. 6. 5. 5. 3. 6. 3.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo8_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1992,
   "id": "45a12995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " S S L M X R N Z . What is the third letter? L \n",
      " I P L S K T . What is the third letter? L \n",
      " X U H Z D Z . What is the third letter? H \n",
      " W E D G Z T S R K . What is the third letter? D \n",
      " L O H R Z X Z E T . What is the third letter? H \n",
      " Z O R P E Q C . What is the third letter? R \n",
      " T S I I A M B V . What is the third letter? I \n",
      " X N I O B J Y V S . What is the third letter? I \n",
      " G P M L S A E . What is the third letter? M \n",
      " R W J A Y E N F C . What is the third letter? J \n",
      " V P E V R W U I . What is the third letter? E \n",
      " V N G P M Y . What is the third letter? G \n",
      " H Z G X J P D . What is the third letter? G \n",
      " L Q T T N X R . What is the third letter? T \n",
      " C Z R E V Z . What is the third letter? R \n",
      " U L X J H O . What is the third letter? X \n",
      " R I C F O W F . What is the third letter? C \n",
      " G H W K I D U Q S . What is the third letter? W \n",
      " C Q B R Z I P . What is the third letter? B \n",
      " D Z C C V A . What is the third letter? C \n",
      " X M F K N O L . What is the third letter?\n",
      " Correct: [0. 2. 4. 6. 4. 2. 4. 5. 3. 5. 6. 5. 3. 6. 4. 7. 5. 6. 6. 5.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo9.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1993,
   "id": "442b5bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " G G D D A M A . What is the third letter? D \n",
      " E E D E G M M . What is the third letter? D \n",
      " D G G M D G E E A . What is the third letter? G \n",
      " G A A M A G . What is the third letter? A \n",
      " D G A D A E . What is the third letter? A \n",
      " M M A A A A . What is the third letter? A \n",
      " A G A D G A D G E . What is the third letter? A \n",
      " M D M D D M D A . What is the third letter? M \n",
      " E D D G E G D . What is the third letter? D \n",
      " A E A M A E M A M . What is the third letter? A \n",
      " D D D M A G M . What is the third letter? D \n",
      " G G A M A A E . What is the third letter? A \n",
      " M M M G D G M . What is the third letter? M \n",
      " M D E D A M E . What is the third letter? E \n",
      " D D M D A D . What is the third letter? M \n",
      " E M A E A A . What is the third letter? A \n",
      " M M G M D A M . What is the third letter? G \n",
      " A G E A E G M A . What is the third letter? E \n",
      " E G A E A D E G G . What is the third letter? A \n",
      " G A E G M E G E G . What is the third letter? E \n",
      " E E D A M M E D E . What is the third letter?\n",
      " Correct: [3. 1. 1. 5. 4. 2. 3. 5. 3. 6. 3. 3. 3. 2. 6. 6. 4. 3. 4. 4.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo9_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2053,
   "id": "bad5232b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " G G D D A M A . What is the third letter? D \n",
      " E E D E G M M . What is the third letter? D \n",
      " D G G M D G E E A . What is the third letter? G \n",
      " G A A M A G . What is the third letter? A \n",
      " D G A D A E . What is the third letter? A \n",
      " M M A A A A . What is the third letter? A \n",
      " A G A D G A D G E . What is the third letter? A \n",
      " M D M D D M D A . What is the third letter? M \n",
      " E D D G E G D . What is the third letter? D \n",
      " A E A M A E M A M . What is the third letter? A \n",
      " D D D M A G M . What is the third letter? D \n",
      " G G A M A A E . What is the third letter? A \n",
      " M M M G D G M . What is the third letter? M \n",
      " M D E D A M E . What is the third letter? E \n",
      " D D M D A D . What is the third letter? M \n",
      " E M A E A A . What is the third letter? A \n",
      " M M G M D A M . What is the third letter? G \n",
      " A G E A E G M A . What is the third letter? E \n",
      " E G A E A D E G G . What is the third letter? A \n",
      " G A E G M E G E G . What is the third letter? E \n",
      " E E D A M M E D E . What is the third letter?\n",
      " Correct: [3. 1. 1. 5. 4. 2. 3. 5. 3. 6. 3. 3. 3. 2. 6. 6. 4. 3. 4. 4.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo9_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1990,
   "id": "d8ee85e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " A A F D A M S A . Which one is on the right of F? D \n",
      " E M F G S S S . Which one is on the right of F? G \n",
      " A A M A M F E A . Which one is on the right of F? E \n",
      " D F A E D M G . Which one is on the right of F? A \n",
      " G M E M A D F E A . Which one is on the right of F? E \n",
      " M D F A A A . Which one is on the right of F? A \n",
      " A D D F E G S G D . Which one is on the right of F? E \n",
      " M D F M M G A E . Which one is on the right of F? M \n",
      " S F G D D G M G . Which one is on the right of F? G \n",
      " S D M G A S F D M . Which one is on the right of F? D \n",
      " G D F E A D D S G . Which one is on the right of F? E \n",
      " D F G S G M S A A . Which one is on the right of F? G \n",
      " G E M S D D F M G . Which one is on the right of F? M \n",
      " M A G G M D F M . Which one is on the right of F? M \n",
      " A S E E F M E M A . Which one is on the right of F? M \n",
      " M A F M A S M . Which one is on the right of F? M \n",
      " D M E M M F S E . Which one is on the right of F? S \n",
      " A A F D A E . Which one is on the right of F? D \n",
      " G E D D S D F E . Which one is on the right of F? E \n",
      " G S D D M F S D . Which one is on the right of F? S \n",
      " A M G F G E A D E . Which one is on the right of F?\n",
      " Correct: [2. 1. 4. 6. 3. 4. 4. 2. 7. 4. 5. 4. 3. 3. 6. 5. 4. 6. 2. 4.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo11.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1988,
   "id": "0eaad0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " S D A D F G O . What are the letters between F and O? G \n",
      " G F E O A A E . What are the letters between F and O? E \n",
      " S F S O E G G D D . What are the letters between F and O? S \n",
      " E A E M S A F E O . What are the letters between F and O? E \n",
      " D F S O D E G S . What are the letters between F and O? S \n",
      " A M G D F D O . What are the letters between F and O? D \n",
      " M E E F E O G M A . What are the letters between F and O? E \n",
      " E A M E M D F G O . What are the letters between F and O? G \n",
      " S F M O D M A . What are the letters between F and O? M \n",
      " S D M A S F A O . What are the letters between F and O? A \n",
      " E A F S O D M A M . What are the letters between F and O? S \n",
      " M G A D A F E O S . What are the letters between F and O? E \n",
      " G S G F M O E D D . What are the letters between F and O? M \n",
      " E G F D O A E . What are the letters between F and O? D \n",
      " S M D F D O D S . What are the letters between F and O? D \n",
      " A M M D F E O . What are the letters between F and O? E \n",
      " D S A S G G F E O . What are the letters between F and O? E \n",
      " G S A A F M O M . What are the letters between F and O? M \n",
      " D G F E O D G G . What are the letters between F and O? E \n",
      " E F S O D G E M A . What are the letters between F and O? S \n",
      " G G D A F E O S D . What are the letters between F and O?\n",
      " Correct: [2. 0. 2. 2. 2. 1. 4. 2. 3. 5. 3. 4. 5. 8. 4. 5. 6. 5. 7. 6.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo12_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1989,
   "id": "429a6af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的字符串是 :  Test sample: \n",
      " K R X X G O F . What is the location of F? Seventh \n",
      " O Q S F O L E Y . What is the location of F? Fourth \n",
      " H E B N M F Z . What is the location of F? Sixth \n",
      " U F O P Y L Q . What is the location of F? Second \n",
      " R K N B F Q . What is the location of F? Fifth \n",
      " V E J G F Q X . What is the location of F? Fifth \n",
      " R D H E F Q W X S . What is the location of F?\n",
      " Correct: [ 6.  6.  7.  7.  7.  8.  9.  8.  9.  9.  9.  8.  9.  9.  9.  7. 10. 10.\n",
      " 10. 10.]\n",
      " Total: 10\n"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo14_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2008,
   "id": "a240ae21",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'foo_gpt3.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2008-38b9871d68df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"foo_gpt3.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"读取的字符串是 : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 关闭打开的文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'foo_gpt3.txt'"
     ]
    }
   ],
   "source": [
    "fo = open(\"foo_gpt3.txt\", \"r+\")\n",
    "str1 = fo.read()\n",
    "print(\"读取的字符串是 : \", str1)\n",
    "# 关闭打开的文件\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1091662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
